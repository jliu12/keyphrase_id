decoupled
ep
caches
cache
ap
uniprocessors
strcpy
latency
saxpy
locality
architectures
slip
instruction
queues
zs
uniprocessor
queue
instructions
deap
processor
eod
memories
memory
execute
astronautics
livermore
interleaved
bandwidth
pipe
sensitivity
benchmarks
convolution
fetch
architecture
insensitivity
r2000
unequal
unbalance
llls
noninterleaved
operands
benchmark
traces
lawrence
fetched
cycles
correlation
decoupling
speedup
loops
processors
mips
bottleneck
tokens
access
pipelined
wm
studies
bus
spatial
streams
token
parallelism
computers
temporal
effects
load
string
cray
block
ahead
unrolling
simulation
cycle
fom
uniproc
handcoded
slow
miss
trace
exhibit
significance
simulations
fig
dae
3100
chip
sma
furnishes
contentions
decoupled architectures
the ep
the ap
memory latency
decoupled architecture
the decoupled
of decoupled
in decoupled
execute processor
a decoupled
with caches
access processor
memory access
the memory
decoupled systems
decoupled system
the execute
access time
decoupled computers
latency effects
and decoupled
zs 1
the access
uniprocessors with
the cache
temporal locality
execution time
cache based
to memory
with cache
the uniprocessor
spatial locality
data memory
ap and
data cache
address calculation
astronautics zs
access execute
the queues
without caches
read queue
lawrence livermore
main memory
and execute
data caches
memory speed
from caches
the astronautics
livermore loops
decoupled access
of memory
block size
uniprocessor with
the benchmarks
instructions are
memory bandwidth
architecture performance
caches and
locality and
sensitivity of
uniprocessors and
architectures can
saxpy unequal
cray 1
that decoupled
write queue
instruction streams
memory unit
the lawrence
strong temporal
in saxpy
the queue
cache in
a bottleneck
cache memories
bandwidth requirement
caches in
memory module
total bandwidth
access and
in fig
an access
effects in
architectures with
slow memory
and ep
memories the
performed simulations
two processors
performance advantage
a decoupled architecture
the execute processor
the decoupled system
in decoupled architectures
a data cache
the memory latency
the access processor
access and execute
of memory latency
memory access time
latency effects in
astronautics zs 1
memory latency effects
in a decoupled
effects in decoupled
to memory access
the main memory
the astronautics zs
the ap and
the read queue
memory latency and
decoupled access execute
lawrence livermore loops
benefit from caches
decoupled architectures with
effects of memory
simulation study of
the data memory
uniprocessor with cache
to memory latency
ap and ep
data cache in
of decoupled computers
decoupled architectures can
as the memory
the access and
performance of decoupled
and decoupled systems
by the execute
and decoupled architectures
by the ap
to the ep
uniprocessors and decoupled
uniprocessors with caches
and the astronautics
cache based systems
the uniprocessor with
decoupled architecture performance
caches and decoupled
the write queue
for the decoupled
cache in a
strong temporal locality
the total bandwidth
and without caches
the two processors
to complete its
in execution time
the total execution
total execution time
a simulation study
the memory access
effect of memory
demand by the
the address calculation
structured memory access
decoupled systems with
stand alone execution
time the ep
data caches in
its section of
and execute processors
do not benefit
the zs 1
study of decoupled
complete its section
of demand by
ep stand alone
the ap has
decoupled system the
ahead of demand
of decoupled systems
with cache decoupled
fine grain parallelism
the ap can
we performed simulations
the lawrence livermore
the deap architecture
associated with caches
an access processor
