multiplication
processor
multiplications
matrices
sup
elementary
matrix
cache
replication
tradeo
ik
communication
nb
kung
2d
3d
na
jk
lpram
cannon
strassen
bounds
bisection
toledo
conventional
snir
tiskin
univac
transferred
wp
asymptotically
sivan
memory
processors
misses
asymptotic
nc
loomis
berntsen
nanbnc
aggarwal
rows
2m
ij
hong
irony
live
chandra
lemma
cut
whitney
unied
memories
dror
degenerates
dag
algebra
multipli
begins
phase
tradeoff
cations
reside
geijn
multiplicands
dekel
phipac
nassimi
lblas
resides
row
constants
cuts
underlies
send
sent
blocked
mnr
ncn
power2
compulsory
watts
mul
rst
2p
replicate
slow
subroutines
summa
prams
matrix multiplication
communication lower
elementary multiplications
lower bounds
c ik
3d algorithms
for matrix
2d algorithms
multiplication algorithms
distributed memory
the processor
processor must
per processor
b jk
of communication
memory parallel
ij b
m words
elements of
the amount
local memory
i sup
conventional matrix
and kung
hong and
parallel computer
the phase
memory per
must send
communication that
of elementary
amount of
memory communication
multiplications involving
of words
words of
a ij
words that
2 elements
bounds for
must perform
the cache
parallel matrix
of c
of memory
send or
slow memory
processor distributed
least words
asymptotic notation
involving rows
conventional multiplication
strassen s
or receive
the conventional
sup 2
p processor
the matrices
a phase
exactly m
the communication
receive at
matrices on
must cross
communication across
of b
that must
cache misses
2 sup
linear algebra
g n
our bounds
at most
asymptotically optimal
lemma 2
multiplication algorithm
and snir
words must
sup words
the lpram
aggarwal chandra
chandra and
3 sup
communication tradeo
the univac
input replication
algorithms are
phase or
n matrices
lower bound
amount of communication
communication lower bounds
for matrix multiplication
matrix multiplication algorithms
bounds for matrix
the amount of
consider the conventional
ij b jk
number of words
distributed memory parallel
elements of c
a ij b
of communication that
number of elementary
memory parallel computer
lower bounds for
conventional matrix multiplication
of elementary multiplications
processor must send
hong and kung
must send or
during a phase
of words that
memory per processor
2 elements of
i sup 2
n i sup
processor distributed memory
on a p
3d algorithms are
p processor distributed
phase is at
during the phase
elementary multiplications involving
lemma 2 2
of a and
that the processor
elements of a
the lower bounds
of local memory
of memory per
a phase is
send or receive
on the amount
n matrices on
words of local
at least words
the processor must
matrices on a
words of memory
multiplications involving rows
two n n
the conventional multiplication
words that must
conventional multiplication of
receive at least
or receive at
parallel matrix multiplication
i n i
a p processor
n n matrices
n 2 elements
a distributed memory
elements of b
1 2 a
of two n
multiplication of two
at most n
least one processor
column of b
sup i p
exactly m words
the phase or
is m r
aggarwal chandra and
algorithms are asymptotically
are asymptotically optimal
one processor must
that 3d algorithms
chandra and snir
the input matrices
the conventional matrix
c is m
matrix multiplication algorithm
involving rows in
memory communication tradeo
the phase the
theorem statement holds
n 1 2
must be transferred
