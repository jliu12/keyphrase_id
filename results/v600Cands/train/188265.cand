combining
prefix
requests
interconnect
ipc
request
hot
ultracomputer
combinable
fetch
interconnection
distribute
iic
processors
processor
sophistication
latency
efj
network
yew
pic
message
bus
trip
distributing
tail
rp3
tzeng
multiprocessors
decombining
chopp
messages
alus
head
spot
memory
mimd
cache
priori
location
saved
forwarded
wait
shared
taxonomy
saturation
blelloch
appending
forward
ppc
participating
distributes
coma
nyu
participant
appended
simd
synchronization
destined
decombined
coherent
increment
unexplored
read
comparators
linked
responsibility
access
combined
fields
serial
gottlieb
lawrie
lock
multiprocessor
routes
waiting
accesses
4c
bandwidth
latencies
restrictions
modules
carry
tree
14b
hsu
heretofore
locations
nodes
goodman
critique
style
net
destination
contention
outstanding
carried
doubling
participants
combine
sent
priority
routing
11b
old
travel
addressing
topology
participate
topologies
buffer
loca
sohi
serialization
accessing
pointers
numa
channels
primitives
unconstrained
sees
cm
intentions
progress
synchronized
coherence
ibm
option
channel
multiprocessing
placed
figs
determines
alu
paradigm
dash
bandwidths
race
schemes
route
classificationscheme
iannucci
theproposed
memorylocation
partoperation
unexploredarea
aboverequirements
myampersandphi
110101
whichsystem
ofthese
membersof
thecombining
woest
lipovski
routingof
rathi
hiedelberger
efficeint
aclassification
efv
reflected
primitive
buffers
serviced
traverse
feel
scans
link
locking
omega
networks
buffered
response
list
percent
chain
nect
hep
freudenthal
norton
ina
almasi
ddm
intolerably
return
benefits
bidirectional
establishes
broadcast
directory
node
alleviate
hierarchy
hillis
von
architecture
visit
neumann
combining set
the combining
request combining
prefix operation
prefix computation
combining tree
the prefix
processor elements
fetch f
the interconnect
combined access
interconnection network
the ultracomputer
hot requests
combining requests
combining operation
software combining
of request
location x
distribute the
computation network
processor combining
to distribute
the interconnection
parallel prefix
memory location
a combining
the processors
the latency
of ipc
priori knowledge
combining can
new combining
the network
requests are
a prefix
for request
combining sets
interconnect processor
interconnect nodes
the head
the forward
sophistication of
trip through
operation on
combining in
the processor
combining network
design space
latency of
shared memory
hot spot
of requests
tail of
wait buffer
forward trip
read combining
shared location
operation is
set and
the combined
f a
to memory
arbitrary interconnection
return trip
the request
combining is
a priori
scale shared
the tail
of combining
the return
value field
a operation
ultracomputer style
old combining
and yew
combining ipc
distribute results
spot addressing
distributing hot
priority chain
interconnect combining
the memory
for hot
the hot
linked list
a fetch
requests to
head and
two messages
the sophistication
non combining
forward message
memory modules
fetch and
head of
the fetch
network nodes
is saved
requests that
distributes the
memory when
all requests
set is
are combined
two requests
the message
wait buffers
yet synchronized
combining took
if alus
x efj
combining by
x 4c
unconstrained yet
link message
where combining
hot rates
efj is
performs each
second combining
component processor
also participating
l locations
the chopp
hot request
fetch increment
combining section
varying hot
the results
distributing the
processor b
is forwarded
knowledge of
memory multiprocessors
network to
a taxonomy
same memory
participating in
the design
the list
four processors
network determines
the combinable
combining of
ibm rp3
result distribution
combining that
synchronized access
the requests
message is
the routes
forwarded to
multiprocessors with
large scale
final value
the nyu
recursive doubling
routes of
nyu ultracomputer
of sophistication
omega network
and tail
carried out
the wait
hierarchical cache
which system
for ipc
efficient synchronization
four regions
f x
in progress
to carry
destined for
final result
bus by
restrictions placed
may combine
i operation
carry out
network the
requests and
taxonomy for
hsu and
elements to
is sent
of messages
request is
set on
determines the
processors also
ipc is
general f
of memory
and distributing
saved on
a linked
the bus
saved in
the combining set
of the combining
the prefix operation
combining set and
distribute the results
of request combining
combining set is
the processor elements
prefix operation on
the combined access
the combining operation
the interconnection network
prefix computation network
prefix operation is
on the combining
fetch f x
for request combining
a priori knowledge
the combining tree
a combining set
determines the combining
operation on the
to distribute the
priori knowledge of
a prefix operation
trip through the
combining can be
the new combining
interconnect processor combining
combining set the
new combining set
memory location x
the design space
of the prefix
tail of the
the latency of
the prefix computation
sophistication of the
a prefix computation
parallel prefix computation
the tail of
in the combining
determine the combining
processor elements to
distributing the results
the forward trip
forward trip through
the fetch f
f a operation
the head and
distributes the results
the return trip
on the return
for a priori
large scale shared
of the combined
scale shared memory
of the interconnect
software combining tree
distributing hot spot
the ultracomputer style
elements to distribute
the priority chain
the hot requests
processor combining ipc
the wait buffer
forwarded to memory
to distribute results
requests are combined
establish the combining
out the prefix
determining the combining
hot spot addressing
the interconnect nodes
old combining set
combining set on
methods of request
ultracomputer style of
which a prefix
the head of
knowledge of the
on the forward
in the network
value field of
the value field
the sophistication of
through the network
to memory when
of the design
set on which
results of the
of the list
shared memory multiprocessors
head of the
to the head
of requests that
the network nodes
participating in the
of hot requests
for varying hot
combining took place
which system component
establishes the combining
varying hot rates
the combining sets
two requests are
hsu and yew
prefix computation on
combining set of
request combining in
non combining requests
where combining took
network to distribute
f x efj
request combining is
a fetch f
also participating in
a software combining
the combining network
the shared location
combining set for
latency of hot
yet synchronized access
the old combining
combining set which
list a and
the forward message
request combining that
combining set we
second combining set
interconnection network determines
implementations of request
processor elements or
request combining by
for hot requests
component processor elements
combining set are
unconstrained yet synchronized
latency to complete
with arbitrary interconnection
f i operation
request combining the
combined access the
latency of the
the latency for
the same memory
to carry out
the final value
destined for the
head and tail
is saved in
the memory location
the results of
and the tail
carry out the
network determines the
synchronized access to
the ibm rp3
general f a
interconnection network to
of all requests
the f a
on the routes
operation is in
method of combining
assume that processors
the routes of
algorithms for distributing
combining operation is
to a shared
same memory location
the final result
on which a
set and the
the nyu ultracomputer
state is saved
saved on the
list of processors
the network the
a parallel prefix
a taxonomy for
routing of messages
in the interconnect
set is determined
set of requests
the memory modules
the latency to
restrictions placed on
fields of the
to the processors
a linked list
field of the
in the combined
for the prefix
on the routing
in the priority
access to shared
waiting for the
the nodes of
of the interconnection
