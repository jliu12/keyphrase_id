proximal
differentiable
convex
convergence
differentiability
rockafellar
h2
lipschitz
zk
monotone
fz
subdifferential
newton
super
hypotheses
ppa
valued
gamma1
smoothness
operator
kd
metric
proposition
operators
hilbert
expansive
vmppa
yosida
bundle
fukushima
nonsmooth
bfgs
moreau
origin
rd
secant
psi
kz
hessian
inclusion
broyden
continuous
hypothesis
aeib
gph
regularization
dist
modulus
lipschitzian
continuity
41
limsup
semi
criteria
fh
ir
h1
zg
ib
mor
iterates
luque
dennis
quasi
resolvent
gradient
echet
propositions
establish
maximal
lemar
rademacher
ffiib
mifflin
sagastiz
domt
iusem
echal
abal
converges
updating
boundedness
characterization
hf
mini
variationelles
sufficiency
rf
nonempty
qi
neighborhood
derivative
steepest
singleton
minty
kwk
1k
zig
1976
singularity
remark
inequations
superlinear
nonlinear
fl
nondifferentiable
strongly
routine
acceleration
chen
criterion
descent
insures
lim
weak
possesses
tucker
banach
f1g
reminiscent
fff
parallels
fr
inclusions
saddle
minimization
x7
kuhn
convergent
1g
satisfied
36
rp
versatile
conjugate
classical
lemma
cluster
zkg
frf
alexandrov
fixe
x12
inverses
inequality
terminology
accelerate
attains
primal
reversal
complicates
employed
inexact
concave
article
preconditioning
oe
proximit
dualit
globalize
rib
mentable
dogleg
elliptiques
martinet
3kd
fkz
hilbertien
equivalently
imply
twice
inverse
definite
continuously
fc
gammarf
minff
cauchy
objective
ff
approximation
ball
variational
disadvantages
valuedness
subdifferentials
multifunction
paralleling
approximations
x3
linearly
rates
nonetheless
thorough
notions
subsequence
splitting
weakly
analog
regularisation
proximal point
t gamma1
variable metric
differentiable at
convex programming
point algorithm
linear convergence
metric proximal
is differentiable
super linear
z k
operator t
the operator
fz k
k z
k g
convex function
monotone operators
finite valued
the proximal
hypothesis h2
kd k
the differentiability
the subdifferential
subdifferential of
of convex
gamma1 is
smoothness hypotheses
differentiability of
lipschitz continuous
gamma1 0
convergence of
at z
global convergence
monotone operator
line search
maximal monotone
d k
the operators
single valued
function f
the origin
non expansive
matrix secant
operators n
rd z
approximation criteria
gamma1 bounded
hilbert space
sequence fz
lipschitz continuity
the super
41 theorem
moreau yosida
with modulus
t z
k k
h k
rockafellar 41
propositions 9
the vmppa
finite dimensional
z with
is lipschitz
continuous at
all k
search routine
generalized hessian
not differentiable
h2 is
w k
the inclusion
convergence results
the moreau
by rockafellar
newton like
18 20
the convergence
secant updating
weak cluster
f zg
7 ir
h2 then
41 proposition
the ppa
z gamma1
a convex
20 24
hypotheses are
f is
n k
is single
the sequence
local convergence
the convex
fh k
fl k
differentiable in
quasi newton
convergence analysis
criterion l
yosida regularization
at y
newton s
theorem 17
the method
z 2
cluster point
nonsmooth equations
establish the
f z
at w
t is
proposition 3
the variable
dimensional convex
25 36
the hilbert
point z
10 18
at 0
bounded if
the function
theorem 20
twice differentiable
f 1g
gamma1 at
convergence result
definition 4
and fukushima
singleton f
in h2
bfgs matrix
regularization f
sense at
inclusion 0
of differentiability
valued finite
zk zk
order sufficiency
vmppa is
semi smoothness
operator setting
modulus ff
or differentiable
rockafellar in
the iterates
of convergence
a neighborhood
7 10
method when
the global
w with
have hence
f gamma1
k 1
origin with
z z
semi continuous
mor e
lower semi
operator d
h1 and
solution z
criterion g
z exists
hypotheses h1
be differentiable
non singularity
rockafellar s
let fz
mini max
k we
in 41
36 in
a variable
s method
valued and
z and
z 0
and mor
space setting
dennis and
h 7
strongly monotone
lemma 21
any z
a hilbert
of super
g satisfies
linear transformations
of t
if z
second order
lemma 14
convex minimization
valued in
splitting methods
of nonsmooth
sequence fh
proximal point algorithm
super linear convergence
metric proximal point
variable metric proximal
t gamma1 is
k z k
t gamma1 0
is differentiable at
the operator t
of convex programming
fz k g
the proximal point
the variable metric
z k k
kd k z
differentiable at z
at z with
gamma1 is differentiable
the super linear
the subdifferential of
the differentiability of
subdifferential of a
differentiable at the
a variable metric
18 20 24
at the origin
gamma1 is lipschitz
operator t gamma1
the function f
operator t is
of t gamma1
convergence of the
case of convex
linear convergence of
sequence fz k
d is differentiable
the operators n
lipschitz continuous at
operators n k
a convex function
the sequence fz
of a convex
is the subdifferential
gamma1 0 is
is lipschitz continuous
2 t z
is single valued
differentiable at 0
set t gamma1
t gamma1 and
line search routine
z gamma1 bounded
3 7 10
propositions 9 and
20 24 25
7 10 18
10 18 20
n k are
at y with
for all k
a line search
the moreau yosida
the convex programming
the method when
the global convergence
bounded if and
of the proximal
fh k g
that t gamma1
matrix secant updating
24 25 36
weak cluster point
k g satisfies
are non expansive
characterization of super
establish the super
is finite valued
at w with
finite dimensional convex
a generalized hessian
newton s method
if the operator
cluster point of
moreau yosida regularization
not differentiable at
the hilbert space
linear convergence is
of super linear
z 2 gamma
and d k
in a neighborhood
a neighborhood of
the operator d
single valued and
gamma1 and d
continuous at the
that the operator
of the operators
of the method
differentiable in the
convex function f
maximal monotone operator
is not differentiable
we have hence
of the sequence
the origin with
if z 0
the line search
second order sufficiency
proposition 3 c
finite valued finite
dist 0 s
linear convergence results
the inclusion 0
s f 1g
h2 is satisfied
chen and fukushima
twice differentiable in
dimensional finite valued
monotone with modulus
a finite valued
valued finite dimensional
solving the inclusion
the approximation criteria
solution set t
by rockafellar in
finite dimensional finite
dennis and mor
continuous linear transformation
hypothesis h2 is
the vmppa is
41 theorem 2
methods in nonlinear
a singleton f
singleton f zg
rd z gamma1
h 7 ir
bfgs matrix secant
any sequence generated
with modulus ff
dimensional convex function
the operator setting
z with i
is twice differentiable
strongly monotone with
t gamma1 at
let fz k
n k z
inclusion 0 2
lower semi continuous
lipschitz continuity of
either case we
to the function
in definition 4
a hilbert space
hypotheses h1 and
hilbert space setting
y with i
of variable metric
the linear transformations
41 theorem 1
0 s k
context of convex
matrices h k
a monotone operator
convergence is established
convex programming problem
any z z
and mor e
f is twice
sequence fh k
a continuous linear
d k z
s k w
be such that
global convergence of
the solution set
k we have
point algorithm for
boundedness of the
the boundedness of
the sequence fh
to convex programming
when the operator
operator is the
k g is
the lipschitz continuity
the local convergence
in the operator
differentiable at y
global convergence result
point algorithm in
and proposition 3
be any sequence
convex function the
hilbert space h
k are non
0 2 t
at a unique
fr echet differentiable
