aaa
prefetching
prefetch
bus
misses
cache
pverify
topopt
miss
pref
vict
victim
aa
pws
invalidation
mp3d
latency0
prefetched
sharing
cpu
lpd
aaaaaa
rdex
latency
prefetches
locusroute
951
multiprocessor
mowry
850
caches
conflict
water
prefetcher
restr
shared
restructuring
restructured
compiler
exclusive
subsystem
np
wrex
multiprocessors
aaaa
invalidated
uniprocessor
progress
invalidate
workloads
utilization
speedups
contention
cycles
memory
rate
801
coherency
750
latencies
conflicts
processor
predicting
oracle
accesses
05
degradations
hit
rates
speedup
instruction
saturated
uniprocessors
kb
workload
lockup
false
bdpa
rdex_pws
traffic
cycle
traces
instructions
speeds
demand
induced
600
interconnect
emulate
associative
locality
processors
simulations
splash
execution
adjusted
simulate
architectures
effectiveness
gupta
architecture
src
million
private
invalidations
mode
strategy
dash
programmer
viable
unnecessary
architectural
throughput
utilizations
distance
normalized
pinpoint
directed
charlie
caused
access
000
transfer
620
ranged
invalidates
mr
438
references
invalidating
molecules
coverage
forgiving
saturation
cpus
locus
attack
read
bottlenecked
exacerbate
baer
hits
slowest
configuration
predictor
mapped
crummey
mellor
055
effective
bandwidth
tracing
barriers
drawbacks
hide
transaction
594
051
strategies
load
stall
wider
caching
reads
sensitive
trace
preloading
increased
eliminates
whalley
slowdowns
microarchitectures
aren
improvements
protocol
hardware
illinois
overhead
sources
bottleneck
577
599
524
400
loads
stanford
tags
hiding
kbyte
lowers
bars
superscalar
percent
five
424
targets
simulated
lookup
placement
indicative
aaa aaa
miss rate
aa aa
cpu miss
non sharing
invalidation misses
data bus
the prefetch
victim cache
prefetch in
bus latency0
of prefetching
aaa aaaaaa
aaaaaa aaa
prefetch distance
cpu misses
shared data
05 data
the cpu
bus latency
progress misses
total miss
951 05
the bus
prefetch induced
850 951
in progress
relative execution
conflict misses
execution time
a victim
exclusive prefetching
sharing misses
memory subsystem
data sharing
with prefetching
the cache
pverify topopt
no prefetching
false sharing
not prefetched
miss rates
write shared
memory latency
cache line
victim caches
prefetching strategy
prefetching for
aaaa aa
mp3d pverify
pref vict
np vict
aa aaaa
the victim
prefetching algorithm
prefetching in
of prefetch
prefetching algorithms
that prefetching
prefetching on
bus based
invalidate operations
latency0 750
bus operation
latency0 850
sharing traffic
cache prefetching
mowry et
8 cycle
a prefetch
prefetching is
bus utilization
prefetch strategy
prefetched aaa
locusroute mp3d
the pref
unnecessary invalidate
801 000
sharing miss
sharing prefetched
latency0 600
restructured programs
600 801
sharing not
bus demand
pverify and
lpd vict
prefetching can
directed prefetching
cycle data
by prefetching
750 850
prefetch algorithm
prefetching strategies
a cache
000 8
misses the
of bus
without prefetching
shared memory
the invalidation
adjusted cpu
and topopt
exclusive prefetch
induced conflict
misses in
the memory
a bus
bus speeds
induced conflicts
basic prefetching
shared mode
mowry and
to no
8 data
data prefetching
transfer latency
of prefetches
and gupta
prefetching more
of cpu
prefetching the
compiler algorithm
a compiler
prefetched prefetch
water pverify
the rdex
np pref
prefetch access
aaa non
rdex pws
prefetched invalidated
prefetch misses
invalidated prefetched
programmer directed
and pws
five workloads
vict pref
topopt relative
misses we
prefetching and
the miss
based multiprocessor
compiler directed
for prefetching
to np
compiler based
data restructuring
invalidated not
of invalidation
mp3d water
the restructured
prefetching we
normalized to
prefetching has
processor locality
memory architecture
high memory
time relative
the adjusted
in shared
direct mapped
prefetching with
al 23
memory latencies
associative cache
victim caching
src data
pref restr
in exclusive
misses represent
bus operations
32 cycles
over np
aa aaa
the wrex
prefetching invalidation
for pverify
prefetch accesses
8 line
predicting invalidation
miss predictor
predicting non
misses that
an exclusive
processor utilization
an 8
workloads with
data transfer
of cache
based prefetching
the data
cache in
cache coherency
based shared
pref and
line victim
cycle bus
speedups with
a shared
aaa aaa aaa
cpu miss rate
prefetch in progress
data bus latency0
the cpu miss
aa aa aa
aaa aaaaaa aaa
aaaaaa aaa aaa
951 05 data
05 data bus
total miss rate
relative execution time
in progress misses
850 951 05
data bus latency
a victim cache
aaa aaa aaaaaa
non sharing misses
of the cpu
the total miss
the victim cache
to no prefetching
the prefetch in
aa aaaa aa
the prefetch distance
bus latency0 850
bus latency0 750
of cpu misses
latency0 750 850
latency0 850 951
mowry et al
the memory subsystem
750 850 951
000 8 data
801 000 8
8 data bus
aa aa aaaa
not prefetched aaa
write shared data
latency0 600 801
non sharing prefetched
8 cycle data
non sharing not
prefetched aaa aaa
bus latency0 600
sharing not prefetched
600 801 000
effectiveness of prefetching
in the cache
the adjusted cpu
with a victim
relative to no
an exclusive prefetch
prefetch induced conflicts
adjusted cpu miss
aaaa aa aa
time relative execution
miss rate the
prefetch induced conflict
prefetching on a
compiler directed prefetching
of prefetching in
mowry and gupta
data transfer latency
a bus based
a cache line
execution time relative
bus based multiprocessor
miss rate and
pverify topopt relative
invalidated not prefetched
locusroute mp3d water
unnecessary invalidate operations
the prefetch induced
mp3d pverify topopt
normalized to np
aaa non sharing
of prefetch induced
aaa aaa non
five workloads with
mp3d water pverify
topopt relative execution
prefetched invalidated not
sources of cpu
pverify and topopt
water pverify topopt
the invalidation misses
prefetched prefetch in
invalidated prefetched prefetch
caused by prefetching
the five workloads
sharing prefetched invalidated
increasing the prefetch
number of prefetch
miss rate is
the data sharing
on a shared
et al 23
prefetching can be
predicting non sharing
an 8 cycle
prefetching invalidation misses
cpu misses in
an 8 line
sharing miss rate
miss rate are
np vict pref
cycle data bus
range of bus
predicting invalidation misses
execution times relative
8 line victim
of memory architectures
data sharing problem
problem of unnecessary
the non sharing
shared data restructuring
of unnecessary invalidate
line victim cache
cpu miss rates
in exclusive mode
vict pref vict
the 8 cycle
execution time figure
of shared data
a compiler algorithm
bus based multiprocessors
high memory latency
without prefetching the
the data bus
prefetching we can
prefetch distance to
load on the
a shared memory
for the five
prefetching more effective
times relative to
range of memory
on the bus
of the applications
architectural and compiler
of prefetching on
of prefetching is
bus utilization is
split transaction bus
of the prefetch
the miss rate
the effectiveness of
shared memory multiprocessors
the load on
misses caused by
replaced in the
of the drawbacks
the bus is
execution time for
the prefetched data
on a bus
total execution time
in shared memory
miss rate for
for the 8
of data sharing
with victim caches
restructuring shared data
data sharing traffic
prefetched aa aa
the 32 cycle
prefetching strategies to
invalidation misses the
for processor locality
cache prefetching on
np pref np
not prefetched aa
with the pref
use of exclusive
and topopt with
wrex prefetching strategy
aaa invalidated prefetched
the long prefetch
uniprocessors and multiprocessors
the bus demand
problem of prefetch
cache in exclusive
the write shared
combined height of
the lpd strategy
of prefetch in
for pverify and
sensitivity to memory
based shared data
pref vict lpd
additional conflict misses
pref and pws
progress number of
the cpu misses
compiler based shared
the prefetch access
transfer latency the
pref np vict
and gupta 22
