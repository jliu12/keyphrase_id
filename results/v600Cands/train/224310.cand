iwarp
lap
cm
gigabit
90
hippi
nectar
bandwidth
fem
elapsed
4k
ana1
testbed
ana
sec
cray
chemical
psc
pipelining
heterogeneous
stochastic
sparse
gen
solver
matching
network
dense
mb
sonet
paragon
supercomputer
phase
incidence
ts
alpha
dhsc
pittsburgh
cmu
nodes
steenkiste
sustainable
throughput
dt
generation
plant
transfer
bw
testbeds
statistical
distributing
uncertainty
supercomputing
hemy
dhsc_write
cf132c
npasses
checksumming
outboard
apost
read_data
bottleneck
sensitivity
materials
32k
communications
mbyte
unweighted
nrows
initialization
bipartite
format
indices
bursts
stream
streams
burst
production
assignment
percent
communication
mimd
raw
matrix
samples
thinking
neuroscience
mpp
inversely
execution
pipeline
overlapped
pipelined
speed
conversion
manifold
atm
sends
dedicated
sent
suited
metropolitan
campus
idle
kbyte
networks
t3d
resources
bayesian
rpc
versus
sustained
pvm
64
floating
expertise
requirements
hide
locates
deployment
intel
center
slowest
multicomputer
simd
bandwidths
transferred
workstations
estimated
serial
1k
across
host
datalink
initialmatching
1512128iwarp
gbs
mummert
mahdavi
tsrange
8919038
01250
cnri
0251
4an
measurements
traffic
national
weighted
tradeoff
primal
lab
cpu
link
km
tasks
machines
architecture
agency
spawar
cm2
jamshid
mcrae
1540
intensive
phases
int
insignificant
buffering
inference
converted
utilization
influences
256
runs
mode
n00039
initiatives
industry
assignments
subsystem
augmenting
optimization
dod
warfare
nsec
1024
impact
conceptualization
climate
connecting
peter
seconds
latencies
matroids
766
predicts
planning
networking
transmit
terminal
c 90
cm 2
the lap
the cm
the iwarp
network bandwidth
the c
lap solution
initial matching
cost matrix
iwarp nodes
lap solver
the application
data generation
execution time
size 4k
nectar testbed
performance model
mb sec
2 nodes
linear assignment
the nectar
elapsed time
of iwarp
iwarp and
on iwarp
reduced cost
analysis phase
chemical process
the dense
of pipelining
generation and
optimization application
sparse approach
stochastic lap
iwarp system
nodes bandwidth
the sparse
the network
assignment problem
bandwidth time
90 for
and cm
90 and
bandwidth mb
process optimization
lap problem
4k as
heterogeneous computing
and analysis
of cm
90 cm
the pittsburgh
the generation
application performance
a gigabit
sec for
high speed
ana on
lap application
phase size
of elapsed
pittsburgh supercomputer
plant data
iwarp c
t dt
solution phase
estimated execution
on c
running on
communication requirements
the stochastic
problem size
by communications
gigabit network
element indices
dense method
application across
n ts
sec and
90 the
the data
dense approach
supercomputer center
elapsed times
the execution
phase of
90 using
time sec
testbed the
on cm
90 is
distributed computing
the elapsed
cray c
the sustainable
nectar gigabit
probability manifold
lap initial
initial reduced
fem running
gigabit testbed
raw materials
statistical reduction
sustainable network
intel iwarp
lap on
atm sonet
the hippi
a hippi
iwarp to
90 where
hippi based
2 lap
lap size
and iwarp
lap initialization
phase figure
weighted matching
the distributed
incidence matrix
the model
sparse method
4k the
production data
of nodes
zero element
dedicated mode
a chemical
at cmu
traffic models
samples n
peter steenkiste
cost data
bound by
application was
distributed memory
to cm
testbed is
model analysis
application components
systems connected
stochastic linear
for distributed
bandwidth requirements
bandwidth is
dense and
overall application
time phase
percent of
speed networks
network performance
the statistical
and sparse
thinking machines
application and
90 to
file server
degree of
of 4k
bipartite matching
the zero
bayesian inference
sensitivity to
pipelining in
the systems
of network
solver phase
fem on
66 node
computing operations
existing separately
application depend
pittsburgh supercomputing
matrix transferred
ana1 cf132c
center psc
alpha file
transfer requirements
matrix unweighted
model ana
nodes cm
developed application
generation computations
neuroscience application
michael hemy
ana1 dhsc_write
2 idle
p iwarp
cray floating
the gigabit
sparse transfer
sample generation
solver initialization
computing gigabit
separately developed
26 km
90 npasses
int lap
lap the
the c 90
the cm 2
on the c
of the application
generation and analysis
cm 2 nodes
and analysis phase
on c 90
reduced cost matrix
the network bandwidth
for the lap
c 90 and
on the cm
the data generation
and cm 2
to the c
c 90 for
degree of pipelining
linear assignment problem
of cm 2
the lap solver
to c 90
nodes bandwidth time
the lap solution
number of cm
90 for the
the execution time
mb sec and
network bandwidth mb
chemical process optimization
time sec for
size 4k as
process optimization application
number of iwarp
c 90 cm
c 90 the
of iwarp nodes
cm 2 is
data generation and
4k as a
of the lap
the sparse approach
application performance model
90 cm 2
bandwidth mb sec
the generation and
cm 2 and
execution time sec
phase of the
estimated execution time
at the pittsburgh
bound by communications
of elapsed time
on the iwarp
iwarp c 90
in the lap
the dense approach
the nectar testbed
90 and cm
lap solution phase
c 90 is
zero element indices
phase size 4k
the initial matching
pittsburgh supercomputer center
the stochastic lap
percent of elapsed
on cm 2
2 nodes bandwidth
the iwarp and
network bandwidth is
the dense method
cm 2 to
c 90 using
number of nodes
the reduced cost
for distributed memory
dense and sparse
cray c 90
for the stochastic
network bandwidth and
impact of network
as a function
suited for the
nectar gigabit testbed
ana on c
the pittsburgh supercomputer
solution phase of
iwarp to c
initial reduced cost
c 90 to
time phase figure
to cm 2
and c 90
fem running on
the zero elements
the sustainable network
the nectar gigabit
cm 2 was
90 using the
approach the cm
lap initial matching
lap on cm
the lap problem
c 90 where
bandwidth time phase
stochastic linear assignment
the intel iwarp
nectar testbed the
a chemical process
cost matrix to
execution time of
running on the
use the model
distributed memory systems
connected by the
and the c
bandwidth and the
a function of
the cost matrix
systems connected by
cm 2 the
of pipelining in
the weighted matching
the sparse method
to the cm
size of 4k
overall application performance
problem size of
to the network
requirements of the
analysis phase of
sent as a
2 to c
architecture and applications
high speed networks
mapping of the
the communication requirements
performance model of
for the dense
indices for the
the application was
a performance model
of the cm
the number of
well suited for
in the pipeline
the model to
and the number
for the initial
the application we
function of the
communications versus effective
c 90 t
sec for lap
interface architecture for
2 network bandwidth
predicts an execution
cm 2 computes
sparse incidence matrix
data generation bottleneck
the iwarp is
supercomputer center psc
matching portion of
lap solver running
sizes lap size
t dt fem
the overall application
sustainable network bandwidth
lap running on
the different systems
output c 90
lower data transfer
sample means are
the lap application
for lap solver
by communications versus
90 t dt
samples n ts
lap solver initialization
gigabit i o
npasses n nrows
based distributed supercomputing
the simulated plant
cm 2 with
at constructing the
o for distributed
1024 iwarp nodes
networking subsystem for
initial matching model
256 iwarp nodes
a is inversely
solver phase size
matrix unweighted bipartite
90 which then
100 mb sec
occurred for repeated
area network man
computing operations are
cm 2 idle
