prefetching
prefetch
cache
prefetched
rpt
prefetches
aaaa
stride
fetch
miss
fetched
instruction
memory
referencing
processor
instructions
multiprocessors
tagged
stream
strides
issued
pollution
hardware
loop
multiprocessor
block
array
misses
obl
ld
blocks
engine
compiler
latency
demand
sequential
caches
buffers
locality
references
policy
referenced
gornish
rac
accesses
unnecessary
microprocessor
prediction
baer
buffer
tag
initiated
hierarchies
steady
pa7200
patterns
dram
word
dahlgren
evicted
pc
replacement
cached
specfp95
access
reference
fetches
overhead
pd
memories
prefetcher
mechanisms
initiating
placed
brought
spatial
latencies
patel
lockup
bandwidth
palacharla
kessler
addresses
directives
strided
secondary
register
shared
requests
scalar
mowry
spectable
weidong
stenstr
turnoff
nproc
benefit
effective
accessed
schemes
iteration
benchmark
processors
hierarchy
transient
stalled
uniprocessors
irregular
powerpc
epilog
compile
hit
initiates
chen
utilization
sigarch
contention
tentative
superscalar
hp
lilja
comparatively
policies
displaced
kenneth
diverse
tolerating
chip
lookahead
hide
software
coherence
necessitated
kadayif
polluting
stalls
ross
speeding
looping
timely
requested
hirzel
binding
seattle
transfers
prolog
entries
stall
anticipates
interconnection
caching
opportunities
ismail
hsin
entry
fetching
counter
sharing
bus
preloading
t3e
exceptions
r2
fu
mechanism
microarchitectures
address
strategies
load
despite
loops
vectorized
hsien
speedups
architecture
11b
shi
news
loads
programmable
iterations
traffic
programs
displace
bodies
tend
mahmut
ratios
blocking
dsm
initiate
programmer
prematurely
predictable
registers
kandemir
2b
cycles
primary
spill
the prefetch
the rpt
aaaa aaaa
data prefetching
prefetching in
the cache
software prefetching
a prefetch
sequential prefetching
demand fetched
the processor
prefetched data
fetch instructions
prefetch engine
prefetch on
fetched prefetched
cache blocks
prefetched block
prefetching is
referencing patterns
cache block
cache miss
on miss
block b
of prefetching
prefetched demand
hardware prefetching
main memory
cache pollution
stream buffers
a cache
prefetch distance
prefetching for
prefetch address
tagged prefetch
prefetching techniques
unnecessary prefetches
be prefetched
prefetches are
processor cache
no prefetching
previous address
prefetched prefetched
the memory
from main
fetch instruction
prefetching was
spatial locality
instruction overhead
prefetching schemes
prefetch is
memory system
memory multiprocessors
data prefetch
access patterns
the prefetched
prefetching mechanisms
prefetch efficiency
dram performance
prefetch mechanisms
are prefetched
shared memory
memory access
the loop
with memory
memory hierarchies
prefetch mechanism
prefetches for
in shared
benchmark programs
main loop
average memory
memory latencies
explicit fetch
rpt prefetching
tagged prefetching
vector prefetching
tag previous
stride state
rpt is
prefetches will
address stride
prefetching opportunities
pd field
array referencing
is prefetched
that prefetches
in multiprocessors
brought into
memory latency
000 0
a fetch
prefetched in
of cache
based prefetching
cache utilization
primary cache
prefetching on
memory instruction
software controlled
prefetch hardware
prefetch operations
stride information
demand fetch
prefetching the
large cache
array references
the fetch
prefetching can
local memory
a prefetched
cache replacement
memory accesses
memory requests
be effective
and patel
stream buffer
and baer
hardware data
prefetching strategies
prefetching scheme
cache misses
cache memories
actual use
and dram
prefetch of
reference prediction
of spatial
memory bandwidth
hardware based
prefetch cache
general applications
reference stream
the block
cache and
fu and
issued for
prefetch for
access pattern
programmable prefetch
vector references
fetch policy
ld b
place prefetched
la pc
k 20
rpt entry
stride array
the rac
prefetch case
rpt entries
product calculation
referencing pattern
looping structures
between microprocessor
ld c
infer prefetching
six benchmark
are issued
program counter
processor systems
prefetching has
initiating a
in multiprocessor
effective address
block is
memory reference
loop iteration
a stride
the reference
on memory
the prefetching
found that
large stride
prefetch strategy
prefetched blocks
j 30
multiprocessor applications
ld a
adaptive prefetching
predict when
prefetch policy
large strides
register space
issued too
are diverse
overlapping computation
memory fetch
state ld
word cache
for for
multiprocessor systems
memory multiprocessor
latency of
advance of
run time
miss ratios
proposed which
b 1
data from
aaaa aaaa aaaa
demand fetched prefetched
prefetch on miss
prefetched demand fetched
into the cache
in the cache
a cache miss
the memory system
from main memory
fetched prefetched demand
by the processor
shared memory multiprocessors
the processor cache
the prefetch on
in shared memory
of spatial locality
a data prefetch
in a cache
data prefetching in
prefetching in shared
block b 1
the prefetch distance
for block b
of the rpt
address stride state
prefetch is issued
and dram performance
the prefetch engine
tag previous address
a prefetched block
prefetched data in
previous address stride
single processor systems
fu and patel
the rpt is
the main loop
sequential prefetching in
reference prediction table
memory access patterns
hardware data prefetching
chen and baer
prefetching techniques have
the prefetch is
data prefetching on
advance of the
be prefetched in
given in figure
can be prefetched
prefetching on the
been proposed which
the cache block
as cache pollution
degree of prefetching
prefetched data are
array referencing patterns
six benchmark programs
10 000 0
computation with memory
k j 30
when the prefetch
between microprocessor and
programmable prefetch engine
gap between microprocessor
with large strides
that prefetches are
ld b i
dram performance has
initiates a prefetch
ld c k
i j 10
000 0 initial
place prefetched data
to the rpt
prefetching schemes are
state ld b
i k 20
average memory latency
ld a i
stride state ld
the tagged prefetch
data from main
as with software
in single processor
with memory accesses
by overlapping computation
prefetching in multiprocessors
fetched prefetched prefetched
j 10 000
the memory hierarchy
to be effective
in advance of
brought into the
load or store
be effective in
the stream buffers
main memory into
the prefetched block
a processor register
overlapping computation with
with software prefetching
cache pollution and
the reference prediction
implemented in such
a prefetch distance
adaptive sequential prefetching
actual memory reference
latency of main
if the prefetch
poor cache utilization
a cache block
a prefetch for
stream buffers as
palacharla and kessler
block has been
large cache blocks
for for for
prefetching in multiprocessor
a secondary cache
kenneth a ross
one loop iteration
the previous address
data prefetching has
a prefetch of
the use of
into the primary
into a processor
proceedings of the
of main memory
the actual memory
block b is
block into the
software prefetching in
based prefetching for
buffers as a
cache block size
memory system in
b i k
the entire array
prefetching in a
cache miss to
the addition of
c k j
with memory hierarchies
main memory access
to the cache
to make room
make room for
to the processor
by the program
into the buffer
to the memory
in multiprocessor systems
the hp pa
in the memory
requested by the
was found that
in figure 2a
computer architecture news
acm sigarch computer
architecture news v
sigarch computer architecture
issued by the
specfp95 benchmark programs
over tagged prefetching
the prefetch destination
shi hsien hsin
no prefetching the
predict when a
diverse and no
prefetched prefetched demand
prefetched data will
cache line turnoff
memory accesses prefetching
stall cycles prefetching
data prefetching techniques
performance has necessitated
and unit stride
fetch data prefetching
weidong shi hsien
the prefetch hardware
benefit of prefetching
the lookahead program
provides optimal performance
on miss policy
hardware based stride
a no prefetching
infer prefetching opportunities
cache blocks may
effectiveness of hardware
the prefetch efficiency
use of increasingly
useful and introduce
misses and issues
word cache blocks
a prefetch address
data prefetching anticipates
prefetching must be
connected via pointers
hit rates the
the six benchmark
