preemption
cache
rmb
rmbs
gen
lmb
preempted
preemptions
schedulability
refill
blocks
block
lmbs
task
response
priority
worst
delay
tasks
wcet
instruction
preemptive
referenced
mapped
memory
cfg
references
associative
scheduler
caches
queue
pc
interference
pessimistic
reference
reload
preempting
invocations
null
timing
cycles
reloading
scheduling
wcets
lud
yudong
fft
marginal
fir
costs
deadline
r3000
utilization
excepting
sang
caching
scenario
lms
resumes
fm
rectify
minsuk
lyul
orst
oldout
flow
replaces
timer
vii
reaching
mooney
busquets
mataix
tomiyama
staschulat
automation
kandemir
monotonic
hiroyuki
r3010
gun
cacheable
predicted
codesign
europe
lru
kolcu
schedulable
unpredictable
explained
iv
tighter
reside
vincent
pays
prediction
invocation
execution
interrupt
hardware
beginnings
lee
embedded
conservatively
safe
smart
anupam
beginning
unpredictability
nikil
predictions
partitions
risc
tan
rolf
dutt
viii
policy
visit
priorities
inter
miss
schema
chong
sram
notices
dram
ernst
predecessor
organization
kill
conscious
sigplan
th
incoming
placed
replaced
live
displaced
strategic
schedulers
chang
firdata
joosun
21034
kwangpo
time200000a
sungpack
seongsoo
hoonsang
10416
mpsocs
nakashima
wcrt
nakada
rhan
sheayun
j2hp
strner
katcher
usefulness
mc
interrupts
assess
periods
outgoing
pacific
complicate
highest
period
estimation
iterative
na
idt7rs383
terference
2231
basumallick
doolittle
hemendra
sungjoo
halambi
sidharth
3392
iii
board
asia
disabled
explain
deriving
filter
replacement
accounting
incorporating
0t
lehoczky
time0
abhik
processings
fpa
roychoudhury
gen c
cache related
related preemption
preemption cost
preemption delay
cache blocks
cache block
memory block
useful cache
case response
rmb c
the cache
block c
memory blocks
response time
basic block
worst case
out b
of preemptions
of cache
cache set
cache memory
task set
if gen
the worst
case preemption
the preemption
c b
schedulability analysis
c out
cache refill
refill time
of useful
lmb c
execution point
cost table
block b
to cache
preempted task
during r
the rmbs
in b
the task
last reference
proposed technique
preemption costs
r k
real time
task interference
per task
task analysis
set associative
preemptions 1
rmbs of
delay queue
of tasks
blocks at
priority task
case cache
block whose
each task
preemption scenario
point p
c in
reference to
each cache
is preempted
analysis technique
block that
priority tasks
rmbs at
set gen
and rmb
marginal preemption
block references
set c
direct mapped
a task
of task
the proposed
run queue
inter task
pc i
a preempted
preemptions of
fixed priority
instruction cache
first reference
time systems
re referenced
pessimistic assumption
g j
each basic
linear programming
lmbs at
th marginal
f gen
the lmb
response times
in basic
in cache
blocks in
higher priority
1 cost
j l
the memory
c at
associative cache
c i
at point
task 3
data flow
mapped to
b is
the wcet
machine cycles
total cache
a memory
integer linear
references from
wcet estimate
pc 3
rmbs and
lmb problem
computing rmbs
the lmbs
and lmb
block in
the scheduler
beginning and
r i
b out
data cache
task j
useful at
task replaces
largest preemption
a preempting
preempted and
block m
task preemption
cache reloading
preempting task
blocks mapped
replaces from
programming problem
timing analysis
explained in
a cache
task is
invocations of
block used
task resumes
cache partitioning
the cfg
rate monotonic
programming technique
time equation
blocks c
flow analysis
store instruction
utilization bound
task i
the references
previous approaches
cache organization
basic blocks
of preemption
block can
the delay
blocks of
at p
associative caches
of invocations
computing systems
case visit
extended timing
initially focus
of rmbs
the rmb
element rmb
sets rmb
timing schema
and lmbs
into schedulability
schema approach
reaching memory
b excepting
task pays
not null
highest priority
task from
cost f
of i
for set
way set
target machine
the beginning
data caching
of pc
cache related preemption
related preemption delay
worst case response
gen c b
cache block c
useful cache blocks
case response time
of useful cache
the worst case
c in b
basic block b
c out b
cache set c
if gen c
worst case preemption
the preemption cost
the cache related
number of useful
preemption cost table
cache refill time
rmb c out
cache blocks at
rmb c in
per task analysis
g j l
the memory block
the cache refill
the proposed technique
c b is
block c i
a memory block
memory block that
number of preemptions
case cache related
of preemptions 1
preemptions 1 cost
to cache set
to cache block
worst case cache
the task set
response time of
each cache block
memory block whose
pc i r
mapped to cache
the delay queue
of cache related
in basic block
related preemption cost
the basic block
at point p
last reference to
data cache memory
memory block references
marginal preemption cost
c if gen
and rmb c
b if gen
gen c if
inter task interference
of cache blocks
the last reference
real time systems
in the cache
each basic block
case preemption scenario
task is preempted
by a preempted
a preempted task
refill time is
higher priority tasks
set associative cache
of the worst
the run queue
in b and
the set gen
set gen c
th marginal preemption
memory blocks of
f gen c
the rmbs of
cache blocks in
linear programming problem
during r i
useful cache block
block c at
preemption delay of
case preemption cost
of preemptions of
reference to c
the cache block
integer linear programming
of cache block
highest priority task
the beginning and
beginning and end
first reference to
linear programming technique
r k i
b is the
for set associative
of a task
during r k
related preemption costs
and lmb c
1 cost f
a per task
b and rmb
memory block m
the lmb problem
b out b
the total cache
pc 3 r
reference to cache
rmbs at the
memory blocks mapped
cache blocks c
preemption cost at
at other points
the rmbs at
blocks mapped to
the first reference
to c in
load store instruction
preemption delay in
each execution point
case of direct
the useful cache
that each cache
preemption cost is
response time equation
of pc i
a useful cache
execution point p
total cache related
block used by
schedulability analysis technique
instruction cache memory
largest preemption cost
set c at
case response times
preempting task replaces
task replaces from
by a preempting
a preempting task
of task 3
replaces from the
preemption cost that
reference in b
cache a memory
cache block used
data flow analysis
is the memory
the rate monotonic
from the cache
block that is
block can be
cache block in
task set t
of invocations of
estimation of cache
set associative caches
a cache block
data flow problem
the memory blocks
i r k
number of invocations
and end of
at the point
the maximum number
of each task
c b if
times of tasks
is the last
can be computed
used by a
maximum number of
cache blocks are
is not null
response times of
a basic block
of direct mapped
for each basic
time the task
cost the task
machine cycles in
gen c out
distinct memory blocks
rmbs of cache
lmb c in
rmbs and lmbs
initially focus on
reference to memory
excepting the references
this integer linear
rmbs of c
lmbs at the
sets rmb c
gives a prediction
worst case visit
