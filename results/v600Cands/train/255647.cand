pursuer
learning
game
ga
games
nn
lazy
evasion
reinforcement
evasive
pursuers
genetic
maneuvers
evader
grefenstette
gll
pursuit
players
payoff
differential
editing
teacher
actions
nearest
reward
pedestrian
action
robot
evades
fitness
evade
agent
plan
training
car
neighbor
chauffeur
success
player
tesauro
atkeson
learner
homicidal
smoke
watkins
learn
000
barto
salzberg
p1
1992
play
escape
backgammon
eager
samuel
1990
gle
playing
teaching
train
angle
database
population
strength
bootstrapping
plateau
markov
sheppard
widrow
clouse
1989
delayed
curvature
sutton
agents
isaacs
rules
task
p2
chess
strategies
edited
fired
utgoff
classifier
neighbors
planning
tasks
ramsey
plans
aha
temporal
learned
radius
wilson
markovian
outperformed
ritter
teach
othello
metagamer
devijver
colombetti
simulator
rewards
1963
bad
1993
stored
td
prioritized
decision
torras
ase
dorigo
tomek
millan
averaging
wins
speeds
sweeping
bearing
rule
90
difficulty
ace
gammon
mutation
neural
stores
parking
maze
maneuvering
competition
achieving
generations
sharply
chromosome
opponents
poor
attributes
percent
1991
holland
abilities
successful
fuel
mccallum
littman
alone
matcher
moore
remained
began
striking
credit
escaping
threshold
learns
700
storing
connectionist
cart
speed
1983
perfect
randomly
consisted
goals
1994
shaping
trials
classifying
pruning
comparator
heading
turns
rl
goldberg
navigate
strategy
1987
climbing
1975
aircraft
pole
1988
gordon
tolerating
strategic
maximally
facing
sensing
gas
sequential
olsder
noncooperative
imado
basar
k nn
the ga
q learning
lazy learning
the game
two pursuer
one pursuer
evasive maneuvers
differential games
reinforcement learning
000 games
a lazy
differential game
genetic algorithm
the evasive
two pursuers
pursuer task
state action
learning to
pursuer game
nearest neighbor
the evader
the pursuer
k nearest
the players
lazy learner
grefenstette et
turn angle
pursuit games
pursuit game
the pedestrian
a game
temporal difference
learning algorithms
action pairs
the car
genetic algorithms
of examples
maneuvers task
delayed reinforcement
pursuer problem
games in
a ga
good examples
control tasks
nn and
games the
a genetic
the genetic
games one
single pursuer
lazy q
lazy approach
lazy methods
markov decision
game we
difference learning
p1 and
game theory
to play
control problems
nn s
nn on
the database
a plan
of differential
ga to
5 000
bad examples
of curvature
nearest neighbors
game is
the homicidal
percent success
the pursuers
that fired
random games
nn for
chauffeur game
ga was
traditional lazy
90 success
pursuer two
homicidal chauffeur
game the
based learning
the payoff
either method
optimal strategies
the state
sequential decision
to evade
learning s
learning algorithm
to train
examples in
car the
nn to
games and
the lazy
to learn
learning for
perfect performance
ga we
ga and
learning approach
the simulator
state space
strategies for
continuous state
of lazy
and p2
the task
example set
robot to
an agent
of actions
train a
examples stored
stored state
barto et
generated games
isaacs 1963
maneuvers game
salzberg 1993
successful evasion
evader e
player pursuit
plan fitness
rule strength
eager learning
complete game
pursuers figure
20 state
game e
learning after
reinforcement problems
it reached
for evasive
prioritized sweeping
pursuer evader
e evades
multi agent
of learning
for lazy
the editing
radius of
decision problems
success rate
to escape
game in
storing examples
to reinforcement
optimal play
payoff function
20 time
action pair
utgoff 1992
correct action
helpful teacher
s performance
the learning
instance based
algorithms to
performance of
the actions
in differential
watkins 1989
classifier systems
000 examples
two player
the pursuit
game that
credit assignment
for k
of q
learn to
learning methods
with lazy
in instance
game as
a pursuit
a helpful
game playing
a reinforcement
tesauro 1992
al 1990
a robot
better than
each example
reward for
these games
a teacher
near perfect
each plan
optimal strategy
a differential
states and
learning and
car and
the two pursuer
the evasive maneuvers
for k nn
of the game
two pursuer task
grefenstette et al
for the ga
of q learning
k nn and
state action pairs
the genetic algorithm
evasive maneuvers task
5 000 games
of k nn
the one pursuer
performance of k
a genetic algorithm
temporal difference learning
differential game theory
lazy learning approach
two pursuer game
a lazy learner
to k nn
k nn s
k nn on
lazy q learning
than the ga
radius of curvature
set of examples
k nearest neighbors
number of examples
markov decision problems
one pursuer two
a lazy learning
homicidal chauffeur game
for lazy learning
pursuer two pursuers
k nn for
lazy learning to
that k nn
the homicidal chauffeur
the ga was
k nn to
q learning s
in the game
k nearest neighbor
of the players
a differential game
with k nn
q learning to
optimal strategies for
of lazy learning
on the two
p1 and p2
to train a
of the car
of the ga
instance based learning
in the database
for evasive maneuvers
the evader e
two pursuers figure
lazy learning methods
pursuer game we
two pursuer problem
in instance based
and k nn
the ga to
000 games and
and the evader
the ga we
the single pursuer
20 time steps
20 state action
delayed reinforcement problems
state action pair
examples to k
learning s performance
of examples stored
randomly generated games
player pursuit games
and the pedestrian
barto et al
evasive maneuvers game
a lazy approach
with lazy learning
and two player
a pursuit game
approaches to reinforcement
000 games the
games one pursuer
near perfect performance
game where e
p1 and p
two player pursuit
nn for the
storing examples in
k nn is
examples in the
the state space
the car and
a helpful teacher
the correct action
the car the
car and the
in the ga
the optimal strategies
and q learning
in differential games
which an agent
to reinforcement learning
a robot to
the example set
perform well on
et al 1990
on one and
one and two
sequential decision making
the k nearest
our experiments demonstrate
of a game
learning for the
threshold was set
on its own
better than the
the ability of
work together to
performance on the
performed better than
genetic algorithms in
in the early
the results of
to determine the
set of actions
strategies for the
the best performance
nn on its
jump start a
a lazy version
the ga learned
standard q learning
to perform sequential
learning the task
cart and pole
lazy learning algorithm
see sheppard salzberg
that lazy methods
q learning after
some state action
two pursuer evasion
two lazy methods
the pedestrian the
reinforcement learning can
the actual reward
of perceptual aliasing
the ga and
class of differential
many bad examples
e is facing
either method could
that genetic algorithms
success stored games
genetic algorithm can
maze like environments
classifier systems and
training agents to
evader pursuer pursuer
one pursuer task
to robot path
pursuers p1 and
either method alone
using simulation models
continued to improve
to play differential
game is a
on the evader
pursuer task is
by grefenstette et
by the players
a sample game
problems widrow 1987
3 000 games
large continuous state
ramsey and grefenstette
success rate on
nn and q
models and competition
games as the
neighbor k nn
after 50 000
approach stores complete
to teach a
finding in non
exceeding the ga
turn angle at
the game then
learning approach had
k nn alone
of differential game
with one pursuer
