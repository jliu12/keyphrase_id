annealing
partitioning
mesh
processors
remote
retrofit
elem
metis
processor
sdsc
heterogeneities
labarre
anl
meshes
subdomains
whams2d
vbns
simulated
partitions
speedup
inviscid
irregular
communication
heterogeneity
sp
barth4
chaco
14971
18369
viscous
0s
multilevel
efficiency
groups
advisory
stripe
group
barth5
6928
spiral
subdomain
partition
consideration
ibm
stripes
superlinear
globus
squares
sps
perf
client
8s
execution
domdec
ecomm
argonne
bisection
markov
temperature
entails
moves
legion
vulcan
network
variance
cr
supercomputers
proc
metric
deltae
cl
2s
7s
load
equalize
5s
decomposer
11451
6s
zhiling
partitioned
meshing
geographically
supercomputer
cut
sc1
ctc
nexus
sc2
comm
networked
interconnection
np
asynchronous
samr
rsb
valerie
message
cornell
regular
disconnected
chain
exchange
partitioners
restriction
9s
p3
placement
2p
machines
plastic
rcm
balanced
ideal
seed
fiedler
comp
homogeneous
kernighan
workstations
testbed
coarsening
spectral
inertial
unstructured
neighboring
subtasks
server
conventional
interface
unequal
bryan
networks
located
cell
sp2
68
slowest
sparse
trapped
gains
multiprocessors
disjoint
serial
resources
graphs
quality
elastic
redistribution
considers
sites
perfect
minimized
gusto
partitions2060100140
36percent
nour
sightly
gammastripes
3082
dongman
127kb
ibmsps
kyungmin
rcb
partitions1030507090barth4
3974
whams3d
46
weighted
288
communicate
materials
greg
parallelize
macro
100
balancing
percent
solver
88
speed
omid
rib
sparspak
3982
osaka
portional
4273
interconnect
intensive
speculative
sized
proven
2n
vertices
backtracking
sequential
mechanics
recursive
remote communication
simulated annealing
mesh partitioning
execution time
network performance
efficiency 0
local communication
processor performance
distributed system
parallel simulated
finite element
partitioning for
cost function
parallel part
multiple markov
at anl
distributed systems
of part
into consideration
and remote
in efficiency
annealing is
for distributed
irregular meshes
efficiency when
heterogeneities in
of squares
local and
communication time
partitioning problem
minimum sum
of processors
processors in
part w
chain approach
retrofit step
even partitioning
client processors
at sdsc
the execution
parallel version
heterogeneity in
as compared
each group
superlinear speedup
a group
the parallel
one processor
ibm sp
labarre 14971
viscous 18369
interface program
advisory system
anl and
18369 elem
the retrofit
14971 elem
the vbns
the mesh
remote and
when processor
mesh based
in execution
communication graph
partitioning the
in network
to partition
processors that
the groups
irregular graphs
ideal reduction
computational load
4 at
regular problems
processor i
cell placement
inviscid 6928
barth5 inviscid
inviscid labarre
the heterogeneities
called part
two ibm
labarre spiral
proc perf
sp machines
stripe partitioning
spiral viscous
exchange solutions
part speedup
annealing program
the whams2d
a distributed
regular meshes
the communication
increase in
the distributed
the application
comparison metric
performance must
cut set
part is
graph partitioning
performance is
for partitioning
markov chain
processor and
3 efficiency
perfect speedup
partitions from
20 at
processor with
the regular
only processor
variance in
part takes
the partitioning
the irregular
based applications
into 8
partitioning process
time resulting
element types
and network
application and
in group
each processor
computational complexity
into 2p
meshes into
used globus
two supercomputers
minimum interface
barth4 barth5
metis efficiency
the advisory
problem indicate
g processors
top domdec
6928 elem
o restriction
mesh part
perf metis
approximately local
whams2d application
multilevel k
restriction proc
w restriction
sdsc mesh
ibm sps
consideration heterogeneity
server processor
sp vulcan
called whams2d
explicit nonlinear
restriction part
message start
proposed recursive
vulcan switch
vbns on
considers heterogeneities
indicate up
0s 3
only local
different partitions
and local
partition problem
sequential execution
the meshes
a processor
communication the
speedup for
the difference
reduction in
element mesh
for homogeneous
the partitions
communication cost
nonlinear finite
performance into
partitioning tool
homogeneous systems
switch ff
small cut
part uses
each temperature
problems indicate
100 subdomains
parallel moves
to metis
sum of
element method
groups in
np complete
of groups
indicate a
8 at
the asynchronous
p processors
way partitioning
disjoint k
and remote communication
increase in efficiency
for distributed systems
mesh partitioning for
local and remote
parallel simulated annealing
the execution time
simulated annealing is
in efficiency when
problem for distributed
in network performance
version of part
partitioning for distributed
considered as compared
performance is considered
sum of squares
the cost function
multiple markov chain
a distributed system
reduction in execution
minimum sum of
in a group
as compared to
parallel version of
processor and network
network performance is
markov chain approach
remote and local
efficiency when processor
number of processors
and network performance
the distributed system
in execution time
heterogeneity in network
only local communication
heterogeneities in the
the retrofit step
mesh based applications
viscous 18369 elem
the regular problems
labarre 14971 elem
processors in a
the parallel version
and local communication
partitioning problem for
on a distributed
execution time is
inviscid labarre spiral
only processor performance
variance in network
labarre spiral viscous
barth5 inviscid labarre
remote communication in
4 at anl
the multiple markov
simulated annealing program
cut set size
3 efficiency 0
even partitioning the
remote communication the
ibm sp machines
used for sequential
parallel part speedup
compared to even
execution time resulting
to even partitioning
at anl and
ideal reduction in
of parallel simulated
mesh partitioning problem
the heterogeneities in
the communication time
the application and
of processors in
only one processor
performance must be
the ideal reduction
with only local
annealing is used
the parallel part
partition problem for
time resulting from
from the irregular
all the groups
part is used
taking into consideration
used to partition
a processor with
the partitioning process
of simulated annealing
for sequential execution
distributed systems is
in each group
is the execution
the network performance
graph partitioning problem
with local and
application and the
on one processor
one processor in
takes into consideration
of groups in
distributed system the
the simulated annealing
execution time using
communication time for
part takes into
annealing is computationally
restriction proc perf
using the vbns
restriction part w
part is that
the irregular problem
performance are considered
system the heterogeneities
into consideration heterogeneity
meshes into 8
the advisory system
perf metis efficiency
8 processors 4
cases and nearly
k way partitioning
nearly perfect speedup
considers heterogeneities in
processors 4 at
superlinear speedup in
vulcan switch ff
speedup in most
cr and cl
network performance must
partitioning for homogeneous
we used globus
proc perf metis
indicate up to
scheme for irregular
explicit nonlinear finite
performance into consideration
way partitioning scheme
sp vulcan switch
o restriction proc
mesh part w
distributed systems these
network performance the
of different partitions
partitions from part
an explicit nonlinear
the vbns on
when processor and
regular problems indicate
barth4 barth5 inviscid
inviscid 6928 elem
problems indicate a
multilevel k way
when processor performance
w o restriction
is approximately local
partitioned into 2p
w restriction part
sdsc mesh part
systems the novel
the whams2d application
at sdsc mesh
irregular meshes into
small cut set
for homogeneous systems
two ibm sps
part w o
part w restriction
irregular problem indicate
and small cut
when network performance
message start up
for irregular graphs
interface program and
balance the execution
consideration heterogeneity in
local communication is
compared to metis
efficiency when network
the finite element
finite element mesh
is considered as
finite element method
cost function is
perfect speedup for
estimate of execution
network performance are
n theta 2n
processor with only
and nearly perfect
to table 8
partitioning the results
time on processor
distributed system consisting
the mesh partitioning
groups in the
i 2 a
for a processor
a i 2
number of groups
