cache
switch
flits
caches
crossbar
4w
arbitration
requests
caesar
snoop
read
fwa
numa
caching
interconnect
header
reply
request
flit
replies
cavallino
remote
sharing
cc
gs
organization
link
bmin
hit
buffer
associativity
invalidation
spider
wr
directory
invalidations
switches
ri
buffers
cycles
coherence
shared
multiprocessors
mm
module
sor
residence
switching
readreply
swc
arbiter
processors
fft
block
sram
bus
memory
attainable
sc
200mhz
access
processor
rsim
hits
fo4
coherent
routing
ge
home
locality
cycle
latency
requester
4kb
l2
transmission
bytes
served
associative
interconnection
wormhole
bidirectional
sgi
accesses
network
reads
message
latencies
byte
multiprocessor
stall
chip
gauss
impact
multistage
stage
invalidated
headers
tag
core
replacements
backward
protocol
128x128
l1
marked
ownership
channels
delay
temporal
registers
evictions
requestor
messages
enter
bits
dirty
tremendously
cached
miss
virtual
misses
nc
destination
stages
outputs
incorporating
bank
interleaved
qwhu
32bytes
duulydo
fohv
6bits
4bits
sharer
inputs
serviced
sensitivity
banks
employ
incoming
scalable
base
16kb
ported
transmitted
width
transmit
medium
8kb
rbe
7lph
st0
intel
addr
owner
64
10b
organizing
blocks
min
msi
sharers
10a
interconnects
queue
throughput
sp2
transmitter
employing
traverse
cacti
warshall
arbitrated
st1
employs
1kb
banked
cedar
eviction
2kb
blocking
128kb
six
embedded
amplifiers
bit
simulator
node
exemplar
serving
bar
invalidate
links
maintain
benefits
queues
router
freq
switch cache
the switch
switch caches
the cache
input block
crossbar switch
4w 4w
cc numa
cache size
of switch
read sharing
network caches
cache module
ri buffer
cache line
read requests
the arbitration
global cache
access time
sharing degree
remote memory
the interconnect
cache access
the snoop
the ri
read request
a switch
arbitration cycle
the caesar
arbitration dependent
the reply
snoop operation
arbitration independent
switching elements
block input
the read
the header
caching technique
crossbar switches
the remote
base system
memory access
cache the
dependent organization
residence time
switch core
link transmission
the wr
home node
set associativity
cache organization
numa multiprocessors
a cache
the crossbar
link inputs
wr buffers
cache embedded
cache interconnect
forward link
link outputs
incoming flits
marked read
cache processing
memory reads
size on
4 cycles
virtual channels
the switching
the bmin
global caching
read header
read transactions
set associative
shared memory
execution time
cache in
of cache
the caching
requests and
data flits
cache to
snoop registers
attainable sharing
embedded switch
reply unit
sgi spider
independent organization
wr buffer
read replies
intel cavallino
swc hit
caesar switch
fwa gs
average read
read latency
caches in
gs and
the network
cache we
maximum of
the directory
network cache
the residence
bidirectional min
associativity on
sram cache
on switch
six applications
access performance
the flit
sor and
line size
theta 8
byte cache
cache is
and ge
subsequent requests
stall time
8 theta
cache hits
caches we
switch architecture
flits of
requests can
organization is
and coherence
a maximum
find that
temporal read
the attainable
each arbitration
cache within
each switching
output width
cavallino 5
as sc
switching element
caches along
read shared
switches such
the fwa
cache output
mm application
interconnect medium
caching protocol
way set
destination memory
remote access
impact of
the sgi
we find
application performance
the requests
the cc
the stage
the base
interconnection network
the memory
access latencies
the mm
2 way
request is
full map
area model
small caches
flit from
shared data
of cc
the processor
the figure
the home
processor cache
memory module
served at
cache lines
temporal locality
the request
organization figure
coherence messages
the block
of shared
the impact
same block
memory multiprocessors
and replies
block is
of requests
small fast
read misses
trace analysis
hit miss
4 switch
line x
cache design
caching scheme
high as
parallel with
requests are
enter the
chip caches
the switch cache
in the switch
a switch cache
the ri buffer
4w 4w 4w
of switch caches
switch cache module
input block input
block input block
the base system
switch cache the
crossbar switch cache
cache size on
the remote memory
to the switch
the cache line
the global cache
the snoop operation
the switching elements
arbitration dependent organization
of the switch
cc numa multiprocessors
a maximum of
of cache size
cache access time
remote memory access
switch cache interconnect
byte cache lines
switch cache hits
of the caesar
switch cache we
of switch cache
switch cache organization
from the ri
switch cache performance
of memory reads
the crossbar switch
of the cache
impact of cache
8 theta 8
in the interconnect
from the switch
embedded switch architecture
on switch cache
fwa gs and
the arbitration dependent
arbitration independent organization
the cc numa
marked read request
the residence time
cache embedded switch
switch cache processing
performance of cc
switch cache access
the caesar switch
we find that
the home node
in the cache
of cc numa
home node and
to the processor
the cache size
memory access latencies
the destination memory
the remote access
of the interconnect
way set associative
cache in a
arbitration cycle a
cache line x
the mm application
each arbitration cycle
the arbitration independent
switch cache to
switches such as
use of switch
sharing degree of
the reply unit
sor and fft
each switching element
encoded as sc
the wr buffers
the wr buffer
the caching protocol
cycle a maximum
gs and ge
switch caches along
the sgi spider
switch cache size
maximum of 4
caesar switch cache
a global cache
the intel cavallino
switch caches in
the interconnect medium
organization is based
attainable sharing degree
average read latency
shown in figure
shared memory multiprocessors
size on the
parallel with the
maximum of four
access performance of
with virtual channels
the six applications
64 byte cache
to the same
as the cache
the impact of
the same block
a crossbar switch
through the switch
served at the
into the switch
cache line size
number of memory
as high as
2 way set
on the switch
access time in
requests and replies
in parallel with
from different processors
in the system
requests to the
the cache access
data flits of
the stage close
f mm figure
design issues such
a cache embedded
axis denotes the
high as 20
outputs backward input
the interconnect we
read sharing locality
the snoop registers
the caching technique
improve the remote
a fwa b
the average read
switch cache in
read sharing degree
switch cache is
switch architecture caesar
get satisfied in
a marked read
the read header
switch cache needs
link inputs backward
switch cache and
the fwa application
switch cache hit
check the switch
that switch caches
the internal switch
c gauss d
fft f mm
forward link inputs
read requests are
number of evictions
4 switch cache
crossbar switch operation
for the fwa
and ge applications
intel cavallino 5
backward link inputs
such as spider
switch cache since
to the snoop
e fft f
read request this
temporal read sharing
memory access performance
stage close to
in the bmin
swc hit bit
forward link outputs
switching elements of
4 cycles of
link outputs backward
theta 8 crossbar
inputs backward link
full map directory
switch cache framework
the switch caches
called switch cache
by as high
link inputs forward
attainable read sharing
backward input block
inputs forward link
link outputs link
remote access performance
the attainable sharing
process incoming flits
set associativity on
outputs link outputs
buffer to a
