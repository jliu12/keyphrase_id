mofn
knn
antecedents
neural
rules
promoter
knns
training
extracted
trained
monks
extraction
kbann
linus
rule
dna
learning
minus35
networks
links
bias
1991
symbolic
towell
comprehensibility
nucleotides
backpropagation
activation
monk
conformation
splice
minus35d
comprehensible
antecedent
nakano
saito
1990
junction
c4
learn
extracting
nucleotide
population
weight
refinement
fuzzy
noordewier
extract
weights
jacket
ourston
extracts
units
datasets
promoters
minus10
network
biological
connectionist
weighted
smiling
exon
intron
setiono
link
overfitting
superior
hinton
summed
activations
hidden
corruptions
fidelity
theories
rudy
negated
intelligible
minus35b
neurally
clusters
revision
quinlan
world
minus
anns
clustering
fu
shape
thrun
mining
yes
mooney
1988
nt
subsets
unable
goldsmith
mozer
judy
accuracy
1989
smolensky
conjunctive
sloan
concept
empirical
cluster
biases
sword
superiority
1987
groups
consequents
consequent
classify
knowledge
came
rumelhart
reproduce
approximately
sites
round
feedforward
interpretable
polymerase
kijsirikul
gyrgy
kokol
minus35a
bochereau
hawley
berenji
witold
pedrycz
boonserm
artificial
holding
recognition
tests
classifying
pruning
unit
incoming
testing
domain
dataset
meanings
ceiling
superfluous
correctly
statistically
dzeroski
octagon
lavrac
bourgine
nowlan
mcclure
protein
zhi
coli
koudelka
daunting
3190
tt
oxford
propositional
overly
subsumed
seven
gene
elimination
disjunction
shifts
intelligence
understandability
gentle
exceed
teaching
ten
trials
color
1956
fermat
rna
expert
shifting
combinatorics
ann
equivalence
head
shavlik
negatively
abilities
1986
tie
hua
shift
suggestion
inputs
interpretability
rule extraction
the mofn
extracted rules
neural networks
the knn
mofn method
rules from
the rules
rules extracted
domain theory
from trained
of mofn
rule sets
by mofn
rule refinement
mofn algorithm
of antecedents
trained knns
of rules
the extracted
the rule
extracted by
neural network
monks problem
mofn rules
approximately here
rule set
training examples
the bias
a knn
splice junction
trained networks
mofn and
the network
weighted links
the networks
promoter recognition
shape round
the training
during training
the promoter
rules are
extract rules
by subset
subset algorithms
the monks
link weights
networks from
our mofn
monks problems
trained neural
and subset
c4 5
subset algorithm
towell et
extracting rules
al 1991
then monk
body shape
that mofn
fu 1991
symbolic rule
rules and
training set
a neural
rules that
real world
initial rules
from neural
fuzzy rules
symbolic knowledge
head shape
dna sequence
which they
learn the
individual rules
antecedents in
negated antecedents
mofn is
mofn s
for promoter
second monks
entire population
nakano 1988
sets extracted
figure approximately
mofn are
minus35d 37
37 t
saito and
and nakano
jacket color
of extracted
al 1990
a rule
machine learning
from which
extraction methods
our rule
fi p
m of
neural learning
superior to
world problems
n style
to subset
whose summed
the activation
knowledge based
based neural
second problem
the comprehensibility
theory revision
knowledge base
rules to
to learn
et al
hidden units
symbolic methods
knn and
all symbolic
testing examples
comprehensibility of
to extract
minus35 37
have activations
antecedents that
positive subset
minus 35
mofn the
style concepts
weighted antecedents
noordewier et
antecedents for
mooney 1990
ourston mooney
bias optimization
junction determination
knn was
promoter domain
first monks
correctly classify
subset are
the splice
for extracting
seen during
a trained
domain theories
bias on
these rules
were extracted
they came
reference point
rules in
the antecedents
h sloan
symbolic rules
towell 1991
standard neural
rudy setiono
conjunctive rules
the unit
or t
a unit
or g
color red
s rules
knn is
from networks
are extracted
each unit
applied intelligence
at classifying
robert h
non input
empirical tests
data mining
rules can
input features
dna sequences
accuracy of
the symbolic
extraction method
refinement methods
to correctly
equivalence classes
of training
output unit
trained using
sequence analysis
unit in
rules for
in knns
yes holding
summed weight
neurally based
minus 10
input unit
negative subsets
sword jacket
the extracted rules
the mofn method
rules from trained
from which they
rules extracted by
networks from which
the rules extracted
the networks from
m of n
number of antecedents
the mofn algorithm
the monks problems
towell et al
et al 1991
extracting rules from
from trained neural
mofn and subset
extract rules from
extracted by mofn
the rule extraction
rule extraction methods
of extracted rules
that the mofn
to extract rules
extracted by subset
of our rule
rules from neural
our rule extraction
from trained knns
from neural networks
extracted rules are
set of rules
et al 1990
for promoter recognition
trained neural networks
the initial rules
symbolic rule refinement
sets extracted by
the second monks
the bias on
figure approximately here
they were extracted
by mofn are
of n style
saito and nakano
the entire population
mofn method is
by the mofn
of the mofn
to rule extraction
second monks problem
rule sets extracted
a neural network
knowledge based neural
based neural networks
real world problems
the second problem
for extracting rules
seen during training
which they came
the splice junction
the comprehensibility of
sets of rules
of the rules
unable to learn
they are extracted
to learn the
which they were
the knn was
our mofn algorithm
body shape round
splice junction determination
robert h sloan
of rules from
in the knn
the promoter domain
rule refinement methods
learn the second
mofn s rules
u theta l
head shape round
the first monks
n style concepts
network from which
up to fi
fuzzy rules from
extraction of rules
superiority of mofn
first monks problem
jacket color red
extracted rules and
noordewier et al
rule extraction method
ourston mooney 1990
of the network
rule set is
the reference point
on the training
into a neural
not seen during
rules extracted from
the accuracy of
rules can be
bias on the
while the rules
hidden and output
of table 9
applied intelligence v
the training examples
comprehensibility of the
using neural networks
to the rules
the rule sets
the training set
of the extracted
accuracy of the
the network from
neural networks to
method is able
superior to the
as a neural
promoter recognition the
reproduce the behavior
whose summed weights
symbolic rules from
non input unit
if head shape
the symbolic methods
from symbolic to
judy goldsmith robert
rule extraction algorithm
or superior to
in the promoter
our subset algorithm
thrun et al
for rule extraction
number of extracted
or g or
of the knn
the mofn rules
has tie yes
a knn is
extracted rules to
initial rule sets
rules from networks
a subset algorithm
red has tie
to fi p
attempts to extract
into neural networks
round smiling yes
method for shifting
sword jacket color
goldsmith robert h
a trained knn
links whose summed
examples not seen
color red has
exceeds the bias
shape round smiling
the promoter problem
a or g
of antecedents in
to be comprehensible
holding sword jacket
and output unit
our mofn method
yes holding sword
the unit s
exceed the bias
at classifying testing
returned by mofn
and body shape
or c or
intelligence v 11
subset and mofn
negatively weighted links
testing methodology for
each hidden and
corruptions of the
that mofn rules
and nakano 1988
initial domain theory
this tests for
rules produced by
unit s bias
round body shape
extraction method in
of empirical tests
the knn and
rule set size
rule extraction is
g or t
input unit in
and testing methodology
the correct theory
of head shape
classifying testing examples
in trained networks
shape round body
