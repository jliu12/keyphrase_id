featuremine
mining
winnow
features
feature
classification
classifiers
sequences
classifier
bayes
subsequence
irrelevant
sequential
accuracy
domains
redundant
ith
produced
predictive
min
attributes
exponentially
primitives
scalable
selection
classification algorithms
features produced
feature set
frequent sequences
class c
feature f
pruning rules
training examples
data mining
value pairs
naive bayes
feature mining
featuremine algorithm
min freq
pruning rule
classification accuracy
boolean features
sequential domains
f 1
features for
produced by
d d
standard classification
spelling correction
mining techniques
selecting features
execution traces
sequence mining
class label
exponentially large
decision lists
max l
sequence data
mining algorithm
potential features
betting sequences
sequential features
improve classification
feature sets
features is
training data
new examples
boolean feature
possible features
frequent sequence
redundant features
sensitive spelling
classification performance
mining for
mining algorithms
feature selection
sequential data
large space
class labels
training set
selection criteria
context sensitive
non distinctive
efficiently search
integrates pruning
sequence classifier
features produced by
produced by featuremine
feature value pairs
wwwwww wwwwww wwwwww
feature f i
data mining techniques
number of features
examples in d
test examples and
standard classification algorithms
criteria for selecting
mining techniques to
sequences as features
context sensitive spelling
sensitive spelling correction
features should be
space of all
features that are
data mining algorithms
set of examples
web usage data
evidence for different
scalable and disk
simulation the fire
intersecting the idlists
mining algorithm itself
different features to
sequence data the
selection criteria for
feature set f
frequent sequences as
plan execution traces
irrelevant features for
features of length
algorithm itself instead
primitives for describing
reduce classification accuracy
pruning rule described
two pruning rules
classify new examples
different min freq
post processing step
y3 time8 ignite
selecting features to
classification algorithms furthermore
present criteria for
first pruning rule
frequent and distinctive
frequent for class
scalable feature mining
large feature sets
significantly correlated with
value pairs for
use data mining
belonging to class
irrelevant or redundant
user specified min
