supernode
supernodes
hyperplanes
tiling
transformation
partitioning
loops
communication
hyperplane
processor
nested
iteration
loop
message
grouping
comp
hyper
dencies
rectangular
mapped
uniform
minimizing
dependencies
supernode size
supernode transformation
total running
grain size
optimal supernode
linear schedule
index space
running time
optimal grain
length vector
side lengths
supernode index
iteration index
relative side
supernode shape
dependence matrix
supernode relative
dependence vectors
different supernode
parameter model
relative length
parameter communication
optimal linear
one parameter
partitioning hyperplanes
supernode sizes
size and
two parameter
supernode transformations
schedule vector
optimal relative
size g
computation phases
parallelepiped supernode
communication model
communication time
communication phases
nested loops
side length
startup penalty
transformation h
matrix h
matrix d
vector r
closed form
supernode partitioning
one supernode
square supernode
communication startup
communication cost
g o
r g
bounded loop
n partitioning
nonlinear program
supernode grain
lengths of
memory parallel
communication phase
iteration space
consider algorithm
transformed algorithm
optimal shape
supernode side
hyperplane matrix
dimensional algorithm
convex cone
constant bounded
space j
distributed memory
single processor
form expression
transformation with
computation time
loop nests
scheduling length
independent supernodes
components depend
affine function
normal vectors
nested loop
real positive
startup time
sotiropoulos georgios
athanasaki aristidis
parallelepiped supernodes
tsoukalas nectarios
athanasaki nectarios
uniform dependence
extreme vectors
constant communication
algorithm problems
total running time
optimal grain size
optimal supernode size
size and shape
iteration index space
grain size and
supernode size and
optimal linear schedule
parameter communication model
relative length vector
running time is
supernode index space
side length vector
amount of data
find the optimal
side lengths of
transformation h r
data to be
relative side length
supernode transformation h
length vector r
different supernode sizes
one parameter model
optimal relative length
parameter model with
length vector is
grain size g
one parameter communication
communication cost is
find an optimal
linear schedule vector
communication startup cost
relative side lengths
matrix d s
dependence matrix d
index space and
supernode relative side
supernode transformation is
supernode size for
distributed memory parallel
number of communication
problem of finding
square supernode shape
two parameter model
two parameter communication
two supernode transformations
lengths of a
supernode index set
constant bounded loop
startup penalty and
j s is
dependence vectors in
discusses how to
model with constant
supernode is a
optimal supernode shape
computation phases and
optimal supernode relative
supernode transformation with
closed form expression
finding an optimal
form expression for
number of phases
expression for the
memory parallel computer
processor in a
shape of a
linear schedule wave
model communication cost
supernode transformation applied
square containing four
bounded loop iteration
shape the total
supernode grain size
schedule wave fronts
affine function of
supernode size changes
components of dependence
parameter model and
size g and
components depend on
changes lemma 3
supernode shape or
algorithm in example
also provided for
n partitioning hyperplanes
supernode size is
communication time t
dependences 12 such
constant communication time
supernode the supernode
supernode relative length
partitioning hyperplanes to
