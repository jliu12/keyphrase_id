seller
sellers
price
pricing
shopbot
agent
prices
learning
agents
opponent
war
reward
economies
simultaneous
convergence
economic
stationary
reinforcement
instantaneous
approximators
profitability
markov
competing
deterministic
observable
infeasible
competitive
simultaneously
realistic
seller 1
seller 2
simultaneous q
discount parameter
price war
profit functions
price wars
shopbot model
quality model
agent q
expected profit
learning in
agent economies
information filtering
parameter fl
two sellers
pricing policies
cyclic price
price pair
myopic opponent
immediate reward
expected reward
take turns
time step
state space
filtering model
current price
setting prices
action pair
alternately take
exact convergence
pricing algorithms
approximate convergence
indicates baseline
economic models
learning is
lookup tables
state s
learning by
reinforcement learning
high prices
derived policies
deterministic policy
cumulative profit
future rewards
derived policy
stationary environment
self consistently
two seller
defined order
optimal pricing
unending cyclic
instantaneous profits
expected profits
sellers alternately
optimal policies
function approximators
fully observable
competing sellers
term consequences
pricing policy
war regime
self consistent
theoretical guarantees
also found
three models
convergence to
software agents
history dependent
nash equilibrium
two competing
p 1
lookup table
full knowledge
optimal policy
simultaneous q learning
myopic vs myopic
price quality model
agent q learning
tesauro and kephart
discount parameter fl
q derived price
cyclic price wars
information filtering model
learning in the
q functions and
alternately take turns
derived price curves
vs discount parameter
functions and policies
model a average
state action pair
profit for both
average profit per
sairamesh and kephart
values of fl
well defined order
solid diamonds and
price wars when
model myopic vs
expected profit for
parameter fl dashed
term consequences of
sellers alternately take
hanson and sairamesh
price war regime
longer term consequences
sandholm and crites
line indicates baseline
kephart hanson and
q derived policy
good approximate convergence
lack of theoretical
agent s current
q derived policies
information filtering and
diamonds vs discount
diamonds and seller
2 open diamonds
1 solid diamonds
myopic optimal price
open diamonds vs
unending cyclic price
adjusting their prices
multi agent systems
despite the lack
dashed line indicates
full knowledge of
small values of
plot of the
price of approximately
profit landscape for
turns setting prices
discount parameter in
current q function
symmetric solution in
vs myopic pricing
basis of price
prices in a
price dynamics trajectory
current price pair
non stationary environment
step lookahead calculation
two player alternating
state space transitions
stationary environment for
myopic 2 average
whether such solutions
vs myopic expected
