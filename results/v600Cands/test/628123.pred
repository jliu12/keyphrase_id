constituents
constituent
parse
sentence
connectionist
corpus
sentences
parsing
parser
generalise
synchrony
generalisations
learning
generalisation
syntactic
article
recurrent
structural
network
systematicity
outputting
linguistic
occurring
grammatical
learn
statistical
networks
representations
structured
ability
incremental
train
language
linguistically
output
english
architectures
across
naturally
holistic
temporal
hebbian
architecture
net
experiments
mechanism
hierarchical
pulsing units
occurring text
time period
pulsing input
parse tree
naturally occurring
natural language
structural relationships
output units
synchrony networks
simple synchrony
language learning
pulsing unit
noun phrase
corpus of
input units
o n
child relationships
structural constituents
precision recall
term memory
generalise across
pulsing inputs
basic ssn
tsvb networks
ssn architectures
structured output
syntactic parsing
output activation
output representations
trainingepochs percentagecorrect
ssn architecture
generalisation ability
connectionist network
current word
one constituent
sentences drawn
output unit
connectionist architecture
generalise over
correct constituents
ssn parser
words fit
statistical parsers
constituent structure
stm mechanism
standard connectionist
temporal synchrony
susanne corpus
sibling output
noun phrases
connectionist language
distributed representation
input unit
learning to
output representation
syntactic structures
corpus used
output the
connectionist networks
fit together
statistical language
simple recurrent
parse trees
structure representing
grandparent parent
pulsing pulsing
generalise in
synchrony variable
parsing natural
form constituents
language parsing
standard task
naturally occurring text
non pulsing units
simple synchrony networks
corpus of naturally
pulsing input units
short term memory
parent child relationships
ability to generalise
number of words
learning to parse
average precision recall
number of constituents
child relationships between
sentences drawn from
synchrony networks ssns
set of constituents
non pulsing unit
learn to parse
basic ssn architecture
structure representing how
words fit together
non pulsing input
hierarchical structure representing
allows the ssn
fit together to
connectionist language learning
precision and recall
statistical language learning
discussed below we
drawn from a
together to form
period and phase
networks ssns for
generalise over constituents
parsing natural language
natural language parsing
synchrony variable binding
parent of constituent
across structural constituents
pulsing units in
current word tag
parent child relationship
english sentences drawn
output activation of
average sentence length
2 structural relationships
sequence of input
occurring text this
shows the activation
representing how those
ssn architecture to
phases to represent
term memory stm
temporal synchrony variable
experiments discussed below
input output representation
architecture to linear
pattern for symbol
occurring text the
ssns for learning
receive the pattern
non pulsing pulsing
structured output representations
ssn s performance
presented to the
association for computational
parsing of natural
syntactic parsing of
context free grammars
natural language sentences
introduced to the
