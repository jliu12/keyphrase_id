multiplication
processor
multiplications
matrices
matrix
replication
communication
bounds
conventional
memory
processors
multipli
mul
subroutine
multiply
ma
matri
computers
matrix multiplication
communication lower
elementary multiplications
lower bounds
c ik
3d algorithms
2d algorithms
multiplication algorithms
distributed memory
processor must
per processor
b jk
memory parallel
ij b
m words
local memory
conventional matrix
parallel computer
memory per
must send
communication that
amount of
memory communication
multiplications involving
bounds for
must perform
parallel matrix
processor distributed
asymptotic notation
conventional multiplication
p processor
exactly m
must cross
communication across
cache misses
asymptotically optimal
lemma 2
multiplication algorithm
words must
aggarwal chandra
communication tradeo
input replication
n matrices
lower bound
sivan toledo
input matrices
theorem statement
bounds also
phase begins
local memories
computation begins
one processor
multiplication and
multipli cations
words per
output combining
alexander tiskin
communication necessary
dror irony
concrete constants
algorithms must
2p 2
capacity cache
argument shows
n n
bulk synchronous
element c
f n
communication network
another processor
amount of communication
communication lower bounds
matrix multiplication algorithms
bounds for matrix
consider the conventional
ij b jk
number of words
distributed memory parallel
elements of c
number of elementary
memory parallel computer
lower bounds for
conventional matrix multiplication
processor must send
hong and kung
must send or
memory per processor
processor distributed memory
3d algorithms are
p processor distributed
phase is at
elementary multiplications involving
elements of a
send or receive
words of local
words of memory
multiplications involving rows
words that must
conventional multiplication of
receive at least
parallel matrix multiplication
elements of b
multiplication of two
least one processor
column of b
exactly m words
aggarwal chandra and
algorithms are asymptotically
one processor must
matrix multiplication algorithm
memory communication tradeo
theorem statement holds
must be transferred
amount of memory
matrix multiplication and
matrix multiplication on
bounds the number
row of a
state and prove
lower bounds on
words that are
lower bounds in
sent and received
communication e cient
2d algorithms are
strassen s algorithm
multiplication algorithms must
element c ik
dror irony sivan
loomis whitney inequality
algorithms must perform
m words are
irony sivan toledo
computer where each
sivan toledo and
processor at least
asymptotically optimal for
communication lower bound
words per processor
communication that must
communication per processor
cannon s algorithm
toledo and alexander
discrete loomis whitney
data that must
c ik of
capacity cache misses
reside in the
end of the
required to store
argument shows that
parallel computer where
cache the number
matrix multiplication is
bulk synchronous parallel
one word of
