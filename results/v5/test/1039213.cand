ele
game
player
games
agent
payo
equilibrium
learning
payos
agents
nash
players
pareto
reward
prole
monitoring
adversary
policy
reinforcement
payments
irrational
imperfect
maximin
rewards
economically
stochastic
action
normative
punishment
cient
actions
rationality
joint
played
play
g2
g1
deviate
perfect
attain
repeated
rational
folk
multiagent
deviates
mix
ai
equilibria
mixing
denition
punish
theorists
bowling
cooperative
converge
descriptive
convergence
defect
histories
plays
rg
veloso
economics
bayesian
stick
cooperate
policies
deviation
resp
prescribed
shneidman
parkes
xed
polynomial
ciently
whom
ciency
probabilistic
social
stipulates
monetary
settings
spirit
surplus
playing
payoff
history
strategies
payment
adopt
articial
rst
knows
adopted
modied
maximizes
dened
shot
justied
strategic
quickly
dierent
stationary
behave
economic
online
outcome
response
matrix
individually
initially
max
jeffrey
mixed
dierences
people
motivation
attained
unknown
covergent
deviators
conitzer
rby
thuc
unplayed
irrationality
deviator
enforceable
knowng
noncooperative
vorobeychik
fassumed
awesome
deviating
tuomas
polynominal
satinder
punishing
ramications
osprings
groves
undiscounted
iterations
paid
complements
interactions
technically
67
dynamics
themselves
associates
learns
visit
learn
adopting
existence
appealing
yevgeniy
boella
conver
vickrey
devoid
leendert
torre
pretend
prisoner
decreased
setting
termed
rigorous
strict
dene
designer
equated
opponents
wellman
shoham
faithfulness
psychology
instructed
sandholm
nv
nding
exploration
average
accomplish
autonomous
uncertainty
yoav
paramount
foe
ages
outset
vu
pv
gence
recommending
guido
incentive
utility
the game
stochastic games
repeated games
player 1
the agents
imperfect monitoring
policy prole
average reward
player 2
pareto ele
an ele
perfect monitoring
nash equilibrium
for player
learning in
learning equilibrium
e cient
the players
joint action
reinforcement learning
the agent
a nash
a game
learning algorithms
a policy
game is
economically e
the adversary
cient learning
probabilistic maximin
learning algorithm
in games
of repeated
equilibrium of
a pareto
both players
repeated game
game g
monitoring setting
side payments
the learning
games with
r max
equilibrium in
multi agent
t mix
game matrix
adversary s
game in
an agent
each agent
other player
other agent
game theory
a learning
a deviation
ele in
payos in
of rewards
games is
the payo
s payo
ele for
normative approach
in equilibrium
reward of
of games
return mixing
best response
agent i
agents will
all agents
average sum
to deviate
mixing time
the player
possible histories
in stochastic
of learning
of actions
common interest
expected payo
maximin value
its payo
monitoring we
algorithms themselves
payo obtained
the ele
ele algorithm
agent initially
xed sum
ele does
initially plays
of ele
game m
the payos
always play
converge to
agent s
sum game
in repeated
agent 1
the rewards
agent reinforcement
equilibrium and
of pareto
this policy
player s
non cooperative
the denition
to learning
games in
on learning
machine learning
the policy
desired value
a repeated
of possible
rg m
sum stochastic
payos obtained
individually rational
and player
payo it
game theorists
players play
strict imperfect
ele where
equilibrium a
nash ele
prole that
self play
equilibrium ele
a normative
folk theorems
both agents
in economics
game associated
ele is
monitoring case
bowling and
ele exists
equilibrium had
and veloso
its agent
deviate from
adversary will
is played
in ai
known the
games and
agent to
player can
an economically
if player
general sum
the imperfect
games the
stick to
by agent
initially unknown
in game
adopted by
of convergence
t 0
g1 and
a player
the perfect
polynomial in
e ciently
the return
no agent
ai and
s actions
of equilibrium
deviates from
behave according
the probabilistic
the spirit
policy for
spirit of
times if
always exist
the expected
actions and
the action
its action
e ciency
work on
1 resp
bayesian approach
in machine
for agent
for learning
denition in
polynomial number
with perfect
agent will
learning v
agent can
a nash equilibrium
of repeated games
economically e cient
e cient learning
the learning algorithms
cient learning equilibrium
learning in games
for player 2
a pareto ele
the other agent
a policy prole
in the game
the game is
the other player
return mixing time
normative approach to
the probabilistic maximin
sum of rewards
average reward of
of possible histories
in stochastic games
perfect monitoring setting
reinforcement learning in
in a nash
average sum of
on learning in
equilibrium of the
approach to learning
the agents will
in repeated games
of an ele
the average reward
ele does not
learning algorithms themselves
adversary will always
of the players
probabilistic maximin value
the ele algorithm
the policy prole
a repeated game
the agent initially
the return mixing
agent initially plays
agent reinforcement learning
in a game
will always play
for player 1
the expected payo
be in equilibrium
repeated games with
nash equilibrium of
the adversary s
to learning in
if the agent
work on learning
a learning algorithm
case of repeated
on its own
the adversary will
learning equilibrium ele
games with perfect
ele in the
stochastic games is
player can observe
which an ele
a game in
bowling and veloso
to deviate from
the game matrix
not always exist
known the game
always exist in
xed sum game
the perfect monitoring
nash equilibrium had
if player 1
an ele does
sum stochastic games
learning v 67
adversary s payo
stick to their
game associated with
in non cooperative
strict imperfect monitoring
learning research in
perfect monitoring we
the joint action
the game g
payo obtained by
a normative approach
an ele exists
an economically e
if the game
repeated game m
have obtained in
the imperfect monitoring
with perfect monitoring
of pareto ele
converge to a
of a policy
in the imperfect
a policy for
that the game
a deviation from
mixing time of
multi agent reinforcement
in game theory
game in which
the learning algorithm
in machine learning
that the agents
the agent will
set of possible
the spirit of
behave according to
of the game
of multi agent
67 n 1
an e cient
existence of an
of actions a
of a learning
t t and
in multi agent
obtained in a
a polynomial number
deviation from the
polynomial number of
machine learning v
number of steps
of the adversary
to the value
multi agent systems
the agent s
v 67 n
the case of
all joint actions
with k actions
be economically e
both players play
only equilibrium of
player 2 is
pareto ele is
to their algorithms
the second action
its aim is
near optimal reinforcement
game theory literature
an ele in
player 1 plays
agents stick to
multi agent interaction
to r max
rewards are based
of games in
of strict imperfect
in an imperfect
parallel to that
every t t
learning in general
the actual game
discuss the extension
stochastic games stochastic
agent i in
imperfect monitoring settings
to general sum
algorithms in computer
each agent can
called folk theorems
1 deviates from
learning in cooperative
of reinforcement learning
joint actions have
had they known
theorems in economics
other player the
any perfect monitoring
equilibrium if for
will attain a
a perfect monitoring
game is g2
a game we
corresponding rg m
player 1 deviates
imperfect monitoring the
s average reward
by the players
t and game
1 denoted cooperate
long term average
failure of at
denition for player
in that equilibrium
and its payo
action leading to
folk theorems in
punishment can be
general sum stochastic
and player 2
speed of convergence
