sup
fgng
regression
ns
lim
convergence
minimax
kd
nonparametric
antos
lip
birge
fg
classication
yang
brick
2d
rate
rates
tending
fp
devroye
gyor
el
bayes
denition
fb
stone
estimation
distributions
1g
plug
gn
lugosi
bricks
polinomial
lq
efy
er
pf
tsybakov
inmum
recognition
classes
pfc
f0
kohler
exponent
entropy
individual
rst
decision
km
fa
bounds
classi
disjoint
xed
xg
pack
fn
universally
jg
kfk1
ibragimov
xunif
fatou
massart
extention
fgn
mammen
kx
khasmiskii
efj
pedent
bxc
eln
k1np
fng
t2n
korostelev
imply
dierent
fy
fc
unif
kfk
c2c
n2n
1q
funtions
10e
efg
estimates
generalizations
mat
identically
log
assertion
recog
reconstruction
probability
derivatives
wants
chervonenkis
1045
borders
qa
barron
theorems
uniformly
asymptotic
remark
metric
lebesgue
vapnik
error
learning
counterexamples
kp
inequality
rules
sample
strange
conditioning
nish
inde
decreases
discrimination
modulus
lipschitz
00
corollary
diers
subclass
vanishing
cn
measurable
nition
segment
specially
kg
assure
tend
slow
jensen
fastest
mr
cubic
posteriori
strongest
converging
1e
references
pattern
k1
contraction
inferior
dened
0g
estimators
smoothness
concerning
d2
therein
density
jx
a2
subsequence
ts
continuity
anything
indicator
fi
strong
wishes
border
arbitrarily
cation
achievable
intersections
exclude
easier
doesn
modied
dropping
innite
tell
fr
rich
distribution
rational
slowly
statistical
spirit
derives
proofs
denitions
exponential
nontrivial
j k
lim sup
of convergence
individual lower
y 2d
convergence for
regression function
n g
c j
ns c
sup x
lower rate
function estimation
kd c
fgng sup
fg n
a j
class d
rate of
lip d
upper rate
k d
2 d
lower rates
yang 16
el n
fp j
b n
k r
a n
sup sup
x y
lower bounds
in yang
sup b
er ns
minimax lower
positive sequence
with kd
sup lim
of distributions
bayes decision
c c
assumption 1
r d
j g
of nonparametric
r ns
2d lim
birge 7
c er
individual upper
classes lip
nonparametric pattern
rules fg
log t
1 d
these classes
tending to
yang s
sup r
sup a
d kd
class f
classes d
fb n
the bayes
c n
an individual
of error
of regression
the classes
bounds for
n l
which satisfy
the rate
d c
sequence tending
in birge
xed distribution
gyor and
see antos
kd moreover
corresponding distribution
satisfying 6
gn sup
exist rules
metric entropy
the brick
distribution class
regression functions
3 fgng
than regression
let fb
of x
1 q
to zero
distributions of
0 1
n j
r i
fa n
plug in
pattern recognition
r r
the class
n a
rates of
log 1
c x
taking values
function class
the plug
m j
f0 1g
classes see
rst term
every sequence
all distributions
every c
d y
x 00
j log
probability of
on 0
exponent of
for d
r a
for every
denition 5
see also
q 1
see devroye
is lip
every distribution
2d el
antos and
t jg
d assumption
i fy
antos gyor
brick i
is sup
devroye et
b ns
estimates see
a ns
strong minimax
to yang
stone 15
kohler 4
sup gn
distribution classes
satisfy lim
d f0
function estimates
exist regression
and lugosi
gives kd
and tsybakov
n lim
fgng lim
choose fp
exist individual
k lq
convergence results
a class
g n
k 3
there exist
theorem 2
a decision
g is
the exponent
convergence of
estimation for
error of
sequence fg
classication is
rule see
if assumption
uniformly bounded
image reconstruction
sequence fa
distribution x
decision rule
and kohler
rate results
minimax theory
ns a
near 1
are arbitrarily
the support
v d
g be
support of
k then
in rule
the sequence
sample size
c j k
a j k
rate of convergence
of convergence for
sup x y
j k d
x y 2d
j k r
regression function estimation
fg n g
0 1 d
fp j g
individual lower rate
k d c
lower rate of
d c j
lim sup sup
el n l
b n a
probability of error
distributions of x
n j k
of x y
c n j
r a j
individual lower rates
fgng sup lim
in yang 16
sup sup x
sup b n
k r a
sup lim sup
lim sup b
upper rate of
k r i
er ns c
convergence for the
an individual lower
r ns c
y 2d lim
log 1 q
rules fg n
is an individual
kd c c
c er ns
the classes lip
sup a n
lim sup r
2d lim sup
ns c er
a class d
sup r ns
classes lip d
minimax lower bounds
individual upper rate
n a n
distribution of x
2 d is
the bayes decision
convergence for a
tending to zero
r r r
f n g
class of distributions
lower bounds for
rates of convergence
c c x
the rate of
n 2 d
convergence of nonparametric
for the plug
sequence tending to
kd moreover for
j k g
k d kd
in birge 7
with kd c
the individual lower
moreover for every
an individual upper
corresponding distribution class
of nonparametric pattern
of convergence results
fa n g
n g which
class d of
c x k
than regression function
a positive sequence
plug in rule
d of distributions
convergence for d
k 3 fgng
fgng sup x
distribution class d
fb n g
nonparametric pattern recognition
lip d and
the corresponding distribution
g which satisfy
n g is
satisfying 6 for
then the sequence
i a j
c 2 c
on 0 1
m j k
a n k
lower rates of
function class f
r i c
of distributions of
n g be
of convergence of
is in a
in a j
the class d
for these classes
for the classes
the plug in
j k then
d is an
as the sample
be the class
of error for
the exponent of
i c j
the rst term
for every c
error for a
for a class
j k 2
the support of
class of functions
6 for any
the sample size
strong minimax lower
is sup x
devroye et al
class f then
expected error of
c k 3
of fp j
ns a ns
sequence fg n
minimax theory of
there exist individual
assertion 2 proof
function estimation for
sup gn sup
second term c
d and v
that is sup
2d a n
because of j
d kd moreover
can choose m
bounds for learning
bayes decision for
if assumption 1
d assumption 1
lim sup gn
antos gyor and
function with support
easier than regression
of individual lower
a n remark
which satisfy lim
for every distribution
and x 00
class d if
birge 7 in
distribution x y
positive sequence fa
near 1 2
with support on
2d el n
with m c
to yang s
6 c j
i f c
for the minimax
x is uniformly
functions f such
a n lim
sequence fa n
the brick i
6 g g
j log t
support of d
exist individual lower
g g d
r d f0
rate for d
y 2d el
sequence b n
arbitrary positive sequence
are arbitrarily close
which are arbitrarily
decision for c
