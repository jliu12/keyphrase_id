{"shared selection": 0.000971904517366954, "a polynomial bound": 0.0009310344469842923, "an irrational choice": 0.0010298199627877902, "that it may": 0.000663411738084629, "is trying to": 0.0008321458774498469, "quickly indeed": 0.000971904517366954, "time 14 3": 0.0010298199627877902, "approach the": 0.001081606834576072, "as the ones": 0.0014021500357344085, "e cient behaviors": 0.0010298199627877902, "polynomially many": 0.0007421847985653504, "g2 the payos": 0.0010298199627877902, "but requires additional": 0.0010298199627877902, "payoff": 0.0012852961794648746, "maintains information about": 0.0009310344469842923, "looking": 0.000205937800019403, "with corresponding": 0.0006290164566258502, "be very close": 0.0008002740946718667, "monitoring where the": 0.0010298199627877902, "constructive existence": 0.000971904517366954, "similarly for player": 0.0020596399255755804, "policy determines the": 0.0009310344469842923, "in this setting": 0.001249607768004622, "addition the": 0.00036281071874830087, "k iterations": 0.000774103816216825, "denition can": 0.000774103816216825, "general way to": 0.0008321458774498469, "in terms": 0.00011277410437070125, "similar results we": 0.0010298199627877902, "it obtained": 0.0008730815719568182, "on normative guidelines": 0.0010298199627877902, "for learning": 0.0020398048168560395, "general context of": 0.0010298199627877902, "replaces": 0.0003168835371517908, "following let": 0.0006290164566258502, "detail first": 0.0008730815719568182, "the number of": 0.0001289448494509707, "agent can": 0.0019736794966288833, "rational they": 0.000971904517366954, "required to": 0.000606014598125074, "order to be": 0.0005243422169685006, "where the deviator": 0.0010298199627877902, "of the proof": 0.0008915109110165033, "presented in the": 0.00042203345812732713, "i a b": 0.0007330505281739418, "an algorithmic": 0.0006939782666478507, "value it could": 0.0020596399255755804, "notice that a": 0.0013498219883241157, "adversary and this": 0.0010298199627877902, "agent setting": 0.000971904517366954, "aspects of": 0.00032046858343152956, "second": -0.001441937188138705, "convergence stipulates that": 0.0010298199627877902, "is given to": 0.0006428310760905615, "exploration stage": 0.000971904517366954, "follows from": 0.0002476445704301782, "line in this": 0.0008321458774498469, "no reason to": 0.0006749109941620578, "over with": 0.0008152096437846543, "the players would": 0.0009310344469842923, "accomplish on its": 0.0020596399255755804, "1 the study": 0.0010298199627877902, "not been": 0.0003134582012487072, "designing": 0.00021201166110983413, "is 1 there": 0.0010298199627877902, "increasing": -1.2322890326095277e-06, "10 contradicting": 0.000971904517366954, "that maximizes the": 0.0007742140246189059, "appropriate payos": 0.000971904517366954, "are unique equilibria": 0.0010298199627877902, "the payo matrix": 0.0010298199627877902, "following each joint": 0.0010298199627877902, "here": -0.0012598137037885455, "maximization of social": 0.0010298199627877902, "in having a": 0.0010298199627877902, "adopt a": 0.0005221368030860054, "constructive result theorem": 0.0010298199627877902, "prole the induced": 0.0010298199627877902, "on the deviating": 0.0010298199627877902, "agents go through": 0.0010298199627877902, "k": -0.00260026376731819, "work uses repeated": 0.0010298199627877902, "we take individual": 0.0010298199627877902, "column j in": 0.0009310344469842923, "form the rows": 0.0010298199627877902, "played making it": 0.0010298199627877902, "for agent 1": 0.0010298199627877902, "game from the": 0.0010298199627877902, "distribution is assumed": 0.0010298199627877902, "because we are": 0.0007010750178672042, "a payment": 0.000971904517366954, "they call convergence": 0.0010298199627877902, "maximizes min s": 0.0010298199627877902, "replace": 0.00013192727756560082, "by most work": 0.0010298199627877902, "idea behind the": 0.0006335389089667411, "one needs": 0.0005042097552001021, "times we get": 0.0010298199627877902, "its own thus": 0.0010298199627877902, "opponents": 0.0007159746543399424, "t step": 0.0008152096437846543, "provides a": 0.00020200486604169134, "player is": 0.0008730815719568182, "denote this": 0.0005159204175055324, "the policy prole": 0.004119279851151161, "this interval of": 0.0010298199627877902, "therefore": -0.000229068874528053, "steps of random": 0.0010298199627877902, "carried out": 0.0005940975321770559, "general case pareto": 0.0010298199627877902, "equilibrium a we": 0.0010298199627877902, "deviation will": 0.001943809034733908, "any strategy": 0.0007421847985653504, "the agents should": 0.0010298199627877902, "from the learning": 0.0008732058717250353, "relax": 0.00036048429703467626, "games m where": 0.0010298199627877902, "learning algorithms": 0.009101836578902572, "constant sum game": 0.0010298199627877902, "a hence a": 0.0009310344469842923, "first to compute": 0.0010298199627877902, "loss": 7.831965472445116e-05, "history of actions": 0.0010298199627877902, "hold": -9.86219477247251e-06, "the agents turn": 0.0010298199627877902, "action we make": 0.0010298199627877902, "and common": 0.0006049243473022664, "his probabilistic maximin": 0.0010298199627877902, "of the fourth": 0.0006527573289679061, "presented here an": 0.0010298199627877902, "devoid of": 0.0008730815719568182, "initially plays defect": 0.0010298199627877902, "or a": 0.00015149809979889223, "concepts": 0.0006221739732145514, "example": -0.00045622727078509256, "trivial rests on": 0.0010298199627877902, "theory 8": 0.000971904517366954, "machine learning what": 0.0010298199627877902, "can be": 0.0, "players play": 0.002915713552100862, "to start": 0.000464748887987192, "where the expected": 0.0010298199627877902, "learning what we": 0.0010298199627877902, "t we denote": 0.0008002740946718667, "the deviating player": 0.0010298199627877902, "machine": 0.00027781731457058147, "how": -0.001105022412419431, "methodology": 0.00019047610901416596, "g1 and g2": 0.0010298199627877902, "action leading to": 0.0020596399255755804, "symposium": 0.0001380505900037682, "if the agent": 0.0034928234869001412, "algorithm the": 0.0002588654391875672, "by learning": 0.0006939782666478507, "remain consistent with": 0.0010298199627877902, "suggest two criteria": 0.0010298199627877902, "deeper notion of": 0.0010298199627877902, "behaviors exist some": 0.0010298199627877902, "descriptive motivation underlying": 0.0010298199627877902, "models based on": 0.000663411738084629, "theory a": 0.0005354021517001512, "exist some": 0.0006939782666478507, "time we prove": 0.0010298199627877902, "in e g": 0.0007742140246189059, "algorithms themselves are": 0.0020596399255755804, "xed stochastic": 0.000971904517366954, "line of": 0.00041030656060455343, "the suggested": 0.0006748149214226754, "purposes a": 0.0007160765724402042, "e we": 0.00032591593593977075, "point on": 0.0008667679538002628, "r rational": 0.000971904517366954, "uses this": 0.0005942188284548949, "denition in this": 0.0010298199627877902, "sum over": 0.0005942188284548949, "in games in": 0.0010298199627877902, "of individually rational": 0.0010298199627877902, "history of states": 0.0010298199627877902, "assumptions are": 0.0004832040417809763, "particular class thus": 0.0010298199627877902, "each player": 0.0008730815719568182, "an agent": 0.005661109047770706, "is more": 0.00016642364028409505, "are not": 0.00015512437989216414, "for updating": 0.0006939782666478507, "should be in": 0.001990235214253887, "above in": 0.00045629221416883416, "as follows given": 0.0005749794499375729, "time after": 0.0005661109047770705, "among all": 0.0003771588365708351, "most of": 0.0004282070880501848, "of the monetary": 0.0010298199627877902, "take in": 0.0007160765724402042, "above it": 0.0005221368030860054, "to do as": 0.0009310344469842923, "a rigorous normative": 0.0010298199627877902, "number of steps": 0.0021900545728066032, "chain is": 0.0006164744968379118, "are greater": 0.0006049243473022664, "e m hence": 0.0010298199627877902, "theoretic approach": 0.000557817444576059, "similar suppose": 0.0008730815719568182, "the agents to": 0.0018620688939685846, "is the payo": 0.0010298199627877902, "an appealing concept": 0.0010298199627877902, "less e cient": 0.0010298199627877902, "algorithm itself": 0.0006290164566258502, "systems machine": 0.000971904517366954, "exists and look": 0.0010298199627877902, "is to": 0.00020807580013473354, "reinforcement learning with": 0.0010298199627877902, "goal was to": 0.0007010750178672042, "k actions for": 0.0010298199627877902, "series": 0.00015554349330363786, "using redundancy": 0.0008730815719568182, "adopt other": 0.000971904517366954, "its own we": 0.0009310344469842923, "result with respect": 0.0009310344469842923, "by more than": 0.0005749794499375729, "while in": 0.0003771588365708351, "agent will treat": 0.0010298199627877902, "s policy": 0.0008730815719568182, "of general": 0.000444416512295841, "algorithms will": 0.0013157863310859221, "one needs to": 0.0006165622637081906, "payment to": 0.000971904517366954, "that given the": 0.000663411738084629, "not exist then": 0.0009310344469842923, "re": 3.092816334898681e-05, "rg": 0.0023234137048890008, "by nv": 0.000971904517366954, "after playing each": 0.0010298199627877902, "selected by using": 0.0010298199627877902, "converge to an": 0.0010298199627877902, "that converge": 0.0008730815719568182, "prole for": 0.000971904517366954, "than that given": 0.0009310344469842923, "all policies that": 0.0010298199627877902, "necessarily": 6.649454709210373e-05, "the more": 0.00024049546193703015, "that u s": 0.0010298199627877902, "learning in the": 0.0007161785195604264, "of a nash": 0.0010298199627877902, "issue of e": 0.0010298199627877902, "game a more": 0.0010298199627877902, "the above the": 0.0015484280492378119, "assuming the": 0.0004197872166755902, "and visit the": 0.0009310344469842923, "fundamental work": 0.0008730815719568182, "designer s choice": 0.0010298199627877902, "payo initialize": 0.000971904517366954, "with this property": 0.0008002740946718667, "algorithm if one": 0.0009310344469842923, "but its aim": 0.0010298199627877902, "opponents machine": 0.000971904517366954, "we face is": 0.0010298199627877902, "guarantee that": 0.0007077806890961889, "k 2 log": 0.0010298199627877902, "termed the ele": 0.0010298199627877902, "see that": 0.00015969187092941227, "cient algorithm for": 0.0008002740946718667, "max of the": 0.0018620688939685846, "on showing the": 0.0010298199627877902, "such an": 0.00023472124176624737, "two adversary": 0.000971904517366954, "similarly": -0.0001839380512777345, "corresponding bayes nash": 0.0010298199627877902, "the game": 0.01887049369877551, "execute it": 0.0007160765724402042, "of strict": 0.0012580329132517005, "our behavior": 0.000971904517366954, "adversary s actions": 0.0010298199627877902, "work the": 0.0003454193697900408, "more complicated": 0.0003560762920625211, "rewards": 0.006780254304461947, "in terms of": 0.00019115514502334854, "that requires": 0.000542504923393336, "are impossible to": 0.0010298199627877902, "for one": 0.0003117480856515576, "in games our": 0.0010298199627877902, "property as": 0.0006427395698875594, "each stage": 0.000557817444576059, "iteration": 0.0005352837404954015, "the past": 0.0003901551635480713, "an e": 0.001973372756042549, "2 this is": 0.0005159938685900292, "refer the reader": 0.0012175213147942792, "play the second": 0.0010298199627877902, "result for": 0.00036281071874830087, "be followed in": 0.0010298199627877902, "the denitions of": 0.0007161785195604264, "an action in": 0.0016005481893437334, "the total": 0.0001498868734990341, "some xed": 0.0006427395698875594, "e they are": 0.0006749109941620578, "reals between 0": 0.0010298199627877902, "ele are": 0.000971904517366954, "to learn": 0.00045629221416883416, "following instance": 0.0008730815719568182, "agent with": 0.0006939782666478507, "not learn the": 0.0008732058717250353, "is a model": 0.0006874022974519222, "the best response": 0.0020596399255755804, "indeed ai": 0.000971904517366954, "indeed an": 0.0007421847985653504, "an incentive to": 0.0009310344469842923, "reality the": 0.0006578931655429611, "predicting how": 0.0008152096437846543, "information about": 0.00045599027831641205, "games as well": 0.0010298199627877902, "convergence in": 0.0006164744968379118, "shall": 0.00017242978035012288, "as closely": 0.0007160765724402042, "in addition the": 0.00043109594775796693, "known prisoner": 0.000971904517366954, "second which they": 0.0010298199627877902, "convergence is": 0.0005842412659181877, "have important ramications": 0.0010298199627877902, "stochastic games and": 0.0010298199627877902, "2 s rewards": 0.0010298199627877902, "describe a concrete": 0.0010298199627877902, "distribution of possible": 0.0009310344469842923, "closely and as": 0.0010298199627877902, "least the": 0.0005221368030860054, "ele where we": 0.0010298199627877902, "reader to 3": 0.0009310344469842923, "agents adopting": 0.000971904517366954, "a lower average": 0.0009310344469842923, "m where at": 0.0010298199627877902, "ele instances in": 0.0010298199627877902, "in the game": 0.006112441102075248, "using a": 0.00021131868600560687, "contrary to": 0.0005661109047770705, "incomplete": 0.0005469396863196594, "incentive to": 0.000774103816216825, "result of": 0.00016135947900774235, "the agents run": 0.0010298199627877902, "each iteration the": 0.0006335389089667411, "we are considering": 0.0006013538961527255, "equilibrium 1": 0.000971904517366954, "s i the": 0.0006874022974519222, "and all": 0.0002193427981572845, "he would": 0.0006748149214226754, "entry in": 0.0004482748456766825, "we said earlier": 0.0009310344469842923, "will play as": 0.0010298199627877902, "is required": 0.0007576625532427712, "both players is": 0.0020596399255755804, "design of": 0.00023472124176624737, "more than this": 0.0010298199627877902, "rewards obtained": 0.0008730815719568182, "1 the ele": 0.0010298199627877902, "for which": 0.00013807024133330608, "rewards are": 0.0017461631439136364, "players whom": 0.000971904517366954, "surprisingly has not": 0.0010298199627877902, "game and describe": 0.0010298199627877902, "suitably modied": 0.0008730815719568182, "singh learning payoff": 0.0010298199627877902, "interest stochastic": 0.000971904517366954, "nding": 0.0007120512245201284, "this case we": 0.0003848863750022802, "policy then the": 0.0010298199627877902, "determines the probability": 0.0008732058717250353, "equilibrium n": 0.000971904517366954, "equilibrium a": 0.002915713552100862, "in a given": 0.000435831200377543, "the so": 0.0007696631738123888, "rate should be": 0.0009310344469842923, "either in": 0.0004832040417809763, "is useful": 0.0003222656159195575, "be rational": 0.0008152096437846543, "will become irrational": 0.0010298199627877902, "m to": 0.0004264387578012798, "k such": 0.0008667679538002628, "pareto ele does": 0.0010298199627877902, "payments will": 0.000971904517366954, "result of the": 0.0003730996443725147, "attracted the attention": 0.0010298199627877902, "on principles": 0.0004881890232438977, "the desired result": 0.0006335389089667411, "uncertain entities": 0.000971904517366954, "learning in xed": 0.0010298199627877902, "played given the": 0.0010298199627877902, "equilibrium had the": 0.0010298199627877902, "issue of": 0.0007593532260731544, "actual game is": 0.0010298199627877902, "on its own": 0.0033170586904231456, "r max we": 0.0010298199627877902, "dilemma game consider": 0.0010298199627877902, "for descriptive purposes": 0.0010298199627877902, "where special": 0.000971904517366954, "strategies is a": 0.0009310344469842923, "result": -0.0028134590467557763, "to both": 0.0003454193697900408, "games reinforcement learning": 0.0010298199627877902, "alternative": 5.361317158527199e-05, "best": -0.00034674364169904703, "to include the": 0.0006013538961527255, "player 1 is": 0.0010298199627877902, "have chosen": 0.0004881890232438977, "states each": 0.000774103816216825, "in 2 has": 0.0010298199627877902, "conceptual": 0.00032772346897154083, "let us": 0.00020596711500872958, "maximizes the": 0.0005842412659181877, "is greater": 0.0002954867076473726, "with appropriate": 0.000549963838367756, "we equated quick": 0.0010298199627877902, "extend": 4.22041129018266e-05, "policy prole is": 0.0020596399255755804, "between 0 and": 0.0005425821592878966, "a bayesian": 0.0005942188284548949, "leads to convergence": 0.0010298199627877902, "policy prole in": 0.0020596399255755804, "every agent thus": 0.0010298199627877902, "the typical assumption": 0.0010298199627877902, "games exists 1": 0.0010298199627877902, "is easy": 0.0004139367998843289, "leading to 6": 0.0010298199627877902, "payos but": 0.000971904517366954, "common description": 0.000971904517366954, "we describe": 0.00020004876243282348, "the lack": 0.00041656361432912804, "i is a": 0.000360586940627226, "wants its agent": 0.0010298199627877902, "s rewards and": 0.0010298199627877902, "folk theorem": 0.0008730815719568182, "of both": 0.00022799513915820602, "related work on": 0.000663411738084629, "pre": 0.00024001662114772696, "makes an irrational": 0.0010298199627877902, "opponents machine learning": 0.0010298199627877902, "for an agent": 0.0016642917548996938, "computed and the": 0.0007330505281739418, "average reward should": 0.0010298199627877902, "be positive negative": 0.0010298199627877902, "normative motivation": 0.000971904517366954, "possible histories of": 0.0009310344469842923, "are greater than": 0.0006749109941620578, "union": 0.00015554349330363786, "to approach the": 0.0008002740946718667, "approach in theoretical": 0.0010298199627877902, "matrix and": 0.000444416512295841, "infinite games machine": 0.0010298199627877902, "much": -0.0006445407219923272, "agents player": 0.000971904517366954, "this work": 0.00017245432551458553, "people play games": 0.0010298199627877902, "if the game": 0.003089459888363371, "ergodic": 0.0005748157780190026, "setting 6": 0.0008730815719568182, "is identical to": 0.0010085630780981543, "probability we": 0.0005842412659181877, "we elaborate": 0.0006578931655429611, "thus after the": 0.0009310344469842923, "be non negative": 0.0009310344469842923, "obtained so far": 0.0008732058717250353, "and is done": 0.0010298199627877902, "similarly but": 0.0008152096437846543, "all the": 0.00011620540062801633, "is if": 0.0003956596676276662, "is in": 8.906845548247869e-05, "choosing each particular": 0.0010298199627877902, "payo for": 0.001943809034733908, "employ": 0.00022467793007595, "fourth international joint": 0.0008732058717250353, "research methodology in": 0.0010298199627877902, "mix as": 0.000971904517366954, "elaborate": 0.00035168238084447203, "immediate but": 0.000971904517366954, "no lower than": 0.0010298199627877902, "from a particular": 0.0007521645399683924, "uncertainty second": 0.000971904517366954, "played": 0.0038374025707352574, "any game out": 0.0010298199627877902, "player": 0.027329164511698537, "we refer": 0.001040608638818372, "be carried": 0.00044065161687170207, "be a nash": 0.0010298199627877902, "to playing": 0.000971904517366954, "25 28": 0.0006748149214226754, "some value t": 0.0010298199627877902, "a 0 is": 0.0006428310760905615, "algorithm for the": 0.00042878089900721635, "the bottom": 0.00035389034454809447, "s and": 0.00018222125467611227, "at each": 0.0007361519317467231, "receive on its": 0.0009310344469842923, "in our setting": 0.0007330505281739418, "be type of": 0.0010298199627877902, "payo by more": 0.0010298199627877902, "uncertainty about": 0.0007160765724402042, "43 may 2007": 0.0010298199627877902, "other solution concept": 0.0010298199627877902, "address these": 0.0005748976023290408, "the action a": 0.0008321458774498469, "that paid": 0.000971904517366954, "reinforcement learning did": 0.0010298199627877902, "cient if": 0.0008152096437846543, "algorithm player 1": 0.0010298199627877902, "game is irreducible": 0.0010298199627877902, "prole by u": 0.0010298199627877902, "not be": 0.00021982507953838455, "pareto ele are": 0.0010298199627877902, "required for": 0.00026275113032004705, "and learns a": 0.0010298199627877902, "we simply": 0.000387471559992312, "exist in an": 0.0010298199627877902, "not exclude the": 0.0009310344469842923, "n 1": 0.0003297376193075768, "that context together": 0.0010298199627877902, "interactions the": 0.0007160765724402042, "actions a times": 0.0020596399255755804, "strategy equilibrium adaptive": 0.0010298199627877902, "g1 since": 0.000971904517366954, "policies that maximizes": 0.0010298199627877902, "pv i m": 0.0010298199627877902, "on online": 0.000971904517366954, "268 july": 0.000971904517366954, "previous": -0.0007179796289017278, "we need however": 0.0010298199627877902, "attain a": 0.00154820763243365, "equilibrium had they": 0.0020596399255755804, "similar results": 0.00043697553507468355, "a dierent approach": 0.0008321458774498469, "ease": 0.0003314917117816786, "had": 0.00043820247106289773, "is as a": 0.0008321458774498469, "ele the learning": 0.0010298199627877902, "cooperative inter actions": 0.0010298199627877902, "player both players": 0.0009310344469842923, "easy": -7.686511164618847e-05, "has": -0.006110701152999793, "bayesian normative approach": 0.0010298199627877902, "class of common": 0.0009310344469842923, "i one time": 0.0010298199627877902, "learning algorithm should": 0.0017464117434500706, "that u": 0.00037223626733611355, "that t": 0.0003373507152868544, "possible": -0.004617321772871078, "possibly": 4.9792967952330065e-05, "issues in": 0.0003848315869061944, "both players have": 0.0008732058717250353, "that e": 0.00036053561152535736, "interest games": 0.001943809034733908, "n g": 0.0010442736061720109, "unique": 4.6932719382360956e-05, "that a": 0.00017652442424152988, "work on learning": 0.0034928234869001412, "go through": 0.000549963838367756, "i e they": 0.0005475136432016508, "as well an": 0.0008732058717250353, "steps": -0.00023745488402283755, "strategy prole that": 0.0010298199627877902, "1 g1 2": 0.0010298199627877902, "policy tells it": 0.0010298199627877902, "instead our": 0.000971904517366954, "also that for": 0.0008002740946718667, "only after": 0.0005042097552001021, "payo from": 0.001943809034733908, "the policies": 0.0013157863310859221, "people": 0.0008910194627548715, "algorithms of": 0.00047837713542937403, "vickrey clarke": 0.000971904517366954, "deviation to be": 0.0010298199627877902, "agents will converge": 0.0010298199627877902, "is due to": 0.00035321824702689864, "our approach makes": 0.0010298199627877902, "been able to": 0.0011886068536149307, "to devise": 0.000557817444576059, "manner that": 0.0005942188284548949, "for": 0, "bottom": 0.00016385653603096098, "is performed for": 0.0006749109941620578, "from the above": 0.0009182504005200987, "vincent conitzer tuomas": 0.0010298199627877902, "consists of": 0.00010565934300280343, "foe": 0.0006747188760310696, "requires that": 0.0003373507152868544, "exposition": 0.0004197274689931713, "that if all": 0.0007161785195604264, "value while obtaining": 0.0010298199627877902, "experimental economics": 0.000971904517366954, "be type": 0.0006939782666478507, "only equilibrium": 0.001943809034733908, "2 can": 0.0003796766130365772, "the notion": 0.0013679708349492363, "the desired value": 0.0008321458774498469, "rules for": 0.0003560762920625211, "we attempt to": 0.000624803884002311, "actions as a": 0.0010298199627877902, "work in": 0.00046042717499527225, "in section": 3.5304884848305974e-05, "more general context": 0.0008732058717250353, "o": -0.0002712438950217945, "entries in": 0.00039848399477585494, "many states each": 0.0010298199627877902, "use the prescribed": 0.0010298199627877902, "itself the classical": 0.0010298199627877902, "setting i": 0.000774103816216825, "average reward stochastic": 0.0010298199627877902, "be performed e": 0.0008732058717250353, "cient joint": 0.000971904517366954, "particular class": 0.0007421847985653504, "in equilibrium when": 0.0010298199627877902, "the classical": 0.0003956596676276662, "follows the agent": 0.0010298199627877902, "prove the following": 0.000552614435925888, "cannot observe": 0.0008730815719568182, "we take": 0.0006373794605320186, "will necessarily": 0.000774103816216825, "equilibria since": 0.000971904517366954, "probability we will": 0.0008321458774498469, "often": -6.519514543160868e-05, "self play i": 0.0010298199627877902, "column j": 0.0006427395698875594, "times we": 0.0005221368030860054, "game playing": 0.0008730815719568182, "face is the": 0.0010298199627877902, "only o k": 0.0008732058717250353, "attractive but as": 0.0010298199627877902, "players is": 0.001943809034733908, "action for": 0.0006939782666478507, "to player": 0.001943809034733908, "shoham thuc": 0.000971904517366954, "denition of": 0.0019241579345309723, "hence in a": 0.0008002740946718667, "nv i": 0.000971904517366954, "outcome 2 we": 0.0010298199627877902, "modeled in repeated": 0.0010298199627877902, "a with corresponding": 0.0010298199627877902, "denoted defect too": 0.0010298199627877902, "in ai speed": 0.0010298199627877902, "a particular": 0.00018131778526571125, "not learn": 0.0006748149214226754, "extended to this": 0.0010298199627877902, "framework of": 0.0004197872166755902, "considered": -0.000279199901227363, "believe that agents": 0.0010298199627877902, "veloso their": 0.000971904517366954, "and the situation": 0.0008321458774498469, "for the agents": 0.0009310344469842923, "rational for": 0.000774103816216825, "the case": 0.0007591202900614539, "rational for player": 0.0010298199627877902, "later": -2.3466359691180475e-05, "can guarantee": 0.0015126292656003066, "be an integral": 0.0010298199627877902, "policies converge to": 0.0010298199627877902, "can accomplish": 0.0017461631439136364, "also take the": 0.0008732058717250353, "25 28 2004": 0.0007742140246189059, "learning v 67": 0.003089459888363371, "exist": -0.0002080461850194282, "exist in": 0.0012496908429873842, "vector i": 0.0006578931655429611, "player 1 resp": 0.0010298199627877902, "general sum games": 0.0010298199627877902, "could attain on": 0.0010298199627877902, "for each state": 0.0007742140246189059, "initialize construct the": 0.0010298199627877902, "major conceptual": 0.000971904517366954, "computer science": 0.0007727611433985281, "ambitious": 0.0005748157780190026, "steps does": 0.000971904517366954, "decreased value while": 0.0010298199627877902, "context of multi": 0.0009310344469842923, "that should be": 0.0005811431115841947, "research methodology": 0.000971904517366954, "where the desired": 0.0010298199627877902, "models": -8.157781245205346e-05, "the set": 0.0004518894517590227, "the underlying": 0.00024643555653405217, "of reinforcement": 0.001943809034733908, "ability to punish": 0.0010298199627877902, "and execute it": 0.0009310344469842923, "the extension to": 0.0006749109941620578, "foe q": 0.000971904517366954, "variable": -5.438520830136898e-05, "value 1 in": 0.0008732058717250353, "side monetary": 0.000971904517366954, "following state the": 0.0010298199627877902, "cooperative multi": 0.0008730815719568182, "this approach is": 0.0003866418347374886, "k 2 times": 0.0009310344469842923, "idea above constitutes": 0.0010298199627877902, "0 as observed": 0.0010298199627877902, "1 and": 0.00027129709291040554, "time": -0.006785683270471483, "to extend": 0.0003100542232769594, "the major": 0.0006949953754534355, "decision": 9.865459444348781e-05, "learn a": 0.0006049243473022664, "each possible history": 0.0010298199627877902, "chain": 0.00022037435531657587, "payo alone the": 0.0010298199627877902, "recommending behavior": 0.000971904517366954, "e a game": 0.0010298199627877902, "a deviation to": 0.0010298199627877902, "for agent i": 0.0020596399255755804, "a manner": 0.0004832040417809763, "eect on": 0.0006578931655429611, "deviates from to": 0.0020596399255755804, "of ele": 0.003887618069467816, "a repeated game": 0.004119279851151161, "agents i": 0.0008730815719568182, "applies to the": 0.0005875760798754402, "stochastic games": 0.01749428131260517, "uses this policy": 0.0010298199627877902, "algorithm works": 0.0005286223582497236, "with the notion": 0.0007521645399683924, "require knowledge of": 0.0008002740946718667, "is a common": 0.0006749109941620578, "the actual game": 0.0020596399255755804, "formally let": 0.0006578931655429611, "require knowledge": 0.0006748149214226754, "s rewards we": 0.0010298199627877902, "should be the": 0.0006527573289679061, "convergence of": 0.00044065161687170207, "common interest": 0.003887618069467816, "choice": -0.00011374676192269778, "high enough": 0.0006578931655429611, "ective": 0.0005041379917849015, "rationality": 0.004295847926039654, "denition of imperfect": 0.0010298199627877902, "online to an": 0.0010298199627877902, "say that a": 0.0004176903288490751, "1 s rewards": 0.0010298199627877902, "denition of pareto": 0.0010298199627877902, "cient behaviors exist": 0.0010298199627877902, "a denition of": 0.0007742140246189059, "in the appendix": 0.0005378088736942846, "participating in a": 0.0008732058717250353, "a multi": 0.0003698290826886664, "monitoring the ele": 0.0010298199627877902, "an agent with": 0.0007742140246189059, "agents 3": 0.0008730815719568182, "agents 1": 0.0008730815719568182, "readers may": 0.0007160765724402042, "tr the": 0.0005842412659181877, "the research": 0.000464748887987192, "knows its payo": 0.0010298199627877902, "but crucial point": 0.0010298199627877902, "mapping from h": 0.0010298199627877902, "in this section": 0.0005122247814693235, "obtained which is": 0.0009310344469842923, "theoretical computer": 0.0004264387578012798, "prole will": 0.000971904517366954, "normative criteria indeed": 0.0010298199627877902, "an rg a": 0.0010298199627877902, "an rg m": 0.0010298199627877902, "times for": 0.00038223374562649956, "we were also": 0.0009310344469842923, "learning is": 0.0006164744968379118, "normative motivation for": 0.0010298199627877902, "learning in": 0.011101069523244194, "start with the": 0.0005378088736942846, "elaborate only on": 0.0010298199627877902, "other payos": 0.000971904517366954, "the agent s": 0.002103225053601613, "row 1 denoted": 0.0010298199627877902, "two criteria": 0.0006578931655429611, "that context": 0.0007421847985653504, "is the return": 0.0009310344469842923, "policy both criteria": 0.0010298199627877902, "understanding": 0.00013497439305704126, "is obtained which": 0.0009310344469842923, "are considering games": 0.0010298199627877902, "be no": 0.00045223161134026404, "denitions": 0.0003392841635235741, "address": 6.519514543160869e-05, "alone": 0.0002161536574559961, "along": -9.86219477247251e-06, "deviation will immediately": 0.0010298199627877902, "more detail": 0.00036281071874830087, "monitoring in repeated": 0.0010298199627877902, "mechanism which ensures": 0.0010298199627877902, "for rational": 0.000774103816216825, "for the learning": 0.0007742140246189059, "studied": 3.9688187795797356e-05, "as input r": 0.0010298199627877902, "pareto optimal": 0.0008730815719568182, "learning strategies": 0.0016304192875693086, "the now revealed": 0.0010298199627877902, "notice that the": 0.000405331588255818, "in stochastic games": 0.005149099813938952, "is another related": 0.0010298199627877902, "prole suitably": 0.000971904517366954, "multiagent systems p": 0.0007742140246189059, "1 can": 0.00033345449157714114, "despite their practical": 0.0010298199627877902, "should manifest": 0.000971904517366954, "a set": 0.00011363870147043404, "maximin of g": 0.0010298199627877902, "any point": 0.00043697553507468355, "actions available": 0.0017461631439136364, "policy ideally we": 0.0010298199627877902, "the other": 0.0005389621358312947, "games machine learning": 0.0010298199627877902, "pursued by": 0.000971904517366954, "positive": 3.2073203103931916e-05, "1 if": 0.0003754232522263093, "agent that uses": 0.0010298199627877902, "agent can guarantee": 0.0010298199627877902, "appropriate equilibrium behavior": 0.0010298199627877902, "following the performance": 0.0010298199627877902, "two criteria for": 0.0010298199627877902, "theoretical": 0.00015663930944890232, "bowling and veloso": 0.003089459888363371, "the probability that": 0.001159925504212466, "introducing": 0.0001588391732678592, "agent visited": 0.000971904517366954, "learning algorithm for": 0.0007010750178672042, "its adversary s": 0.0020596399255755804, "of the history": 0.0013498219883241157, "appendix": 0.00018492499062485924, "studied in machine": 0.0010298199627877902, "above consider": 0.0008730815719568182, "they should be": 0.0006749109941620578, "is used in": 0.0003651693276568247, "valued": 0.00019808061892815683, "any game": 0.000971904517366954, "times now": 0.0008730815719568182, "the new": 0.00014039749331145107, "stochastic games is": 0.003089459888363371, "pretend": 0.0007739936391863359, "that is typically": 0.0010298199627877902, "values": -0.0018389961334313006, "following": -0.008213299557314702, "the descriptive stance": 0.0010298199627877902, "is selected": 0.00036511734625786996, "that these payos": 0.0010298199627877902, "the expected": 0.002210359421966953, "will be s": 0.0010298199627877902, "equilibrium and learning": 0.0010298199627877902, "the rst which": 0.0010298199627877902, "awesome": 0.000872957307571399, "develop a denition": 0.0010298199627877902, "a general polynomial": 0.0010298199627877902, "that initially the": 0.0008732058717250353, "need to": 0.00026313998836604283, "and execute": 0.0006290164566258502, "line algorithms where": 0.0010298199627877902, "can view": 0.000557817444576059, "that simple dynamics": 0.0010298199627877902, "observe and update": 0.0010298199627877902, "player 2 s": 0.0010298199627877902, "or the": 0.00015474752600739777, "that any strategy": 0.0009310344469842923, "we get": 0.0007321165006174954, "speed of convergence": 0.0020596399255755804, "monitoring": 0.009612691531021733, "we initially do": 0.0010298199627877902, "repeated games 6": 0.0010298199627877902, "repeated games 5": 0.0010298199627877902, "optimal": -5.916281119352247e-05, "average payo": 0.001943809034733908, "vector i e": 0.0008002740946718667, "parameter": -1.972438954494502e-05, "great interest": 0.0007421847985653504, "improve robustness of": 0.0009310344469842923, "results for": 0.0002141035440250924, "at each of": 0.0007010750178672042, "at a desired": 0.0008732058717250353, "learning algorithms will": 0.0010298199627877902, "date": 0.0002550184271602697, "such": -0.006191949113490687, "revealed": 0.00037962257423597423, "that the": 2.9579377712310006e-05, "natural": -6.909243211173783e-05, "this line appear": 0.0010298199627877902, "su": 0.00018676151280474932, "st": 0.00029700648758495716, "and ai and": 0.0010298199627877902, "cannot": -0.0005770644562143593, "so": -0.0034665783520904333, "with incomplete information": 0.0018620688939685846, "our goal is": 0.0008966773322547537, "basic action": 0.0008730815719568182, "knowledge of t": 0.0009310344469842923, "pay a": 0.0007421847985653504, "actions such as": 0.0008732058717250353, "initially plays row": 0.0020596399255755804, "algorithm can": 0.00032046858343152956, "the speed of": 0.000552614435925888, "the players play": 0.0010298199627877902, "no information about": 0.0007521645399683924, "desired value after": 0.0010298199627877902, "on principles of": 0.0005811431115841947, "in the return": 0.0008732058717250353, "the learning algorithm": 0.002653646952338516, "more realistic but": 0.0010298199627877902, "hence in": 0.0005159204175055324, "it as": 0.0003517324423933467, "judgment of irrationality": 0.0010298199627877902, "g by": 0.00041030656060455343, "rules out": 0.0006939782666478507, "human behavior in": 0.0010298199627877902, "constitutes": 0.00030017084314280963, "the extension of": 0.0011267492712723848, "decreased": 0.0007695536288118463, "e assuming": 0.0007421847985653504, "the entry 6": 0.0010298199627877902, "compute and act": 0.0010298199627877902, "to stochastic games": 0.0010298199627877902, "11 and": 0.00033153889921396065, "we were": 0.0011390298391097315, "of ele instances": 0.0010298199627877902, "learning and ai": 0.0010298199627877902, "side payments": 0.006803331621568678, "which they": 0.0007302346925157399, "g1 and": 0.002445628931353963, "designed by": 0.0006164744968379118, "state not only": 0.0010298199627877902, "stick to": 0.002619244715870455, "lower than that": 0.0007521645399683924, "and so": 0.0002079740793332138, "surplus in": 0.000971904517366954, "approach in economics": 0.0010298199627877902, "bowling": 0.0026188719227141968, "to 10": 0.00043697553507468355, "and the corresponding": 0.00039949343125814357, "adversary deviates from": 0.0010298199627877902, "normative guidelines to": 0.0010298199627877902, "histories h": 0.000971904517366954, "follow naturally": 0.0008730815719568182, "increasing its payo": 0.0010298199627877902, "game 8 2": 0.0010298199627877902, "convergence stipulates": 0.000971904517366954, "resp g1": 0.001943809034733908, "common approach": 0.0006427395698875594, "some nash": 0.000971904517366954, "issues involved": 0.0006748149214226754, "self play": 0.002915713552100862, "irrationality as": 0.000971904517366954, "the classical approach": 0.0008732058717250353, "without loss": 0.0003067138737249001, "a joint": 0.0005942188284548949, "games 16 15": 0.0010298199627877902, "e polynomial": 0.0008730815719568182, "following theorem": 0.0003100542232769594, "related point": 0.000971904517366954, "one for": 0.00029393785638675104, "their algorithms regardless": 0.0010298199627877902, "sense justied": 0.000971904517366954, "this best action": 0.0010298199627877902, "possibility": 0.00011854670124325419, "quite": 8.44082258036532e-05, "in fact in": 0.0005811431115841947, "complicated": 0.00015228537331450805, "imperfect monitoring settings": 0.0020596399255755804, "knowng this variable": 0.0010298199627877902, "2 the probability": 0.0008002740946718667, "convergence after all": 0.0010298199627877902, "bayesian model": 0.0006578931655429611, "mixing time of": 0.002793103340952877, "immediately reduce the": 0.0010298199627877902, "of researchers in": 0.0009310344469842923, "wish to": 0.0005972485932628641, "equilibrium 1 the": 0.0010298199627877902, "always play defect": 0.0010298199627877902, "along this line": 0.0008732058717250353, "that a pair": 0.0010298199627877902, "action is a": 0.0018620688939685846, "learning rules that": 0.0020596399255755804, "pre determined selection": 0.0010298199627877902, "torre enforceable": 0.000971904517366954, "on the": 0.0, "the entry 1": 0.0010298199627877902, "one": 0, "is identical the": 0.0009310344469842923, "of learning strategies": 0.0010298199627877902, "class despite": 0.000971904517366954, "study of": 0.0005177308783751344, "sets of possible": 0.0010298199627877902, "cient learning equilibrium": 0.008238559702302322, "need however to": 0.0010298199627877902, "repeated games except": 0.0010298199627877902, "played with": 0.000971904517366954, "policy the second": 0.0010298199627877902, "ele provides a": 0.0010298199627877902, "2": 0, "view of": 0.0002748967592131235, "a player is": 0.0010298199627877902, "if we cannot": 0.0009310344469842923, "where its": 0.000774103816216825, "of vickrey clarke": 0.0010298199627877902, "entries in the": 0.0005578968604992618, "the issues involved": 0.0008002740946718667, "procedure that": 0.0005099512042140099, "we face": 0.0007421847985653504, "algorithms along this": 0.0010298199627877902, "value assumed repeat": 0.0010298199627877902, "k 2 the": 0.0007010750178672042, "introduction reinforcement learning": 0.0009310344469842923, "specied is not": 0.0010298199627877902, "york new york": 0.000663411738084629, "r max is": 0.0009310344469842923, "actions in a": 0.0009310344469842923, "possible history notice": 0.0010298199627877902, "payo as well": 0.0010298199627877902, "not increase the": 0.0007010750178672042, "players each of": 0.0010298199627877902, "games stochastic games": 0.0020596399255755804, "first consider the": 0.0006013538961527255, "dierent approach motivated": 0.0010298199627877902, "than that of": 0.00042425064540523185, "rewards obtained by": 0.0010298199627877902, "form of a": 0.0005159938685900292, "from now": 0.00046046251587537234, "future": -1.4788854253952322e-05, "where at": 0.0006427395698875594, "in general non": 0.0008732058717250353, "agents turn": 0.000971904517366954, "the netherlands": 0.000549963838367756, "exposition we": 0.0007421847985653504, "the standard notion": 0.0008732058717250353, "entry 1 500": 0.0010298199627877902, "side payments is": 0.0010298199627877902, "playing using multiplicative": 0.0009310344469842923, "say": -5.233771422221996e-05, "side payments in": 0.0010298199627877902, "of the sets": 0.00053318373443515, "agent initially": 0.003887618069467816, "games uses in": 0.0010298199627877902, "the near future": 0.001285662152181123, "point on when": 0.0010298199627877902, "instructed": 0.0007159746543399424, "note": -0.001424338172651668, "standard notion of": 0.0008732058717250353, "take": -0.0007915636653936049, "monitoring setup": 0.000971904517366954, "6 9": 0.0009973577212966454, "g and": 0.0008001465872011139, "robustness of distributed": 0.0010298199627877902, "12 2": 0.000549963838367756, "given class": 0.0013157863310859221, "by all": 0.00036281071874830087, "denition in": 0.0020244447642680263, "in fact": 0.00013729829394587933, "1 g1": 0.0008730815719568182, "matrix m dened": 0.0010298199627877902, "the best that": 0.0009310344469842923, "use simple heuristic": 0.0010298199627877902, "6 a": 0.00034336616306129136, "general context": 0.0008152096437846543, "average": 0.0007019116727334786, "increase the": 0.0002748967592131235, "player 1 deviates": 0.0020596399255755804, "where both": 0.0011497952046580816, "cient learning": 0.007857734147611364, "players a common": 0.0010298199627877902, "allow side payments": 0.0010298199627877902, "the prescribed strategies": 0.0010298199627877902, "laws": 0.0004197274689931713, "examine the case": 0.0008732058717250353, "reward first note": 0.0010298199627877902, "surplus": 0.0013494377520621391, "satisfy any rationality": 0.0010298199627877902, "second action by": 0.0010298199627877902, "which also": 0.00044065161687170207, "able to show": 0.0014661010563478836, "merit": 0.0005424277094845126, "describe a": 0.0003186897302660093, "algorithm to attain": 0.0010298199627877902, "game in a": 0.0010298199627877902, "to denote the": 0.0008311253039779468, "this paper address": 0.0010298199627877902, "too concerned": 0.000971904517366954, "introducing side": 0.000971904517366954, "such an adversary": 0.0008732058717250353, "later assume we": 0.0010298199627877902, "repeated games for": 0.0010298199627877902, "reinforcement procedure leading": 0.0010298199627877902, "know the game": 0.0010298199627877902, "criteria for learning": 0.0010298199627877902, "268 july 19": 0.0010298199627877902, "methodology in": 0.0006164744968379118, "we are learning": 0.0010298199627877902, "bi matrix this": 0.0010298199627877902, "considered irrational its": 0.0010298199627877902, "reinforcement learning stochastic": 0.0010298199627877902, "another in addition": 0.0009310344469842923, "greater than": 0.0003923692956262694, "computer science here": 0.0010298199627877902, "that if adopted": 0.0010298199627877902, "the idea is": 0.0008864289836066309, "same setting if": 0.0010298199627877902, "rests on showing": 0.0010298199627877902, "possible histories for": 0.0020596399255755804, "shneidman david c": 0.0010298199627877902, "learning payoff": 0.000971904517366954, "games the generalization": 0.0010298199627877902, "settings": 0.0014097647800075316, "this applies to": 0.0010298199627877902, "payments for the": 0.0010298199627877902, "borrow": 0.0005285471202254922, "a new joint": 0.0010298199627877902, "we describe a": 0.0004737656933058489, "where": -0.012144939768559251, "security level": 0.0007421847985653504, "canada david c": 0.0010298199627877902, "rst which": 0.000971904517366954, "a tuple": 0.00041656361432912804, "novel combination": 0.000971904517366954, "the game might": 0.0010298199627877902, "perfect monitoring 2": 0.0010298199627877902, "been proposed it": 0.0010298199627877902, "us": -0.00019047610901416596, "algorithms will be": 0.0008321458774498469, "the descriptive motivation": 0.0010298199627877902, "close to": 0.001080922133299522, "is an": 9.279769780355074e-05, "g see": 0.000557817444576059, "descriptive stance": 0.000971904517366954, "not always": 0.0009560691907980279, "show that there": 0.0005378088736942846, "the remaining sections": 0.0008002740946718667, "convergence as specied": 0.0010298199627877902, "has attracted the": 0.0009310344469842923, "we present in": 0.0005633746356361924, "known 1 the": 0.0010298199627877902, "instead our goal": 0.0010298199627877902, "perfect monitoring we": 0.003089459888363371, "policy to": 0.0006164744968379118, "as models of": 0.0008321458774498469, "payo p": 0.000971904517366954, "boella leendert van": 0.0010298199627877902, "learning near": 0.0008730815719568182, "plays defect the": 0.0010298199627877902, "autonomous": 0.0006948964578081959, "payo an": 0.000971904517366954, "noncooperative settings": 0.000971904517366954, "for in": 0.0008597459103893571, "many": -0.0016201756363710329, "strategies from that": 0.0010298199627877902, "face are": 0.0008730815719568182, "s": -0.024420627409832616, "the actual": 0.0006030743117944199, "a possibly": 0.00046046251587537234, "than the best": 0.0007330505281739418, "the required": 0.0006167525305437022, "first the": 0.0008122879116285782, "payo as": 0.000971904517366954, "more complicated a": 0.0010298199627877902, "social surplus we": 0.0010298199627877902, "our rst requirement": 0.0010298199627877902, "of steps": 0.0016662544573165122, "s behavior before": 0.0010298199627877902, "of equilibrium is": 0.0010298199627877902, "1 500": 0.0013879565332957013, "is close": 0.0007803103270961426, "combined": 0.00010705674809908032, "could have": 0.0008528775156025596, "called a game": 0.0010298199627877902, "wants": 0.00032403512727420655, "enable": 0.0001886117812523639, "stipulates that if": 0.0010298199627877902, "same learning": 0.0017461631439136364, "manifest in the": 0.0009310344469842923, "equilibrium and as": 0.0010298199627877902, "assumed repeat compute": 0.0010298199627877902, "are unique": 0.0006049243473022664, "an appropriate": 0.0002614473441041457, "observe": 0.00026168857111109976, "g2 is": 0.0008152096437846543, "and treats the": 0.0010298199627877902, "as specied is": 0.0010298199627877902, "s payo as": 0.0010298199627877902, "ele for a": 0.0010298199627877902, "for ease of": 0.000624803884002311, "carried out e": 0.0010298199627877902, "will go": 0.0006748149214226754, "be the": 0.0002490002795964919, "single": -0.00046710406475760643, "1 performs k": 0.0010298199627877902, "best action": 0.0008730815719568182, "equilibrium in stochastic": 0.0020596399255755804, "policies": 0.0018950686997976723, "were able to": 0.0005201099482447018, "repeat compute": 0.000971904517366954, "situation": 0.00012779681754850647, "denote the expected": 0.0008321458774498469, "we need to": 0.000539788671599923, "results are highly": 0.0010298199627877902, "the actual initially": 0.0010298199627877902, "learning algorithm can": 0.0008321458774498469, "that requires that": 0.0009310344469842923, "assumptions made": 0.0006290164566258502, "player 2 theorem": 0.0010298199627877902, "will converge to": 0.0014661010563478836, "equilibrium adaptive game": 0.0010298199627877902, "lower than the": 0.001249607768004622, "will behave in": 0.0010298199627877902, "behave in": 0.0006290164566258502, "behavior performing a": 0.0010298199627877902, "together our concepts": 0.0010298199627877902, "science and computational": 0.0010298199627877902, "cooperative multiagent systems": 0.0010298199627877902, "from that behavior": 0.0010298199627877902, "5 8 and": 0.0008732058717250353, "with appropriate side": 0.0010298199627877902, "actions for every": 0.0010298199627877902, "ai perspective": 0.001943809034733908, "with the understanding": 0.0008732058717250353, "see 9 and": 0.0010298199627877902, "would like": 0.00022040572533156756, "distributed algorithmic": 0.000971904517366954, "clarke groves mechanisms": 0.0010298199627877902, "but does": 0.0004333839769001314, "model partial": 0.0008730815719568182, "agent performed and": 0.0010298199627877902, "be s": 0.0006939782666478507, "update following": 0.000971904517366954, "the induced markov": 0.0010298199627877902, "we show that": 0.000279162272105921, "and act compute": 0.0010298199627877902, "the sequence of": 0.0008915109110165033, "be a": 0.000205375581233899, "complete information": 0.0006290164566258502, "is assumed to": 0.0004033618086640399, "t the average": 0.0009310344469842923, "not improved": 0.0008730815719568182, "that setting recall": 0.0010298199627877902, "include the side": 0.0009310344469842923, "about the": 0.0005678347583816781, "latter result is": 0.0009310344469842923, "dene the": 0.0008027176385274169, "typically used to": 0.0009310344469842923, "let be the": 0.000435831200377543, "while our": 0.0005748976023290408, "more constrained": 0.0008730815719568182, "being": -0.00014746540445299965, "resp": 0.0018203478179764357, "following constructive result": 0.0010298199627877902, "another in": 0.0005221368030860054, "the special": 0.0003698290826886664, "the proof of": 0.0003002563132006521, "in computer science": 0.0013055146579358122, "a function of": 0.00031465227566877173, "and perfect monitoring": 0.0010298199627877902, "t is the": 0.00041984698137044723, "to deviate": 0.004365407859784092, "treated as strategies": 0.0010298199627877902, "145 168": 0.000971904517366954, "interested in": 0.00045820296439404986, "action can be": 0.0017464117434500706, "aspects": 0.00014429486934358564, "both players behave": 0.0010298199627877902, "large enough": 0.0003796766130365772, "period": 0.00021201166110983413, "is g2 increasing": 0.0010298199627877902, "equal to": 0.0002965688045779744, "in reality the": 0.0007742140246189059, "games except": 0.000971904517366954, "provided": -5.489076014972739e-05, "this context of": 0.0009310344469842923, "the agents expected": 0.0010298199627877902, "lack of general": 0.0010298199627877902, "attempt to": 0.00026671552906703795, "replace concepts": 0.000971904517366954, "payo it obtained": 0.0010298199627877902, "is where both": 0.0020596399255755804, "value for player": 0.0020596399255755804, "game rg the": 0.0010298199627877902, "inter": 0.00020197611499329373, "stationary": 0.0010299518768170674, "iterations": 0.000870890571891628, "algorithms that converge": 0.0010298199627877902, "in question and": 0.0009310344469842923, "dene the notion": 0.0010298199627877902, "if one of": 0.0005425821592878966, "bayesian approach in": 0.0010298199627877902, "must be polynomial": 0.0009310344469842923, "human behavior we": 0.0010298199627877902, "attain the optimal": 0.0010298199627877902, "ele becomes irrational": 0.0010298199627877902, "iteration l then": 0.0020596399255755804, "be executed in": 0.000663411738084629, "known the": 0.0027125246169666804, "refer": -0.00014218345240337221, "results to that": 0.0010298199627877902, "modied to": 0.0006427395698875594, "often use": 0.0007421847985653504, "games appears in": 0.0010298199627877902, "i by": 0.0003560762920625211, "its payos": 0.001943809034733908, "cooperative systems we": 0.0010298199627877902, "phase is over": 0.0009310344469842923, "acm": -1.2322890326095277e-06, "so called": 0.0006234961713031152, "following state": 0.0008730815719568182, "l then u": 0.0010298199627877902, "not in line": 0.0020596399255755804, "act": 0.00029700648758495716, "such assumptions": 0.0007421847985653504, "agents can guarantee": 0.0010298199627877902, "executed for": 0.0006939782666478507, "state and": 0.0003796766130365772, "with incomplete": 0.0014321531448804085, "moreover convergence as": 0.0010298199627877902, "challenging setting first": 0.0010298199627877902, "attain the": 0.0008152096437846543, "learning should go": 0.0010298199627877902, "corresponding policies of": 0.0010298199627877902, "conceptually": 0.00030339130299607265, "the reader to": 0.000552614435925888, "technically": 0.0008394549379863426, "leendert van": 0.0008730815719568182, "player is a": 0.0010298199627877902, "g1 is": 0.0008152096437846543, "do so su": 0.0010298199627877902, "required to be": 0.0005943034268074654, "july 25 29": 0.0008002740946718667, "july 25 28": 0.0007742140246189059, "algorithm should become": 0.0010298199627877902, "complete": -7.69933625417051e-05, "however researches": 0.000971904517366954, "above a": 0.000549963838367756, "a common": 0.0008331103723965445, "sum game where": 0.0010298199627877902, "with": 0, "facing uncertainty about": 0.0010298199627877902, "line is": 0.000464748887987192, "initially has no": 0.0010298199627877902, "multiplicative weights": 0.0008152096437846543, "robustness": 0.00027908280661428827, "such as the": 0.00027821490529698044, "when the e": 0.0010298199627877902, "line in": 0.000464748887987192, "the player": 0.004076048218923272, "m hence": 0.0006939782666478507, "ai speed of": 0.0010298199627877902, "agent s osprings": 0.0010298199627877902, "ai": 0.0027795858312327838, "certain": -8.231876828458826e-05, "irrational for each": 0.0010298199627877902, "an": 0, "as": -0.04626673730128414, "at": -0.012383898226981374, "wish to obtain": 0.0020596399255755804, "once the": 0.0002653850764502335, "i one": 0.0006290164566258502, "theorems in economics": 0.0020596399255755804, "and column": 0.0005159204175055324, "response policy": 0.000971904517366954, "the context": 0.0010100243302084567, "ideally": 0.0003392841635235741, "covergent learning": 0.000971904517366954, "play some": 0.000971904517366954, "max a general": 0.0010298199627877902, "0 be": 0.0003517324423933467, "obtain high enough": 0.0010298199627877902, "note here is": 0.0008732058717250353, "agent deviates the": 0.0010298199627877902, "this learning strategy": 0.0010298199627877902, "acts as follows": 0.0010298199627877902, "2 will not": 0.0009310344469842923, "assume the": 0.00030181687348044, "out the": 0.0003117480856515576, "1 performs action": 0.0010298199627877902, "employed by the": 0.0007521645399683924, "has any motivation": 0.0010298199627877902, "taken in 2": 0.0010298199627877902, "rational agents": 0.000774103816216825, "approximately equal": 0.0006164744968379118, "in which the": 0.0005152474404303967, "joint action a": 0.0010298199627877902, "even more constrained": 0.0010298199627877902, "settings in": 0.00154820763243365, "impossibility": 0.000493272972217439, "in the more": 0.0006874022974519222, "treats the": 0.0006939782666478507, "consider": -0.0030898556304512024, "to have": 0.00015230705094772007, "plays b": 0.000971904517366954, "obtained for a": 0.0007330505281739418, "is pareto": 0.000971904517366954, "the twenty": 0.0005042097552001021, "close to an": 0.0008002740946718667, "repeated games in": 0.0010298199627877902, "note that this": 0.000360586940627226, "a class": 0.0002748967592131235, "the desired values": 0.0009310344469842923, "time t": 0.0006555402399983049, "prole which also": 0.0010298199627877902, "intuitive idea": 0.0008152096437846543, "dealing with economic": 0.0010298199627877902, "tr": 0, "ts": 0.00040720998722279956, "participating in": 0.0006427395698875594, "to": 0, "at least the": 0.0005943034268074654, "th": 0.00012004714744661106, "paper address these": 0.0010298199627877902, "an economically e": 0.003089459888363371, "complements to": 0.001943809034733908, "see by examining": 0.0010298199627877902, "first the agents": 0.0020596399255755804, "to what the": 0.0010298199627877902, "procedures that": 0.0006049243473022664, "learning is not": 0.0009310344469842923, "particular work": 0.000971904517366954, "in the particular": 0.0007521645399683924, "the times if": 0.0020596399255755804, "on e cient": 0.0009310344469842923, "action do": 0.000971904517366954, "initially unknown e": 0.0010298199627877902, "the history of": 0.0013748045949038444, "the payo obtained": 0.0010298199627877902, "researchers in": 0.0006578931655429611, "that here": 0.0006049243473022664, "strategy 2 if": 0.0010298199627877902, "perspective we": 0.0007160765724402042, "some time": 0.0005221368030860054, "if all agents": 0.0010298199627877902, "dierence player 2": 0.0010298199627877902, "the corresponding payos": 0.0010298199627877902, "attained e ciently": 0.0010298199627877902, "large": -0.00023355203237880321, "the denition can": 0.0010298199627877902, "to assess": 0.0004736982533495064, "adjust": 0.0002938960206542736, "on line": 0.0007696631738123888, "note that there": 0.0005243422169685006, "multiagent reinforcement": 0.0017461631439136364, "general class of": 0.0007330505281739418, "rewards and then": 0.0010298199627877902, "is its goal": 0.0010298199627877902, "played game": 0.000971904517366954, "are impossible": 0.000774103816216825, "in particular consider": 0.0008732058717250353, "past": 0.00020002028979370696, "constrained setting": 0.000971904517366954, "that are": 0.0001566616068595, "let be an": 0.0006013538961527255, "dierences": 0.0008964220867858512, "ele we must": 0.0010298199627877902, "used to": 0.0001304120923350243, "section": -0.003171282721352953, "it is participating": 0.0010298199627877902, "best it can": 0.0010298199627877902, "contrast": 6.519514543160869e-05, "settings what happens": 0.0010298199627877902, "these payos might": 0.0010298199627877902, "such interactions": 0.000971904517366954, "a model": 0.000544261575603426, "is greater than": 0.00037148284442569784, "combined choices": 0.000971904517366954, "that we have": 0.0003407149755618269, "formally part of": 0.0010298199627877902, "and the possible": 0.0009310344469842923, "line of related": 0.0010298199627877902, "bayes nash": 0.000971904517366954, "e ciently": 0.0023918856771468705, "following iterations": 0.0008730815719568182, "optimal reinforcement": 0.001943809034733908, "the notion of": 0.0018015378792039126, "observe its": 0.0008152096437846543, "model m 0": 0.0008002740946718667, "social": 0.0014798189166523171, "action": 0.005747877774484744, "these are unique": 0.0010298199627877902, "1 and k": 0.0006874022974519222, "possibly mixed action": 0.0010298199627877902, "correlated equilibrium a": 0.0010298199627877902, "no distribution is": 0.0010298199627877902, "the times": 0.000929497775974384, "followed": 0.00011709098103499112, "5 8": 0.00044065161687170207, "determined selection": 0.000971904517366954, "obtained by": 0.0010157352909747734, "of is the": 0.0006527573289679061, "desired value": 0.0029687391942614014, "payo was rst": 0.0010298199627877902, "we can online": 0.0010298199627877902, "we develop a": 0.0005633746356361924, "partial information is": 0.0010298199627877902, "select": 9.865459444348781e-05, "one that": 0.0003454193697900408, "e ciently finally": 0.0010298199627877902, "o k": 0.0009383165454816595, "to guarantee": 0.00034133740538055095, "policy prole which": 0.0010298199627877902, "6": -0.005011822580379597, "in equilibrium and": 0.0010298199627877902, "payo notice": 0.000971904517366954, "more": -0.011455594469439079, "expected payo obtained": 0.0020596399255755804, "parameter we": 0.0006748149214226754, "not care": 0.000774103816216825, "games under strict": 0.0010298199627877902, "the understanding": 0.0005842412659181877, "a nash ele": 0.0010298199627877902, "if it": 0.0002965688045779744, "dictated by that": 0.0010298199627877902, "except in the": 0.0007742140246189059, "setting we need": 0.0008732058717250353, "normative": 0.0057277972347195396, "5 a": 0.0002762949277458691, "this applies": 0.0008730815719568182, "against such an": 0.0010298199627877902, "suppose that we": 0.0005875760798754402, "science": 0.00011529766746928276, "which we simply": 0.0008732058717250353, "next to": 0.000549963838367756, "if the": 0.00013565502515329865, "to attain the": 0.0009310344469842923, "to the set": 0.00042203345812732713, "learn": 0.0008204095294794891, "equilibria concepts": 0.000971904517366954, "s and let": 0.0007521645399683924, "in that": 0.0008321182014204753, "and pretend that": 0.0010298199627877902, "initially unknown such": 0.0010298199627877902, "to nash": 0.000971904517366954, "them will attain": 0.0010298199627877902, "algorithm by a": 0.0007521645399683924, "ciently and": 0.0008152096437846543, "of steps will": 0.0010298199627877902, "the understanding of": 0.0006749109941620578, "states": -5.924436742114192e-05, "algorithms moreover": 0.0008152096437846543, "sense": 1.2330519779803883e-05, "payo vector": 0.000971904517366954, "exist some pre": 0.0010298199627877902, "information": -0.0014001420285559487, "theorists adopt a": 0.0010298199627877902, "the learning algorithms": 0.00837931002285863, "knowing the payo": 0.0010298199627877902, "lead to playing": 0.0010298199627877902, "models based": 0.0006049243473022664, "of the now": 0.0008732058717250353, "learning a survey": 0.0010298199627877902, "players hence in": 0.0010298199627877902, "function of the": 0.0003407149755618269, "the normative": 0.0008730815719568182, "agent to punish": 0.0010298199627877902, "out e": 0.0008152096437846543, "s total": 0.0006748149214226754, "much more fundamental": 0.0009310344469842923, "nding a": 0.0006290164566258502, "is if the": 0.0006749109941620578, "is given": 0.00011205669904345332, "an action": 0.0014210947600485193, "mapping": 8.905577850333232e-05, "it is clear": 0.00039385997938814706, "for t steps": 0.0009310344469842923, "shneidman distributed implementations": 0.0010298199627877902, "always g1": 0.000971904517366954, "develop": 9.865459444348781e-05, "algorithm by": 0.00044065161687170207, "algorithm as long": 0.0009310344469842923, "related point game": 0.0010298199627877902, "monitoring proof the": 0.0010298199627877902, "a novel combination": 0.0010298199627877902, "1 is dened": 0.0009310344469842923, "describe how the": 0.0006749109941620578, "learning in cooperative": 0.0020596399255755804, "the two": 0.00011492147504882952, "2 is similar": 0.0017464117434500706, "i m the": 0.0007742140246189059, "ease of exposition": 0.0008002740946718667, "this setting": 0.0009973577212966454, "p 145": 0.0006578931655429611, "fundamental": 0.00023709340248650838, "2 denote": 0.0006748149214226754, "regardless of": 0.0003517324423933467, "max we": 0.0006939782666478507, "action and": 0.0017527237977545634, "reward of the": 0.0020596399255755804, "player 1 performs": 0.0020596399255755804, "the strategy of": 0.0008002740946718667, "could have done": 0.0010298199627877902, "paper": -0.0013686818123552775, "e 2": 0.0004230779228348551, "its": -0.022195214284538214, "we could have": 0.000663411738084629, "convergence is of": 0.0010298199627877902, "rapidly": 0.0004903975513068897, "termed": 0.0007395528909444583, "as consisting": 0.0006748149214226754, "polynomial time we": 0.0007742140246189059, "not exist": 0.00037467912962542367, "for every agent": 0.0010298199627877902, "play they do": 0.0010298199627877902, "the setting": 0.000542504923393336, "two cases": 0.0003373507152868544, "in e ciency": 0.0010298199627877902, "to show that": 0.0014750548186682852, "is based": 0.0001222294119626361, "e m": 0.0005354021517001512, "agents to": 0.0013157863310859221, "are in": 0.00016727689319632073, "e i": 0.0003560762920625211, "e g": 0.00018905792776059888, "e a": 0.0007179831900854835, "this algorithm learns": 0.0009310344469842923, "that no": 0.000242850915721573, "replace concepts that": 0.0010298199627877902, "the value of": 0.00023975037128866865, "polynomial bound on": 0.0009310344469842923, "always": -0.0014746540445299966, "follow normative": 0.000971904517366954, "to sets": 0.0005942188284548949, "repeated common interest": 0.0010298199627877902, "each possible": 0.0005159204175055324, "repeated games m": 0.0010298199627877902, "a xed sequence": 0.0009310344469842923, "of the denition": 0.0008002740946718667, "reduce": -1.9748122473713975e-05, "of these": 5.2345164430650154e-05, "when the players": 0.0010298199627877902, "to be using": 0.0008732058717250353, "theoretic literature on": 0.0010298199627877902, "the situation": 0.00033153889921396065, "psychology": 0.0007159746543399424, "all the entries": 0.0007742140246189059, "not care about": 0.0008732058717250353, "ele but": 0.001943809034733908, "research": -0.0004683639241399645, "denoted": -4.314305566213696e-05, "discounting": 0.0006426480897324373, "to better align": 0.0010298199627877902, "and less": 0.0005159204175055324, "rst requirement then": 0.0010298199627877902, "actions that": 0.0005942188284548949, "maintains information": 0.0008730815719568182, "reinforcement procedure": 0.000971904517366954, "to nash ele": 0.0010298199627877902, "see the": 0.00028786948439001953, "assumptions a": 0.0006939782666478507, "multi agent systems": 0.002103225053601613, "imagine": 0.00039560335398297115, "of related work": 0.0006527573289679061, "learning in a": 0.0008732058717250353, "class despite the": 0.0010298199627877902, "and all states": 0.0010298199627877902, "implications of": 0.00047837713542937403, "a learning equilibria": 0.0010298199627877902, "2 to": 0.00022910148219702493, "monitoring settings": 0.001943809034733908, "more ambitious objective": 0.0010298199627877902, "must be": 0.00017678081460855544, "maximizes min": 0.000971904517366954, "in strategic form": 0.0020596399255755804, "is of": 0.00040204954119627993, "had ages to": 0.0010298199627877902, "setting is that": 0.0010298199627877902, "major": 0.00020730478897596107, "max 3 r": 0.0010298199627877902, "well note": 0.000971904517366954, "rules for updating": 0.0010298199627877902, "it turns out": 0.0004509656222210493, "we had": 0.00044065161687170207, "number": -0.004126775898635201, "actions selected": 0.000971904517366954, "values the": 0.0003698290826886664, "set of both": 0.0008732058717250353, "plays cooperate": 0.000971904517366954, "action it used": 0.0010298199627877902, "rg m and": 0.0010298199627877902, "guess": 0.0003650653796557838, "introduction": 0, "proposed before": 0.0008152096437846543, "and understand": 0.0008152096437846543, "st john s": 0.0008002740946718667, "second which": 0.0007421847985653504, "is initially": 0.0005099512042140099, "ctr jeffrey shneidman": 0.0010298199627877902, "in economics and": 0.0020596399255755804, "should follow": 0.0008152096437846543, "games that may": 0.0010298199627877902, "in noncooperative": 0.000971904517366954, "idea behind": 0.000464748887987192, "and we": 0.0002593576394352413, "since the game": 0.0010298199627877902, "immediate": 0.00019808061892815683, "time the denition": 0.0010298199627877902, "such as": 5.3620803353469175e-05, "0 and the": 0.0004865784002866409, "deviator s payo": 0.0010298199627877902, "with descriptive models": 0.0010298199627877902, "non trivial rests": 0.0010298199627877902, "alone the denitions": 0.0010298199627877902, "uses in": 0.0006578931655429611, "determines": 0.00021694849190062533, "converge to": 0.0037895860267960512, "notion of convergence": 0.0010298199627877902, "deviator": 0.000872957307571399, "maximal social surplus": 0.0010298199627877902, "on the existence": 0.0006749109941620578, "and perfect": 0.000774103816216825, "determined": -6.435129682801354e-05, "and let t": 0.0006335389089667411, "to the case": 0.0008864289836066309, "r max a": 0.0010298199627877902, "game theory": 0.00501253600708143, "for the": 1.2324644474184386e-05, "defect": 0.002376537016735347, "it is useful": 0.0005378088736942846, "obtained for": 0.00036053561152535736, "deviate from the": 0.0008732058717250353, "is participating": 0.0008730815719568182, "the punishment remains": 0.0010298199627877902, "a vector of": 0.0005159938685900292, "been played": 0.001943809034733908, "is identical": 0.001221803859171839, "prove the": 0.0008373676011125933, "of what": 0.0003901551635480713, "extension to stochastic": 0.0010298199627877902, "with complete information": 0.0008732058717250353, "parkes jeffrey": 0.000971904517366954, "self": 0.0005493057326377795, "other agents": 0.0006427395698875594, "will immediately": 0.0007421847985653504, "also": -0.008591695852079308, "maximin this is": 0.0010298199627877902, "by game": 0.000971904517366954, "one another in": 0.0006874022974519222, "the uncertain": 0.0008730815719568182, "the class of": 0.0011391920016722472, "play": 0.0038195248112911496, "p and he": 0.0010298199627877902, "to payos": 0.000971904517366954, "obtain the": 0.00020397751600166201, "result with": 0.0006290164566258502, "dierence player": 0.000971904517366954, "of nash": 0.0017461631439136364, "m and a": 0.0006874022974519222, "impossibility result": 0.000774103816216825, "results we prove": 0.0010298199627877902, "we use the": 0.00024209723165078393, "to guarantee that": 0.0005425821592878966, "sandholm": 0.0007159746543399424, "time t consists": 0.0010298199627877902, "denitely desirable": 0.000971904517366954, "deviations": 0.00041334544264567334, "this policy to": 0.0010298199627877902, "e cient outcome": 0.0010298199627877902, "cover": 0.00023813263627527116, "introduce efficient": 0.000971904517366954, "necessarily converge to": 0.0009310344469842923, "the attention": 0.0006748149214226754, "s reward": 0.000971904517366954, "take an": 0.0006427395698875594, "behavior but": 0.0008152096437846543, "applies to": 0.0003771588365708351, "algorithms is": 0.00043697553507468355, "over all agents": 0.0009310344469842923, "it is based": 0.00053318373443515, "algorithms in": 0.0008547245552498751, "these issues in": 0.0007521645399683924, "agent in both": 0.0010298199627877902, "g for": 0.00037467912962542367, "of time the": 0.0006165622637081906, "players follow": 0.000971904517366954, "sum games": 0.0008730815719568182, "nash equilibrium": 0.012223142007395457, "view a repeated": 0.0010298199627877902, "agent deviate": 0.000971904517366954, "formally assume": 0.0008730815719568182, "approach taken in": 0.0007330505281739418, "can be positive": 0.0008321458774498469, "third annual": 0.0007160765724402042, "yoav": 0.0006747188760310696, "converges in self": 0.0010298199627877902, "to do in": 0.0008732058717250353, "that within t": 0.0010298199627877902, "choose to": 0.0004264387578012798, "action fassumed knowng": 0.0010298199627877902, "columns": 0.00020002028979370696, "convergence adopted by": 0.0010298199627877902, "29 2005 the": 0.0008732058717250353, "some positive constant": 0.0010298199627877902, "games is immediate": 0.0010298199627877902, "mainly concerned with": 0.0009310344469842923, "maximin value that": 0.0010298199627877902, "history namely": 0.000971904517366954, "closely": 0.00014429486934358564, "m and": 0.0010668621162681518, "not been proposed": 0.0010298199627877902, "are highly valuable": 0.0010298199627877902, "agent replaces its": 0.0010298199627877902, "j th": 0.00043697553507468355, "they would": 0.000557817444576059, "2 has signicant": 0.0010298199627877902, "be positive": 0.0005748976023290408, "our impossibility result": 0.0010298199627877902, "8 is mainly": 0.0010298199627877902, "set": -0.0070691289870568105, "notice also": 0.0006164744968379118, "is done": 0.00020596711500872958, "be non": 0.00046915827274082977, "see": -0.0016386173448577038, "employed by": 0.0005661109047770705, "when the joint": 0.0020596399255755804, "are initially": 0.000557817444576059, "in the case": 0.0012104861582539197, "agents can do": 0.0010298199627877902, "exist one": 0.0006427395698875594, "e cient joint": 0.0010298199627877902, "similar to": 9.247359675191711e-05, "action by": 0.0008152096437846543, "times if": 0.002226554395696051, "designed similarly but": 0.0010298199627877902, "deviation from": 0.001887049369877551, "available": -0.00012520855054594932, "rst time update": 0.0010298199627877902, "heuristic": 0.00018676151280474932, "with the agent": 0.0009310344469842923, "consider games": 0.000971904517366954, "to note here": 0.0007742140246189059, "point if": 0.0005842412659181877, "should e ciently": 0.0010298199627877902, "remain consistent": 0.000971904517366954, "mixed strategies probabilistic": 0.0010298199627877902, "a of": 0.0003496018060391435, "improved": 5.489076014972741e-05, "have multiple games": 0.0010298199627877902, "of deviators in": 0.0010298199627877902, "extend our results": 0.0008732058717250353, "should be an": 0.0009310344469842923, "we start with": 0.00048327283506710686, "lead to the": 0.0005159938685900292, "the denition for": 0.0016642917548996938, "for any xed": 0.0007161785195604264, "here an extension": 0.0010298199627877902, "algorithm as a": 0.0006874022974519222, "players behave according": 0.0020596399255755804, "has no": 0.0002954867076473726, "corresponds": -5.617053686364201e-05, "minimizing the": 0.00035829109812661935, "for nding the": 0.0008002740946718667, "probability distribution": 0.00040135881926370846, "to be in": 0.0004648150538311537, "agents": 0.01460261518623135, "it gets in": 0.0010298199627877902, "done had": 0.000971904517366954, "using the": 7.436740192558509e-05, "of an equilibrium": 0.0010298199627877902, "b we say": 0.0008002740946718667, "43 may": 0.000971904517366954, "matrix this": 0.0006427395698875594, "above we know": 0.0009310344469842923, "solution is": 0.00029087875337945615, "beyond recommending behavior": 0.0010298199627877902, "and related": 0.0003796766130365772, "relax the perfect": 0.0010298199627877902, "others stick to": 0.0010298199627877902, "natural candidate the": 0.0010298199627877902, "be economically e": 0.0020596399255755804, "the approximation": 0.0004042861100519966, "games in game": 0.0010298199627877902, "a value that": 0.0007010750178672042, "uncertain": 0.0005041379917849015, "strategies in": 0.0005286223582497236, "exponential": 0.0003379350088270865, "punishment remains": 0.000971904517366954, "algorithm itself as": 0.0009310344469842923, "to learning should": 0.0010298199627877902, "concepts introduced in": 0.0010298199627877902, "strategies is": 0.0008730815719568182, "the study of": 0.0009475313866116978, "non negative reals": 0.0008002740946718667, "agent interaction in": 0.0010298199627877902, "sizes is trivial": 0.0010298199627877902, "behavior 2 this": 0.0010298199627877902, "descriptive models of": 0.0010298199627877902, "individually rational": 0.002915713552100862, "we would": 0.0004159481586664276, "indeed in": 0.0005842412659181877, "a dierent": 0.00046915827274082977, "for quite": 0.0008152096437846543, "should satisfy": 0.0006164744968379118, "rate moreover convergence": 0.0010298199627877902, "that each": 0.0005095590740517288, "ele exists with": 0.0010298199627877902, "is easy to": 0.000567943721347027, "in equilibrium in": 0.0010298199627877902, "the action the": 0.0008002740946718667, "e ciency": 0.0021144894329988943, "updating their behavior": 0.0010298199627877902, "to lead": 0.0005942188284548949, "obtain a corresponding": 0.0010298199627877902, "the total payo": 0.0010298199627877902, "our benchmark": 0.0008730815719568182, "in equilibrium it": 0.0010298199627877902, "agent will": 0.0020244447642680263, "deviate from its": 0.0009310344469842923, "game another appealing": 0.0010298199627877902, "convergence as": 0.0007421847985653504, "correlated equilibrium": 0.001943809034733908, "monitoring case is": 0.0010298199627877902, "columns correspond to": 0.0008732058717250353, "at any point": 0.0005749794499375729, "learning in general": 0.0020596399255755804, "games technically speaking": 0.0010298199627877902, "rationality the": 0.000971904517366954, "plays defect": 0.000971904517366954, "as with the": 0.0005578968604992618, "recent": 5.233771422221995e-05, "initially unknown game": 0.0010298199627877902, "action a": 0.0017246928069871226, "makes": -0.0001382031926506407, "signicant merit": 0.000971904517366954, "to playing the": 0.0010298199627877902, "above constitutes": 0.000971904517366954, "concrete": 0.00024760932355138087, "friend or foe": 0.0010298199627877902, "games and we": 0.0010298199627877902, "agents and": 0.0010708043034003023, "based approach the": 0.0008732058717250353, "refer to": 0.0004496606204971023, "should follow normative": 0.0010298199627877902, "york yevgeniy vorobeychik": 0.0010298199627877902, "trying to minimize": 0.0008002740946718667, "own much like": 0.0010298199627877902, "understand the issues": 0.0010298199627877902, "perfect monitoring assumption": 0.0010298199627877902, "punish the adversary": 0.0010298199627877902, "negative reals": 0.0007160765724402042, "denote the": 0.0010046947407815067, "at each iteration": 0.0005943034268074654, "introduction reinforcement": 0.0008730815719568182, "contradicting": 0.0005158469873294001, "of at most": 0.0010085630780981543, "some positive": 0.0006748149214226754, "that corresponds": 0.000464748887987192, "readers": 0.00034744822890409797, "we initially": 0.0007160765724402042, "it can": 9.042750208413418e-05, "strategies probabilistic": 0.000971904517366954, "similar we dene": 0.0010298199627877902, "need only o": 0.0010298199627877902, "need only a": 0.0010298199627877902, "input": -6.389840877425322e-05, "distributed computing july": 0.0007521645399683924, "will attain": 0.001943809034733908, "our denition of": 0.0007161785195604264, "based on its": 0.0006428310760905615, "possible actions consider": 0.0010298199627877902, "not play some": 0.0010298199627877902, "in games looking": 0.0010298199627877902, "policy will be": 0.0020596399255755804, "if all": 0.0005151740955990187, "stochastic games stochastic": 0.0020596399255755804, "deviating player s": 0.0010298199627877902, "game theory diers": 0.0010298199627877902, "value of agent": 0.0010298199627877902, "agents will reach": 0.0010298199627877902, "when the": 0.0002937262320865847, "case finally we": 0.0009310344469842923, "property pursued": 0.000971904517366954, "chooses some": 0.0008730815719568182, "which is common": 0.0008732058717250353, "monetary payments is": 0.0010298199627877902, "games in which": 0.0017464117434500706, "motivation underlying learning": 0.0010298199627877902, "which both players": 0.0009310344469842923, "which we": 0.0001588617838263315, "m let": 0.000549963838367756, "an action at": 0.0009310344469842923, "1 deviates from": 0.0020596399255755804, "instructed to pay": 0.0010298199627877902, "1 the denition": 0.0010298199627877902, "reals between": 0.000971904517366954, "play column 1": 0.0010298199627877902, "here the dierences": 0.0010298199627877902, "the spirit of": 0.002499215536009244, "the spirit": 0.002264443619108282, "is an e": 0.0008002740946718667, "be a parameter": 0.0008002740946718667, "improved after polynomially": 0.0010298199627877902, "which is described": 0.000663411738084629, "player can": 0.002619244715870455, "parameters and": 0.0003848315869061944, "and its": 0.0003043523601279354, "behave": 0.0010200737086410788, "too 2 if": 0.0010298199627877902, "respectively the": 0.00025008444186787576, "g2 is where": 0.0010298199627877902, "be": 0, "a novel": 0.0011786519316866566, "bi": 0.00041334544264567334, "enough value": 0.000971904517366954, "veloso": 0.0023219809175590075, "to this": 0.00014510504156782479, "become irrational": 0.001943809034733908, "content i e": 0.0010298199627877902, "dictated": 0.00048313526807733544, "by": 0, "becomes irrational": 0.000971904517366954, "observed throughout this": 0.0010298199627877902, "to the security": 0.0008321458774498469, "chain is ergodic": 0.0010298199627877902, "computational": -2.4646242544066226e-06, "games is the": 0.0010298199627877902, "into": -0.0005285471202254922, "integral": 0.00027072409997109604, "context of repeated": 0.0010298199627877902, "money to": 0.0008730815719568182, "though imperfect technique": 0.0010298199627877902, "appropriate": -0.0004939126097075296, "monitoring case": 0.002915713552100862, "called a": 0.00025505472871573733, "closely and": 0.000971904517366954, "gence and convergence": 0.0010298199627877902, "the players if": 0.0010298199627877902, "its previous observations": 0.0010298199627877902, "variable with": 0.0005159204175055324, "the players in": 0.0010298199627877902, "the algorithm in": 0.0004934134257972276, "that is played": 0.0010298199627877902, "modied first the": 0.0010298199627877902, "the algorithm is": 0.00036210043856606787, "a pareto e": 0.0010298199627877902, "suit": 0.0005941342541838367, "and surprisingly has": 0.0010298199627877902, "then his utility": 0.0010298199627877902, "can observe its": 0.0010298199627877902, "considerably": 0.00022467793007595, "of its": 0.00017137564199155834, "players the adversary": 0.0010298199627877902, "mix in": 0.0017461631439136364, "by resorting": 0.0008152096437846543, "i by and": 0.0010298199627877902, "2007 rob powers": 0.0010298199627877902, "in more": 0.0003083762652718511, "pareto ele we": 0.0010298199627877902, "mix is": 0.000774103816216825, "assess the speed": 0.0010298199627877902, "line": -0.00032756284936154956, "have perfect monitoring": 0.0010298199627877902, "ai and must": 0.0010298199627877902, "of lesser": 0.000971904517366954, "most times": 0.000774103816216825, "have to select": 0.0009310344469842923, "is at": 0.00018863862990449944, "take t": 0.0008152096437846543, "of a class": 0.000552614435925888, "is as": 0.00021828498298308586, "the proof": 0.0005771466006209378, "the class": 0.0008122879116285782, "playing each": 0.000971904517366954, "view the designer": 0.0010298199627877902, "mix is known": 0.0010298199627877902, "take a": 0.00035829109812661935, "agent acts as": 0.0010298199627877902, "far in the": 0.0008002740946718667, "moreover we": 0.0012402128455637725, "with corresponding rg": 0.0010298199627877902, "with the game": 0.0009310344469842923, "what we need": 0.0007161785195604264, "payos the": 0.000971904517366954, "as the agent": 0.0008732058717250353, "appropriate payos as": 0.0010298199627877902, "psychology experimental economics": 0.0010298199627877902, "some previously": 0.0008730815719568182, "which also allows": 0.0010298199627877902, "vorobeychik michael": 0.000971904517366954, "g 11": 0.0006748149214226754, "and agent": 0.0006427395698875594, "than the probabilistic": 0.0010298199627877902, "repeatedly we": 0.0008730815719568182, "we assume the": 0.0004800375137323266, "by nv i": 0.0010298199627877902, "appears in section": 0.0007742140246189059, "dynamics lead": 0.000971904517366954, "here theorem": 0.0008152096437846543, "does not depend": 0.00048327283506710686, "games looking for": 0.0010298199627877902, "hence we": 0.00030181687348044, "deviate": 0.0033464283075549228, "deviators in": 0.000971904517366954, "some xed stochastic": 0.0010298199627877902, "been carried out": 0.0006165622637081906, "players combined": 0.000971904517366954, "be replaced": 0.00039848399477585494, "numerically in the": 0.0008732058717250353, "following theorem 6": 0.0009310344469842923, "irrational for": 0.000971904517366954, "while in the": 0.00053318373443515, "player 2 is": 0.0020596399255755804, "with m and": 0.0015484280492378119, "compute the side": 0.0010298199627877902, "mix in which": 0.0010298199627877902, "can adjust": 0.0007160765724402042, "algorithm": -0.007632419799954027, "played with a": 0.0010298199627877902, "denition": 0.0026194589990279826, "our goal": 0.0006826748107611019, "examples of": 0.0002476445704301782, "at time t": 0.00047686941115904235, "stance are": 0.000971904517366954, "having": -2.719260415068449e-05, "a fundamental": 0.0004072679530572796, "receive identical": 0.0008730815719568182, "partial": 9.198087715557318e-05, "were also able": 0.0010298199627877902, "histories of": 0.000774103816216825, "u s thus": 0.0010298199627877902, "results": -0.00547472724942111, "on a novel": 0.0008732058717250353, "phase each agent": 0.0010298199627877902, "e ciency a": 0.0010298199627877902, "that may be": 0.0004865784002866409, "recall that we": 0.0005749794499375729, "the action": 0.002149364775973393, "by examining the": 0.0006165622637081906, "the fact that": 0.0007848503137171248, "then the": 9.833004687995318e-05, "concerned": 0.0005770644562143593, "only economically": 0.000971904517366954, "we believe": 0.0002805523466765939, "assumption in that": 0.0010298199627877902, "261 268 july": 0.0010298199627877902, "payment structure guarantees": 0.0010298199627877902, "the dierence player": 0.0010298199627877902, "be approximated by": 0.0012331245274163811, "process k": 0.000971904517366954, "situation where": 0.0004832040417809763, "of a game": 0.0010298199627877902, "value in time": 0.0010298199627877902, "of rewards and": 0.0010298199627877902, "examine the": 0.0003560762920625211, "mixing": 0.002642735601127461, "state the agents": 0.0010298199627877902, "prole in m": 0.0010298199627877902, "fundamental decision that": 0.0010298199627877902, "games immediately rules": 0.0010298199627877902, "been carried": 0.000542504923393336, "experimental economics machine": 0.0010298199627877902, "try": 0.0001588391732678592, "setting a player": 0.0010298199627877902, "structure guarantees": 0.0008730815719568182, "systems that is": 0.0008732058717250353, "an imperfect monitoring": 0.0020596399255755804, "work bowling": 0.000971904517366954, "by repeating": 0.0006748149214226754, "as in the": 0.0005118633735628682, "literature on equilibrium": 0.0010298199627877902, "strategies probabilistic actions": 0.0010298199627877902, "common approach in": 0.0010298199627877902, "values if": 0.0005748976023290408, "the proof for": 0.0005690630947869114, "q learning": 0.0008730815719568182, "dynamics": 0.0008372484198428646, "games started with": 0.0010298199627877902, "equilibrium denition in": 0.0010298199627877902, "player repeated": 0.001943809034733908, "property as we": 0.0009310344469842923, "k times": 0.000549963838367756, "player 2 performs": 0.0020596399255755804, "used to assess": 0.0009310344469842923, "will predict human": 0.0010298199627877902, "in games uses": 0.0010298199627877902, "union of the": 0.0005159938685900292, "approach makes no": 0.0010298199627877902, "is termed": 0.0006049243473022664, "t efficient learning": 0.0010298199627877902, "respectively": -0.00017242978035012288, "assigned the": 0.0004933431890106373, "that are based": 0.0006428310760905615, "7 where special": 0.0010298199627877902, "to select": 0.0003296442778898719, "rule leads": 0.000971904517366954, "let": -0.0022504396295326564, "rst requirement": 0.0008730815719568182, "in noncooperative settings": 0.0010298199627877902, "unknown game to": 0.0010298199627877902, "michael p": 0.0008730815719568182, "it could have": 0.0008002740946718667, "we refer to": 0.0006814299511236538, "as a strategy": 0.0009310344469842923, "player s payo": 0.0010298199627877902, "great": 0.0002161536574559961, "ctr": -0.00020394848418896612, "a corresponding": 0.0003771588365708351, "receive": 0.0005770644562143593, "involved": 0.00010722634317054398, "times if the": 0.0017464117434500706, "contradicting ele but": 0.0010298199627877902, "g1 2": 0.000971904517366954, "introduced in": 0.0002563168538695653, "survey": 0.00015554349330363786, "0 in g": 0.0008732058717250353, "performed for": 0.0004832040417809763, "side payments so": 0.0010298199627877902, "that will": 0.0018012814325307162, "where c": 0.00036745646293076414, "not exclude": 0.0008152096437846543, "knows its adversary": 0.0010298199627877902, "we prove": 0.0011819468305894903, "given some": 0.0006049243473022664, "boolean valued": 0.0007421847985653504, "to use": 0.0003733419910166501, "singh learning": 0.000971904517366954, "payo was": 0.000971904517366954, "tools": 0.00014272193707343892, "set of players": 0.0010298199627877902, "did choose to": 0.0010298199627877902, "pareto ele a": 0.0010298199627877902, "parkes jeffrey shneidman": 0.0010298199627877902, "reward because": 0.000971904517366954, "setup all that": 0.0010298199627877902, "in time polynomial": 0.0014021500357344085, "appendix 4": 0.0008730815719568182, "next": -0.0013673492157991486, "cases we were": 0.0010298199627877902, "he known in": 0.0010298199627877902, "veloso suggest two": 0.0010298199627877902, "imperfect monitoring setup": 0.0010298199627877902, "constant sum": 0.000971904517366954, "observe following the": 0.0010298199627877902, "guarantee that an": 0.0010298199627877902, "is what they": 0.0010298199627877902, "can accomplish on": 0.0020596399255755804, "generalize our results": 0.0009310344469842923, "algorithms regardless of": 0.0009310344469842923, "cient i e": 0.0010298199627877902, "payoff functions in": 0.0010298199627877902, "results cannot": 0.0008730815719568182, "this": 0, "rewards of this": 0.0010298199627877902, "are the the": 0.0010298199627877902, "do not know": 0.0005425821592878966, "rewards r in": 0.0010298199627877902, "state the return": 0.0010298199627877902, "show that the": 0.00025509104060763877, "process": -0.00014906333536586383, "we make": 0.0003067138737249001, "general sum": 0.002619244715870455, "convergence of a": 0.0007742140246189059, "choosing each": 0.000971904517366954, "purposes": 0.000133447269920425, "high": -0.0002488592358755069, "we also": 0.0005638705218535063, "algorithms satisfying": 0.000971904517366954, "as if its": 0.0020596399255755804, "are attractive but": 0.0010298199627877902, "second the descriptive": 0.0010298199627877902, "an agent deviates": 0.0010298199627877902, "of equilibrium in": 0.0010298199627877902, "here the": 0.0002614473441041457, "equilibrium or": 0.000971904517366954, "2 this": 0.00025380054655457654, "agents 3 a": 0.0010298199627877902, "average payo to": 0.0010298199627877902, "equilibrium of": 0.006984652575654546, "of rewards of": 0.0010298199627877902, "algorithm termed": 0.0008730815719568182, "behavior that corresponds": 0.0010298199627877902, "to this context": 0.0010298199627877902, "agent acts": 0.000971904517366954, "viewed as an": 0.0006165622637081906, "the payo": 0.004859522586834771, "in the imperfect": 0.002793103340952877, "maximizes u we": 0.0010298199627877902, "2 from": 0.0004072679530572796, "but crucial": 0.000971904517366954, "that no agent": 0.0010298199627877902, "where the game": 0.0010298199627877902, "the same algorithm": 0.0006527573289679061, "not of great": 0.0010298199627877902, "stochastically the identity": 0.0010298199627877902, "so that": 0.00010425165746807497, "prole that maximizes": 0.0010298199627877902, "games looking": 0.000971904517366954, "are not required": 0.0007161785195604264, "such that": 0.0002556300185326139, "michael p wellman": 0.0010298199627877902, "appear in": 0.00028344496914384004, "to rational": 0.0008730815719568182, "3 a deviation": 0.0010298199627877902, "allow": -6.260427527297466e-05, "show that this": 0.0004865784002866409, "the basic idea": 0.00042425064540523185, "game a": 0.0008730815719568182, "heuristic rules for": 0.0010298199627877902, "we also take": 0.0008732058717250353, "game g": 0.006803331621568678, "game i": 0.000971904517366954, "quickly lead to": 0.0020596399255755804, "move": 0.0001395999506136815, "t iterations": 0.0008730815719568182, "game m": 0.003887618069467816, "polynomial time": 0.0018026780576267869, "such that paid": 0.0010298199627877902, "agents to use": 0.0010298199627877902, "game s": 0.000971904517366954, "we take in": 0.0009310344469842923, "others stick": 0.000971904517366954, "learner will": 0.000971904517366954, "is whether this": 0.0009310344469842923, "game the players": 0.0009310344469842923, "perfect": 0.0033338569078537965, "the the policy": 0.0010298199627877902, "negative or zero": 0.0010298199627877902, "1 plays a": 0.0010298199627877902, "prole executed": 0.000971904517366954, "chosen": -4.85235677441778e-05, "high as": 0.000542504923393336, "issues first": 0.0008730815719568182, "corresponding policies": 0.0008730815719568182, "payo is at": 0.0010298199627877902, "the design of": 0.0003447812898412679, "games m": 0.000971904517366954, "states the": 0.00046915827274082977, "cooperate too": 0.000971904517366954, "defect too": 0.000971904517366954, "games b": 0.000971904517366954, "their prescribed learning": 0.0010298199627877902, "games a": 0.0008152096437846543, "2 then they": 0.0009310344469842923, "the set of": 0.0009766801016958013, "learns a best": 0.0010298199627877902, "strategy prole": 0.001943809034733908, "9 and the": 0.0007010750178672042, "the other agents": 0.0007742140246189059, "elds for quite": 0.0010298199627877902, "game 8": 0.000971904517366954, "8 is": 0.0004042861100519966, "are people i": 0.0010298199627877902, "in xed sum": 0.0010298199627877902, "t 0 and": 0.0006428310760905615, "better align": 0.000971904517366954, "us try and": 0.0010298199627877902, "to see": 0.0005173629765437566, "of policies for": 0.0010298199627877902, "from the normative": 0.0010298199627877902, "in infinite games": 0.0010298199627877902, "with complete": 0.0006164744968379118, "naturally given an": 0.0010298199627877902, "games 5": 0.000971904517366954, "games 1": 0.000971904517366954, "at least": 0.00026313998836604283, "hand these results": 0.0010298199627877902, "a decreased value": 0.0010298199627877902, "agents for each": 0.0010298199627877902, "common knowledge": 0.0008730815719568182, "information game theory": 0.0010298199627877902, "algorithm described": 0.00043697553507468355, "perfect monitoring": 0.012634758725770402, "the ele algorithm": 0.004119279851151161, "m we denote": 0.0009310344469842923, "social surplus in": 0.0010298199627877902, "actual initially": 0.000971904517366954, "payments as part": 0.0010298199627877902, "equilibrium behavior": 0.000971904517366954, "algorithm when adopted": 0.0010298199627877902, "pareto": 0.011470220892528181, "under the following": 0.0008002740946718667, "economics machine learning": 0.0010298199627877902, "matrix": 0.000986545944434878, "algorithms along": 0.0008730815719568182, "4 log k": 0.0010298199627877902, "develop a": 0.0003796766130365772, "a more realistic": 0.0006335389089667411, "tr the dynamics": 0.0010298199627877902, "adaptive": 0.00016385653603096098, "issue of convergence": 0.0010298199627877902, "itself may be": 0.0008002740946718667, "interactions": 0.0008634855370793712, "an instance": 0.0003454193697900408, "of e cient": 0.0015484280492378119, "desired values if": 0.0010298199627877902, "concerned with how": 0.0008321458774498469, "initialize": 0.00035168238084447203, "not seem": 0.00044065161687170207, "of the next": 0.0004800375137323266, "positive constant r": 0.0010298199627877902, "order to": 0.00040683796244397554, "their average payo": 0.0010298199627877902, "reduce the": 0.00020102477059813996, "could": -0.00045200980104799764, "to approximately": 0.0006049243473022664, "equilibria because": 0.000971904517366954, "had he": 0.000971904517366954, "david": 0.00038470963747623955, "length": -1.9748122473713975e-05, "and behave according": 0.0010298199627877902, "s osprings thus": 0.0010298199627877902, "time after the": 0.0007330505281739418, "assumed": -4.438459520051911e-05, "der torre enforceable": 0.0010298199627877902, "attain this average": 0.0010298199627877902, "is non trivial": 0.0006749109941620578, "our major claim": 0.0010298199627877902, "any case the": 0.0007742140246189059, "payos": 0.016586188843856577, "determine stochastically the": 0.0010298199627877902, "agent using": 0.0008730815719568182, "the case of": 0.002095780547188656, "is always": 0.00044725171006585173, "technically more": 0.000971904517366954, "learn the": 0.0005159204175055324, "not required": 0.0005286223582497236, "line algorithms": 0.0013879565332957013, "tuomas sandholm": 0.000971904517366954, "case theorem 2": 0.0009310344469842923, "play investigated by": 0.0010298199627877902, "to learn quickly": 0.0010298199627877902, "a xed sum": 0.0010298199627877902, "non cooperative inter": 0.0010298199627877902, "of actions available": 0.0020596399255755804, "interval of": 0.0004933431890106373, "and stochastic games": 0.0010298199627877902, "s dilemma game": 0.0009310344469842923, "visit the": 0.0013879565332957013, "and must": 0.0004986788606483227, "learn quickly": 0.0008730815719568182, "stochastic games as": 0.0010298199627877902, "the learner": 0.0006578931655429611, "and potentially a": 0.0010298199627877902, "learning in non": 0.0020596399255755804, "gence": 0.0006747188760310696, "e cient behavior": 0.0020596399255755804, "by introducing side": 0.0010298199627877902, "equilibrium and": 0.003492326287827273, "every s i": 0.0009310344469842923, "the same result": 0.0005875760798754402, "interest game i": 0.0010298199627877902, "but requires": 0.0006049243473022664, "many times": 0.00043697553507468355, "some pre determined": 0.0010298199627877902, "elds for": 0.000971904517366954, "appealing": 0.0008026033889346861, "the entries in": 0.0006428310760905615, "the literature on": 0.0007330505281739418, "that should follow": 0.0010298199627877902, "probabilistic maximin": 0.007775236138935632, "on when": 0.0006290164566258502, "adversary payos hence": 0.0010298199627877902, "we equated": 0.000971904517366954, "reality the adversary": 0.0010298199627877902, "not seem too": 0.0009310344469842923, "described numerically": 0.000971904517366954, "two paradigms": 0.0008730815719568182, "challenging setting": 0.000971904517366954, "viewed": 0.00011854670124325419, "manner that would": 0.0009310344469842923, "as consisting of": 0.0007330505281739418, "average reward i": 0.0010298199627877902, "uncertain entities and": 0.0010298199627877902, "a strategy for": 0.0008002740946718667, "mechanism": 0.00020730478897596107, "learning procedures that": 0.0010298199627877902, "every game in": 0.0010298199627877902, "it does not": 0.0005838687573121072, "question is whether": 0.0006165622637081906, "algorithms moreover one": 0.0010298199627877902, "look at": 0.0003454193697900408, "learning did": 0.000971904517366954, "1 during this": 0.0009310344469842923, "rationality requirement it": 0.0010298199627877902, "autonomous agents": 0.0012098486946045329, "take a natural": 0.0010298199627877902, "of our approach": 0.0005042815390490772, "payos as the": 0.0010298199627877902, "parkes specification faithfulness": 0.0010298199627877902, "online to": 0.000971904517366954, "more than": 0.00023712715243704024, "no general way": 0.0010298199627877902, "addition for": 0.0007160765724402042, "face": 0.0005306946091838572, "i e polynomial": 0.0009310344469842923, "context together our": 0.0010298199627877902, "its own": 0.0014319147551684834, "trials the": 0.000774103816216825, "fact": -0.0011233896503797499, "increased reward in": 0.0010298199627877902, "agents they": 0.000971904517366954, "of nash equilibrium": 0.0010298199627877902, "redundancy to": 0.0007421847985653504, "it it": 0.0005748976023290408, "trivial": 0.00024001662114772696, "vorobeychik": 0.000872957307571399, "be a policy": 0.0010298199627877902, "steps to": 0.0005286223582497236, "game g after": 0.0010298199627877902, "this latter": 0.000557817444576059, "payo obtained by": 0.003089459888363371, "steps will": 0.0008730815719568182, "should": -0.004203936582818458, "entities": 0.0002878285123597904, "using a shared": 0.0009310344469842923, "learning and in": 0.0009310344469842923, "p i": 0.0005415252744190521, "multiagent learning algorithm": 0.0010298199627877902, "same result with": 0.0010298199627877902, "the ones": 0.0007210712230507147, "insight": 0.00029083735304450325, "understanding of learning": 0.0010298199627877902, "rationality than": 0.000971904517366954, "with imperfect": 0.0008730815719568182, "prescribed strategies": 0.000971904517366954, "is its": 0.00037467912962542367, "deviates either in": 0.0010298199627877902, "sections dealt": 0.000971904517366954, "if player": 0.002619244715870455, "multiagent systems": 0.0019736794966288833, "of lesser interest": 0.0010298199627877902, "ele the previous": 0.0010298199627877902, "e 2 from": 0.0010298199627877902, "optimal value in": 0.0010298199627877902, "a situation where": 0.0006749109941620578, "rationality stipulates": 0.000971904517366954, "h": -0.00013298909418420747, "actions and payos": 0.0010298199627877902, "receive the appropriate": 0.0009310344469842923, "time next": 0.0008730815719568182, "all following iterations": 0.0010298199627877902, "the form": 0.00014195868959541953, "type of utility": 0.0010298199627877902, "a combination": 0.00038223374562649956, "might be actually": 0.0010298199627877902, "agents adopt": 0.000971904517366954, "a given": 0.00029744423981042944, "expected payo by": 0.0010298199627877902, "justied by": 0.0007160765724402042, "agent maintains": 0.000971904517366954, "existence of an": 0.0024662490548327622, "each agent to": 0.0018620688939685846, "knows that it": 0.0008732058717250353, "a non bayesian": 0.0010298199627877902, "agents can": 0.0013496298428453508, "optimal probabilistic maximin": 0.0010298199627877902, "state will be": 0.0009310344469842923, "2 denote the": 0.0008732058717250353, "a pair of": 0.00035321824702689864, "the extended": 0.00045629221416883416, "important line of": 0.0010298199627877902, "game this strategy": 0.0010298199627877902, "the approximation parameters": 0.0009310344469842923, "of relevant games": 0.0010298199627877902, "is the maximization": 0.0010298199627877902, "desired learning": 0.000971904517366954, "ele because": 0.000971904517366954, "theorists despite": 0.000971904517366954, "like in": 0.0004881890232438977, "0 1": 0.00038665437271265317, "tells it": 0.0008730815719568182, "we can": 0.00016380473876257984, "complex and": 0.0004986788606483227, "guido boella": 0.0008730815719568182, "its corresponding rg": 0.0010298199627877902, "t step average": 0.0010298199627877902, "interaction has attracted": 0.0010298199627877902, "with rational": 0.000774103816216825, "strategy leads to": 0.0008732058717250353, "which an ele": 0.003089459888363371, "better align the": 0.0010298199627877902, "starting at": 0.00043697553507468355, "adjusted": 0.00034744822890409797, "the generalization to": 0.0010298199627877902, "near future": 0.0011497952046580816, "a value": 0.0005470175425027654, "here no distribution": 0.0010298199627877902, "to an equilibrium": 0.0010298199627877902, "agents designed": 0.000971904517366954, "iteration g is": 0.0010298199627877902, "to increased": 0.0006939782666478507, "function agent i": 0.0010298199627877902, "are dierent for": 0.0010298199627877902, "where our goal": 0.0010298199627877902, "players a": 0.000971904517366954, "the optimal value": 0.0005943034268074654, "c can": 0.00045629221416883416, "important ramications": 0.000971904517366954, "proof in order": 0.0009310344469842923, "does require knowledge": 0.0010298199627877902, "the set a": 0.0006165622637081906, "ciently we": 0.0008730815719568182, "obtained by directing": 0.0010298199627877902, "the punishment": 0.001943809034733908, "next they run": 0.0010298199627877902, "and let": 0.0005885539434394041, "the agents can": 0.0020596399255755804, "leading to 1": 0.0010298199627877902, "where is": 0.0006409371668630591, "for ease": 0.0005661109047770705, "rby": 0.000872957307571399, "its return mixing": 0.0010298199627877902, "researchers have adopted": 0.0009310344469842923, "of self play": 0.0010298199627877902, "the policies that": 0.0010298199627877902, "non cooperative setting": 0.0010298199627877902, "whom we refer": 0.0020596399255755804, "rational 2": 0.000971904517366954, "player the agent": 0.0010298199627877902, "best response upon": 0.0010298199627877902, "players 1": 0.000971904517366954, "that will predict": 0.0010298199627877902, "the average sum": 0.0009310344469842923, "online as we": 0.0010298199627877902, "m where the": 0.0018620688939685846, "agent thus no": 0.0010298199627877902, "surprisingly": 0.00030667021960111354, "quasi linear the": 0.0010298199627877902, "theory in": 0.0005099512042140099, "vu": 0.0006747188760310696, "g1 2 g2": 0.0010298199627877902, "in all other": 0.0007521645399683924, "greater": -3.207320310393193e-05, "prove the existence": 0.0015043290799367848, "game as": 0.000774103816216825, "simplifying assumption that": 0.0008321458774498469, "this work uses": 0.0010298199627877902, "have an ele": 0.0010298199627877902, "that t must": 0.0010298199627877902, "notion of an": 0.000663411738084629, "cases we": 0.000387471559992312, "except that t": 0.0010298199627877902, "and multiagent": 0.0013496298428453508, "r such that": 0.0005633746356361924, "a series": 0.0003373507152868544, "receives more": 0.0008152096437846543, "upon": 7.831965472445116e-05, "player 2 the": 0.0010298199627877902, "from its": 0.0003151849303416359, "infinite": 0.00017242978035012288, "is mainly": 0.0004832040417809763, "the following algorithm": 0.0011267492712723848, "identity": 0.000481504741029072, "symposium on": 0.0002614473441041457, "agents involved": 0.0008730815719568182, "all other cases": 0.0007742140246189059, "was rst": 0.0006427395698875594, "cient outcome": 0.000971904517366954, "1 this follows": 0.0010298199627877902, "question when player": 0.0010298199627877902, "s actions": 0.002322311448650475, "value assumed": 0.000971904517366954, "matrix contains the": 0.0010298199627877902, "repeated common": 0.000971904517366954, "xed": 0.0017163914295741142, "max we denote": 0.0010298199627877902, "for player 2": 0.0072087397395145325, "less": -0.00015390983237028235, "dened case": 0.000971904517366954, "makes no": 0.0006049243473022664, "in repeated games": 0.004119279851151161, "the side payment": 0.0010298199627877902, "player 1 can": 0.0010298199627877902, "and potentially": 0.0006939782666478507, "polynomial number": 0.0020244447642680263, "equilibrium is": 0.0008152096437846543, "associates a": 0.0014321531448804085, "equilibrium it": 0.000971904517366954, "among all policies": 0.0010298199627877902, "setting since": 0.0008152096437846543, "for all": 0.00013040885175871392, "equilibrium in": 0.006111571003697728, "5": -0.0026188719227141968, "e for any": 0.0006527573289679061, "term adversary": 0.000971904517366954, "equilibrium if": 0.001943809034733908, "observe following": 0.000971904517366954, "increased": 0.00010004317613226729, "is maximized it": 0.0010298199627877902, "well an": 0.0008152096437846543, "is required to": 0.0004536379033545901, "equilibria exist one": 0.0010298199627877902, "behavior that will": 0.0010298199627877902, "eventually lead": 0.000774103816216825, "is done in": 0.0004865784002866409, "implications of this": 0.0006874022974519222, "8 and": 0.00028936800859759385, "games 6": 0.000971904517366954, "and look at": 0.0008732058717250353, "much as": 0.0003848315869061944, "follow the policy": 0.0010298199627877902, "become": 1.9724389544945034e-05, "repeated games immediately": 0.0010298199627877902, "in a manner": 0.000552614435925888, "aspects of pareto": 0.0010298199627877902, "associated with m": 0.0017464117434500706, "the possibility": 0.0002954867076473726, "ciency is": 0.0006939782666478507, "amount of money": 0.0008732058717250353, "enable the agents": 0.0010298199627877902, "of rewards": 0.004859522586834771, "and the payo": 0.0010298199627877902, "and 2 respectively": 0.0007742140246189059, "game parameters this": 0.0010298199627877902, "multiagent reinforcement learning": 0.0018620688939685846, "e cient if": 0.0010298199627877902, "choosing": 0.00011419676523269817, "steps does not": 0.0010298199627877902, "boolean valued variable": 0.0010298199627877902, "strategies now assume": 0.0010298199627877902, "will be": 0.0005595559882916718, "detail first consider": 0.0010298199627877902, "t we": 0.0003373507152868544, "equilibrium adaptive": 0.000971904517366954, "player whom we": 0.0010298199627877902, "does": -0.004546799869102406, "gets in the": 0.0010298199627877902, "attain this": 0.000971904517366954, "guarantee themselves": 0.000971904517366954, "for an": 0.0002255482087414025, "0 step policy": 0.0010298199627877902, "this follows": 0.00041656361432912804, "strict imperfect monitoring": 0.003089459888363371, "in which an": 0.0013498219883241157, "adversary": 0.00922993897274889, "class thus there": 0.0010298199627877902, "stage": 0.00047651751980357765, "far and": 0.0014843695971307007, "determined selection algorithm": 0.0010298199627877902, "its own to": 0.0010298199627877902, "extended discussion in": 0.0010298199627877902, "the agent we": 0.0010298199627877902, "learning equilibrium a": 0.0010298199627877902, "500 most of": 0.0010298199627877902, "games and so": 0.0010298199627877902, "in one of": 0.0004707237014509277, "attractive but": 0.000971904517366954, "to use a": 0.00042425064540523185, "heuristic rules": 0.000774103816216825, "in one": 0.0002141035440250924, "also when the": 0.0008321458774498469, "assess": 0.0003314917117816786, "also that": 0.00036281071874830087, "a pareto ele": 0.0072087397395145325, "agents is maximized": 0.0010298199627877902, "agent interaction has": 0.0010298199627877902, "following algorithm termed": 0.0010298199627877902, "indeed ai researchers": 0.0010298199627877902, "of cooperative": 0.000774103816216825, "as dictated by": 0.0008732058717250353, "signicant": 0.00037962257423597423, "that modied game": 0.0010298199627877902, "extension to sets": 0.0010298199627877902, "the steps": 0.00041656361432912804, "attained had": 0.000971904517366954, "play i e": 0.0010298199627877902, "agents and multiagent": 0.0014661010563478836, "follow suit": 0.0008730815719568182, "it will": 0.00045378896110978936, "naturally": 0.0001474654044529997, "function": -0.0007960419137757859, "number t we": 0.0010298199627877902, "to 0 in": 0.0016005481893437334, "perfect monitoring denote": 0.0010298199627877902, "and some positive": 0.0009310344469842923, "natural question": 0.0005661109047770705, "on online algorithms": 0.0010298199627877902, "convergence": 0.0023813263627527116, "vector of": 0.00036053561152535736, "unknown such": 0.000971904517366954, "resorting to": 0.0007160765724402042, "t 0 polynomial": 0.0020596399255755804, "compute": -0.00032934456089836434, "all that": 0.0004736982533495064, "and pareto ele": 0.0020596399255755804, "reinforcement": 0.008629414569315206, "to their": 0.0009119805566328241, "convergence adopted": 0.000971904517366954, "c parkes jeffrey": 0.0010298199627877902, "value which": 0.0004933431890106373, "distribution": 4.4402098003436224e-05, "the optimal": 0.0010668621162681518, "the appendix": 0.00045629221416883416, "nding a policy": 0.0010298199627877902, "known in": 0.0004482748456766825, "use simple": 0.0007160765724402042, "is initialized": 0.0005221368030860054, "although a b": 0.0010298199627877902, "is maximized": 0.0005842412659181877, "max is": 0.0006290164566258502, "denote": -0.0009451550971521542, "provided to the": 0.0006749109941620578, "algorithm should quickly": 0.0010298199627877902, "information about the": 0.0007303386553136493, "t steps": 0.0007160765724402042, "paid rby player": 0.0010298199627877902, "monitoring assumption the": 0.0010298199627877902, "and veloso": 0.002915713552100862, "ability is": 0.0007160765724402042, "trials": 0.0004197274689931713, "details are presented": 0.0010298199627877902, "of learning in": 0.0008321458774498469, "ele exists in": 0.0010298199627877902, "details": -7.686511164618847e-05, "actions consider": 0.0008730815719568182, "this desired value": 0.0010298199627877902, "learning articial intelligence": 0.0010298199627877902, "repeat": 0.00023582981019343917, "consider a repeated": 0.0010298199627877902, "is 2 e": 0.0010298199627877902, "2004 st john": 0.0008002740946718667, "values each agent": 0.0010298199627877902, "do is to": 0.0007330505281739418, "s the probability": 0.0010298199627877902, "arrive at": 0.000444416512295841, "have obtained": 0.0017246928069871226, "the size": 0.00030461410189544015, "to payos that": 0.0010298199627877902, "other agent plays": 0.0010298199627877902, "what follows we": 0.0005943034268074654, "ensure that": 0.0005026310441017636, "agent using them": 0.0010298199627877902, "probability that after": 0.0009310344469842923, "rule": 0.00010722634317054398, "existence the denition": 0.0010298199627877902, "typical assumption": 0.000971904517366954, "the particular": 0.00035389034454809447, "guidelines to": 0.000971904517366954, "new basic tools": 0.0010298199627877902, "not be followed": 0.0010298199627877902, "dierent designers will": 0.0010298199627877902, "we prove the": 0.0015860928530912477, "stationary policy then": 0.0010298199627877902, "desirable": 0.00014429486934358564, "in cooperative": 0.0016304192875693086, "view the learning": 0.0010298199627877902, "but while": 0.0006939782666478507, "interested in having": 0.0010298199627877902, "an issue our": 0.0010298199627877902, "identity of this": 0.0009310344469842923, "conitzer": 0.000872957307571399, "the agents go": 0.0010298199627877902, "we can dene": 0.0006527573289679061, "g is a": 0.0004536379033545901, "equilibria since they": 0.0010298199627877902, "date most work": 0.0010298199627877902, "defect the adversary": 0.0020596399255755804, "not obtain": 0.0007160765724402042, "of actions as": 0.0009310344469842923, "p now": 0.0007421847985653504, "nash equilibrium the": 0.0009310344469842923, "to be associated": 0.0007742140246189059, "could have obtained": 0.0009310344469842923, "that the agents": 0.002619617615175106, "are presented in": 0.0004134631378172694, "time algorithm": 0.00047837713542937403, "end to an": 0.0010298199627877902, "strategy of": 0.0005354021517001512, "special": -0.00015701314266665985, "the adversary payos": 0.0020596399255755804, "game more": 0.000971904517366954, "played in": 0.000971904517366954, "the deviator s": 0.0010298199627877902, "average sum of": 0.004655172234921462, "ele it will": 0.0010298199627877902, "b introduction": 1.4184979055133344e-05, "covergent learning in": 0.0010298199627877902, "laws proceedings of": 0.0010298199627877902, "0 of the": 0.0005633746356361924, "a fundamental decision": 0.0010298199627877902, "strategies that": 0.0005748976023290408, "related elds": 0.000971904517366954, "does not know": 0.0006527573289679061, "be classes of": 0.0009310344469842923, "approximation": 7.699336254170508e-05, "motivation in mind": 0.0010298199627877902, "its goal is": 0.0008321458774498469, "rigorous": 0.0007301307593115676, "in games the": 0.0010298199627877902, "can observe following": 0.0010298199627877902, "possibly mixed": 0.0008730815719568182, "a player": 0.002445628931353963, "in stochastic": 0.0040488895285360526, "s rewards": 0.001943809034733908, "simple dynamics": 0.000971904517366954, "punishment mechanism": 0.000971904517366954, "our approach": 0.0010202189148629493, "the game are": 0.0010298199627877902, "to model": 0.00028199309165360617, "technique for punishing": 0.0010298199627877902, "mentioned earlier": 0.0004881890232438977, "above": -0.004169378746849176, "on when several": 0.0010298199627877902, "consisting": 0.00010283419803078707, "david c": 0.0017461631439136364, "nv i n": 0.0010298199627877902, "ideally we": 0.0006748149214226754, "and is": 0.0001956132776380709, "time of the": 0.0003831496416266841, "equals": 0.00022686218700514307, "players would have": 0.0010298199627877902, "wellman satinder": 0.000971904517366954, "rewards we note": 0.0010298199627877902, "based on the": 0.00017364346723648056, "be viewed as": 0.0003590870410572324, "are special classes": 0.0010298199627877902, "immediately reduce": 0.000971904517366954, "and in": 0.00032760138940532917, "we would like": 0.00033805687792305044, "obtained": -0.0031385076023621324, "if a a": 0.0007330505281739418, "m to refer": 0.0010298199627877902, "to their prescribed": 0.0010298199627877902, "since its": 0.0005042097552001021, "study": -0.00016463753656917652, "if it does": 0.0006013538961527255, "their behavior in": 0.0009310344469842923, "strategy takes an": 0.0010298199627877902, "prole that leads": 0.0010298199627877902, "agent s behavior": 0.0008732058717250353, "that this learning": 0.0010298199627877902, "the probability of": 0.0003763816768240042, "using the expected": 0.0008732058717250353, "over with the": 0.0009310344469842923, "players play a": 0.0010298199627877902, "to be individually": 0.0009310344469842923, "prisoner s dilemma": 0.0009310344469842923, "s total payo": 0.0010298199627877902, "highly": 0.00012000831057386348, "we formalize the": 0.0006874022974519222, "parameter that": 0.0006049243473022664, "does not seem": 0.0005475136432016508, "setting our": 0.0006939782666478507, "follows from the": 0.0003848863750022802, "then is": 0.00040135881926370846, "total": -0.000180829263347863, "knows that": 0.0005748976023290408, "0 and as": 0.0010298199627877902, "information to": 0.0003117480856515576, "chooses": 0.0002079444786956771, "each state not": 0.0010298199627877902, "fact in the": 0.0006749109941620578, "possible probability": 0.0008730815719568182, "corresponds to": 0.00012742687664529998, "agents known the": 0.0010298199627877902, "algorithm is used": 0.0006165622637081906, "infinite games": 0.0008152096437846543, "novel e": 0.001943809034733908, "28 2004": 0.0006049243473022664, "replaces its payos": 0.0010298199627877902, "knowledge of the": 0.000435831200377543, "manifest in": 0.0008730815719568182, "the denition of": 0.0014212970799175467, "work": -0.004114544289159831, "use the term": 0.0005633746356361924, "if the other": 0.0008321458774498469, "setting studied in": 0.0010298199627877902, "groves": 0.000872957307571399, "requirement then is": 0.0010298199627877902, "from the following": 0.0005749794499375729, "the bottom line": 0.0009310344469842923, "the idea above": 0.0010298199627877902, "e cient policy": 0.0010298199627877902, "for imperfect": 0.000971904517366954, "12 2 as": 0.0010298199627877902, "many settings": 0.0008730815719568182, "approach taken": 0.0005748976023290408, "and player 2": 0.0020596399255755804, "and player 1": 0.0010298199627877902, "appropriate equilibrium": 0.001943809034733908, "or a polynomial": 0.0010298199627877902, "being played": 0.000971904517366954, "other player both": 0.0010298199627877902, "in some sense": 0.0005875760798754402, "enforceable social laws": 0.0010298199627877902, "response value against": 0.0010298199627877902, "weights the": 0.0005748976023290408, "ciency a": 0.000971904517366954, "8 2": 0.0004264387578012798, "earlier the": 0.0005042097552001021, "the goals": 0.0006164744968379118, "exponential number": 0.0012580329132517005, "a times": 0.0016304192875693086, "it knows its": 0.0010298199627877902, "stage because": 0.0008730815719568182, "interactions in": 0.0007160765724402042, "we have multiple": 0.0009310344469842923, "that case since": 0.0010298199627877902, "n g the": 0.0009310344469842923, "earlier": 8.44082258036532e-05, "policy is": 0.0010442736061720109, "of researchers": 0.0006164744968379118, "what they converge": 0.0010298199627877902, "policy in": 0.0012580329132517005, "in games": 0.007336886794061889, "agent receives more": 0.0010298199627877902, "the following two": 0.0007122539725908914, "as mentioned": 0.00033539158148356945, "used when this": 0.0010298199627877902, "max is appropriate": 0.0010298199627877902, "assumption that the": 0.0004934134257972276, "order": -0.0026435333975437293, "corresponding payos obtained": 0.0010298199627877902, "polynomial time algorithm": 0.0006165622637081906, "adopting the descriptive": 0.0010298199627877902, "t mix be": 0.0010298199627877902, "we simply guess": 0.0010298199627877902, "is a policy": 0.0020596399255755804, "higher values": 0.0006049243473022664, "theory of": 0.0002488608288383314, "proof now": 0.0008152096437846543, "actions a b": 0.0010298199627877902, "to react online": 0.0010298199627877902, "a 0 in": 0.0007010750178672042, "the rows": 0.0004986788606483227, "by agent i": 0.0020596399255755804, "conver gence": 0.0008730815719568182, "online algorithms in": 0.0010298199627877902, "action for each": 0.0010298199627877902, "above the": 0.000530770152900467, "learning did choose": 0.0010298199627877902, "the adversary": 0.008680078774293377, "refer the": 0.0010084195104002043, "then": -0.008513930031049693, "them": -0.0007726511574686393, "by most": 0.0006164744968379118, "to have an": 0.0006013538961527255, "models of human": 0.0009310344469842923, "theory literature is": 0.0010298199627877902, "on learning in": 0.004655172234921462, "detrimental eect on": 0.0010298199627877902, "period of time": 0.0005749794499375729, "they": -0.007299636332561481, "by the dierent": 0.0009310344469842923, "proof for": 0.00034749768772671775, "of work on": 0.0007521645399683924, "we shall take": 0.0008732058717250353, "the monetary": 0.000971904517366954, "the exploration": 0.0013879565332957013, "is paid c": 0.0010298199627877902, "this case": 8.77133294553476e-05, "l": -0.0003379350088270865, "provide a": 0.0005799815590689798, "leads to increased": 0.0009310344469842923, "we restrict": 0.0003796766130365772, "follows we": 0.0003517324423933467, "not concerned with": 0.0007161785195604264, "as an instance": 0.0007161785195604264, "linear the sum": 0.0010298199627877902, "stage or": 0.0008152096437846543, "increase the expected": 0.0010298199627877902, "is typically": 0.0003848315869061944, "0 where": 0.000888833024591682, "g by the": 0.0007161785195604264, "goal is to": 0.0010908834220427705, "to remain consistent": 0.0010298199627877902, "players each": 0.000971904517366954, "adopting the": 0.0013496298428453508, "one is": 0.00027076263720952605, "mark it known": 0.0010298199627877902, "we refer the": 0.0012175213147942792, "for any": 0.00033402193514165394, "is termed quasi": 0.0010298199627877902, "available to each": 0.0010298199627877902, "exists some": 0.0006290164566258502, "and is a": 0.0004648150538311537, "has any": 0.0007421847985653504, "between 0": 0.0004197872166755902, "other player the": 0.0020596399255755804, "game g repeatedly": 0.0010298199627877902, "crucial point": 0.0006578931655429611, "in the form": 0.0003763816768240042, "the rewards": 0.003492326287827273, "generalization is": 0.0006578931655429611, "the fact": 0.00046263000039431263, "and the action": 0.0015484280492378119, "after polynomial": 0.001943809034733908, "2 using": 0.000444416512295841, "standard": -0.00013298909418420747, "ai perspective we": 0.0010298199627877902, "ele is similar": 0.0010298199627877902, "with s i": 0.0008002740946718667, "s thus after": 0.0010298199627877902, "we consider": 0.0002444588239252722, "with in an": 0.0009310344469842923, "boella": 0.0007739936391863359, "stages b": 0.000971904517366954, "view its adversary": 0.0010298199627877902, "of g1": 0.000774103816216825, "of g2": 0.000971904517366954, "so we elaborate": 0.0010298199627877902, "folk theorems e": 0.0010298199627877902, "update the": 0.000387471559992312, "provided to": 0.0004986788606483227, "is of paramount": 0.0009310344469842923, "another": -0.001000195390903403, "general polynomial": 0.0008730815719568182, "for more details": 0.0005042815390490772, "the complements to": 0.0020596399255755804, "that each agent": 0.0020596399255755804, "related work": 0.0004880776670783302, "equilibria": 0.0026988755041242782, "approximately": 0.0002518318794360444, "approach in the": 0.0006527573289679061, "articial intelligence and": 0.0010298199627877902, "observations": 0.0001506699336826659, "corresponding payos": 0.000971904517366954, "s does not": 0.0007161785195604264, "using them will": 0.0010298199627877902, "john": 0.00020996895063142424, "stochastic games appears": 0.0010298199627877902, "the theory of": 0.00042878089900721635, "determined sequence of": 0.0010298199627877902, "to be non": 0.0005943034268074654, "of mixed": 0.0013879565332957013, "their work bowling": 0.0010298199627877902, "learning equilibria": 0.000971904517366954, "v 67": 0.0019282187096626782, "0 and": 0.0005931376091559488, "mechanism implementations": 0.000971904517366954, "requires additional": 0.0007160765724402042, "stick to their": 0.003089459888363371, "design of learning": 0.0009310344469842923, "that is the": 0.00028890827989669197, "agent 2 denote": 0.0010298199627877902, "same learning algorithms": 0.0010298199627877902, "learning for dealing": 0.0010298199627877902, "dierences have": 0.000971904517366954, "number of iterations": 0.0009072758067091802, "play to ensure": 0.0010298199627877902, "functions in": 0.0003517324423933467, "23 43": 0.000971904517366954, "acm symposium on": 0.0004033618086640399, "will be optimal": 0.0008321458774498469, "of our": 0.00033402193514165394, "1 u 2": 0.0008732058717250353, "high as his": 0.0010298199627877902, "long term average": 0.0020596399255755804, "a stationary": 0.0012580329132517005, "dictated by": 0.0005842412659181877, "manner": 0.00014870095250983967, "to the xed": 0.0009310344469842923, "prole is an": 0.0010298199627877902, "in both": 0.00041193423001745916, "latter": 4.094535617019369e-05, "results are": 0.0002193427981572845, "and some": 0.00028936800859759385, "are assigned": 0.00041030656060455343, "is called": 0.000168132855851404, "4 imperfect monitoring": 0.0010298199627877902, "games and": 0.0026992596856907016, "player using the": 0.0010298199627877902, "we assume": 0.00020850331493614993, "where its aim": 0.0010298199627877902, "minimize the adversary": 0.0010298199627877902, "ele algorithm": 0.003887618069467816, "can receive on": 0.0010298199627877902, "if the agents": 0.0009310344469842923, "j th action": 0.0010298199627877902, "phase": 0.00012779681754850647, "is truly": 0.000774103816216825, "k actions g": 0.0010298199627877902, "payments so that": 0.0010298199627877902, "16 15": 0.0006939782666478507, "converge at the": 0.0010298199627877902, "the players follow": 0.0010298199627877902, "agent maintains information": 0.0010298199627877902, "pareto ele the": 0.0010298199627877902, "an agent s": 0.0007521645399683924, "in polynominal": 0.000971904517366954, "notion": 0.0004253046849235102, "aim is that": 0.0010298199627877902, "cient punishment mechanism": 0.0010298199627877902, "the lack of": 0.00047686941115904235, "can be attained": 0.0008732058717250353, "prole the": 0.000971904517366954, "to ensure that": 0.0007035650363932974, "e g 11": 0.0007330505281739418, "quickly a learning": 0.0010298199627877902, "subtle": 0.00034331729227235583, "max of": 0.00154820763243365, "most and": 0.0014843695971307007, "descriptive stance are": 0.0010298199627877902, "ele where the": 0.0020596399255755804, "latter result": 0.0008730815719568182, "cient punishment": 0.001943809034733908, "we discuss": 0.00022362585503292586, "all we": 0.00044065161687170207, "approaches have been": 0.000663411738084629, "with an important": 0.0008321458774498469, "agents are assumed": 0.0009310344469842923, "not well": 0.000542504923393336, "other more": 0.0006427395698875594, "each of the": 0.00023589695991160358, "agents i e": 0.0010298199627877902, "out to be": 0.000435831200377543, "polynomial time next": 0.0010298199627877902, "and deviations": 0.000971904517366954, "incomplete information": 0.00154820763243365, "converge to a": 0.0029322021126957673, "for multi agent": 0.0008732058717250353, "over a hence": 0.0010298199627877902, "for that setting": 0.0010298199627877902, "25 29 2005": 0.0008321458774498469, "line appear in": 0.0010298199627877902, "games our approach": 0.0010298199627877902, "use the algorithm": 0.0007742140246189059, "one time": 0.0005099512042140099, "first consider": 0.00045223161134026404, "there bowling": 0.000971904517366954, "first note": 0.0005099512042140099, "payos a natural": 0.0010298199627877902, "r such": 0.0004933431890106373, "games ts into": 0.0010298199627877902, "the major issues": 0.0009310344469842923, "visited and": 0.0006939782666478507, "while obtaining": 0.000971904517366954, "the value can": 0.0008732058717250353, "observed": 0.0001408187423387723, "agent within a": 0.0010298199627877902, "may be lower": 0.0009310344469842923, "is g2": 0.001943809034733908, "with this": 0.00018956914887471784, "equivalent to": 0.00018771162611315464, "interest if we": 0.0010298199627877902, "policy for a": 0.0008002740946718667, "third annual acm": 0.0008321458774498469, "the probability": 0.0012690027327728827, "time the concepts": 0.0010298199627877902, "value the": 0.0003901551635480713, "here because we": 0.0010298199627877902, "in multiagent reinforcement": 0.0010298199627877902, "after k": 0.0006578931655429611, "after o": 0.0006939782666478507, "after a": 0.0003134582012487072, "choose an": 0.0005286223582497236, "in g then": 0.0008732058717250353, "provide a rigorous": 0.0010298199627877902, "we": -0.06490745706297617, "of agent i": 0.0020596399255755804, "terms": -0.0001706929910352277, "the insight": 0.000774103816216825, "or longer": 0.0008152096437846543, "results we": 0.0006409371668630591, "times if both": 0.0010298199627877902, "is over with": 0.0010298199627877902, "is participating in": 0.0009310344469842923, "the ones modeled": 0.0010298199627877902, "game theory in": 0.0010298199627877902, "agents run an": 0.0010298199627877902, "strategy prole will": 0.0010298199627877902, "settings in ele": 0.0010298199627877902, "for most times": 0.0010298199627877902, "m we": 0.0004042861100519966, "each of": 0.00028358689164089833, "to be type": 0.0008321458774498469, "concepts and results": 0.0008732058717250353, "receives": 0.00019424824308268248, "are assumed": 0.0003560762920625211, "learning strategies moreover": 0.0010298199627877902, "action selected by": 0.0010298199627877902, "agents that": 0.0006939782666478507, "that approach is": 0.0009310344469842923, "s behavior": 0.0017527237977545634, "game first": 0.000971904517366954, "the action it": 0.0010298199627877902, "the algorithm works": 0.0007010750178672042, "steps or": 0.0006748149214226754, "ones modeled": 0.000971904517366954, "use a technique": 0.0008321458774498469, "polynomial": 0.0016698719715130365, "to their algorithms": 0.0020596399255755804, "about them": 0.0007160765724402042, "simple dynamics lead": 0.0010298199627877902, "can guarantee themselves": 0.0010298199627877902, "stage because the": 0.0010298199627877902, "nodes proceedings": 0.000971904517366954, "2 p 23": 0.0008002740946718667, "existence results for": 0.0010298199627877902, "convergence rate should": 0.0010298199627877902, "on equilibrium in": 0.0010298199627877902, "knowng": 0.000872957307571399, "t 0 step": 0.0010298199627877902, "equilibrium in any": 0.0010298199627877902, "investigated by bowling": 0.0010298199627877902, "situation where the": 0.0007521645399683924, "introduce efficient learning": 0.0010298199627877902, "intuitively the return": 0.0010298199627877902, "as closely and": 0.0010298199627877902, "were also": 0.0005042097552001021, "two player": 0.0017461631439136364, "adversary can adjust": 0.0010298199627877902, "know that within": 0.0010298199627877902, "log k 2": 0.0020596399255755804, "context together": 0.000971904517366954, "moreover as mentioned": 0.0010298199627877902, "typical assumption in": 0.0010298199627877902, "and of": 0.0002653850764502335, "previous observations and": 0.0010298199627877902, "dierences are much": 0.0010298199627877902, "contrary to the": 0.0007521645399683924, "the actions in": 0.0008321458774498469, "the complements": 0.001943809034733908, "contains the rewards": 0.0010298199627877902, "dierences have important": 0.0010298199627877902, "the twenty third": 0.0008002740946718667, "is denoted": 0.00028199309165360617, "games except that": 0.0010298199627877902, "rationality to": 0.000971904517366954, "aim": 0.0003772235625047278, "any perfect": 0.001943809034733908, "also determine": 0.0007421847985653504, "applies": 0.00012147592237903854, "property": -4.197345036809869e-05, "for agent": 0.002081934799943552, "of what the": 0.0007330505281739418, "rational behavior in": 0.0010298199627877902, "largely by work": 0.0010298199627877902, "of game": 0.000971904517366954, "to improve robustness": 0.0009310344469842923, "perform": -3.7178408662627056e-05, "the joint action": 0.003089459888363371, "examining the two": 0.0010298199627877902, "e when": 0.0004933431890106373, "exists a pareto": 0.0010298199627877902, "can attain on": 0.0010298199627877902, "equilibrium in the": 0.0010298199627877902, "predict human": 0.000971904517366954, "from h the": 0.0009310344469842923, "form the": 0.0006004271441769054, "combination of": 0.0004515988600765688, "where is a": 0.0005425821592878966, "it known": 0.000971904517366954, "of choose r": 0.0010298199627877902, "that leads": 0.0012580329132517005, "must visit the": 0.0010298199627877902, "each state": 0.0015477612525165972, "the third": 0.00018403798293668077, "cient solution is": 0.0010298199627877902, "9 to": 0.0005286223582497236, "it knows": 0.0006939782666478507, "with a probability": 0.001990235214253887, "setting we assume": 0.0010298199627877902, "prescribed": 0.0017928441735717024, "whether this": 0.000557817444576059, "2 using the": 0.0007010750178672042, "all states": 0.000549963838367756, "action with every": 0.0010298199627877902, "and computational": 0.0004986788606483227, "the": 0, "work on on": 0.0010298199627877902, "the equilibrium of": 0.0010298199627877902, "case the denition": 0.0010298199627877902, "non cooperative settings": 0.0010298199627877902, "see 9": 0.0006049243473022664, "end to": 0.00046046251587537234, "this ability is": 0.0009310344469842923, "games which are": 0.0010298199627877902, "by work": 0.0008152096437846543, "a possibly mixed": 0.0010298199627877902, "a stochastic": 0.0005354021517001512, "this is due": 0.0004648150538311537, "when several nash": 0.0010298199627877902, "not too": 0.000464748887987192, "e cient algorithm": 0.0006874022974519222, "class of repeated": 0.0020596399255755804, "be our": 0.0007421847985653504, "dierent sizes": 0.0008730815719568182, "a perfect": 0.0010084195104002043, "we now": 0.0003227189580154847, "replaced by one": 0.0007742140246189059, "obtain the maximal": 0.0009310344469842923, "necessarily converge": 0.0008730815719568182, "follows the": 0.0005334310581340759, "game and the": 0.0009310344469842923, "punish it as": 0.0010298199627877902, "rewards as": 0.000971904517366954, "designers": 0.0006554469379430817, "to obtain in": 0.0008732058717250353, "behavior that": 0.0011884376569097899, "or with": 0.0004933431890106373, "agent systems machine": 0.0010298199627877902, "equilibrium equals the": 0.0010298199627877902, "expected payos as": 0.0010298199627877902, "to the best": 0.0010756177473885693, "theorems e": 0.0008730815719568182, "games with": 0.006521677150277234, "maximin value for": 0.0010298199627877902, "security": 0.00028486763453033367, "is a standard": 0.000663411738084629, "its own i": 0.0009310344469842923, "of nitely": 0.0008730815719568182, "exploration stage or": 0.0010298199627877902, "game consider": 0.0008730815719568182, "on s": 0.00045629221416883416, "many readers may": 0.0010298199627877902, "the new issues": 0.0009310344469842923, "then they will": 0.0008732058717250353, "start with in": 0.0008732058717250353, "let a be": 0.0004969500605540478, "e a policy": 0.0010298199627877902, "re ective": 0.0008730815719568182, "to as the": 0.0008966773322547537, "articial agents except": 0.0010298199627877902, "agent plays": 0.001943809034733908, "reward this learning": 0.0010298199627877902, "the only economically": 0.0010298199627877902, "may be": 0.0004473525324320743, "the ele": 0.003887618069467816, "correspond to": 0.0003772772598089989, "over the actions": 0.0010298199627877902, "in cognitive psychology": 0.0010298199627877902, "before hand these": 0.0010298199627877902, "are interested": 0.0002954867076473726, "strategy for an": 0.0010298199627877902, "constructive": 0.0006408459432412455, "we note that": 0.0003797306672240824, "discuss the": 0.0005281273191356508, "denes the policies": 0.0010298199627877902, "justied": 0.0010848554189690253, "properties": -0.0002671673355099969, "strategies moreover": 0.000971904517366954, "a stationary policy": 0.0020596399255755804, "stochastic games tr": 0.0010298199627877902, "implementations of": 0.0004072679530572796, "within t": 0.000774103816216825, "content i": 0.000971904517366954, "dierent designers": 0.000971904517366954, "obtaining similar results": 0.0010298199627877902, "within a": 0.00023472124176624737, "is assumed over": 0.0010298199627877902, "the common": 0.00033539158148356945, "dilemma": 0.0005941342541838367, "and covergent learning": 0.0010298199627877902, "the case economic": 0.0010298199627877902, "of failure of": 0.0016642917548996938, "to an adversary": 0.0008732058717250353, "involved are people": 0.0010298199627877902, "bound": -3.968818779579734e-05, "evolve our behavior": 0.0010298199627877902, "on its": 0.0019228115005891775, "payo": 0.02269688999685637, "player 1 s": 0.0010298199627877902, "each iteration g": 0.0010298199627877902, "67 n 1": 0.002496437632349541, "max a": 0.000774103816216825, "matrix g dened": 0.0010298199627877902, "as quickly indeed": 0.0010298199627877902, "learn quickly he": 0.0010298199627877902, "cient behavior performing": 0.0010298199627877902, "always receive identical": 0.0010298199627877902, "way": -0.00024519877565344487, "shoham thuc vu": 0.0010298199627877902, "player knows only": 0.0010298199627877902, "corresponding game": 0.000971904517366954, "was": -0.0006785683270471482, "of irrationality as": 0.0010298199627877902, "max 3": 0.0008152096437846543, "if several economically": 0.0010298199627877902, "we have that": 0.0008864289836066309, "it observe": 0.000971904517366954, "using multiplicative": 0.0008730815719568182, "e will lead": 0.0010298199627877902, "step average reward": 0.0010298199627877902, "adversary to denote": 0.0010298199627877902, "turn out to": 0.0006335389089667411, "cooperative interactions": 0.000971904517366954, "ele the": 0.001943809034733908, "if its": 0.0006747014305737088, "computing": -0.00014746540445299965, "s policies converge": 0.0010298199627877902, "optimal policy": 0.0007421847985653504, "expected time it": 0.0010298199627877902, "without initially knowing": 0.0010298199627877902, "as his": 0.000971904517366954, "too irrational": 0.000971904517366954, "distributions": 0.0001672530849280036, "policy formally": 0.000971904517366954, "parallel to": 0.0009567542708587481, "the agents known": 0.0010298199627877902, "monitoring where": 0.000971904517366954, "histories for all": 0.0010298199627877902, "reality": 0.00026011513263944863, "interested": 0.00012004714744661106, "4 there exists": 0.0007330505281739418, "desired value is": 0.0010298199627877902, "moreover one should": 0.0010298199627877902, "a common description": 0.0010298199627877902, "update": 0.00024001662114772696, "been able": 0.0010708043034003023, "a nash equilibrium": 0.009310344469842923, "in cooperative multiagent": 0.0010298199627877902, "2 an": 0.00037223626733611355, "approach most": 0.0008152096437846543, "this section": 0.00023241080125603267, "our average": 0.000971904517366954, "interval": 0.00011854670124325419, "together": -4.725607610261224e-05, "of this approach": 0.000435831200377543, "known prisoner s": 0.0010298199627877902, "ele are 1": 0.0010298199627877902, "pretend that the": 0.0010298199627877902, "is appropriate here": 0.0010298199627877902, "bayesian approach the": 0.0009310344469842923, "k we get": 0.0008732058717250353, "ele we also": 0.0010298199627877902, "2 as": 0.00029087875337945615, "number t": 0.0007160765724402042, "payments structure": 0.000971904517366954, "concept": 0.00036710993640144473, "class of relevant": 0.0010298199627877902, "performed and let": 0.0010298199627877902, "then the learning": 0.0009310344469842923, "g 0": 0.0012402128455637725, "people i e": 0.0010298199627877902, "in row i": 0.0008002740946718667, "and m": 0.00025505472871573733, "and k": 0.0005909734152947452, "the adversary will": 0.003201096378687467, "at least as": 0.0005119876058604116, "as over the": 0.0010298199627877902, "games 5 8": 0.0010298199627877902, "and a": 4.192245707881857e-05, "cooperate too if": 0.0010298199627877902, "case finally": 0.0008730815719568182, "by and": 0.0004197872166755902, "is otherwise player": 0.0010298199627877902, "agent performed": 0.000971904517366954, "be individually rational": 0.0020596399255755804, "agent is trying": 0.0010298199627877902, "to be our": 0.0009310344469842923, "online algorithms": 0.000774103816216825, "he would have": 0.0010298199627877902, "s actions and": 0.0018620688939685846, "a nash": 0.009603897291525002, "is limited": 0.0003771588365708351, "s i 2": 0.0008321458774498469, "and theoretical importance": 0.0010298199627877902, "and 2": 0.00015474752600739777, "prescribed ele": 0.000971904517366954, "entries": 0.0001621739657256426, "input r max": 0.0010298199627877902, "in the future": 0.00043825368369120325, "imperfect technique": 0.000971904517366954, "of imperfect": 0.0017461631439136364, "presented": -0.0003589898144508639, "turns": 0.00017242978035012288, "3 intuitively": 0.0008152096437846543, "does not exist": 0.00047686941115904235, "p": -0.0042626774933137695, "to see that": 0.000334145338206845, "works as": 0.000464748887987192, "show that": 0.0006870807660644526, "follows let a": 0.0007742140246189059, "reward for": 0.0008730815719568182, "convergence though": 0.000971904517366954, "of e ciency": 0.0008732058717250353, "to include": 0.0003240812532709715, "this learning algorithm": 0.0010298199627877902, "this algorithm": 0.0007921909787034762, "n 1 2": 0.0013690715281332831, "nash equilibria exist": 0.0010298199627877902, "had they": 0.0016304192875693086, "initialized": 0.00027072409997109604, "of the the": 0.0006428310760905615, "with how": 0.0007160765724402042, "appear": 2.9681860502854687e-05, "payo vector i": 0.0010298199627877902, "then his": 0.000971904517366954, "shared": 0.00012890814439846544, "than or": 0.00036281071874830087, "satisfy": 2.9601398668957483e-05, "5 a pareto": 0.0010298199627877902, "to that": 0.0008622716275729277, "v": -0.0010299518768170674, "in their": 0.000485701831443146, "expected time": 0.0005661109047770705, "straightforward the learning": 0.0010298199627877902, "e when all": 0.0010298199627877902, "play the rst": 0.0010298199627877902, "appears": 3.092816334898681e-05, "be discussed": 0.0004042861100519966, "0 is performed": 0.0009310344469842923, "nash equilibrium equals": 0.0010298199627877902, "they run the": 0.0010298199627877902, "quickly he does": 0.0010298199627877902, "can not tell": 0.0010298199627877902, "if adopted": 0.001943809034733908, "regardless": 0.00023582981019343917, "always exist": 0.002226554395696051, "reach formally": 0.000971904517366954, "to evolve": 0.0006578931655429611, "in ai": 0.0027759130665914026, "according to": 0.0003233405980187704, "the empty": 0.0003796766130365772, "well note that": 0.0010298199627877902, "zero then": 0.0006427395698875594, "punish the": 0.001943809034733908, "fact that the": 0.0003169737659493852, "ignores the issue": 0.0009310344469842923, "and its payo": 0.0020596399255755804, "prove": 5.426141748040133e-05, "in a repeated": 0.0020596399255755804, "twenty third annual": 0.0008002740946718667, "corresponding value although": 0.0010298199627877902, "try and": 0.0007160765724402042, "in and k": 0.0010298199627877902, "we consider games": 0.0010298199627877902, "or foe q": 0.0010298199627877902, "case that": 0.0003151849303416359, "is extended": 0.00045223161134026404, "actions such": 0.000774103816216825, "least 1": 0.0004482748456766825, "weights the theory": 0.0010298199627877902, "the sets of": 0.0004969500605540478, "the intuitive": 0.000549963838367756, "that for a": 0.00043109594775796693, "setting if the": 0.0008732058717250353, "payo it knows": 0.0010298199627877902, "is not well": 0.000663411738084629, "learning algorithms must": 0.0010298199627877902, "similarly but in": 0.0010298199627877902, "machine learning": 0.002985071304608959, "follow naturally given": 0.0010298199627877902, "be its": 0.0005942188284548949, "i the": 0.0001715843792304364, "rapidly obtain a": 0.0010298199627877902, "theoretical computer science": 0.0004865784002866409, "that the next": 0.0007330505281739418, "p 45 76": 0.0010298199627877902, "in which": 0.000434320984963337, "visited and the": 0.0008321458774498469, "the performance": 0.0001715843792304364, "agents will": 0.00464462289730095, "how quickly a": 0.0009310344469842923, "executed for t": 0.0010298199627877902, "of pareto": 0.003492326287827273, "examining the": 0.00044065161687170207, "action a i": 0.0020596399255755804, "redundancy": 0.0003392841635235741, "from a": 0.00012911127193114934, "ambitious objective is": 0.0010298199627877902, "in the exploration": 0.0009310344469842923, "discussion": 2.0986725184049335e-05, "from h": 0.0005354021517001512, "before while": 0.0008730815719568182, "of iterations is": 0.0006749109941620578, "criterion": 0.0005493057326377795, "be actually g1": 0.0010298199627877902, "monitoring denote": 0.000971904517366954, "irrational its detrimental": 0.0010298199627877902, "due to the": 0.00021482559663777324, "using strategies": 0.0008152096437846543, "case theorem": 0.000774103816216825, "that player 2": 0.0020596399255755804, "deviates": 0.0030819337747554306, "g1 and player": 0.0010298199627877902, "cient punishment procedure": 0.0010298199627877902, "as well": 0.0003481488488459569, "of ele is": 0.0010298199627877902, "observed and mark": 0.0010298199627877902, "for quite some": 0.0009310344469842923, "to the spirit": 0.0010298199627877902, "take t the": 0.0010298199627877902, "as follows let": 0.00047686941115904235, "progressively": 0.0005158469873294001, "knows its": 0.001943809034733908, "optimal policy formally": 0.0010298199627877902, "action the": 0.0005661109047770705, "typical": 0.00017811155700666464, "on agent": 0.0014843695971307007, "is dened as": 0.00053318373443515, "procedure for": 0.0003517324423933467, "idea is quite": 0.0009310344469842923, "game where its": 0.0010298199627877902, "indeed": 0.00019917187180932026, "15 12 2": 0.0009310344469842923, "an ele much": 0.0010298199627877902, "new york yevgeniy": 0.0010298199627877902, "action is the": 0.0008732058717250353, "game playing using": 0.0009310344469842923, "agents that should": 0.0010298199627877902, "equated quick with": 0.0010298199627877902, "played in what": 0.0010298199627877902, "on autonomous": 0.0012854791397751187, "will lead to": 0.0017249383498127188, "0 1 we": 0.0006874022974519222, "response against": 0.000971904517366954, "is irrational": 0.000971904517366954, "we follow suit": 0.0010298199627877902, "these payos": 0.000971904517366954, "be the action": 0.0010298199627877902, "the maximization of": 0.0009310344469842923, "must arrive": 0.000971904517366954, "in designing articial": 0.0010298199627877902, "issues one needs": 0.0010298199627877902, "the rewards are": 0.0018620688939685846, "for punishing without": 0.0010298199627877902, "i n g": 0.0010298199627877902, "of failure": 0.001085009846786672, "be similar in": 0.0008321458774498469, "is called a": 0.0003730996443725147, "non": -0.0022326624529143057, "convergence rate": 0.0012854791397751187, "consider the class": 0.0008002740946718667, "of agent": 0.0013157863310859221, "plays row 2": 0.0010298199627877902, "bottom line is": 0.0009310344469842923, "introduce": -1.7273108027934456e-05, "plays row 1": 0.0010298199627877902, "is selected by": 0.0007330505281739418, "own to": 0.0008152096437846543, "with every state": 0.0010298199627877902, "not": 0, "now": -0.002511745259528594, "discuss": -2.7130708740200655e-05, "general perfect monitoring": 0.0010298199627877902, "had he known": 0.0010298199627877902, "at time": 0.00037223626733611355, "imperfect monitoring we": 0.0010298199627877902, "a corresponding value": 0.0009310344469842923, "a view": 0.0005221368030860054, "ele algorithm the": 0.0010298199627877902, "using multiplicative weights": 0.0009310344469842923, "concerned with": 0.0011544947607185834, "term average sum": 0.0020596399255755804, "directing": 0.0006426480897324373, "are 1": 0.0008528775156025596, "e ciency this": 0.0010298199627877902, "general perfect": 0.000971904517366954, "accomplish": 0.0006948964578081959, "use this": 0.00032046858343152956, "rational and covergent": 0.0010298199627877902, "and the term": 0.0007161785195604264, "a learning rule": 0.0010298199627877902, "increase": 4.929618084650774e-06, "rational": 0.0031651414276002484, "function is": 0.00024523367939375136, "first we do": 0.0008732058717250353, "m 0 of": 0.0007521645399683924, "however while": 0.0007160765724402042, "to be an": 0.0004677409380222729, "policy for player": 0.0020596399255755804, "rate moreover": 0.000971904517366954, "in that joint": 0.0010298199627877902, "players payos in": 0.0010298199627877902, "a policy that": 0.0008321458774498469, "care": 0.00026011513263944863, "natural requirements for": 0.0010298199627877902, "of the policy": 0.0008321458774498469, "stochastic contexts": 0.000971904517366954, "for learning research": 0.0010298199627877902, "both players": 0.006966934345951425, "the agent initially": 0.004119279851151161, "moreover we need": 0.0008732058717250353, "to both agents": 0.0010298199627877902, "of convergence rate": 0.0010298199627877902, "if several": 0.0007421847985653504, "perfect and imperfect": 0.0010298199627877902, "termed the": 0.0006290164566258502, "can observe": 0.0017246928069871226, "as follows": 0.00016380473876257984, "2 can guarantee": 0.0010298199627877902, "players whom we": 0.0010298199627877902, "if for": 0.0007921909787034762, "algorithm of the": 0.0007330505281739418, "above the following": 0.0008732058717250353, "which game": 0.000971904517366954, "to model partial": 0.0009310344469842923, "its action is": 0.0009310344469842923, "was to show": 0.0008002740946718667, "histories to the": 0.0010298199627877902, "impossible": 0.0001588391732678592, "will treat the": 0.0009310344469842923, "size": -0.0003310990064917965, "were able": 0.00046046251587537234, "both players always": 0.0010298199627877902, "repeat compute and": 0.0010298199627877902, "selected and": 0.000549963838367756, "payo for both": 0.0010298199627877902, "play against": 0.000971904517366954, "row i": 0.0005842412659181877, "we present": 0.00014117710933096947, "action repeatedly this": 0.0010298199627877902, "its adversary": 0.001943809034733908, "approximated by": 0.000896549691353365, "friend": 0.0006426480897324373, "which is non": 0.0008732058717250353, "9 most": 0.0008730815719568182, "the end": 0.00019522836659569394, "general way": 0.0006939782666478507, "that": -0.11697627921456745, "be treated as": 0.0005943034268074654, "more fundamental": 0.000774103816216825, "concrete algorithm": 0.000971904517366954, "designer wants its": 0.0010298199627877902, "vu a general": 0.0010298199627877902, "adversary will": 0.002864306289760817, "a policy prole": 0.006178919776726742, "ciency this": 0.000971904517366954, "than": -0.004753074033470694, "i and column": 0.0008732058717250353, "the objective": 0.00036281071874830087, "is justied by": 0.0008002740946718667, "rational learning strategies": 0.0010298199627877902, "row 1": 0.0006939782666478507, "by a nash": 0.0010298199627877902, "row 2": 0.0007160765724402042, "games the folk": 0.0010298199627877902, "of two player": 0.0009310344469842923, "the particular context": 0.0010298199627877902, "ensure that the": 0.0004334456773524235, "column 2": 0.0006939782666478507, "insight of": 0.0008152096437846543, "column 1": 0.0006939782666478507, "detrimental eect": 0.000971904517366954, "punishment of": 0.000971904517366954, "the same": 2.4651599048225154e-05, "least the value": 0.0010298199627877902, "pareto ele for": 0.0010298199627877902, "while the others": 0.0009310344469842923, "he does not": 0.0007742140246189059, "predict human behavior": 0.0010298199627877902, "from 9 to": 0.0008732058717250353, "online": 0.0010060315371144643, "objective": 0.00029812667073172766, "july 19 23": 0.0007010750178672042, "interaction has": 0.0008730815719568182, "case of": 0.0011277410437070126, "are repeated games": 0.0010298199627877902, "agents go": 0.000971904517366954, "of utility function": 0.0010298199627877902, "learning algorithm that": 0.0008732058717250353, "with a game": 0.0010298199627877902, "the assumption": 0.0002440388335391651, "the designer s": 0.0010298199627877902, "action can": 0.0014843695971307007, "or other solution": 0.0010298199627877902, "value although we": 0.0010298199627877902, "game theorists adopt": 0.0010298199627877902, "we also need": 0.0005690630947869114, "setting a": 0.0005842412659181877, "not always exist": 0.003089459888363371, "view of the": 0.00043109594775796693, "ele much": 0.000971904517366954, "policy prole suitably": 0.0010298199627877902, "i for in": 0.0010298199627877902, "treat the adversary": 0.0010298199627877902, "actual game": 0.001943809034733908, "implications": 0.00024046123258007927, "crucial point about": 0.0010298199627877902, "exists with imperfect": 0.0010298199627877902, "throughout this section": 0.0006165622637081906, "then they": 0.0005159204175055324, "the exploration phase": 0.0010298199627877902, "exclude the possibility": 0.0008321458774498469, "typically": 4.7256076102612245e-05, "by examining": 0.00047837713542937403, "this average reward": 0.0010298199627877902, "fact that all": 0.0006874022974519222, "interval of possible": 0.0010298199627877902, "depend on": 0.0002161844266599044, "reach formally let": 0.0010298199627877902, "punishment can be": 0.0020596399255755804, "side payments will": 0.0010298199627877902, "cient now we": 0.0010298199627877902, "by u 1": 0.0009310344469842923, "there for more": 0.0010298199627877902, "what we": 0.0007165821962532387, "1 500 most": 0.0010298199627877902, "realistic but": 0.000971904517366954, "work on normative": 0.0010298199627877902, "only": -0.00785661576814259, "that all agents": 0.0020596399255755804, "2 the": 0.00018905121178474228, "with discounting": 0.000971904517366954, "upon conver gence": 0.0010298199627877902, "2 g2": 0.0008730815719568182, "exponential number of": 0.0013748045949038444, "monitoring 2": 0.0008730815719568182, "we adopt": 0.00042987295519467854, "is considered": 0.00028936800859759385, "truly": 0.00041334544264567334, "under the": 0.00018222125467611227, "term average": 0.001943809034733908, "judgment of": 0.0007421847985653504, "vickrey": 0.0007739936391863359, "beyond recommending": 0.000971904517366954, "same setting": 0.0008730815719568182, "both ele": 0.001943809034733908, "can do is": 0.0009310344469842923, "at any": 0.0004952891408603564, "strategies the": 0.0006049243473022664, "ele a pareto": 0.0010298199627877902, "and computational learning": 0.0008732058717250353, "classes of": 0.0008459792749608185, "payos might be": 0.0010298199627877902, "each joint": 0.0016304192875693086, "learning ctr": 0.000971904517366954, "will not be": 0.0008067236173280798, "and g2 are": 0.0010298199627877902, "signicant merit for": 0.0010298199627877902, "here is": 0.00025505472871573733, "0 polynomial": 0.0017461631439136364, "also discuss": 0.0005842412659181877, "maximize u next": 0.0010298199627877902, "namely": 5.1064331644678514e-05, "an agent that": 0.0017464117434500706, "k we": 0.00034336616306129136, "union of": 0.0003222656159195575, "immediately rules": 0.000971904517366954, "approach motivated largely": 0.0010298199627877902, "th action and": 0.0010298199627877902, "rob powers": 0.000971904517366954, "be viewed": 0.0002849081850832917, "3": 0, "identity of": 0.0015477612525165972, "between": -0.0005158469873294001, "equilibrium of the": 0.004655172234921462, "game i e": 0.0010298199627877902, "uses the": 0.00020298909787029243, "notice": 0.0005389535377919357, "international joint conference": 0.0014661010563478836, "adopted by the": 0.0008732058717250353, "ai we are": 0.0010298199627877902, "the near": 0.0010442736061720109, "about its agent": 0.0010298199627877902, "that initially": 0.0006939782666478507, "agent designer wants": 0.0010298199627877902, "a payo": 0.001943809034733908, "monitoring settings in": 0.0010298199627877902, "for that": 0.0003002135720884527, "ciency of": 0.0006290164566258502, "agent designers there": 0.0010298199627877902, "r rational and": 0.0010298199627877902, "agent or a": 0.0010298199627877902, "other game": 0.000971904517366954, "a natural number": 0.0007330505281739418, "his utility": 0.000971904517366954, "it should": 0.0002513155220508818, "s payo an": 0.0010298199627877902, "in economics for": 0.0010298199627877902, "optimal the long": 0.0010298199627877902, "be attained": 0.0007160765724402042, "consider the": 0.0005529670073067819, "deviating": 0.000872957307571399, "one time after": 0.0010298199627877902, "for every": 0.0016899155672733877, "use the same": 0.0009354818760445458, "learning": 0.0188176587981749, "moreover": -8.880419600687245e-05, "actually": -1.3565354370100328e-05, "distributed algorithmic mechanism": 0.0010298199627877902, "uses the agent": 0.0010298199627877902, "followed in equilibrium": 0.0010298199627877902, "induced markov": 0.000971904517366954, "failure of": 0.0010084195104002043, "approach motivated": 0.000971904517366954, "rationality than that": 0.0010298199627877902, "model of multi": 0.0010298199627877902, "1 and is": 0.0006428310760905615, "agent if it": 0.0010298199627877902, "is not devoid": 0.0010298199627877902, "is played the": 0.0010298199627877902, "systems we": 0.0004482748456766825, "with discounting or": 0.0010298199627877902, "this setting our": 0.0009310344469842923, "is always g1": 0.0010298199627877902, "obtained and": 0.0006939782666478507, "the simplifying": 0.0008152096437846543, "t 0 as": 0.0009310344469842923, "procedure for that": 0.0010298199627877902, "in any game": 0.0010298199627877902, "in repeated": 0.003492326287827273, "irrational its": 0.000971904517366954, "these": -0.006072469884279626, "one of players": 0.0010298199627877902, "deviation will lead": 0.0010298199627877902, "approach the behavior": 0.0010298199627877902, "point if an": 0.0009310344469842923, "to obtain a": 0.0003447812898412679, "s payo initialize": 0.0010298199627877902, "the major conceptual": 0.0010298199627877902, "8 and stochastic": 0.0010298199627877902, "by the complements": 0.0010298199627877902, "histories for an": 0.0010298199627877902, "are people": 0.000971904517366954, "their long term": 0.0010298199627877902, "ensure that all": 0.000663411738084629, "long term": 0.0009973577212966454, "case we": 0.00020397751600166201, "their prescribed": 0.0008730815719568182, "additional notation": 0.0008152096437846543, "and the other": 0.0003546663244307511, "algorithms is 1": 0.0010298199627877902, "agents use": 0.0016304192875693086, "g dened": 0.0008730815719568182, "potentially a": 0.0006939782666478507, "maximized it is": 0.0010298199627877902, "investigated": 0.0001886117812523639, "value can": 0.0004736982533495064, "29 2005": 0.000774103816216825, "of rationality than": 0.0010298199627877902, "is treated as": 0.0005875760798754402, "multiagent systems distributed": 0.0010298199627877902, "attain at least": 0.0010298199627877902, "in a xed": 0.0009310344469842923, "mix we": 0.000971904517366954, "times to ensure": 0.0008732058717250353, "to recent": 0.000971904517366954, "would take": 0.0005842412659181877, "single agent": 0.0014843695971307007, "we show": 0.00013043284439489752, "with each joint": 0.0010298199627877902, "innite number": 0.0007421847985653504, "learning equilibrium if": 0.0020596399255755804, "bayesian it": 0.000971904517366954, "other agent designers": 0.0010298199627877902, "coordinate": 0.00022467793007595, "in non cooperative": 0.003089459888363371, "game theorists adopting": 0.0010298199627877902, "probabilistic actions": 0.000971904517366954, "be played": 0.0008730815719568182, "strategies and telling": 0.0010298199627877902, "will be treated": 0.0008321458774498469, "form the joint": 0.0010298199627877902, "the actions": 0.0009383165454816595, "reward however while": 0.0010298199627877902, "valuable": 0.00026801701724071423, "joint action at": 0.0010298199627877902, "will be executed": 0.000663411738084629, "is required but": 0.0010298199627877902, "positive constant": 0.0005842412659181877, "to punish": 0.001943809034733908, "speed": 0.00020287269474321531, "e ciency of": 0.0006874022974519222, "of the": 0.0, "be optimal among": 0.0010298199627877902, "of stochastic games": 0.0020596399255755804, "rst": 0.0011541289124287187, "complements": 0.0008666445880226083, "in an economically": 0.0009310344469842923, "is of lesser": 0.0010298199627877902, "case pareto ele": 0.0010298199627877902, "it does require": 0.0009310344469842923, "rational nodes proceedings": 0.0010298199627877902, "rules": 0.0002868802624090048, "1 plays": 0.001943809034733908, "trivial in a": 0.0010298199627877902, "g1 is where": 0.0010298199627877902, "is quite simple": 0.0007742140246189059, "and view": 0.0006748149214226754, "using": -0.0051411847178594984, "be no lower": 0.0010298199627877902, "them they": 0.000774103816216825, "must visit": 0.0008730815719568182, "random play they": 0.0010298199627877902, "every state and": 0.0009310344469842923, "in a with": 0.0008321458774498469, "play as": 0.000971904517366954, "the speed": 0.0004230779228348551, "players receive": 0.000971904517366954, "s reward is": 0.0010298199627877902, "of nitely many": 0.0010298199627877902, "relevant games and": 0.0010298199627877902, "t": 0, "consistent with": 0.0003186897302660093, "multiplicative": 0.00035168238084447203, "given set": 0.00046046251587537234, "policy in time": 0.0010298199627877902, "methodology in multiagent": 0.0010298199627877902, "cient learning in": 0.0010298199627877902, "nding the best": 0.0010298199627877902, "in which both": 0.0006874022974519222, "on agent 2": 0.0010298199627877902, "c where": 0.0004264387578012798, "on agent 1": 0.0010298199627877902, "cient solution": 0.00154820763243365, "theorems e g": 0.0010298199627877902, "less e": 0.0008152096437846543, "its corresponding": 0.00045629221416883416, "an ele does": 0.003089459888363371, "average reward this": 0.0010298199627877902, "approximation parameters": 0.0008152096437846543, "prole for agent": 0.0010298199627877902, "an algorithm for": 0.000810663176511636, "stochastic games 16": 0.0010298199627877902, "the value for": 0.000624803884002311, "the concept of": 0.0003866418347374886, "trivial in": 0.0006578931655429611, "need however": 0.000971904517366954, "because the": 0.000277688156083747, "tells it to": 0.0009310344469842923, "equivalent": -3.46743641699047e-05, "there exists ele": 0.0010298199627877902, "a result the": 0.0004677409380222729, "based on equilibria": 0.0010298199627877902, "simple heuristic rules": 0.0010298199627877902, "dened indeed in": 0.0010298199627877902, "hold here": 0.000971904517366954, "the expected time": 0.0007010750178672042, "is approximately equal": 0.0008002740946718667, "if its goal": 0.0010298199627877902, "exponentially far in": 0.0010298199627877902, "all policies": 0.0008730815719568182, "agents have": 0.000774103816216825, "moreover as": 0.0006578931655429611, "actions have": 0.001943809034733908, "the denition in": 0.0017464117434500706, "now assume that": 0.000624803884002311, "their long": 0.0008730815719568182, "pay a certain": 0.0010298199627877902, "rules out the": 0.0008321458774498469, "paper address": 0.000971904517366954, "joint actions": 0.001943809034733908, "numerically": 0.00036048429703467626, "of g2 is": 0.0010298199627877902, "games these": 0.0008730815719568182, "valued variable": 0.0008152096437846543, "learning with": 0.0005942188284548949, "rewards will": 0.000971904517366954, "the the best": 0.0008732058717250353, "an imperfect": 0.0017461631439136364, "they would have": 0.0007521645399683924, "spirit of": 0.002231269778304236, "be known": 0.0005099512042140099, "agent i is": 0.0018620688939685846, "log": 0.00015134065205489117, "if employed": 0.000971904517366954, "folk theorems": 0.002915713552100862, "removing": 0.00021825391481015917, "face is": 0.0006748149214226754, "requires additional notation": 0.0010298199627877902, "algorithm with this": 0.0009310344469842923, "start": 9.859236169301548e-06, "with the above": 0.0010486844339370012, "e in a": 0.0008002740946718667, "an ele where": 0.0010298199627877902, "may 2007": 0.001496036581944968, "is the minimal": 0.0006428310760905615, "deviation is considered": 0.0010298199627877902, "as long": 0.0002614473441041457, "many times to": 0.0009310344469842923, "of the so": 0.0014661010563478836, "the performance of": 0.0002645407941590159, "is similar": 0.0008001950497312939, "equilibrium a common": 0.0010298199627877902, "2 notice": 0.0006290164566258502, "not an issue": 0.0007521645399683924, "its goal": 0.0014843695971307007, "will have": 0.00025505472871573733, "behaviors exist": 0.000971904517366954, "trying": 0.00025251823875749443, "multi agent reinforcement": 0.002793103340952877, "normative approach to": 0.005149099813938952, "rapidly lead to": 0.0010298199627877902, "equilibrium policy tells": 0.0010298199627877902, "1 there exists": 0.001326823476169258, "in their work": 0.0018620688939685846, "prole by": 0.000971904517366954, "modied": 0.0011238774063273278, "assumed to": 0.0004977216576766628, "thus we restrict": 0.0008732058717250353, "complements to r": 0.0020596399255755804, "game in": 0.00570646750649258, "describe": -0.00022264959620173818, "the process k": 0.0010298199627877902, "play and": 0.000971904517366954, "g2 and visit": 0.0010298199627877902, "that player": 0.001943809034733908, "game is": 0.008906217582784204, "knows only": 0.0008152096437846543, "in our": 8.501452792615033e-05, "1 when": 0.0007969679895517099, "treated as the": 0.0007742140246189059, "exist in the": 0.0012331245274163811, "game is computed": 0.0010298199627877902, "will eventually adopt": 0.0010298199627877902, "6 9 most": 0.0010298199627877902, "results for both": 0.0008321458774498469, "of our average": 0.0010298199627877902, "construct the": 0.0003771588365708351, "the one shot": 0.0020596399255755804, "terms of": 0.00010284883635079144, "call rationality": 0.000971904517366954, "our behavior but": 0.0010298199627877902, "theoretic literature": 0.000971904517366954, "is clear that": 0.0004155626519889734, "played the idea": 0.0010298199627877902, "payo is not": 0.0010298199627877902, "for more": 0.0002777034574655148, "motivation underlying": 0.000971904517366954, "states s": 0.0006290164566258502, "constrained setting is": 0.0010298199627877902, "any motivation to": 0.0010298199627877902, "mark it": 0.0008730815719568182, "agent s average": 0.0010298199627877902, "should be": 0.0005856948974113642, "information to date": 0.0010298199627877902, "punish the other": 0.0010298199627877902, "that the algorithm": 0.0005159938685900292, "vincent conitzer": 0.000971904517366954, "groves mechanisms": 0.000971904517366954, "some outcome is": 0.0010298199627877902, "cannot replace": 0.0008730815719568182, "games we equated": 0.0010298199627877902, "may be in": 0.0007010750178672042, "i and": 0.00012075854637915474, "approach is that": 0.0004800375137323266, "2 will": 0.0009973577212966454, "and these dierences": 0.0010298199627877902, "possible games": 0.001943809034733908, "time using": 0.0005099512042140099, "of is": 0.00037467912962542367, "have that there": 0.0009310344469842923, "framework for learning": 0.0009310344469842923, "and mark": 0.0006578931655429611, "payos obtained by": 0.0010298199627877902, "ability to": 0.0005972485932628641, "algorithms should satisfy": 0.0010298199627877902, "nodes": 3.092816334898681e-05, "case where": 0.00028199309165360617, "very": -0.000229068874528053, "action at each": 0.0020596399255755804, "in game theory": 0.002793103340952877, "games learning to": 0.0010298199627877902, "earlier it": 0.0007160765724402042, "case is": 0.0002735087712513827, "one should view": 0.0009310344469842923, "one that requires": 0.0010298199627877902, "actions a": 0.0018147730419067994, "are special": 0.0005748976023290408, "that for every": 0.0008864289836066309, "games appears": 0.000971904517366954, "actions g": 0.000971904517366954, "integral part of": 0.0007161785195604264, "to a value": 0.0006335389089667411, "they compute the": 0.0010298199627877902, "natural candidate": 0.0007421847985653504, "for both agents": 0.0020596399255755804, "computational learning": 0.0006939782666478507, "other player": 0.00523848943174091, "maximin": 0.006983658460571192, "payos hence the": 0.0010298199627877902, "of length t": 0.0007330505281739418, "adaptive game playing": 0.0009310344469842923, "have that": 0.0007543176731416702, "agent deviate from": 0.0010298199627877902, "of this desired": 0.0010298199627877902, "same result": 0.0005286223582497236, "section uses": 0.0008730815719568182, "benchmark for success": 0.0010298199627877902, "and must be": 0.0006874022974519222, "it observed throughout": 0.0010298199627877902, "assumption that": 0.000530770152900467, "is a basic": 0.0007010750178672042, "45 76": 0.000971904517366954, "a particular class": 0.0008321458774498469, "classes of games": 0.0020596399255755804, "individual rationality the": 0.0010298199627877902, "policies and side": 0.0010298199627877902, "learner": 0.0005158469873294001, "not tell the": 0.0009310344469842923, "an ele for": 0.0020596399255755804, "be unknown below": 0.0010298199627877902, "it attain at": 0.0010298199627877902, "resp g1 are": 0.0010298199627877902, "thus we": 0.0004408114506631351, "have been played": 0.0020596399255755804, "we borrow": 0.0006748149214226754, "literature is the": 0.0008732058717250353, "dominated strategies": 0.000971904517366954, "rely on a": 0.0006428310760905615, "certain amount of": 0.0006527573289679061, "is paid": 0.0006939782666478507, "stochastic games b": 0.0010298199627877902, "in equilibrium": 0.004859522586834771, "the entry in": 0.0007521645399683924, "denition in the": 0.0018620688939685846, "repeated games the": 0.0010298199627877902, "optimal probabilistic": 0.000971904517366954, "game is g2": 0.0020596399255755804, "principles of distributed": 0.0006749109941620578, "motivated largely by": 0.0010298199627877902, "behavior before hand": 0.0010298199627877902, "amount": 2.594955263221671e-05, "corresponding strategies": 0.000971904517366954, "we can view": 0.0006428310760905615, "payo in a": 0.0010298199627877902, "imperfect monitoring recall": 0.0010298199627877902, "b introduction reinforcement": 0.0009310344469842923, "we adopt the": 0.0005690630947869114, "discussed later": 0.000557817444576059, "g2 resp": 0.001943809034733908, "lower than": 0.0012793162734038395, "over the uncertain": 0.0010298199627877902, "column 2 denoted": 0.0010298199627877902, "2 the only": 0.0008732058717250353, "what we borrow": 0.0010298199627877902, "economic in e": 0.0010298199627877902, "takes": -5.873688529485504e-05, "interesting examples of": 0.0010298199627877902, "contains": -0.00014906333536586383, "identical to": 0.0006707831629671389, "happens after an": 0.0010298199627877902, "them they treat": 0.0010298199627877902, "are equivalent to": 0.0005633746356361924, "actions and": 0.002199855353471024, "as the other": 0.0007521645399683924, "taken": -5.687338096134889e-05, "algorithm to": 0.00022040572533156756, "multi agent setting": 0.0010298199627877902, "the only": 0.0003711193652769863, "monitoring 2 t": 0.0010298199627877902, "typical to": 0.0008730815719568182, "and similarly": 0.0010084195104002043, "while other more": 0.0010298199627877902, "by a game": 0.0009310344469842923, "move to": 0.000549963838367756, "a we introduce": 0.0007742140246189059, "earlier the learning": 0.0010298199627877902, "for updating their": 0.0010298199627877902, "will have learning": 0.0010298199627877902, "learning algorithm as": 0.0018620688939685846, "one another": 0.00041030656060455343, "us try": 0.0008730815719568182, "approach is not": 0.0013498219883241157, "to use this": 0.0006749109941620578, "deviator s": 0.000971904517366954, "u s does": 0.0010298199627877902, "both players play": 0.0020596399255755804, "are classes of": 0.0008732058717250353, "games that": 0.0008730815719568182, "we say that": 0.000326578295499111, "history": 0.0012750921358013485, "probability that all": 0.0008321458774498469, "articial agents": 0.000971904517366954, "specied": 0.0003560256122600642, "starting at state": 0.0009310344469842923, "third international joint": 0.0007742140246189059, "described in 4": 0.0007010750178672042, "p 23": 0.0005842412659181877, "unique strategy": 0.000971904517366954, "have obtained in": 0.003089459888363371, "of learning": 0.004033678041600817, "exclude": 0.00037962257423597423, "now revealed": 0.000971904517366954, "the behavior": 0.0002777034574655148, "clarke": 0.0005941342541838367, "play the": 0.0010199024084280198, "for rational behavior": 0.0010298199627877902, "be followed": 0.0006290164566258502, "denition can be": 0.0008732058717250353, "the standard": 0.00022040572533156756, "at the end": 0.00032781678431008626, "monitoring proof": 0.000971904517366954, "given an": 0.0005972485932628641, "are presented": 0.000272130787801713, "rationality to be": 0.0010298199627877902, "game theory literature": 0.0020596399255755804, "only after an": 0.0010298199627877902, "then u 1": 0.0010298199627877902, "new basic": 0.0008730815719568182, "and update": 0.0004832040417809763, "the dynamics": 0.0009866863780212745, "convergence though denitely": 0.0010298199627877902, "in the context": 0.001205295026450472, "classical approach": 0.0008152096437846543, "a": 0, "that agent": 0.000774103816216825, "the entries": 0.0004333839769001314, "any deviation will": 0.0010298199627877902, "in g1 and": 0.0010298199627877902, "as using a": 0.0009310344469842923, "any xed policy": 0.0010298199627877902, "ele we": 0.001943809034733908, "a function agent": 0.0010298199627877902, "in 10 the": 0.0007161785195604264, "point about them": 0.0010298199627877902, "max will learn": 0.0010298199627877902, "assumed over": 0.000971904517366954, "player the": 0.0017461631439136364, "eventually adopt": 0.000971904517366954, "learning with the": 0.0010298199627877902, "notice that these": 0.0007521645399683924, "we denote this": 0.0006428310760905615, "is that the": 0.0004953596546902055, "strategy leads": 0.0008152096437846543, "a probability": 0.0016054352770548338, "adopted by all": 0.0009310344469842923, "result the": 0.00035829109812661935, "m and denote": 0.0020596399255755804, "exists a t": 0.0009310344469842923, "a policy i": 0.0010298199627877902, "the corresponding strategies": 0.0010298199627877902, "in ele": 0.000971904517366954, "and veloso suggest": 0.0010298199627877902, "removal of strictly": 0.0010298199627877902, "systems": -0.0013464837311668383, "information and": 0.00029240195497445495, "above side payments": 0.0010298199627877902, "to a view": 0.0008321458774498469, "mixed action": 0.000971904517366954, "strategies and": 0.0005942188284548949, "each state s": 0.0009310344469842923, "is the only": 0.0004134631378172694, "motivated": 0.00019047610901416596, "we wish to": 0.0008440669162546543, "that these": 0.00023701178129379517, "except that": 0.0003151849303416359, "faithfulness in networks": 0.0010298199627877902, "policies 1 if": 0.0010298199627877902, "to date most": 0.0009310344469842923, "whom chooses some": 0.0010298199627877902, "since the": 5.874524641731693e-05, "2 if the": 0.0005578968604992618, "question when": 0.0008730815719568182, "irrationality": 0.000872957307571399, "are considering": 0.0005354021517001512, "be optimal": 0.0005842412659181877, "itself may": 0.0006939782666478507, "have chosen the": 0.0006874022974519222, "hence a": 0.0004264387578012798, "and theoretical": 0.0006049243473022664, "algorithm termed the": 0.0009310344469842923, "subtle but crucial": 0.0010298199627877902, "the desired": 0.001683468233559211, "folk theorems in": 0.0020596399255755804, "the approach": 0.00026671552906703795, "game in question": 0.0010298199627877902, "will also": 0.00033345449157714114, "polynomially": 0.0004482110433929256, "learning algorithms moreover": 0.0010298199627877902, "should satisfy the": 0.0007742140246189059, "a boolean valued": 0.0008002740946718667, "particular action": 0.000774103816216825, "a learning": 0.004949674545309803, "our approach is": 0.00043109594775796693, "expected payo": 0.003887618069467816, "chosen the": 0.0005042097552001021, "new york new": 0.000663411738084629, "2 p 45": 0.0009310344469842923, "our approach in": 0.0006428310760905615, "but also determine": 0.0010298199627877902, "lower reward": 0.000971904517366954, "payo alone": 0.000971904517366954, "beyond": 0.00012147592237903854, "and ai": 0.0007421847985653504, "are much more": 0.0006165622637081906, "and an": 0.00016303716947679305, "since": -0.0017928441735717024, "a given class": 0.0014661010563478836, "dominated": 0.0003100100937262511, "7": -0.0005748157780190026, "and as": 0.0008726362601383686, "issue": 0.0001646722804491822, "dealt with": 0.0004881890232438977, "have no reason": 0.0009310344469842923, "to 10 contradicting": 0.0010298199627877902, "much like in": 0.0009310344469842923, "future the above": 0.0010298199627877902, "is said": 0.00029704876608852796, "is initially unknown": 0.0010298199627877902, "obtain a desired": 0.0008002740946718667, "reason": -3.697051864967361e-06, "every state": 0.0005748976023290408, "guarantee themselves can": 0.0010298199627877902, "agent visited and": 0.0010298199627877902, "agent plays as": 0.0010298199627877902, "this non": 0.0006427395698875594, "the players have": 0.0008732058717250353, "it will attain": 0.0010298199627877902, "modeled in": 0.000557817444576059, "economically e cient": 0.009268379665090113, "new issues": 0.000774103816216825, "exponentially": 0.00029083735304450325, "let a 0": 0.0007330505281739418, "below we describe": 0.0007010750178672042, "is more complicated": 0.0006749109941620578, "adversary s behavior": 0.0020596399255755804, "to that modied": 0.0010298199627877902, "probability": 0.000548907601497274, "value of the": 0.000295010963733657, "of a pareto": 0.0020596399255755804, "and decreased": 0.0008730815719568182, "and that is": 0.0006874022974519222, "the distribution": 0.000272130787801713, "reinforcement learning research": 0.0010298199627877902, "receive on": 0.0008730815719568182, "face are 1": 0.0010298199627877902, "if the player": 0.0010298199627877902, "the normative motivation": 0.0010298199627877902, "in g by": 0.0008002740946718667, "too if the": 0.0008732058717250353, "potentially a payment": 0.0010298199627877902, "follows the steps": 0.0009310344469842923, "both criteria": 0.000971904517366954, "sum stochastic": 0.002915713552100862, "obtain expected": 0.000971904517366954, "exists a": 0.0006612171759947027, "payos as": 0.001943809034733908, "every agent": 0.000774103816216825, "a constant": 0.0001961846478131347, "168 may": 0.000971904517366954, "although a": 0.0005042097552001021, "player 1 when": 0.0020596399255755804, "to believe that": 0.0006749109941620578, "economic in": 0.000971904517366954, "games is identical": 0.0010298199627877902, "and learns": 0.0008152096437846543, "there bowling and": 0.0010298199627877902, "many settings what": 0.0010298199627877902, "to 3 for": 0.0008002740946718667, "be approximated": 0.0009973577212966454, "rational agents adopting": 0.0010298199627877902, "of cooperative systems": 0.0010298199627877902, "immediate but requires": 0.0010298199627877902, "not concerned": 0.0006164744968379118, "as with": 0.0003698290826886664, "in 10": 0.00033539158148356945, "the columns": 0.0004482748456766825, "possible actions": 0.0008152096437846543, "maximin this": 0.000971904517366954, "thus should": 0.000971904517366954, "in general": 0.0003622756391374642, "suggested equilibrium policy": 0.0010298199627877902, "truly in the": 0.0010298199627877902, "do not": 3.7183700962792543e-05, "in cognitive": 0.0008730815719568182, "unknown but the": 0.0010298199627877902, "on learning": 0.00308237248418956, "a game will": 0.0010298199627877902, "conceptually the": 0.000774103816216825, "2 plays b": 0.0010298199627877902, "rewards of": 0.000971904517366954, "players always": 0.000971904517366954, "converge to the": 0.001249607768004622, "policy as": 0.0006427395698875594, "all designed": 0.0008730815719568182, "behavior if that": 0.0010298199627877902, "s i associates": 0.0010298199627877902, "payo to": 0.000971904517366954, "defect if": 0.000971904517366954, "multiplicative weights the": 0.0010298199627877902, "adopted by most": 0.0009310344469842923, "fassumed knowng this": 0.0010298199627877902, "issue our": 0.000971904517366954, "the agent": 0.0096238853812102, "the players whom": 0.0010298199627877902, "clear": 2.0986725184049335e-05, "following two": 0.0005787360171951877, "the other agent": 0.006178919776726742, "concept in the": 0.0007161785195604264, "can not": 0.00037223626733611355, "algorithm will": 0.0009044632226805281, "context agents are": 0.0010298199627877902, "might be unknown": 0.0010298199627877902, "policy both": 0.000971904517366954, "negative or": 0.000971904517366954, "given some value": 0.0010298199627877902, "theorem 5 a": 0.0010298199627877902, "action to": 0.0006578931655429611, "matrix correspond to": 0.0010298199627877902, "distributions over": 0.0006748149214226754, "game we": 0.0017461631439136364, "the dierences are": 0.0010298199627877902, "a basic": 0.0004042861100519966, "to cover the": 0.000624803884002311, "will always play": 0.004119279851151161, "parameters": -5.936372100570939e-05, "a multi agent": 0.0008732058717250353, "identical to the": 0.0005159938685900292, "these results": 0.0008958728898942962, "values for t": 0.0008321458774498469, "of values one": 0.0009310344469842923, "situation in stochastic": 0.0010298199627877902, "wants its": 0.000971904517366954, "adversary s payo": 0.003089459888363371, "reward see": 0.000971904517366954, "stance are not": 0.0010298199627877902, "guarantees that": 0.00035389034454809447, "where we wish": 0.0009310344469842923, "instances in this": 0.0008732058717250353, "for removing knowledge": 0.0010298199627877902, "point game theorists": 0.0010298199627877902, "during": -0.00011275805340224541, "model partial information": 0.0010298199627877902, "the literature": 0.00030181687348044, "6 stochastic": 0.000971904517366954, "had they known": 0.0020596399255755804, "of ele for": 0.0010298199627877902, "the above captures": 0.0010298199627877902, "wellman": 0.0007159746543399424, "t and all": 0.0007521645399683924, "plays his j": 0.0010298199627877902, "m with": 0.0004881890232438977, "when all agents": 0.0010298199627877902, "where the player": 0.0010298199627877902, "by using": 0.00014908455434598707, "of on": 0.000557817444576059, "they compute": 0.0008730815719568182, "players the": 0.0008152096437846543, "payos as dictated": 0.0010298199627877902, "payos hence": 0.000971904517366954, "close": 0.00012353743641881396, "setting proof": 0.0017461631439136364, "two player repeated": 0.0010298199627877902, "is to choose": 0.000663411738084629, "started with descriptive": 0.0010298199627877902, "u 2 then": 0.0009310344469842923, "parameters this": 0.0005842412659181877, "probability of at": 0.0007521645399683924, "framework of repeated": 0.0010298199627877902, "state will": 0.0007421847985653504, "a framework": 0.0003373507152868544, "deviation is": 0.0008152096437846543, "above side": 0.000971904517366954, "minimal t such": 0.0010298199627877902, "and move": 0.0005661109047770705, "all joint": 0.001943809034733908, "e cient punishment": 0.0020596399255755804, "of games is": 0.0010298199627877902, "agent while": 0.0008152096437846543, "c where c": 0.0007010750178672042, "nding the": 0.000557817444576059, "of games in": 0.0020596399255755804, "u 1 if": 0.0010298199627877902, "23 2004 new": 0.0007742140246189059, "prole is a": 0.0010298199627877902, "both": -0.007899606596622602, "without initially": 0.000971904517366954, "cooperative multi agent": 0.0009310344469842923, "adopted by": 0.0025709582795502375, "guarantee a best": 0.0010298199627877902, "games with k": 0.0020596399255755804, "case where the": 0.0004737656933058489, "of which": 0.00016642364028409505, "time it": 0.00035829109812661935, "namely the": 0.0003560762920625211, "1 and agent": 0.0009310344469842923, "to be": 1.8487111070193754e-05, "will enable": 0.0005942188284548949, "experimental": 7.17200656022512e-05, "in a nash": 0.005149099813938952, "because the average": 0.0008321458774498469, "perspective the choice": 0.0010298199627877902, "behavior of": 0.00023472124176624737, "any rationality": 0.000971904517366954, "another appealing": 0.000971904517366954, "this paper a": 0.0005811431115841947, "punishment procedure": 0.000971904517366954, "as prescribed by": 0.0009310344469842923, "mix steps it": 0.0010298199627877902, "described": -0.0004158889573913542, "we relax": 0.0006578931655429611, "in having": 0.0008152096437846543, "appear in e": 0.0010298199627877902, "games uses": 0.000971904517366954, "while our approach": 0.0008321458774498469, "we must": 0.0002563168538695653, "t efficient": 0.0006427395698875594, "m dened": 0.0008152096437846543, "general non cooperative": 0.0010298199627877902, "be executed": 0.00037467912962542367, "of at": 0.0010061747444507084, "of pareto ele": 0.003089459888363371, "initially do not": 0.0010298199627877902, "this payo": 0.000971904517366954, "model based approach": 0.0008321458774498469, "that joint action": 0.0010298199627877902, "any perfect monitoring": 0.0020596399255755804, "policies of the": 0.0008732058717250353, "to work": 0.0003222656159195575, "and deviations should": 0.0010298199627877902, "possible payos by": 0.0010298199627877902, "while": -0.0016575336186291467, "guido": 0.0006747188760310696, "mechanism which": 0.0006164744968379118, "assumption the desired": 0.0010298199627877902, "another related": 0.0013879565332957013, "conference on autonomous": 0.0014021500357344085, "history of": 0.0009866863780212745, "4 log": 0.0007421847985653504, "any stage because": 0.0010298199627877902, "agent knows that": 0.0010298199627877902, "individually rational they": 0.0010298199627877902, "s does": 0.0006578931655429611, "the player knows": 0.0020596399255755804, "justied the": 0.000971904517366954, "the descriptive": 0.0017461631439136364, "the two cases": 0.0006428310760905615, "in addition we": 0.0004509656222210493, "descriptive motivation": 0.001943809034733908, "aim is to": 0.0005811431115841947, "to select an": 0.0008002740946718667, "used": -0.003579873271699712, "as using": 0.0006578931655429611, "that would be": 0.0005943034268074654, "second the": 0.00039288397722888555, "on autonomous agents": 0.0014021500357344085, "the term": 0.0005334310581340759, "the players receive": 0.0010298199627877902, "we assume that": 0.00021761355734897564, "uses": -0.0006287461722650778, "of our results": 0.0005943034268074654, "other for k": 0.0010298199627877902, "fact that": 0.00045685208399996426, "well dened": 0.0011497952046580816, "outset a": 0.000971904517366954, "remains a": 0.000549963838367756, "agent as a": 0.0009310344469842923, "as well and": 0.000663411738084629, "finally note": 0.0005942188284548949, "4 there": 0.0004832040417809763, "can view a": 0.0009310344469842923, "assumptions are typical": 0.0010298199627877902, "associated with the": 0.0003590870410572324, "solution concept in": 0.0010298199627877902, "is an appealing": 0.0010298199627877902, "game is known": 0.0010298199627877902, "p 45": 0.0007421847985653504, "and if": 0.0002335852782197112, "learning and": 0.0009473965066990128, "where our": 0.0006578931655429611, "is ergodic": 0.000971904517366954, "cient algorithm": 0.0006290164566258502, "survey markov games": 0.0010298199627877902, "payos obtained for": 0.0010298199627877902, "theorems in": 0.0014321531448804085, "policies 1": 0.000971904517366954, "particular context": 0.0008730815719568182, "two distinctive": 0.000971904517366954, "guarantees": 0.00011419676523269817, "remaining": 6.162369165004876e-06, "and stochastic": 0.0006748149214226754, "policy is the": 0.0008321458774498469, "that here the": 0.0008321458774498469, "systems july 25": 0.0008732058717250353, "side monetary payments": 0.0010298199627877902, "showing": 0.00012147592237903854, "that in general": 0.000552614435925888, "recall that in": 0.0006749109941620578, "game": 0.02953309945684833, "punish it": 0.000971904517366954, "monitoring setting 6": 0.0010298199627877902, "other game parameters": 0.0010298199627877902, "games we": 0.0008730815719568182, "realistic but also": 0.0010298199627877902, "manifest": 0.0005285471202254922, "time update the": 0.0010298199627877902, "that paid rby": 0.0010298199627877902, "mixing time 14": 0.0010298199627877902, "threat that": 0.000971904517366954, "our setting we": 0.0009310344469842923, "revealed game is": 0.0010298199627877902, "to the fact": 0.0004113910069980645, "prescribed learning": 0.000971904517366954, "imperfect monitoring where": 0.0010298199627877902, "a view of": 0.0007742140246189059, "some": -0.007250594666369, "similar in terms": 0.0008732058717250353, "16 15 12": 0.0010298199627877902, "500 the": 0.0008152096437846543, "0 we": 0.00030181687348044, "replaced by a": 0.0005080852977998101, "pv i": 0.000971904517366954, "required policy": 0.000971904517366954, "tell the dierence": 0.0010298199627877902, "perfect monitoring setting": 0.005149099813938952, "appropriate solution concept": 0.0010298199627877902, "rg the players": 0.0010298199627877902, "specically": 0.00040720998722279956, "an issue": 0.0005159204175055324, "depend on s": 0.0008732058717250353, "satisfying the": 0.0003517324423933467, "previous section uses": 0.0010298199627877902, "so by resorting": 0.0010298199627877902, "run": -7.412246185128837e-05, "game m let": 0.0010298199627877902, "markov games": 0.0008730815719568182, "any stage": 0.0007160765724402042, "step": -0.000254817480339662, "powers yoav": 0.000971904517366954, "view its": 0.000971904517366954, "matrix moreover we": 0.0010298199627877902, "results on": 0.000644531231839115, "hence the": 0.00019332718635632658, "2 denoted": 0.0014321531448804085, "works": 3.4674364169904715e-05, "along this": 0.0005842412659181877, "g repeatedly": 0.000971904517366954, "systems predicting how": 0.0010298199627877902, "like a": 0.00039848399477585494, "other cases the": 0.0007330505281739418, "on the agents": 0.0009310344469842923, "about minimizing the": 0.0010298199627877902, "state the other": 0.0010298199627877902, "the corresponding bayes": 0.0010298199627877902, "learn a t": 0.0010298199627877902, "by the players": 0.0020596399255755804, "within": -0.0002608285601691304, "get that the": 0.0008732058717250353, "b we": 0.0003517324423933467, "where both players": 0.0020596399255755804, "we note": 0.00028638295103369663, "be polynomial in": 0.0008732058717250353, "is otherwise": 0.0007160765724402042, "xed sum game": 0.003089459888363371, "underlying learning": 0.000971904517366954, "learning stochastic": 0.0008730815719568182, "reinforcement learning near": 0.0010298199627877902, "games with discounting": 0.0010298199627877902, "veloso consider the": 0.0010298199627877902, "previous observations": 0.000774103816216825, "initially plays": 0.003887618069467816, "g1 are": 0.0008730815719568182, "other agent": 0.005195293589957453, "ciently converge": 0.000971904517366954, "u we use": 0.0008321458774498469, "have been carried": 0.0007161785195604264, "economics for dealing": 0.0010298199627877902, "decision that should": 0.0009310344469842923, "the remaining": 0.00018863862990449944, "section we prove": 0.0006335389089667411, "initialized to the": 0.0008321458774498469, "knowng this": 0.000971904517366954, "policy will": 0.0017461631439136364, "case pareto": 0.000971904517366954, "is a deeper": 0.0010298199627877902, "and g2": 0.0008730815719568182, "punishment mechanism which": 0.0010298199627877902, "and denote": 0.0009473965066990128, "intuitive": 0.00020996895063142424, "payo theorem 3": 0.0010298199627877902, "here theorem 5": 0.0010298199627877902, "we also discuss": 0.0006874022974519222, "said earlier it": 0.0010298199627877902, "paramount importance": 0.0008730815719568182, "deviates the other": 0.0010298199627877902, "designing articial agents": 0.0010298199627877902, "the well known": 0.00042425064540523185, "similar": -0.0019225378297237363, "learning in games": 0.008238559702302322, "following are natural": 0.0010298199627877902, "instance of": 0.0006004271441769054, "to obtain": 0.0005584792899710896, "the dierence": 0.0004736982533495064, "payos it observed": 0.0010298199627877902, "in multi": 0.001496036581944968, "criteria are": 0.0006427395698875594, "bayesian approach used": 0.0010298199627877902, "value it": 0.0011684825318363755, "value is": 0.00028344496914384004, "is the": 3.1428088819329385e-05, "notice that in": 0.0006428310760905615, "and the": 0.0, "regardless of what": 0.0007330505281739418, "do so": 0.000699203612078287, "have adopted this": 0.0010298199627877902, "choice of": 0.0006516966420619427, "conver gence and": 0.0010298199627877902, "value in": 0.0006908387395800816, "imperfect monitoring": 0.013606663243137355, "the rewards r": 0.0010298199627877902, "imperfect monitoring the": 0.0020596399255755804, "average reward for": 0.0010298199627877902, "for example the": 0.00024447114081751033, "in question when": 0.0010298199627877902, "similarly for": 0.0009209250317507447, "player whom": 0.000971904517366954, "economics and": 0.001943809034733908, "will predict": 0.0008730815719568182, "of an innite": 0.0009310344469842923, "of human": 0.0005042097552001021, "reward first": 0.000971904517366954, "a given game": 0.0010298199627877902, "in games which": 0.0010298199627877902, "to do o": 0.0010298199627877902, "distributed mechanism": 0.000971904517366954, "structure": -0.000254817480339662, "not well dened": 0.0009310344469842923, "no reason": 0.000549963838367756, "correlated": 0.0006480702545484131, "e": -0.028206240893194658, "learning has": 0.000774103816216825, "using strategies that": 0.0009310344469842923, "required": -0.0009771996542957706, "to obtain maximal": 0.0010298199627877902, "this ability": 0.000774103816216825, "own i e": 0.0009310344469842923, "on the new": 0.0007161785195604264, "be carried out": 0.0005201099482447018, "requires": -0.00023418196206998225, "2 steps of": 0.0010298199627877902, "section we assume": 0.000663411738084629, "removing knowledge of": 0.0010298199627877902, "our benchmark for": 0.0010298199627877902, "and less e": 0.0010298199627877902, "stochastically": 0.0005941342541838367, "say that": 0.0002193427981572845, "simply guess progressively": 0.0010298199627877902, "agent i starting": 0.0010298199627877902, "mechanism design": 0.0008152096437846543, "may 2007 guido": 0.0010298199627877902, "mechanisms proceedings": 0.0008730815719568182, "in strategic": 0.001943809034733908, "that denes the": 0.0009310344469842923, "exists and": 0.000549963838367756, "should quickly": 0.001943809034733908, "the implications of": 0.0006087606573971396, "they treat the": 0.0009310344469842923, "call convergence": 0.000971904517366954, "naturally given": 0.000971904517366954, "interested in designing": 0.0009310344469842923, "function of": 0.00018403798293668077, "thus no": 0.0006049243473022664, "suitably modied to": 0.0009310344469842923, "strict imperfect": 0.002915713552100862, "learning procedure that": 0.0010298199627877902, "g2": 0.0033819468765413484, "g1": 0.0033819468765413484, "later assume": 0.000971904517366954, "lead to a": 0.0019736537031889104, "2 performs": 0.0014843695971307007, "telling": 0.0005577380512591538, "quite simple": 0.0006164744968379118, "the dierent agents": 0.0010298199627877902, "required but": 0.000774103816216825, "to a lower": 0.000663411738084629, "employ the same": 0.0008732058717250353, "machine learning articial": 0.0010298199627877902, "michael": 0.00021407307099007605, "game moreover": 0.000971904517366954, "stationary opponents machine": 0.0010298199627877902, "far and the": 0.0017464117434500706, "as a constant": 0.000663411738084629, "that the size": 0.0006087606573971396, "line is that": 0.0010298199627877902, "is rational": 0.0008152096437846543, "the maximization": 0.0008730815719568182, "punishing": 0.000872957307571399, "adopt a bayesian": 0.0010298199627877902, "an appealing": 0.0008730815719568182, "desired strategy": 0.000971904517366954, "go": 0.0003777478191540665, "solution is played": 0.0010298199627877902, "and denote by": 0.0014661010563478836, "suggest two": 0.0007421847985653504, "plays": 0.002358298101934392, "of convergence adopted": 0.0010298199627877902, "tell the": 0.0006748149214226754, "were interested in": 0.0008002740946718667, "other agent is": 0.0010298199627877902, "after polynomial time": 0.0020596399255755804, "cooperative setting we": 0.0010298199627877902, "science and": 0.0008813032337434041, "other agent if": 0.0010298199627877902, "single agent while": 0.0010298199627877902, "equilibria concepts are": 0.0010298199627877902, "policy prole that": 0.0020596399255755804, "i in": 0.0006361255221171649, "common description of": 0.0010298199627877902, "stance": 0.0005285471202254922, "made by game": 0.0010298199627877902, "enough k": 0.0008152096437846543, "g2 the": 0.000971904517366954, "i is": 0.0002429864286505693, "the previous": 0.00019872491852475179, "entities and": 0.0006049243473022664, "descriptive motivation in": 0.0010298199627877902, "t and game": 0.0020596399255755804, "a natural question": 0.0007010750178672042, "an extension": 0.0003083762652718511, "where c can": 0.0010298199627877902, "work that features": 0.0010298199627877902, "to some desired": 0.0009310344469842923, "systems distributed": 0.0006290164566258502, "always 0": 0.0008152096437846543, "interest game": 0.000971904517366954, "of rewards as": 0.0010298199627877902, "if we": 0.00021556039867918025, "games 16": 0.000971904517366954, "claim": 0.00016554950324589824, "simple heuristic": 0.0006427395698875594, "k iterations of": 0.0009310344469842923, "i the game": 0.0010298199627877902, "its payo it": 0.0010298199627877902, "punishment can": 0.001943809034733908, "this strategy takes": 0.0010298199627877902, "interactions it is": 0.0010298199627877902, "stochastically the": 0.0008730815719568182, "boolean": 0.0001886117812523639, "these dierences have": 0.0010298199627877902, "paid c": 0.000971904517366954, "as much": 0.0003454193697900408, "then with a": 0.0008321458774498469, "partial information": 0.0013157863310859221, "remains": -6.1623691650048665e-06, "to increased reward": 0.0010298199627877902, "and its corresponding": 0.0007010750178672042, "player 1 and": 0.0020596399255755804, "this policy will": 0.0020596399255755804, "rst obstacle we": 0.0010298199627877902, "agents is": 0.0007421847985653504, "shneidman": 0.001745914615142798, "to that of": 0.0003517825181966487, "rewards let be": 0.0010298199627877902, "this idea": 0.00041030656060455343, "started": 0.0002627137333473286, "becomes": -5.873688529485504e-05, "vu a": 0.000971904517366954, "benchmark": 0.0003100100937262511, "desired solution the": 0.0010298199627877902, "carried out so": 0.0009310344469842923, "and player": 0.002915713552100862, "receive identical payos": 0.0010298199627877902, "equilibrium policy": 0.000971904517366954, "performing a": 0.00046915827274082977, "designer s": 0.0008730815719568182, "behavior performing": 0.000971904517366954, "cannot provide interesting": 0.0010298199627877902, "and let policy": 0.0010298199627877902, "other agent s": 0.0010298199627877902, "time of": 0.0006454246723220043, "side payments for": 0.0010298199627877902, "have a set": 0.0013498219883241157, "variable is": 0.00041030656060455343, "appropriate equilibrium in": 0.0010298199627877902, "a more rigorous": 0.0008002740946718667, "average reward criterion": 0.0010298199627877902, "of t mix": 0.0010298199627877902, "is not": 6.410467335787843e-05, "not notice a": 0.0010298199627877902, "bayesian model of": 0.0009310344469842923, "policy for both": 0.0010298199627877902, "on single": 0.0006049243473022664, "let p i": 0.0007010750178672042, "special well dened": 0.0010298199627877902, "this paper in": 0.0005475136432016508, "these results to": 0.0006335389089667411, "is non": 0.00032591593593977075, "properties are impossible": 0.0010298199627877902, "choose to adopt": 0.0010298199627877902, "case the": 0.0002593576394352413, "particular consider the": 0.0008732058717250353, "above it is": 0.0007010750178672042, "that the agent": 0.0007330505281739418, "a t 0": 0.0016642917548996938, "more fundamental work": 0.0010298199627877902, "minimize their": 0.000971904517366954, "the case where": 0.00039571599730699815, "more general model": 0.0008321458774498469, "be lower": 0.0007160765724402042, "case of pareto": 0.0010298199627877902, "2 if": 0.00046042717499527225, "a game in": 0.003089459888363371, "in the spirit": 0.001990235214253887, "that agents designed": 0.0010298199627877902, "appropriate here": 0.000971904517366954, "similar 3 e": 0.0010298199627877902, "theorem in": 0.0004986788606483227, "tools for learning": 0.0010298199627877902, "become irrational after": 0.0010298199627877902, "2 is": 0.0004916395824143196, "construct the following": 0.0008002740946718667, "a game is": 0.0010298199627877902, "known proof the": 0.0010298199627877902, "solution the major": 0.0010298199627877902, "games with perfect": 0.003089459888363371, "i e we": 0.0004969500605540478, "agents to obtain": 0.0009310344469842923, "player knows its": 0.0010298199627877902, "times for in": 0.0010298199627877902, "economics machine": 0.000971904517366954, "that if we": 0.0004934134257972276, "a short": 0.0004230779228348551, "will use": 0.00029862429663143203, "have important": 0.000971904517366954, "dened indeed": 0.000971904517366954, "results on e": 0.0010298199627877902, "value may": 0.0006427395698875594, "history at": 0.0008730815719568182, "need to devise": 0.0010298199627877902, "mentioned": 2.9681860502854687e-05, "in addition they": 0.0008732058717250353, "and visit": 0.0008152096437846543, "performs action a": 0.0010298199627877902, "an integral": 0.000557817444576059, "9 these are": 0.0010298199627877902, "done in": 0.00028344496914384004, "payments so": 0.000971904517366954, "the next": 0.00022902692202148424, "distributed implementations of": 0.0009310344469842923, "initialize construct": 0.000971904517366954, "general case": 0.0007121525841250422, "over the set": 0.0011499588998751457, "cient manner this": 0.0010298199627877902, "to correlated equilibrium": 0.0010298199627877902, "of steps to": 0.0010298199627877902, "a policy is": 0.0009310344469842923, "insight of a": 0.0010298199627877902, "the agent will": 0.002619617615175106, "each can": 0.0006939782666478507, "rigorous notion of": 0.0010298199627877902, "next they": 0.0008730815719568182, "guarantee itself": 0.000971904517366954, "of the well": 0.0006165622637081906, "repeatedly this": 0.000971904517366954, "setting we": 0.0010572447164994472, "of game theory": 0.0010298199627877902, "work that": 0.0005354021517001512, "in the size": 0.0005475136432016508, "next iteration for": 0.0010298199627877902, "su ciently many": 0.0008732058717250353, "rationality in": 0.0008730815719568182, "random play to": 0.0010298199627877902, "is a mapping": 0.0005943034268074654, "multiple games": 0.000971904517366954, "so far and": 0.0016642917548996938, "it could": 0.0008027176385274169, "the above we": 0.0006527573289679061, "are natural requirements": 0.0010298199627877902, "are learning in": 0.0010298199627877902, "to minimize the": 0.0007914319946139963, "values for": 0.0005334310581340759, "could attain": 0.000971904517366954, "145": 0.0004263780634150286, "to 6": 0.00046046251587537234, "to 3": 0.0003771588365708351, "to 1": 0.0002193427981572845, "to 0": 0.0006373794605320186, "maximizes": 0.0011093293364166873, "the nash": 0.000971904517366954, "more rigorous notion": 0.0010298199627877902, "to the value": 0.0021327349377406, "although we initially": 0.0010298199627877902, "as well note": 0.0010298199627877902, "maximized": 0.0004263780634150286, "of this work": 0.00039949343125814357, "assumptions about": 0.00043697553507468355, "sets of dierent": 0.0010298199627877902, "needs to face": 0.0010298199627877902, "to n": 0.0003151849303416359, "required policy prole": 0.0010298199627877902, "to a": 8.136044530075738e-05, "the steps of": 0.0006087606573971396, "k 2 m": 0.0009310344469842923, "ele conceptually": 0.000971904517366954, "possible games which": 0.0010298199627877902, "simple and": 0.0003393324602016557, "g1 are lower": 0.0010298199627877902, "1 the probabilistic": 0.0010298199627877902, "this policy is": 0.0008732058717250353, "to r": 0.0006867323261225827, "literature the": 0.0006290164566258502, "in all": 0.00036444250935222455, "a 0 be": 0.0007742140246189059, "games is": 0.004859522586834771, "times": -0.0008226735842462965, "2005 the": 0.0008152096437846543, "parameters and the": 0.0006165622637081906, "g is": 0.000765164186147212, "games in": 0.0030964152648673, "assume we": 0.0005286223582497236, "was rst obtained": 0.0009310344469842923, "there are classes": 0.0010298199627877902, "constructive result": 0.000971904517366954, "sections we formalize": 0.0010298199627877902, "play games": 0.000971904517366954, "payos a": 0.000971904517366954, "well dened indeed": 0.0010298199627877902, "the best": 0.0009985418417045703, "procedures that if": 0.0010298199627877902, "a threat that": 0.0010298199627877902, "of a learning": 0.0024008222840156, "telling each agent": 0.0010298199627877902, "pareto ele": 0.013606663243137355, "adopted": 0.0011343109350257154, "we associate a": 0.000663411738084629, "iterations of": 0.0004482748456766825, "new york": 0.000774943119984624, "rst obtained once": 0.0010298199627877902, "setting studied": 0.000971904517366954, "similar suppose that": 0.0010298199627877902, "is economically e": 0.0010298199627877902, "punish": 0.0026188719227141968, "at a": 0.00012296715395040747, "the algorithm": 0.0006787999722565153, "payment to the": 0.0010298199627877902, "next iteration": 0.0005842412659181877, "in polynominal time": 0.0010298199627877902, "updating": 0.0002550184271602697, "mainly concerned": 0.0008152096437846543, "surprisingly has": 0.000971904517366954, "has signicant": 0.0008730815719568182, "articial intelligence": 0.0008152096437846543, "learning research in": 0.003089459888363371, "to the other": 0.0008485012908104637, "tools for": 0.00044065161687170207, "with descriptive": 0.001943809034733908, "played is greater": 0.0010298199627877902, "align the": 0.0007421847985653504, "strategies that maximize": 0.0010298199627877902, "behaviors": 0.00035168238084447203, "that is if": 0.0005005713348648543, "game associated": 0.002915713552100862, "in this context": 0.0005119876058604116, "satinder singh": 0.000971904517366954, "action of": 0.0005099512042140099, "based on": 0.0001482660261828191, "following model": 0.0007421847985653504, "need": -0.001691717736009038, "constrained": 0.00019047610901416596, "is said to": 0.0003651693276568247, "exists an": 0.00034749768772671775, "for the existence": 0.0013498219883241157, "to a decreased": 0.0010298199627877902, "pursued": 0.0005424277094845126, "able": -0.0004303203936135073, "1 resp player": 0.0010298199627877902, "issues one": 0.0008730815719568182, "m the payo": 0.0010298199627877902, "ciently finally": 0.000971904517366954, "instance": -4.941497456752558e-05, "but its": 0.0005221368030860054, "that joint": 0.000971904517366954, "payoff functions": 0.000971904517366954, "each state is": 0.0007742140246189059, "singh": 0.0004482110433929256, "parameter that is": 0.0008732058717250353, "rewards r": 0.000971904517366954, "a shared selection": 0.0010298199627877902, "idea in our": 0.0009310344469842923, "exist one is": 0.0010298199627877902, "of the strategy": 0.0007742140246189059, "s dilemma": 0.0008730815719568182, "unknown below": 0.000971904517366954, "policy in response": 0.0010298199627877902, "assumptions about the": 0.0005475136432016508, "notion of equilibrium": 0.0020596399255755804, "action of the": 0.0006428310760905615, "side payments structure": 0.0010298199627877902, "and then with": 0.0010298199627877902, "an adversary": 0.0010572447164994472, "obtaining similar": 0.000971904517366954, "proceedings": -7.039907907354142e-05, "is not of": 0.0006874022974519222, "i e for": 0.0004737656933058489, "considerably from": 0.000971904517366954, "the xed": 0.0012854791397751187, "i e will": 0.0009310344469842923, "parkes": 0.001745914615142798, "general results on": 0.0010298199627877902, "actions for": 0.0006164744968379118, "the outset": 0.000774103816216825, "value of": 0.00018905792776059888, "in the perfect": 0.0020596399255755804, "in the remaining": 0.0006749109941620578, "setting below we": 0.0010298199627877902, "game matrix": 0.005831427104201724, "to use the": 0.0003576004752760881, "human behavior": 0.0017461631439136364, "below we will": 0.0007161785195604264, "ele where": 0.002915713552100862, "related elds for": 0.0010298199627877902, "the agent plays": 0.0010298199627877902, "dynamics of": 0.0009866863780212745, "general case theorem": 0.0010298199627877902, "from the desired": 0.0008321458774498469, "algorithmic mechanism": 0.000971904517366954, "for both": 0.0007465824865149943, "considered irrational": 0.001943809034733908, "employed": 0.00017771041848258512, "performs the": 0.0008461558456697102, "very close to": 0.0004934134257972276, "now take": 0.0007421847985653504, "joint": 0.003988146883424672, "addition they should": 0.0010298199627877902, "following model m": 0.0010298199627877902, "2 notice that": 0.0006874022974519222, "procedures": 0.0001886117812523639, "we dene": 0.0007913193352553324, "a reinforcement procedure": 0.0010298199627877902, "section we show": 0.0004737656933058489, "500 the only": 0.0010298199627877902, "payments formally": 0.000971904517366954, "is the following": 0.0004264994694695317, "their requirements": 0.000774103816216825, "cient behavior with": 0.0010298199627877902, "irrational after": 0.001943809034733908, "are assumed to": 0.00044833866612737684, "of repeated": 0.007236824820972572, "learning in multi": 0.0010298199627877902, "the only equilibrium": 0.0020596399255755804, "suppose that": 0.00023021358749763612, "choice that": 0.0006939782666478507, "play games reinforcement": 0.0010298199627877902, "computed": -4.5990438577786594e-05, "learning algorithms in": 0.0008732058717250353, "14 3": 0.0005942188284548949, "by learning algorithms": 0.0010298199627877902, "computer": -0.0003127104584599601, "the outset a": 0.0010298199627877902, "game with respect": 0.0010298199627877902, "the required policy": 0.0010298199627877902, "and convergence": 0.0006578931655429611, "be irrational": 0.000971904517366954, "underlying learning research": 0.0010298199627877902, "choose r such": 0.0010298199627877902, "some t 0": 0.0010298199627877902, "maximin value of": 0.0010298199627877902, "provide new": 0.0006748149214226754, "the concepts": 0.0004832040417809763, "learning strategies is": 0.0010298199627877902, "a perfect monitoring": 0.0020596399255755804, "where we": 0.00027076263720952605, "dominated strategies now": 0.0010298199627877902, "state": -0.0006478582908318415, "be the the": 0.0008732058717250353, "stochastic game the": 0.0010298199627877902, "will rapidly": 0.0008152096437846543, "they run an": 0.0010298199627877902, "solution the": 0.000464748887987192, "attention": 0.0004049231791711237, "importance": 0.00027301757160748174, "behave in an": 0.0010298199627877902, "from the outset": 0.0010298199627877902, "each joint action": 0.0020596399255755804, "s osprings": 0.000971904517366954, "cover the": 0.0004933431890106373, "is always 0": 0.0009310344469842923, "see that if": 0.0006087606573971396, "makes an": 0.0006939782666478507, "given to the": 0.0006013538961527255, "much like": 0.000549963838367756, "for dealing": 0.0011497952046580816, "to an e": 0.0008732058717250353, "ideally we would": 0.0007742140246189059, "appealing alternative will": 0.0010298199627877902, "first we": 0.00022362585503292586, "of paramount importance": 0.0009310344469842923, "chosen the above": 0.0010298199627877902, "would play": 0.000971904517366954, "s j": 0.0004042861100519966, "systems we have": 0.0007330505281739418, "importance to better": 0.0010298199627877902, "the probabilistic maximin": 0.005149099813938952, "19 23 2004": 0.0007742140246189059, "policies of": 0.000774103816216825, "paradigms 1 the": 0.0010298199627877902, "equilibria exist": 0.000971904517366954, "for a joint": 0.0010298199627877902, "maximize": 0.0005306946091838572, "that may": 0.00029862429663143203, "s u": 0.0005221368030860054, "this context agents": 0.0010298199627877902, "adjust its": 0.0008152096437846543, "otherwise player": 0.0008730815719568182, "addition": -0.0004001727045290692, "than that": 0.0005848039099489099, "treat": 0.000458137749056106, "powers yoav shoham": 0.0010298199627877902, "in particular": 0.00021840092627021943, "he known": 0.000971904517366954, "corresponding": -0.0022556236480120507, "obtained in": 0.0013415663259342778, "but also technically": 0.0010298199627877902, "non cooperative": 0.003260838575138617, "history notice that": 0.0010298199627877902, "appealing concept": 0.000971904517366954, "consider the special": 0.0008321458774498469, "always exist in": 0.003089459888363371, "into one": 0.00037223626733611355, "which are initially": 0.0010298199627877902, "that the value": 0.0005286976176970826, "a pareto": 0.006984652575654546, "novel": 0.0006422192129702281, "reward i": 0.000971904517366954, "contexts": 0.00031341358721494, "in the past": 0.0004934134257972276, "rob powers yoav": 0.0010298199627877902, "while other": 0.0006427395698875594, "modied first": 0.000971904517366954, "much of this": 0.0008321458774498469, "r max of": 0.0020596399255755804, "is indeed an": 0.0008732058717250353, "above we": 0.00032777011999915245, "loss of choose": 0.0010298199627877902, "matrix g and": 0.0010298199627877902, "that we": 0.0002449851362671834, "from that": 0.001081606834576072, "s we can": 0.0007161785195604264, "too concerned with": 0.0010298199627877902, "plays a and": 0.0010298199627877902, "will also be": 0.0005690630947869114, "this section we": 0.0007277825538865158, "the economically": 0.000971904517366954, "able to": 0.0007201523616443828, "policy that": 0.0005842412659181877, "agents of": 0.0006939782666478507, "we must visit": 0.0010298199627877902, "equilibrium the learning": 0.0010298199627877902, "9 to 10": 0.0010298199627877902, "in networks": 0.0005942188284548949, "series of": 0.00032046858343152956, "normative criteria": 0.000971904517366954, "that agent 1": 0.0010298199627877902, "than 1 during": 0.0010298199627877902, "a threat": 0.0008730815719568182, "c parkes": 0.001943809034733908, "the underlying game": 0.0010298199627877902, "ele does not": 0.004119279851151161, "iterations if several": 0.0010298199627877902, "games machine": 0.000971904517366954, "interest games these": 0.0010298199627877902, "properties for": 0.0009567542708587481, "both players for": 0.0010298199627877902, "games 6 while": 0.0010298199627877902, "that for all": 0.0003920250525809008, "i": -0.022265722909025294, "dened case of": 0.0010298199627877902, "two paradigms 1": 0.0010298199627877902, "modeled": 0.00018129197857836914, "well": -0.0025554576575904865, "results to general": 0.0020596399255755804, "note that": 0.00016884048241892308, "rational they should": 0.0010298199627877902, "information game": 0.000971904517366954, "exploration phase": 0.000971904517366954, "rate should": 0.0008730815719568182, "polynominal": 0.000872957307571399, "detail": 6.131268375924486e-05, "leads to payos": 0.0010298199627877902, "game is as": 0.0010298199627877902, "is played game": 0.0010298199627877902, "mix be": 0.000971904517366954, "concepts that are": 0.0009310344469842923, "considered irrational if": 0.0010298199627877902, "the following games": 0.0010298199627877902, "i a": 0.0002805523466765939, "i e": 0.0004687889179247152, "i n": 0.0003373507152868544, "i m": 0.00041656361432912804, "obtain in the": 0.0008002740946718667, "form of": 0.00017862653075909445, "by dierent": 0.000774103816216825, "based on agent": 0.0018620688939685846, "the optimal probabilistic": 0.0010298199627877902, "concepts and": 0.0005221368030860054, "incomplete information game": 0.0010298199627877902, "now explain these": 0.0010298199627877902, "261": 0.00048313526807733544, "general criterion": 0.000971904517366954, "any xed": 0.0006164744968379118, "immediately": 0.00011747377058971008, "268": 0.0005748157780190026, "agents expected": 0.000971904517366954, "i 2": 0.00027076263720952605, "m the": 0.00028936800859759385, "sizes": 8.634975413947112e-05, "the game theory": 0.0020596399255755804, "can be viewed": 0.00037804761782699145, "cannot provide": 0.0006578931655429611, "payments": 0.00785661576814259, "monitoring we start": 0.0010298199627877902, "more complex and": 0.0008002740946718667, "the e": 0.001195451984327565, "initially knowing the": 0.0010298199627877902, "9 and": 0.0003002135720884527, "typical to work": 0.0010298199627877902, "would be": 0.0001327052786993835, "our results": 0.0007576625532427712, "u for": 0.0004482748456766825, "the t": 0.0004134042818545908, "some appropriate": 0.0008152096437846543, "players for": 0.000971904517366954, "david c parkes": 0.0020596399255755804, "cient approaches": 0.000971904517366954, "all states s": 0.0009310344469842923, "actually g1 and": 0.0010298199627877902, "out so": 0.000774103816216825, "had the": 0.0005221368030860054, "be used": 5.170812663072138e-05, "need only": 0.0009383165454816595, "are highly": 0.0005042097552001021, "do as much": 0.0009310344469842923, "most previous work": 0.0008321458774498469, "monitoring the same": 0.0010298199627877902, "resp 2 is": 0.0010298199627877902, "obtained in a": 0.002256493619905177, "in xed": 0.000971904517366954, "we prove rely": 0.0010298199627877902, "games at any": 0.0010298199627877902, "future and": 0.000774103816216825, "directing the agents": 0.0010298199627877902, "an ele we": 0.0010298199627877902, "one should": 0.0005159204175055324, "his i": 0.000971904517366954, "monetary": 0.0014319493086798849, "his j": 0.000971904517366954, "refer to that": 0.0009310344469842923, "that there are": 0.00032781678431008626, "m 0": 0.00041656361432912804, "bottom line": 0.000774103816216825, "value for": 0.0005668899382876801, "follows given": 0.0005159204175055324, "each agent maintains": 0.0010298199627877902, "will be able": 0.0010851643185757931, "above constitutes the": 0.0010298199627877902, "setting since our": 0.0010298199627877902, "some action to": 0.0009310344469842923, "now assume": 0.0005221368030860054, "as quickly": 0.0006939782666478507, "general model of": 0.0007742140246189059, "this approach most": 0.0010298199627877902, "setting 6 stochastic": 0.0010298199627877902, "known in advance": 0.0006428310760905615, "resp b by": 0.0010298199627877902, "thuc vu a": 0.0010298199627877902, "total payo for": 0.0010298199627877902, "a xed": 0.0008597459103893571, "maximization of": 0.0007421847985653504, "previously": 4.7256076102612245e-05, "a with": 0.0003517324423933467, "computational learning for": 0.0010298199627877902, "own i": 0.0008730815719568182, "must be modied": 0.0009310344469842923, "adversary quickly the": 0.0010298199627877902, "same algorithm this": 0.0010298199627877902, "utility": 0.0006629834235633571, "visit the entry": 0.0020596399255755804, "rigorous notion": 0.000971904517366954, "additional": -0.00011419676523269817, "science and treats": 0.0010298199627877902, "u for some": 0.0008732058717250353, "monetary payments": 0.001943809034733908, "be in equilibrium": 0.004119279851151161, "the expected t": 0.0010298199627877902, "agent 2 s": 0.0010298199627877902, "there may": 0.00036053561152535736, "of rewards will": 0.0010298199627877902, "and the players": 0.0010298199627877902, "about the game": 0.0010298199627877902, "let t mix": 0.0010298199627877902, "this phase": 0.000557817444576059, "distribution of": 0.000242850915721573, "goals": 0.00023355203237880321, "and are": 0.0001539317412432176, "the exploration stage": 0.0010298199627877902, "we introduce efficient": 0.0010298199627877902, "run the": 0.0003771588365708351, "distribution on": 0.000464748887987192, "he": 0.0006091414932580322, "1 s actions": 0.0010298199627877902, "be an e": 0.0009310344469842923, "its payo from": 0.0010298199627877902, "in and": 0.0004264387578012798, "constant r max": 0.0010298199627877902, "are typical to": 0.0010298199627877902, "in any": 0.0004323688533198088, "actions g for": 0.0010298199627877902, "empty": 4.346451032610047e-05, "here an": 0.0006049243473022664, "this payo was": 0.0010298199627877902, "games these are": 0.0010298199627877902, "values for agent": 0.0010298199627877902, "agent reinforcement learning": 0.004119279851151161, "u 2 a": 0.0008321458774498469, "prole": 0.010795502016497113, "agent initially plays": 0.004119279851151161, "devise": 0.00040720998722279956, "of the corresponding": 0.0003763816768240042, "game being played": 0.0010298199627877902, "equilibrium if for": 0.0020596399255755804, "or foe": 0.000971904517366954, "this theorem": 0.0004230779228348551, "9 these": 0.0006939782666478507, "an even more": 0.0008732058717250353, "0 step": 0.0008152096437846543, "iterations is": 0.0005748976023290408, "functions": -6.779667630156865e-05, "is associated with": 0.00041984698137044723, "state the": 0.0010488054181174305, "3 for": 0.0002130703251709539, "iterations if": 0.0008152096437846543, "otherwise player 1": 0.0010298199627877902, "multi agent": 0.0060492434730226655, "g2 are": 0.000971904517366954, "enforceable social": 0.000971904517366954, "behavior imagine": 0.000971904517366954, "setup all": 0.000971904517366954, "individual rationality to": 0.0010298199627877902, "a series of": 0.000405331588255818, "the required generalization": 0.0010298199627877902, "ele hold here": 0.0010298199627877902, "through a": 0.00028199309165360617, "and convergence though": 0.0010298199627877902, "it is rational": 0.0010298199627877902, "what the actual": 0.0009310344469842923, "of on line": 0.0008002740946718667, "for dealing with": 0.0012670778179334821, "approach used to": 0.0009310344469842923, "the players a": 0.0010298199627877902, "non trivial": 0.00038223374562649956, "psychology experimental": 0.000971904517366954, "least as": 0.0004482748456766825, "to denote": 0.0005909734152947452, "sum game": 0.003492326287827273, "dened over": 0.0014843695971307007, "run an algorithm": 0.0018620688939685846, "while obtaining similar": 0.0010298199627877902, "limited": 4.22041129018266e-05, "the second": 0.0001304120923350243, "of multi": 0.0012402128455637725, "consists": -0.00010705674809908032, "always receive": 0.000971904517366954, "ele provides": 0.000971904517366954, "show the": 0.0002141035440250924, "agents adopting the": 0.0010298199627877902, "rg m u": 0.0020596399255755804, "we often use": 0.0009310344469842923, "and describe": 0.00047837713542937403, "eect on the": 0.0007161785195604264, "game is played": 0.0009310344469842923, "but as with": 0.0008732058717250353, "polynomial in and": 0.0010298199627877902, "least as high": 0.0008732058717250353, "of choose": 0.0008730815719568182, "is over": 0.00046046251587537234, "from it it": 0.0010298199627877902, "theorists despite the": 0.0010298199627877902, "be treated": 0.0004482748456766825, "2004 new york": 0.0006874022974519222, "column 1 denoted": 0.0010298199627877902, "look": 0.00011709098103499112, "to learning": 0.003145082283129252, "rst action": 0.000971904517366954, "probability that": 0.0009455547910249078, "provides a more": 0.000663411738084629, "cooperative setting": 0.000971904517366954, "solution": -0.0003389833815078433, "vector": 5.9363721005709374e-05, "constructive existence results": 0.0010298199627877902, "markov": 0.0005877920413085473, "of learning procedures": 0.0010298199627877902, "importance these": 0.000971904517366954, "set a": 0.00034133740538055095, "2 theorem": 0.00043697553507468355, "the game that": 0.0010298199627877902, "log k": 0.0011884376569097899, "addition they": 0.0008152096437846543, "even": -0.00026534730459192864, "dierent for": 0.000774103816216825, "july 19": 0.0006427395698875594, "eventually lead to": 0.0008321458774498469, "of repeated games": 0.009268379665090113, "players receive the": 0.0010298199627877902, "to cover": 0.0004832040417809763, "a best": 0.0012580329132517005, "we are interested": 0.00036829598867252344, "reader there": 0.000971904517366954, "new": -0.0017165864613617793, "in both cases": 0.00044833866612737684, "is mainly concerned": 0.0009310344469842923, "initialized to": 0.000549963838367756, "and is treated": 0.0010298199627877902, "behavior": 0.00028865882793538725, "a certain": 0.00023021358749763612, "in many": 0.00021828498298308586, "assumption that all": 0.0007521645399683924, "a technique for": 0.0005425821592878966, "best it": 0.0008730815719568182, "joint action in": 0.0010298199627877902, "play cooperate": 0.000971904517366954, "and surprisingly": 0.0008730815719568182, "behavior with the": 0.0010298199627877902, "suitably": 0.00038477681440592316, "rests": 0.0005941342541838367, "they call rationality": 0.0010298199627877902, "economics": 0.0022992631120760105, "agent will go": 0.0010298199627877902, "0 where is": 0.0009310344469842923, "highly valuable": 0.0008730815719568182, "1 and are": 0.0007161785195604264, "adopting": 0.0008144199744455991, "against stationary opponents": 0.0010298199627877902, "joint action is": 0.0020596399255755804, "bayes": 0.00040720998722279956, "reward stochastic": 0.000971904517366954, "step average": 0.000971904517366954, "the approach taken": 0.0006527573289679061, "ciency of our": 0.0010298199627877902, "adopting the corresponding": 0.0010298199627877902, "that in order": 0.0005875760798754402, "reward in the": 0.0010298199627877902, "enough k we": 0.0010298199627877902, "a deeper notion": 0.0010298199627877902, "players if": 0.000971904517366954, "with each": 0.0002214738315017785, "prole adjusted": 0.000971904517366954, "show constructive": 0.000971904517366954, "players in": 0.000774103816216825, "be irrational for": 0.0010298199627877902, "determine stochastically": 0.000971904517366954, "to general": 0.001115634889152118, "0 be the": 0.0004969500605540478, "the requirement": 0.0004042861100519966, "call": -6.68487307365218e-05, "with polynomial": 0.0005942188284548949, "described in": 0.00011783488326033789, "of which the": 0.000663411738084629, "the values the": 0.0010298199627877902, "type": -8.098228635398019e-05, "tell": 0.0003650653796557838, "the term agent": 0.0009310344469842923, "of both players": 0.0010298199627877902, "reward because we": 0.0010298199627877902, "variable with each": 0.0010298199627877902, "perform from a": 0.0010298199627877902, "be an economically": 0.0010298199627877902, "agent with complete": 0.0010298199627877902, "know that": 0.00029393785638675104, "will be close": 0.0008732058717250353, "present in": 0.0002954867076473726, "nash equilibrium n": 0.0010298199627877902, "setup": 0.00034744822890409797, "maximizes u": 0.000971904517366954, "an appropriate equilibrium": 0.0010298199627877902, "goals of": 0.0005099512042140099, "and mark it": 0.0009310344469842923, "for the class": 0.0005875760798754402, "a deviation": 0.004891257862707926, "newfoundland": 0.0006163867549510861, "dilemma game": 0.0008730815719568182, "policy to converge": 0.0010298199627877902, "plays as": 0.000971904517366954, "selection algorithm if": 0.0010298199627877902, "also show": 0.0007803103270961426, "to a situation": 0.0009310344469842923, "adversary as": 0.000774103816216825, "implementations": 0.0003176783465357184, "stochastic games exists": 0.0010298199627877902, "to minimize": 0.000877205864923365, "the learning": 0.006554726817601328, "r max will": 0.0010298199627877902, "be in": 0.0013269253822511676, "ciency this latter": 0.0010298199627877902, "are equivalent": 0.0003698290826886664, "finally note that": 0.0006527573289679061, "we now explain": 0.0008732058717250353, "guidelines to the": 0.0010298199627877902, "agents for": 0.0007421847985653504, "technique for removing": 0.0010298199627877902, "2 we allow": 0.0010298199627877902, "b denote the": 0.0007010750178672042, "to face are": 0.0010298199627877902, "the payos": 0.003887618069467816, "if the total": 0.0007010750178672042, "interactions in a": 0.0009310344469842923, "description of a": 0.0006013538961527255, "strategy takes": 0.000971904517366954, "with ele in": 0.0010298199627877902, "the extended discussion": 0.0010298199627877902, "a framework for": 0.00044321449180331545, "used when": 0.00047837713542937403, "prove rely": 0.000971904517366954, "for punishing": 0.000971904517366954, "of actions a": 0.0024008222840156, "if employed by": 0.0010298199627877902, "attempt": 0.00011709098103499112, "approaches have": 0.000542504923393336, "third": -9.958593590466013e-05, "get close to": 0.0009310344469842923, "and results": 0.0004134042818545908, "probability distribution on": 0.000663411738084629, "had ages": 0.000971904517366954, "to each agent": 0.0010298199627877902, "be classes": 0.0008730815719568182, "imperfect technique for": 0.0010298199627877902, "use the": 0.0003357741243067012, "would have been": 0.0005286976176970826, "assuming the other": 0.0010298199627877902, "we get that": 0.001285662152181123, "i starting": 0.0006578931655429611, "strategic form": 0.001943809034733908, "it would": 0.000252554184414257, "the players may": 0.0010298199627877902, "in g2": 0.001943809034733908, "in g1": 0.0008152096437846543, "a resp": 0.0008730815719568182, "to refer to": 0.0005005713348648543, "the following constructive": 0.0010298199627877902, "previous section": 0.00022799513915820602, "before": -0.0003518764837060426, "all agents involved": 0.0010298199627877902, "t such": 0.0004264387578012798, "convergence rate moreover": 0.0010298199627877902, "better": -9.314441622249571e-05, "bayesian approach": 0.002081934799943552, "satinder singh learning": 0.0010298199627877902, "algorithms where our": 0.0010298199627877902, "the so called": 0.0008915109110165033, "as we said": 0.0008321458774498469, "of g1 is": 0.0010298199627877902, "maximal": 0.0005017592547840107, "valuable but": 0.000971904517366954, "the appendix 4": 0.0009310344469842923, "combination": 0.00013039029086321739, "to do": 0.0006939946032079003, "at state": 0.0006578931655429611, "s action": 0.0007160765724402042, "for every repeated": 0.0020596399255755804, "obtained by agent": 0.0020596399255755804, "particular work on": 0.0010298199627877902, "is irrational may": 0.0010298199627877902, "cannot replace concepts": 0.0010298199627877902, "but there": 0.00046046251587537234, "proof for the": 0.0005578968604992618, "pareto e cient": 0.0020596399255755804, "structure guarantees that": 0.0009310344469842923, "using redundancy to": 0.0010298199627877902, "rely on": 0.0003169286451286095, "parkes specification": 0.000971904517366954, "we believe that": 0.0003797306672240824, "its strategy 2": 0.0010298199627877902, "that should": 0.0009209250317507447, "benchmark for": 0.0006939782666478507, "in 1 and": 0.0007521645399683924, "see below and": 0.0010298199627877902, "side": 0.0003685082055317432, "ele provide": 0.000971904517366954, "learning ctr jeffrey": 0.0010298199627877902, "results on the": 0.0004969500605540478, "multi agent interactions": 0.0010298199627877902, "punishment remains a": 0.0010298199627877902, "the distribution of": 0.0003730996443725147, "principles": 0.000160501580343024, "behavior in": 0.0017626064674868083, "tuomas": 0.000872957307571399, "dierent agents will": 0.0010298199627877902, "behavior if": 0.0008730815719568182, "a policy we": 0.0010298199627877902, "but while our": 0.0010298199627877902, "repeated game be": 0.0010298199627877902, "guess progressively": 0.000971904517366954, "have a": 0.00016734139926038977, "crucial": 0.00018310191087925984, "discussed later assume": 0.0010298199627877902, "plays a": 0.0004881890232438977, "content": 0.00023813263627527116, "settings in both": 0.0010298199627877902, "if one": 0.00030181687348044, "reader": 0.00029812667073172766, "the game as": 0.0009310344469842923, "e i without": 0.0010298199627877902, "are attractive": 0.0007160765724402042, "actions and that": 0.0010298199627877902, "agents are": 0.0006164744968379118, "that given some": 0.0010298199627877902, "together our": 0.000971904517366954, "linear": -6.131268375924485e-05, "of whom chooses": 0.0010298199627877902, "parameter we now": 0.0008732058717250353, "we would have": 0.0005633746356361924, "the empty history": 0.0010298199627877902, "does not increase": 0.0006165622637081906, "is played in": 0.0010298199627877902, "they call": 0.0013496298428453508, "policy ideally": 0.000971904517366954, "of the one": 0.0012331245274163811, "2 respectively the": 0.0007742140246189059, "can receive": 0.0007160765724402042, "prole that maximize": 0.0010298199627877902, "and update following": 0.0010298199627877902, "observe and": 0.0007421847985653504, "features": 7.435047625491984e-05, "rst time": 0.0007160765724402042, "play algorithms along": 0.0010298199627877902, "player can observe": 0.003089459888363371, "specically we": 0.0006049243473022664, "set of": 0.00016038884342222466, "algorithm is a": 0.001105228871851776, "because a polynomial": 0.0010298199627877902, "agent 1 resp": 0.0020596399255755804, "a parameter we": 0.0010298199627877902, "states the agent": 0.0010298199627877902, "so su ciently": 0.0010298199627877902, "after the policy": 0.0010298199627877902, "get that": 0.001115634889152118, "minimal t": 0.0008730815719568182, "agent that": 0.0014321531448804085, "player 1 plays": 0.0020596399255755804, "show that people": 0.0010298199627877902, "algorithms themselves": 0.003887618069467816, "game we play": 0.0010298199627877902, "of equilibrium": 0.002322311448650475, "appendix 4 imperfect": 0.0010298199627877902, "payo an even": 0.0010298199627877902, "actions consider the": 0.0010298199627877902, "shot game associated": 0.0020596399255755804, "by both players": 0.0018620688939685846, "of g": 0.00029862429663143203, "of e": 0.000877205864923365, "for success": 0.0008730815719568182, "p 261 268": 0.0010298199627877902, "b is denoted": 0.0009310344469842923, "of a": 8.627210712341168e-06, "associates a possibly": 0.0010298199627877902, "utility is": 0.000971904517366954, "concept of ele": 0.0010298199627877902, "an agent deviate": 0.0010298199627877902, "of t": 0.00024523367939375136, "an ele in": 0.0020596399255755804, "general class": 0.0006427395698875594, "york new": 0.0006049243473022664, "proof the idea": 0.0008321458774498469, "instructed to": 0.0008730815719568182, "move to the": 0.0007010750178672042, "proof the": 0.000549793518426247, "observe the actions": 0.0010298199627877902, "new issues first": 0.0010298199627877902, "but the agents": 0.0010298199627877902, "cooperate it": 0.000971904517366954, "appropriate side payments": 0.0010298199627877902, "mixed action with": 0.0010298199627877902, "mind": 0.00028486763453033367, "solution concept of": 0.0010298199627877902, "align the research": 0.0010298199627877902, "of repeated multi": 0.0010298199627877902, "seem": 0.00017069299103522766, "agent in a": 0.0008732058717250353, "tells": 0.0003168835371517908, "may be the": 0.0005943034268074654, "most of the": 0.0006410284164597082, "of money": 0.000774103816216825, "vickrey clarke groves": 0.0010298199627877902, "by each agent": 0.0009310344469842923, "require that the": 0.0005378088736942846, "in response": 0.00046046251587537234, "we associate": 0.00045223161134026404, "monitoring setting": 0.006803331621568678, "notice a subtle": 0.0010298199627877902, "of the optimal": 0.0005690630947869114, "facing uncertainty": 0.000971904517366954, "guarantees that it": 0.0010298199627877902, "to choose an": 0.0007161785195604264, "the concept": 0.00029704876608852796, "allows side": 0.000971904517366954, "nash ele hold": 0.0010298199627877902, "own much": 0.000971904517366954, "natural number": 0.0005842412659181877, "algorithms that": 0.000994616697641882, "probability distributions over": 0.0008732058717250353, "play cooperate it": 0.0010298199627877902, "equilibrium another related": 0.0010298199627877902, "m": -0.004413577961762008, "always play column": 0.0020596399255755804, "to pay": 0.000557817444576059, "we are": 0.00032664684835624446, "playing the": 0.0006578931655429611, "cooperative systems": 0.000971904517366954, "desired no": 0.000971904517366954, "extended to": 0.000272130787801713, "s ability": 0.001132221809554141, "policy prole executed": 0.0010298199627877902, "in mind that": 0.0007330505281739418, "believe that": 0.0005727659020673933, "history at time": 0.0010298199627877902, "g and its": 0.0008002740946718667, "view a": 0.000542504923393336, "algorithm works as": 0.0007521645399683924, "said to be": 0.0003763816768240042, "stage based on": 0.0009310344469842923, "and the payos": 0.0020596399255755804, "the the complements": 0.0010298199627877902, "and he is": 0.0010298199627877902, "in multiagent": 0.000774103816216825, "explain": 0.00015554349330363786, "policies converge": 0.000971904517366954, "next state": 0.001099927676735512, "and treats": 0.000971904517366954, "in a perfect": 0.0020596399255755804, "term agent to": 0.0009310344469842923, "p 261": 0.0007160765724402042, "monitoring setting a": 0.0010298199627877902, "criteria indeed from": 0.0010298199627877902, "several economically": 0.000971904517366954, "and the extended": 0.0008732058717250353, "the framework of": 0.0005286976176970826, "negative reals between": 0.0010298199627877902, "the suggested equilibrium": 0.0010298199627877902, "to refer": 0.00042987295519467854, "adaptive game": 0.0008730815719568182, "1 of a": 0.0007161785195604264, "player both": 0.0008730815719568182, "after a short": 0.0009310344469842923, "then the expected": 0.0006749109941620578, "19": -0.00014429486934358564, "will play": 0.0006748149214226754, "denoted cooperate the": 0.0010298199627877902, "quite some": 0.000774103816216825, "expected payo in": 0.0010298199627877902, "average reward": 0.013606663243137355, "numerically in": 0.0008152096437846543, "players if player": 0.0010298199627877902, "themselves are": 0.0012580329132517005, "actions as": 0.0007160765724402042, "addition we": 0.000387471559992312, "a probability distribution": 0.0006013538961527255, "ages to evolve": 0.0010298199627877902, "many readers": 0.000971904517366954, "borrow from the": 0.0010298199627877902, "two cases e": 0.0010298199627877902, "with respect": 0.00031697802900841035, "to converge": 0.0005099512042140099, "consisting of an": 0.0008002740946718667, "and pareto": 0.001943809034733908, "said": 0.0002429518447580771, "cient behaviors": 0.000971904517366954, "play and learns": 0.0010298199627877902, "p wellman": 0.000971904517366954, "how the agent": 0.0010298199627877902, "merit for descriptive": 0.0010298199627877902, "more realistic": 0.0004933431890106373, "assumption in": 0.0005159204175055324, "action in the": 0.0007521645399683924, "its strategy": 0.0008730815719568182, "compute the probabilistic": 0.0010298199627877902, "10 contradicting ele": 0.0010298199627877902, "the e ciency": 0.000663411738084629, "stationary policy both": 0.0010298199627877902, "re ective of": 0.0010298199627877902, "no assumptions about": 0.0008002740946718667, "to 1 500": 0.0009310344469842923, "suggested": 0.00016385653603096098, "simplifying assumption": 0.0007421847985653504, "learning algorithm in": 0.0008321458774498469, "since our": 0.00046046251587537234, "required generalization": 0.000971904517366954, "uncertainty": 0.0006785683270471482, "against": 0.00030430904211482297, "in that approach": 0.0009310344469842923, "therefore the": 0.00018403798293668077, "contribution": 0.00017242978035012288, "matrix are": 0.0005942188284548949, "well thus we": 0.0009310344469842923, "learning algorithm is": 0.0015484280492378119, "to compute": 0.0005226087252478786, "stochastic game m": 0.0010298199627877902, "surplus we also": 0.0010298199627877902, "within a polynomial": 0.0010298199627877902, "a result": 0.0005799815590689798, "as over": 0.000774103816216825, "next to compute": 0.0010298199627877902, "payos it": 0.000971904517366954, "the results": 0.00010636503940643717, "i in that": 0.0017464117434500706, "some sense justied": 0.0010298199627877902, "there is a": 0.00018620082993924417, "newfoundland canada david": 0.0010298199627877902, "there exists a": 0.000863731404259633, "vector of values": 0.0010298199627877902, "detrimental": 0.0006426480897324373, "interest": 0.0002456721370211621, "basic": -0.00015319299493403552, "payos in": 0.004859522586834771, "this desired": 0.0008730815719568182, "s we": 0.0006908387395800816, "game matrix contains": 0.0010298199627877902, "deeper": 0.00048313526807733544, "for the case": 0.0003447812898412679, "a more general": 0.0004619438365452935, "2 an ele": 0.0010298199627877902, "game g as": 0.0010298199627877902, "work on online": 0.0010298199627877902, "for algorithms that": 0.0010298199627877902, "168": 0.0005941342541838367, "a denition": 0.0006748149214226754, "the actions selected": 0.0010298199627877902, "a times now": 0.0010298199627877902, "is the standard": 0.0005811431115841947, "learning equilibrium in": 0.0020596399255755804, "paper in the": 0.0007521645399683924, "a game": 0.0092892457946019, "rewards and": 0.0017461631439136364, "the game itself": 0.0010298199627877902, "joint action of": 0.0010298199627877902, "to rational behavior": 0.0010298199627877902, "2 if an": 0.0008732058717250353, "near": 0.0006156393294811294, "common property pursued": 0.0010298199627877902, "suppose": -1.2322890326095277e-06, "explain these": 0.0007421847985653504, "played is": 0.001943809034733908, "outset a tuple": 0.0010298199627877902, "of best response": 0.0010298199627877902, "interactions it": 0.000971904517366954, "mind that is": 0.0010298199627877902, "case of nash": 0.0010298199627877902, "in time t": 0.0008002740946718667, "is": 0, "it": -0.029680548457427562, "the appropriate": 0.0004809909238740603, "its action and": 0.0020596399255755804, "in": 0, "such that for": 0.0010683809588863372, "if": -0.02786377101070809, "from the ai": 0.0010298199627877902, "respect to a": 0.00042425064540523185, "no agent can": 0.0008732058717250353, "make": -0.00018492499062485924, "other assumptions": 0.0008730815719568182, "or zero then": 0.0009310344469842923, "context of self": 0.0008732058717250353, "player 2 plays": 0.0020596399255755804, "that converges": 0.0008152096437846543, "an economically": 0.002619244715870455, "computing july": 0.0006748149214226754, "approach makes": 0.0007160765724402042, "potentially": 0.0001588391732678592, "rewards we": 0.000971904517366954, "dierent sizes is": 0.0010298199627877902, "a manner that": 0.0006874022974519222, "is based on": 0.00020533123534822575, "evolve": 0.00043332229401130416, "and side": 0.0008152096437846543, "has signicant merit": 0.0010298199627877902, "alternative will": 0.000971904517366954, "of games with": 0.0010298199627877902, "how the": 0.00016899155672733874, "some desired": 0.0008152096437846543, "step policy": 0.000971904517366954, "concept of": 0.0005878757127735021, "selected and the": 0.0009310344469842923, "to show constructive": 0.0010298199627877902, "in general perfect": 0.0010298199627877902, "a normative": 0.002915713552100862, "here is that": 0.0005201099482447018, "assigned": 7.831965472445116e-05, "performed and": 0.0006427395698875594, "particular context of": 0.0010298199627877902, "a deviation will": 0.0010298199627877902, "human": 0.0004323073149119922, "irreducible i e": 0.0010298199627877902, "learning in polynominal": 0.0010298199627877902, "the implications": 0.0005159204175055324, "2007 guido": 0.000971904517366954, "obtained by removal": 0.0010298199627877902, "candidate": 0.00018492499062485924, "possible histories": 0.004076048218923272, "learning equilibrium denition": 0.0010298199627877902, "the well": 0.00032591593593977075, "for in parallel": 0.0020596399255755804, "unique strategy equilibrium": 0.0010298199627877902, "perform from": 0.000971904517366954, "to punish the": 0.0020596399255755804, "fassumed knowng": 0.000971904517366954, "rules that": 0.0008813032337434041, "for each agent": 0.0008321458774498469, "unique equilibria": 0.000971904517366954, "desirable ignores": 0.000971904517366954, "follows first the": 0.0007161785195604264, "general criterion and": 0.0010298199627877902, "that equilibrium": 0.001943809034733908, "model based": 0.0004264387578012798, "performance": -9.04146316739315e-05, "g as consisting": 0.0010298199627877902, "learning equilibria because": 0.0010298199627877902, "required for the": 0.0005005713348648543, "if both": 0.00037223626733611355, "ambitious objective": 0.000971904517366954, "an equilibrium of": 0.0009310344469842923, "performing": 0.0001259159397180222, "a subtle": 0.000774103816216825, "much as we": 0.0008732058717250353, "rg m": 0.002915713552100862, "value that agent": 0.0010298199627877902, "of players each": 0.0010298199627877902, "played then each": 0.0010298199627877902, "on e": 0.0005286223582497236, "rg a": 0.000971904517366954, "on a": 6.560903761450088e-05, "policy then": 0.000971904517366954, "knowledge the notion": 0.0010298199627877902, "algorithm player": 0.000971904517366954, "theorists": 0.0026188719227141968, "given to": 0.00041656361432912804, "respect to nash": 0.0010298199627877902, "do it for": 0.0010298199627877902, "xed stochastic game": 0.0010298199627877902, "this is a": 0.0002929542004865784, "is computed and": 0.0007742140246189059, "approach the dynamics": 0.0010298199627877902, "a situation": 0.000444416512295841, "that an agent": 0.0007521645399683924, "ciently many times": 0.0010298199627877902, "we now take": 0.0008732058717250353, "cognitive psychology": 0.000971904517366954, "now revealed game": 0.0010298199627877902, "adversary will always": 0.004119279851151161, "alternative will be": 0.0010298199627877902, "it to do": 0.0010298199627877902, "the framework": 0.0003560762920625211, "game theory and": 0.0009310344469842923, "existence of nash": 0.0010298199627877902, "predicting": 0.00032403512727420655, "have that u": 0.0008732058717250353, "first let": 0.0006049243473022664, "during this phase": 0.0008321458774498469, "in an": 0.0002897816471560046, "observations and initially": 0.0010298199627877902, "denitions of": 0.000549963838367756, "deviate and pretend": 0.0010298199627877902, "get close": 0.0008730815719568182, "we dene u": 0.0010298199627877902, "how quickly": 0.0006939782666478507, "g the expected": 0.0009310344469842923, "solution by e": 0.0010298199627877902, "it may": 0.00020298909787029243, "importance these results": 0.0010298199627877902, "desired result": 0.0005748976023290408, "negative": 0.00015134065205489117, "repeating the process": 0.0009310344469842923, "s matrix": 0.0008152096437846543, "common interest game": 0.0010298199627877902, "adversary payos": 0.001943809034733908, "attained had he": 0.0010298199627877902, "self play investigated": 0.0010298199627877902, "ele algorithm player": 0.0010298199627877902, "row i and": 0.0008732058717250353, "are assigned the": 0.0007521645399683924, "use g": 0.000774103816216825, "use a": 0.00015803414121146655, "researchers in cognitive": 0.0010298199627877902, "out to deviate": 0.0010298199627877902, "desired no agent": 0.0010298199627877902, "use r": 0.0006578931655429611, "the netherlands vincent": 0.0010298199627877902, "cient therefore the": 0.0010298199627877902, "p i a": 0.0008321458774498469, "form": -0.0007213836977402377, "1 in all": 0.0009310344469842923, "entry 1": 0.0007421847985653504, "entry 6": 0.000971904517366954, "do o": 0.0008730815719568182, "failure": 0.0003379350088270865, "leendert van der": 0.0009310344469842923, "of steps is": 0.0008321458774498469, "concepts are": 0.0006290164566258502, "in a game": 0.004119279851151161, "we allow side": 0.0010298199627877902, "monitoring assumption": 0.000971904517366954, "call convergence stipulates": 0.0010298199627877902, "the rst time": 0.0007742140246189059, "we get the": 0.0004648150538311537, "be presented here": 0.0008732058717250353, "theoretical importance": 0.0008730815719568182, "economic": 0.001008275983569803, "close to their": 0.0008732058717250353, "algorithmic framework": 0.0008730815719568182, "iterations of the": 0.0005749794499375729, "over a": 0.00024049546193703015, "stages": 0.0002550184271602697, "then with": 0.001085009846786672, "learning stochastic games": 0.0010298199627877902, "t such that": 0.0004899574431705119, "choices some": 0.000971904517366954, "will converge": 0.0018494234905137357, "1 the": 0.00023062815989727562, "major issues": 0.0007421847985653504, "to ensure": 0.00046944248353249473, "in row": 0.0006290164566258502, "the idea": 0.0006644214945053356, "mechanism design friend": 0.0010298199627877902, "multiagent learning": 0.0008730815719568182, "may 2007 rob": 0.0010298199627877902, "t 0 where": 0.0009310344469842923, "similar to a": 0.000552614435925888, "and as a": 0.0010756177473885693, "attention is": 0.0006164744968379118, "ctr jeffrey": 0.0008730815719568182, "it could attain": 0.0010298199627877902, "the following given": 0.0007330505281739418, "claim is that": 0.0009310344469842923, "and in particular": 0.0005578968604992618, "given the": 0.0004302831148813362, "out of": 0.0002161844266599044, "agent while the": 0.0010298199627877902, "modied game": 0.000971904517366954, "in infinite": 0.0007421847985653504, "novel e cient": 0.0020596399255755804, "not an": 0.0003901551635480713, "for player": 0.011662854208403448, "survey markov": 0.000971904517366954, "compute the policies": 0.0010298199627877902, "show that simple": 0.0010298199627877902, "setting proof consider": 0.0010298199627877902, "mix be its": 0.0010298199627877902, "a subtle but": 0.0010298199627877902, "after playing": 0.000971904517366954, "get the desired": 0.0008002740946718667, "previous work on": 0.0006165622637081906, "social laws": 0.0008730815719568182, "the union of": 0.0004155626519889734, "that corresponds to": 0.00053318373443515, "assume": -0.001300575663197243, "prescribed ele becomes": 0.0010298199627877902, "following two paradigms": 0.0010298199627877902, "imperfect monitoring case": 0.0020596399255755804, "player s": 0.003260838575138617, "that a learning": 0.0008732058717250353, "consider a": 0.000168132855851404, "shot game": 0.001943809034733908, "t t": 0.001024012216141653, "the side": 0.0015664104092580162, "not exponentially far": 0.0010298199627877902, "from a given": 0.0005080852977998101, "of learning algorithms": 0.0016642917548996938, "against other agent": 0.0010298199627877902, "that we consider": 0.0005690630947869114, "ciency is by": 0.0010298199627877902, "evolve our": 0.000971904517366954, "shot": 0.0010848554189690253, "with in": 0.00046046251587537234, "lower average": 0.000774103816216825, "as mentioned earlier": 0.0005875760798754402, "phase each": 0.0006578931655429611, "depend": 4.346451032610047e-05, "viewed as": 0.0002694041520782948, "technique": -8.692902065220094e-05, "that all joint": 0.0020596399255755804, "0": -0.010419878316989215, "finally": -0.0003310990064917965, "not notice": 0.0008730815719568182, "denoted defect": 0.001943809034733908, "looking for algorithms": 0.0010298199627877902, "must": -0.0008987117203037999, "t 0": 0.002492534044437648, "notion of rationality": 0.0010298199627877902, "criteria for": 0.0005042097552001021, "agents known": 0.000971904517366954, "they should rapidly": 0.0010298199627877902, "by one": 0.00029704876608852796, "approach to learning": 0.004366029358625177, "the rst obstacle": 0.0010298199627877902, "to show": 0.001061087869609325, "did": 9.727051390093234e-05, "minimal": 8.098228635398019e-05, "the payos but": 0.0010298199627877902, "that if the": 0.0007272556146951803, "b in addition": 0.0008732058717250353, "the typical": 0.0004832040417809763, "algorithm when": 0.000542504923393336, "dealing": 0.0004323073149119922, "coordinate e": 0.0008730815719568182, "maximization": 0.0005285471202254922, "only on": 0.000252554184414257, "the adversary can": 0.000663411738084629, "for near": 0.000971904517366954, "with respect to": 0.0005531049007305596, "to converge to": 0.000663411738084629, "payments in": 0.000971904517366954, "learning algorithms that": 0.0010298199627877902, "it gets": 0.0005748976023290408, "period of": 0.0004072679530572796, "our denition": 0.0006427395698875594, "another related work": 0.0010298199627877902, "adopt the e": 0.0010298199627877902, "by directing": 0.000971904517366954, "international": 6.435129682801357e-05, "also discuss the": 0.0007742140246189059, "payments is": 0.001943809034733908, "is we": 0.00035829109812661935, "time of is": 0.0009310344469842923, "by p": 0.00036281071874830087, "by u": 0.0005221368030860054, "outcome 2": 0.000971904517366954, "is trying": 0.000774103816216825, "equilibrium it should": 0.0010298199627877902, "will reach formally": 0.0010298199627877902, "by a": 5.182670050004308e-05, "by e": 0.0009125844283376683, "exists 1": 0.0008730815719568182, "results we have": 0.0006749109941620578, "an important line": 0.0010298199627877902, "reader to": 0.00047837713542937403, "rewards and deviations": 0.0010298199627877902, "used to model": 0.0005475136432016508, "repeated game this": 0.0010298199627877902, "will immediately reduce": 0.0010298199627877902, "is to minimize": 0.0011499588998751457, "reward however": 0.0008730815719568182, "for every game": 0.0020596399255755804, "networks with": 0.00046046251587537234, "rigorous normative": 0.000971904517366954, "best that": 0.0008730815719568182, "payments as": 0.000971904517366954, "optimal average sum": 0.0010298199627877902, "of general results": 0.0010298199627877902, "useful": -0.00010705674809908032, "rationality the learning": 0.0010298199627877902, "action it": 0.0007421847985653504, "is that": 0.0003276094775251597, "quickly indeed ai": 0.0010298199627877902, "action is": 0.0015298536126420296, "attain on its": 0.0020596399255755804, "action in": 0.0016062064551004536, "k 2 steps": 0.0010298199627877902, "5 pareto": 0.000971904517366954, "action if": 0.000774103816216825, "joint action fassumed": 0.0010298199627877902, "learning algorithm to": 0.0008321458774498469, "his probabilistic": 0.0008730815719568182, "associated with": 0.0011120324867843205, "general sum stochastic": 0.0020596399255755804, "equilibrium when facing": 0.0010298199627877902, "j in the": 0.0005119876058604116, "m let be": 0.0008732058717250353, "visit": 0.0008266908852913467, "having a learning": 0.0010298199627877902, "proof in": 0.00044065161687170207, "0 where all": 0.0009310344469842923, "in question": 0.0009125844283376683, "to correlated": 0.000971904517366954, "policy is a": 0.0009310344469842923, "adversary s policy": 0.0010298199627877902, "players 1 and": 0.0010298199627877902, "does not care": 0.0009310344469842923, "speaking the results": 0.0010298199627877902, "assigned the rewards": 0.0010298199627877902, "cient now": 0.000971904517366954, "by each": 0.00035829109812661935, "symposium on principles": 0.0005633746356361924, "attempt to react": 0.0010298199627877902, "receives more than": 0.0009310344469842923, "equilibrium ele a": 0.0010298199627877902, "know which game": 0.0010298199627877902, "own to show": 0.0010298199627877902, "cooperative inter": 0.000971904517366954, "perfect and": 0.0007160765724402042, "the second which": 0.0010298199627877902, "if both players": 0.0010298199627877902, "making": 1.9748122473713975e-05, "arrive": 0.00028195295600150634, "been played with": 0.0010298199627877902, "result if the": 0.0008732058717250353, "converges in": 0.000774103816216825, "dierence": 0.00030017084314280963, "interest this applies": 0.0010298199627877902, "played game theorists": 0.0010298199627877902, "1 performs": 0.00154820763243365, "predict": 0.00025004884772585073, "agent": 0.02356076712319508, "games learning": 0.000971904517366954, "desirable ignores the": 0.0010298199627877902, "are identical for": 0.0008321458774498469, "be obtained": 0.0002079740793332138, "is obtained": 0.0002193427981572845, "we start": 0.00029862429663143203, "be actually": 0.000774103816216825, "a model based": 0.0007521645399683924, "normalize": 0.00038477681440592316, "equilibrium and of": 0.0010298199627877902, "designers will all": 0.0010298199627877902, "the setting studied": 0.0010298199627877902, "surplus in repeated": 0.0010298199627877902, "the identity": 0.0010003634747314234, "deviation to": 0.0008730815719568182, "an adversary s": 0.0010298199627877902, "progressively higher values": 0.0010298199627877902, "finally we discuss": 0.0007161785195604264, "a lower": 0.00047402356258759035, "algorithm the ele": 0.0010298199627877902, "by directing the": 0.0010298199627877902, "all following": 0.0008730815719568182, "designer": 0.0007209685940693525, "novel combination of": 0.0010298199627877902, "may": -0.004546799869102406, "max": 0.0009555615006261861, "which the rewards": 0.0020596399255755804, "features algorithms that": 0.0010298199627877902, "game matrix g": 0.0020596399255755804, "designed": 9.451215220522449e-05, "denote the player": 0.0010298199627877902, "these are repeated": 0.0010298199627877902, "a stochastic game": 0.0010298199627877902, "the security level": 0.0010298199627877902, "a single": 6.585388212784525e-05, "m with a": 0.0008732058717250353, "times to": 0.0005042097552001021, "for a general": 0.000624803884002311, "osprings": 0.000872957307571399, "q": -4.472660117228903e-05, "provide": -0.00080250790171512, "b if all": 0.0008321458774498469, "useful to": 0.00034133740538055095, "given large": 0.000971904517366954, "that learning": 0.0006748149214226754, "for the punishment": 0.0010298199627877902, "probabilistic maximin values": 0.0020596399255755804, "irrational i": 0.000971904517366954, "setting first": 0.000971904517366954, "policy we": 0.0005748976023290408, "we have chosen": 0.0005578968604992618, "following assumptions a": 0.0008732058717250353, "from that point": 0.0016642917548996938, "candidate the nash": 0.0010298199627877902, "is a b": 0.0014661010563478836, "irrational r": 0.000971904517366954, "also able to": 0.0007521645399683924, "they known the": 0.0020596399255755804, "game theorists": 0.002915713552100862, "to convergence": 0.0007160765724402042, "the dierences": 0.0007160765724402042, "theory of learning": 0.0008321458774498469, "interesting": -3.34243653682609e-05, "cient approaches have": 0.0010298199627877902, "economically e": 0.008747140656302586, "removing knowledge": 0.000971904517366954, "integral part": 0.0006578931655429611, "it known 1": 0.0010298199627877902, "policy": 0.009001758518130626, "he is paid": 0.0010298199627877902, "algorithms provided": 0.0008152096437846543, "the player cannot": 0.0010298199627877902, "probabilistic actions and": 0.0010298199627877902, "limited to": 0.0003796766130365772, "there exists some": 0.0006874022974519222, "g see 9": 0.0010298199627877902, "note that given": 0.0008732058717250353, "to the issue": 0.0008002740946718667, "that maximizes min": 0.0010298199627877902, "this property as": 0.0009310344469842923, "maximin of": 0.000971904517366954, "game this": 0.0008730815719568182, "of states": 0.0004264387578012798, "behind the algorithm": 0.0008732058717250353, "the next state": 0.0013055146579358122, "be the adversary": 0.0009310344469842923, "concept in": 0.0011884376569097899, "of reinforcement learning": 0.0020596399255755804, "recall that": 0.00041999767890003886, "of paramount": 0.0008730815719568182, "e cient approaches": 0.0010298199627877902, "joint conference on": 0.0013748045949038444, "formalize the notion": 0.0008321458774498469, "candidate the": 0.0007421847985653504, "of mixed strategies": 0.0020596399255755804, "ai researchers have": 0.0010298199627877902, "greater than or": 0.0005578968604992618, "an adversary and": 0.0008732058717250353, "quickly lead": 0.001943809034733908, "execute it observe": 0.0010298199627877902, "particular consider": 0.0008152096437846543, "arrive at a": 0.0006527573289679061, "other agent as": 0.0009310344469842923, "the future the": 0.0007742140246189059, "these dierences": 0.000971904517366954, "steps or longer": 0.0010298199627877902, "paid rby": 0.000971904517366954, "canada": 0.00025004884772585073, "player cannot": 0.000971904517366954, "performs action": 0.000971904517366954, "number of": 7.768409826163465e-05, "the one": 0.00028235421866193894, "throughout this": 0.0004134042818545908, "values the players": 0.0010298199627877902, "despite the fact": 0.0012175213147942792, "prole in polynomial": 0.0010298199627877902, "have to": 0.00012967881971762065, "imperfect and": 0.0008730815719568182, "two player game": 0.0009310344469842923, "after": -0.0029713118826165705, "or other": 0.00043697553507468355, "adopted this non": 0.0010298199627877902, "setting i e": 0.0008732058717250353, "mechanisms": 0.00017771041848258512, "john s": 0.0006939782666478507, "1 resp 2": 0.0020596399255755804, "introduced in this": 0.0007521645399683924, "strategies from": 0.000971904517366954, "plays b we": 0.0010298199627877902, "our attention": 0.0004134042818545908, "value while": 0.0006939782666478507, "reinforcement learning in": 0.005149099813938952, "of distributed computing": 0.0006428310760905615, "monitoring denote the": 0.0010298199627877902, "play they": 0.000971904517366954, "does not exclude": 0.0009310344469842923, "paradigms 1": 0.000971904517366954, "advance": 0.0002653473045919286, "games started": 0.000971904517366954, "cannot observe the": 0.0010298199627877902, "e cient manner": 0.0008321458774498469, "an even": 0.00046046251587537234, "the game being": 0.0010298199627877902, "complete information as": 0.0010298199627877902, "14 3 intuitively": 0.0010298199627877902, "1 the agents": 0.0010298199627877902, "algorithms the": 0.00034336616306129136, "setting recall": 0.000971904517366954, "first": -0.0033578197519453703, "that is": 0.00022752590726516007, "that it": 0.0002556300185326139, "making it": 0.0004832040417809763, "suit however": 0.000971904517366954, "class thus": 0.0008730815719568182, "case of convergence": 0.0010298199627877902, "considering games with": 0.0010298199627877902, "equilibrium denition": 0.000971904517366954, "player 1 of": 0.0010298199627877902, "1 2 p": 0.001501714004594563, "that if": 0.0006148357697520375, "the judgment": 0.0008152096437846543, "decreased reward": 0.000971904517366954, "that in": 0.00029600591340638233, "u 1 the": 0.0010298199627877902, "on the possible": 0.0008321458774498469, "2 log": 0.0005159204175055324, "the value he": 0.0010298199627877902, "play a": 0.0004881890232438977, "best payo obtained": 0.0010298199627877902, "to obtain expected": 0.0010298199627877902, "play i": 0.000971904517366954, "can be approximated": 0.0011751521597508803, "speaking": 0.00023582981019343917, "be its return": 0.0010298199627877902, "below and": 0.0005748976023290408, "maximin value": 0.003887618069467816, "observe the": 0.0009763780464877954, "lower reward however": 0.0010298199627877902, "of length": 0.00029240195497445495, "concept of a": 0.0006087606573971396, "major claim is": 0.0010298199627877902, "largely by": 0.0008730815719568182, "v 67 n": 0.002103225053601613, "conitzer tuomas": 0.000971904517366954, "game first we": 0.0010298199627877902, "an integral part": 0.0007161785195604264, "11": -0.00037962257423597423, "10": -0.0008144199744455991, "13": -0.0002790828066142882, "12": -0.0003277234689715408, "15": -0.00026801701724071423, "14": -0.00026011513263944863, "here because": 0.0006290164566258502, "16": -0.00020002028979370696, "third international": 0.0006748149214226754, "using a pre": 0.0009310344469842923, "have no": 0.0003151849303416359, "sets of": 0.00033970604936781913, "is common": 0.0004986788606483227, "were": -0.0006178134000582089, "example the": 0.00013346626597308272, "columns correspond": 0.0008152096437846543, "payments formally part": 0.0010298199627877902, "now follows the": 0.0010298199627877902, "t must be": 0.0006874022974519222, "known to both": 0.0008321458774498469, "showing the agent": 0.0010298199627877902, "the study": 0.0007302346925157399, "there is another": 0.0006165622637081906, "use r max": 0.0010298199627877902, "groves mechanisms proceedings": 0.0010298199627877902, "also be economically": 0.0010298199627877902, "issues in more": 0.0010298199627877902, "and any deviation": 0.0010298199627877902, "perspective the": 0.0006164744968379118, "rationality requirement": 0.000971904517366954, "always g1 and": 0.0010298199627877902, "e assuming the": 0.0008732058717250353, "efficient": -8.945320234457806e-05, "available to the": 0.0006527573289679061, "in networks with": 0.0008732058717250353, "converges": 0.0003168835371517908, "a tuple of": 0.0006749109941620578, "and payos": 0.000971904517366954, "ele instances": 0.000971904517366954, "algorithm for nding": 0.0015484280492378119, "games for which": 0.0010298199627877902, "through a series": 0.0007742140246189059, "interactions the literature": 0.0010298199627877902, "of learning rules": 0.0020596399255755804, "paid": 0.0008666445880226083, "the average reward": 0.004119279851151161, "pair": -4.5990438577786594e-05, "expected t iterations": 0.0010298199627877902, "may be played": 0.0010298199627877902, "ele notice": 0.000971904517366954, "they treat": 0.000774103816216825, "yevgeniy vorobeychik": 0.000971904517366954, "adopt behavior": 0.000971904517366954, "the same setting": 0.0009310344469842923, "easy to": 0.00032775972160954637, "attracted the": 0.0008730815719568182, "theoretical importance these": 0.0010298199627877902, "exists some t": 0.0010298199627877902, "canada david": 0.0008730815719568182, "set a of": 0.0007521645399683924, "time it would": 0.0010298199627877902, "not depend on": 0.00044321449180331545, "a concrete": 0.0004986788606483227, "show": -0.0035246526878268502, "it used when": 0.0010298199627877902, "and these": 0.0003848315869061944, "nash equilibrium had": 0.003089459888363371, "valued variable with": 0.0010298199627877902, "previously unplayed joint": 0.0010298199627877902, "theorists adopt": 0.000971904517366954, "polynomial time and": 0.0007521645399683924, "as follows the": 0.0004155626519889734, "each agent or": 0.0010298199627877902, "markov chain": 0.0005354021517001512, "context of pareto": 0.0010298199627877902, "so called folk": 0.0020596399255755804, "s matrix and": 0.0010298199627877902, "date most": 0.0008730815719568182, "after k 2": 0.0010298199627877902, "sum over all": 0.0007330505281739418, "histories": 0.002368154162952094, "that point on": 0.0018620688939685846, "denote the same": 0.0008321458774498469, "attention of": 0.0006578931655429611, "get": -0.00020935085688887983, "requires that a": 0.0006874022974519222, "will be used": 0.0003866418347374886, "games thus": 0.000971904517366954, "for k times": 0.0010298199627877902, "probabilistic maximin value": 0.004119279851151161, "that despite their": 0.0008732058717250353, "ele provide new": 0.0010298199627877902, "exposition we normalize": 0.0010298199627877902, "by both": 0.0009763780464877954, "technique for": 0.0006167525305437022, "this variable": 0.0006164744968379118, "with polynomial in": 0.0010298199627877902, "the existence": 0.001560912958227558, "based approach": 0.0003796766130365772, "allow side": 0.000971904517366954, "new joint": 0.000971904517366954, "an agent designer": 0.0010298199627877902, "be using strategies": 0.0010298199627877902, "follows let": 0.0004134042818545908, "we develop": 0.0003771588365708351, "s we have": 0.0007161785195604264, "know which": 0.000549963838367756, "polynomial time convergence": 0.0009310344469842923, "the attention of": 0.0007521645399683924, "after polynomially many": 0.0009310344469842923, "leendert": 0.0007739936391863359, "it used": 0.0006939782666478507, "fact in": 0.00046915827274082977, "of vickrey": 0.000971904517366954, "satisfying": 0.00010283419803078707, "interaction in a": 0.0008732058717250353, "mixing time": 0.004365407859784092, "policy prole the": 0.0010298199627877902, "some nash equilibrium": 0.0010298199627877902, "distribution is": 0.00042987295519467854, "behind": 0.00018676151280474932, "the optimal average": 0.0010298199627877902, "m trials": 0.000971904517366954, "go through a": 0.0010298199627877902, "t 0 we": 0.0007742140246189059, "learning algorithm will": 0.0009310344469842923, "particular action for": 0.0010298199627877902, "no assumptions": 0.0007160765724402042, "while the approach": 0.0010298199627877902, "algorithms then": 0.0008152096437846543, "approximately obtain the": 0.0010298199627877902, "a general criterion": 0.0010298199627877902, "it is easy": 0.00030239751985769166, "games as": 0.0017461631439136364, "games at": 0.000971904517366954, "value although": 0.0008730815719568182, "of this policy": 0.0016642917548996938, "from its learning": 0.0010298199627877902, "classical approach in": 0.0010298199627877902, "1 m with": 0.0009310344469842923, "behavior in multi": 0.0010298199627877902, "although we": 0.00036511734625786996, "described numerically in": 0.0010298199627877902, "the special well": 0.0010298199627877902, "react online": 0.000971904517366954, "according": -0.0002509763727165324, "the previous section": 0.000295010963733657, "by introducing": 0.0004072679530572796, "as observed and": 0.0010298199627877902, "2 theorem 4": 0.0006749109941620578, "underlying game g": 0.0010298199627877902, "of possible": 0.002966798501008847, "be attained e": 0.0010298199627877902, "there is": 8.158942495204665e-05, "among": -7.831965472445115e-05, "m u for": 0.0009310344469842923, "assumed over the": 0.0010298199627877902, "then we generalize": 0.0009310344469842923, "the game from": 0.0010298199627877902, "expected average": 0.001943809034733908, "steps will be": 0.0010298199627877902, "by bowling and": 0.0010298199627877902, "models of such": 0.0009310344469842923, "considering": 4.472660117228903e-05, "yoav shoham": 0.000971904517366954, "probabilistic maximin of": 0.0010298199627877902, "for example": 4.032231570877893e-05, "known the game": 0.003089459888363371, "utility function is": 0.0010298199627877902, "ele but its": 0.0010298199627877902, "mark": 0.00024281635111643188, "to satisfy any": 0.0010298199627877902, "0 as input": 0.0009310344469842923, "resorting to recent": 0.0010298199627877902, "the denitions": 0.0005661109047770705, "p now that": 0.0010298199627877902, "proceedings of": 0.00042353132799290844, "desired value may": 0.0010298199627877902, "bi matrix": 0.000971904517366954, "imperfect monitoring proof": 0.0010298199627877902, "a learning procedure": 0.0010298199627877902, "behavior as prescribed": 0.0010298199627877902, "quick with": 0.000971904517366954, "bayesian": 0.002136153673560385, "in what": 0.0004333839769001314, "within t mix": 0.0010298199627877902, "obtain expected payos": 0.0010298199627877902, "section we": 0.00032664684835624446, "individually rational 2": 0.0010298199627877902, "games 1 g1": 0.0010298199627877902, "game in which": 0.002793103340952877, "uses repeated games": 0.0010298199627877902, "awesome a": 0.000971904517366954, "also technically more": 0.0010298199627877902, "2004 st": 0.0007160765724402042, "a deviation is": 0.0010298199627877902, "eventually": 0.00038849648616536497, "point game": 0.000971904517366954, "monitoring we also": 0.0020596399255755804, "5 pareto ele": 0.0010298199627877902, "g as": 0.00041030656060455343, "a game from": 0.0010298199627877902, "action and player": 0.0010298199627877902, "be economically": 0.001943809034733908, "removal of": 0.0005159204175055324, "normative approach": 0.004859522586834771, "best payo": 0.000971904517366954, "proof of": 0.00020397751600166201, "g 0 as": 0.0008732058717250353, "pay": 0.0003204229716206228, "ability is required": 0.0010298199627877902, "same": -0.002874078890095013, "in parallel to": 0.0015043290799367848, "payos our": 0.000971904517366954, "e cient learning": 0.00837931002285863, "exists in": 0.00045223161134026404, "the number": 3.7183700962792543e-05, "average reward first": 0.0010298199627877902, "all joint actions": 0.0020596399255755804, "jeffrey": 0.0009124545415701851, "extended": -5.438520830136898e-05, "or equal": 0.0003560762920625211, "section 6": 0.00017952045810190525, "reward see below": 0.0010298199627877902, "dene u 2": 0.0010298199627877902, "should become": 0.0008152096437846543, "our concepts": 0.000774103816216825, "the denition": 0.0031878719582068395, "take the": 0.0003117480856515576, "researches in multi": 0.0010298199627877902, "0 as": 0.0007969679895517099, "largely": 0.00030667021960111354, "and column j": 0.0008321458774498469, "of games": 0.004859522586834771, "ones they would": 0.0010298199627877902, "at the corresponding": 0.0008002740946718667, "value is the": 0.0006874022974519222, "awesome a general": 0.0010298199627877902, "its other": 0.0006939782666478507, "do is": 0.0006049243473022664, "do it": 0.0006578931655429611, "money": 0.0005748157780190026, "s average": 0.0014843695971307007, "variable is initialized": 0.0010298199627877902, "since they are": 0.0005749794499375729, "against other": 0.0007421847985653504, "identity of the": 0.0012670778179334821, "limited to a": 0.0007521645399683924, "do in": 0.000549963838367756, "seem too irrational": 0.0010298199627877902, "too irrational r": 0.0010298199627877902, "be presented": 0.0004482748456766825, "probabilistic maximin this": 0.0010298199627877902, "at most": 0.00031938374185882455, "of dierent sizes": 0.0009310344469842923, "j in": 0.00029704876608852796, "b by agent": 0.0010298199627877902, "4": -0.003491829230285596, "non bayesian": 0.0016304192875693086, "deviate at any": 0.0010298199627877902, "extension to": 0.0007913193352553324, "behavior in non": 0.0010298199627877902, "k actions": 0.0017461631439136364, "proposed it": 0.0008730815719568182, "learning what": 0.0008730815719568182, "similar we": 0.0008152096437846543, "work uses": 0.0006939782666478507, "denoted cooperate": 0.001943809034733908, "into one of": 0.0006087606573971396, "facing": 0.0005577380512591538, "by in": 0.0004933431890106373, "either": -0.00024760932355138087, "game out": 0.000971904517366954, "enough value in": 0.0010298199627877902, "desired properties are": 0.0010298199627877902, "to a game": 0.0010298199627877902, "polynominal time using": 0.0010298199627877902, "netherlands vincent conitzer": 0.0010298199627877902, "can adjust its": 0.0010298199627877902, "s behavior in": 0.0009310344469842923, "be polynomial": 0.000774103816216825, "best response against": 0.0010298199627877902, "gence and": 0.000971904517366954, "policy prole where": 0.0010298199627877902, "assumed to be": 0.0007303386553136493, "a we": 0.0002488608288383314, "then there is": 0.0004334456773524235, "game are the": 0.0010298199627877902, "a i for": 0.0006527573289679061, "for one another": 0.0010298199627877902, "agents turn out": 0.0010298199627877902, "is treated": 0.0004832040417809763, "his utility is": 0.0010298199627877902, "values one for": 0.0008732058717250353, "not improved after": 0.0010298199627877902, "whom we": 0.0016304192875693086, "given an rg": 0.0020596399255755804, "to see by": 0.0010298199627877902, "agent 1 and": 0.0010298199627877902, "every repeated": 0.001943809034733908, "the best we": 0.0008002740946718667, "notion of a": 0.0010161705955996202, "of multi agent": 0.002496437632349541, "great interest this": 0.0010298199627877902, "adopted this": 0.0008730815719568182, "notion of e": 0.0010298199627877902, "played making": 0.000971904517366954, "agents except": 0.000971904517366954, "where at each": 0.0008732058717250353, "turns out to": 0.0005080852977998101, "following assumptions": 0.0005748976023290408, "equilibrium n g": 0.0010298199627877902, "while the": 0.00027459658789175866, "observed throughout": 0.0008730815719568182, "theorems": 0.0006360349833295023, "practical": 1.6036601551965958e-05, "mixed": 0.0009005125294284287, "game g is": 0.0020596399255755804, "to convergence after": 0.0010298199627877902, "more rigorous": 0.0007160765724402042, "2 a policy": 0.0010298199627877902, "0 and execute": 0.0010298199627877902, "pareto e": 0.001943809034733908, "adversary policies": 0.000971904517366954, "of great interest": 0.0008002740946718667, "at each stage": 0.0007010750178672042, "a single agent": 0.0008732058717250353, "than this": 0.0005286223582497236, "the rows of": 0.0006428310760905615, "decreased reward only": 0.0010298199627877902, "stipulates that the": 0.0010298199627877902, "context of stochastic": 0.0020596399255755804, "in 4 we": 0.0006874022974519222, "with the": 3.697578135695479e-05, "after all we": 0.0009310344469842923, "in ai and": 0.0020596399255755804, "takes an": 0.000549963838367756, "enough": -2.4661039559607807e-05, "nash ele it": 0.0010298199627877902, "this line": 0.0006748149214226754, "the bayesian model": 0.0008321458774498469, "obtain in": 0.0006427395698875594, "systems p": 0.000542504923393336, "i th action": 0.0010298199627877902, "the generalization": 0.00045629221416883416, "to adopt": 0.0005942188284548949, "the probabilistic": 0.002281461070844171, "very close": 0.00040135881926370846, "and k such": 0.0018620688939685846, "reason to": 0.0005286223582497236, "xed sum": 0.003887618069467816, "designers there is": 0.0010298199627877902, "which ensures": 0.0006290164566258502, "corresponding strategies from": 0.0010298199627877902, "adversary can": 0.0005842412659181877, "that a player": 0.0009310344469842923, "often use the": 0.0010298199627877902, "addition the learning": 0.0010298199627877902, "and veloso their": 0.0010298199627877902, "this non bayesian": 0.0010298199627877902, "that are greater": 0.0008321458774498469, "10 the": 0.0003050667212128553, "general": -0.004972375676725179, "examine": 0.0001672530849280036, "that converge to": 0.0009310344469842923, "is a pareto": 0.0020596399255755804, "e they": 0.0004832040417809763, "that of": 0.00045935477161686814, "is typically used": 0.0008002740946718667, "a general class": 0.0007742140246189059, "this is in": 0.0005690630947869114, "e in": 0.00033345449157714114, "used to compute": 0.0004737656933058489, "not know which": 0.0007330505281739418, "finally we": 0.00020696839994216446, "matrix moreover": 0.000971904517366954, "agent has any": 0.0010298199627877902, "that behavior the": 0.0010298199627877902, "case since": 0.0004986788606483227, "weights": 0.00018310191087925984, "future not": 0.0008152096437846543, "appropriate side": 0.000971904517366954, "learning should": 0.0008730815719568182, "it will play": 0.0009310344469842923, "more than the": 0.0005633746356361924, "3 r max": 0.0010298199627877902, "game g 0": 0.0010298199627877902, "on normative": 0.000971904517366954, "important": -0.00038849648616536497, "this algorithm is": 0.0009414474029018554, "to approach": 0.0007160765724402042, "technically more challenging": 0.0010298199627877902, "algorithms provided to": 0.0009310344469842923, "theory in reality": 0.0010298199627877902, "the game and": 0.0008732058717250353, "in some": 0.00016642364028409505, "if an agent": 0.0016005481893437334, "general multiagent": 0.000971904517366954, "game we have": 0.0009310344469842923, "that mix": 0.0008730815719568182, "average sum": 0.004365407859784092, "u": -0.0002369774696845677, "conitzer tuomas sandholm": 0.0010298199627877902, "therefore the two": 0.0007742140246189059, "starting": 2.9681860502854687e-05, "s actions the": 0.0009310344469842923, "u we": 0.00045629221416883416, "how people": 0.0008730815719568182, "be s j": 0.0010298199627877902, "both agents they": 0.0010298199627877902, "the security": 0.0005221368030860054, "is computed": 0.00028199309165360617, "a survey markov": 0.0010298199627877902, "take individual": 0.000971904517366954, "we use r": 0.0007521645399683924, "behavior will be": 0.0008732058717250353, "cooperative": 0.0025554576575904865, "theoretic approach is": 0.0009310344469842923, "results cannot replace": 0.0010298199627877902, "now take a": 0.0009310344469842923, "intuitively the": 0.00046915827274082977, "to note": 0.00034336616306129136, "attain a value": 0.0010298199627877902, "near optimal": 0.001115634889152118, "of dierent": 0.000549963838367756, "proposed before while": 0.0010298199627877902, "the above work": 0.0008321458774498469, "the appropriate payos": 0.0010298199627877902, "is no": 0.00010354964470300034, "exists a probability": 0.0010298199627877902, "every game": 0.001943809034733908, "to general sum": 0.0020596399255755804, "given set of": 0.0005475136432016508, "much of": 0.0008528775156025596, "corresponding bayes": 0.000971904517366954, "straightforward": 6.779667630156865e-05, "we attempt": 0.000557817444576059, "in non": 0.0014210947600485193, "are repeated": 0.0007160765724402042, "p 23 43": 0.0010298199627877902, "2 then": 0.00033345449157714114, "take the equilibrium": 0.0010298199627877902, "modied to include": 0.0009310344469842923, "2 we": 0.00012667955246027228, "e ciently and": 0.0009310344469842923, "of possible games": 0.0010298199627877902, "game g to": 0.0010298199627877902, "policy prole by": 0.0010298199627877902, "adversary payos the": 0.0010298199627877902, "called folk": 0.001943809034733908, "minimize the": 0.0006101334424257105, "whom chooses": 0.000971904517366954, "as part of": 0.0008966773322547537, "economically": 0.0064437718890594815, "that is we": 0.0004865784002866409, "concept in this": 0.0010298199627877902, "devoid of content": 0.0010298199627877902, "sum games multiagent": 0.0010298199627877902, "interest this": 0.0006748149214226754, "row 2 denoted": 0.0010298199627877902, "a pair": 0.00023701178129379517, "zero": -2.719260415068449e-05, "perspective": 0.00045372437401028614, "equilibrium reinforcement": 0.000971904517366954, "and so we": 0.0005690630947869114, "hence the agent": 0.0009310344469842923, "we do so": 0.0006749109941620578, "their work": 0.0010708043034003023, "with a a": 0.0007330505281739418, "markov chain is": 0.0008321458774498469, "is contrary to": 0.0009310344469842923, "dierences are": 0.0008730815719568182, "at most and": 0.0016005481893437334, "with economic in": 0.0010298199627877902, "play against other": 0.0010298199627877902, "cient behavior": 0.001943809034733908, "who use simple": 0.0010298199627877902, "ai researchers": 0.0008730815719568182, "equilibrium notice": 0.000971904517366954, "lesser interest": 0.000971904517366954, "type of": 0.00018678809807347595, "players hence": 0.000971904517366954, "correspond to player": 0.0020596399255755804, "entry 6 9": 0.0010298199627877902, "algorithm in question": 0.0010298199627877902, "the dynamics of": 0.0011886068536149307, "that a deviation": 0.0020596399255755804, "game are": 0.000971904517366954, "proof now follows": 0.0010298199627877902, "we will use": 0.00037804761782699145, "idea in": 0.0005221368030860054, "part of the": 0.0007239359348533832, "to approximately obtain": 0.0010298199627877902, "of human behavior": 0.0010298199627877902, "a policy": 0.00899835397842583, "a a 0": 0.001249607768004622, "multiagent systems july": 0.0008321458774498469, "case economic": 0.000971904517366954, "unplayed joint action": 0.0010298199627877902, "is approximately": 0.0004482748456766825, "idea is": 0.0008416570400297818, "prole executed for": 0.0010298199627877902, "s ability to": 0.001249607768004622, "agents should be": 0.0010298199627877902, "shneidman distributed": 0.000971904517366954, "would have": 0.0010668621162681518, "no lower": 0.0008152096437846543, "the choice of": 0.0006978943901230977, "is initialized to": 0.0007330505281739418, "maximin values": 0.001943809034733908, "selected by": 0.0009209250317507447, "set of policies": 0.0010298199627877902, "under strict": 0.000971904517366954, "start with": 0.0006786649204033114, "should rapidly obtain": 0.0010298199627877902, "algorithm that denes": 0.0010298199627877902, "plays this": 0.000971904517366954, "the optimal policy": 0.0008002740946718667, "goal was": 0.0006427395698875594, "follow suit however": 0.0010298199627877902, "that approach": 0.0007160765724402042, "two": -0.005417955474304351, "level probabilistic maximin": 0.0010298199627877902, "it attain": 0.0008730815719568182, "torre": 0.0007739936391863359, "theory literature the": 0.0010298199627877902, "security level probabilistic": 0.0010298199627877902, "s behavior imagine": 0.0010298199627877902, "the case that": 0.00042425064540523185, "denition of e": 0.0009310344469842923, "satisfy the": 0.00025505472871573733, "particular": -0.001179149050967196, "agent has": 0.0013496298428453508, "2 the study": 0.0009310344469842923, "distinctive aspects": 0.000971904517366954, "the uncertain entities": 0.0010298199627877902, "agent interaction": 0.00154820763243365, "include": -6.260427527297466e-05, "are 1 we": 0.0009310344469842923, "recall": 4.6932719382360956e-05, "der": 0.00041334544264567334, "properties for every": 0.0009310344469842923, "that although": 0.00042987295519467854, "identical payos in": 0.0010298199627877902, "payos that are": 0.0010298199627877902, "remain": 0.00010423681948665338, "them will": 0.000557817444576059, "to is the": 0.0008321458774498469, "result 5": 0.0008730815719568182, "strategies": 0.0012563995555231334, "descriptive purposes": 0.000971904517366954, "whether this ability": 0.0010298199627877902, "perfect monitoring is": 0.0010298199627877902, "we were able": 0.0005633746356361924, "as the appropriate": 0.0008002740946718667, "its learning": 0.0008730815719568182, "above a nash": 0.0010298199627877902, "agents run": 0.000971904517366954, "multiple games a": 0.0010298199627877902, "well and we": 0.0009310344469842923, "iterations at": 0.0007421847985653504, "is the set": 0.00031236076488458777, "attain": 0.0032527791868446013, "mentioned earlier the": 0.0007521645399683924, "sum of": 0.001102028626657838, "take individual rationality": 0.0010298199627877902, "by the agents": 0.0009310344469842923, "the issues": 0.0004881890232438977, "are classes": 0.000774103816216825, "payo obtained": 0.003887618069467816, "agent j when": 0.0010298199627877902, "can guarantee a": 0.0007742140246189059, "acts": 0.00032772346897154083, "i without": 0.0008152096437846543, "for which an": 0.0007330505281739418, "paramount importance to": 0.0009310344469842923, "of the setting": 0.0010298199627877902, "sequence of": 0.000675966226909355, "the same learning": 0.0018620688939685846, "punishing without initially": 0.0010298199627877902, "is whether": 0.00044065161687170207, "are all": 0.00026275113032004705, "payo theorem": 0.000971904517366954, "efficient learning equilibrium": 0.0020596399255755804, "should an agent": 0.0010298199627877902, "in what follows": 0.00053318373443515, "guess progressively higher": 0.0010298199627877902, "is straightforward the": 0.0008002740946718667, "that any": 0.00025758704779950934, "i starting at": 0.0008732058717250353, "context of": 0.0017632458026525404, "response": 0.0010035185095680214, "taken in": 0.00045629221416883416, "properties are": 0.00042987295519467854, "i 2 s": 0.0007161785195604264, "payments is always": 0.0010298199627877902, "player knows": 0.0017461631439136364, "playing": 0.0012999668820339125, "jeffrey shneidman david": 0.0010298199627877902, "if a": 8.434215726409365e-05, "required but there": 0.0010298199627877902, "equivalent to the": 0.00039949343125814357, "cient outcome 2": 0.0010298199627877902, "algorithm learns": 0.0008152096437846543, "through": -0.0001621739657256426, "iteration for": 0.0006578931655429611, "unplayed": 0.000872957307571399, "existence": 0.0008114907789728613, "6 9 these": 0.0010298199627877902, "each stage based": 0.0010298199627877902, "the previous sections": 0.00053318373443515, "robustness of": 0.0004881890232438977, "25": -0.000170004855872817, "this property": 0.0003100542232769594, "23": -0.00018628883244499141, "multiagent": 0.0030950819239764006, "28": -2.2226121656032243e-05, "29": -3.697051864967361e-06, "agent we need": 0.0010298199627877902, "agents use the": 0.0018620688939685846, "osprings thus": 0.000971904517366954, "agent 1": 0.003492326287827273, "games immediately": 0.000971904517366954, "researches": 0.0006426480897324373, "best response policy": 0.0010298199627877902, "above captures": 0.0008730815719568182, "a certain amount": 0.0006527573289679061, "payos might": 0.000971904517366954, "setting proof in": 0.0010298199627877902, "of actions that": 0.0008002740946718667, "we consider a": 0.00041984698137044723, "joint action": 0.009719045173669541, "ele but while": 0.0010298199627877902, "adopted by both": 0.0010298199627877902, "are required to": 0.0005159938685900292, "agent i": 0.004723704449958728, "agent j": 0.0008152096437846543, "in 7 where": 0.0008732058717250353, "from to": 0.0010572447164994472, "a reinforcement": 0.0008730815719568182, "agent s": 0.003774098739755102, "is where": 0.0007857679544577711, "repeating": 0.00035168238084447203, "as a bi": 0.0010298199627877902, "of repeated common": 0.0010298199627877902, "or the following": 0.0010298199627877902, "is performed": 0.0002735087712513827, "rational behavior as": 0.0010298199627877902, "line appear": 0.000971904517366954, "reward should manifest": 0.0010298199627877902, "in an imperfect": 0.0020596399255755804, "idea": -0.00019305389048404061, "players in that": 0.0010298199627877902, "i th": 0.00029704876608852796, "discounting or": 0.000971904517366954, "following algorithm": 0.0010084195104002043, "payo notice that": 0.0010298199627877902, "6 stochastic games": 0.0010298199627877902, "states each state": 0.0009310344469842923, "as we would": 0.0008732058717250353, "that maximize u": 0.0020596399255755804, "hence we get": 0.0008732058717250353, "receive the": 0.0004933431890106373, "a desired value": 0.0020596399255755804, "of related": 0.00046915827274082977, "attain a lower": 0.0010298199627877902, "suggested equilibrium": 0.000971904517366954, "the extension": 0.0011869790028829986, "of ele provides": 0.0010298199627877902, "equilibrium ele notice": 0.0010298199627877902, "to coordinate e": 0.0010298199627877902, "payos in g": 0.0010298199627877902, "the player using": 0.0010298199627877902, "played the": 0.000971904517366954, "have attained": 0.000971904517366954, "after o k": 0.0010298199627877902, "newfoundland canada": 0.0007160765724402042, "is unknown": 0.0005042097552001021, "redundancy to improve": 0.0009310344469842923, "payment structure": 0.000971904517366954, "way to": 0.00018495131446694105, "plays as if": 0.0010298199627877902, "action the agent": 0.0010298199627877902, "annual acm": 0.00042987295519467854, "performance of its": 0.0009310344469842923, "and instead": 0.000557817444576059, "generalization is straightforward": 0.0010298199627877902, "pareto ele in": 0.0020596399255755804, "learning a": 0.000557817444576059, "value that each": 0.0010298199627877902, "learning in noncooperative": 0.0010298199627877902, "intelligence and": 0.000549963838367756, "u s": 0.001381387547626117, "instances": 0.00011419676523269817, "learning v": 0.0020244447642680263, "done": -0.0002028726947432154, "failure of at": 0.0020596399255755804, "best response for": 0.0010298199627877902, "only equilibrium of": 0.0020596399255755804, "several": -0.00044074871063315175, "t consists": 0.0008152096437846543, "phase is": 0.00042987295519467854, "are not concerned": 0.0007330505281739418, "irrational may be": 0.0010298199627877902, "twenty": 0.00033534384570482143, "resp 2": 0.001943809034733908, "construct": 1.6036601551965958e-05, "payo by": 0.000971904517366954, "probability distributions": 0.0005099512042140099, "assumption": -0.00011374676192269778, "our average payo": 0.0010298199627877902, "of pareto e": 0.0010298199627877902, "agents will be": 0.0009310344469842923, "agent as part": 0.0010298199627877902, "performing a resp": 0.0010298199627877902, "instance of a": 0.0006087606573971396, "playing the second": 0.0010298199627877902, "we know": 0.0002335852782197112, "the game associated": 0.0010298199627877902, "u 2": 0.0008597459103893571, "such interactions the": 0.0010298199627877902, "u 1": 0.001777666049183364, "also determine stochastically": 0.0010298199627877902, "part": -0.0007179796289017278, "over all": 0.0002735087712513827, "when several": 0.0007421847985653504, "believe": 0.0002578162887969309, "a game more": 0.0010298199627877902, "b": 0, "learns the required": 0.0010298199627877902, "design friend": 0.000971904517366954, "in machine": 0.002081934799943552, "way to guarantee": 0.0009310344469842923, "for multi": 0.00045629221416883416, "value the identity": 0.0010298199627877902, "of learning algorithm": 0.0010298199627877902, "short period of": 0.0008321458774498469, "contrary": 0.00035168238084447203, "as we": 0.00048407843702322705, "to the context": 0.0008321458774498469, "resp b": 0.000971904517366954, "treated": 0.0003518764837060426, "s payo notice": 0.0010298199627877902, "approximately equal to": 0.0007330505281739418, "try and understand": 0.0010298199627877902, "as input": 0.00036281071874830087, "in section 6": 0.00032171035426604966, "games first to": 0.0010298199627877902, "about the best": 0.0009310344469842923, "positive negative": 0.0007421847985653504, "ages": 0.0006747188760310696, "algorithm as": 0.0007644674912529991, "appealing alternative": 0.0008730815719568182, "more detail first": 0.0009310344469842923, "i associates": 0.001943809034733908, "learning rule is": 0.0009310344469842923, "denoted defect the": 0.0010298199627877902, "the deviating": 0.000971904517366954, "will punish it": 0.0010298199627877902, "the value it": 0.0020596399255755804, "of random play": 0.0020596399255755804, "learning has taken": 0.0010298199627877902, "this setting the": 0.0008732058717250353, "e punishment": 0.000971904517366954, "probability that the": 0.0005159938685900292, "for every 0": 0.0014661010563478836, "a new": 6.715482486134023e-05, "strategic form the": 0.0020596399255755804, "obtained which": 0.000774103816216825, "the outcome associated": 0.0010298199627877902, "and are dierent": 0.0010298199627877902, "strategy of agent": 0.0010298199627877902, "most": -0.0033578197519453703, "contribution of": 0.000387471559992312, "torre enforceable social": 0.0010298199627877902, "following instance of": 0.0010298199627877902, "there exists": 0.001061087869609325, "justied by the": 0.0007742140246189059, "given the above": 0.0016005481893437334, "ciently many": 0.0008152096437846543, "with perfect monitoring": 0.003089459888363371, "agent as": 0.00154820763243365, "ele notice that": 0.0010298199627877902, "adopt behavior that": 0.0010298199627877902, "of a normative": 0.0010298199627877902, "an equilibrium another": 0.0010298199627877902, "for every t": 0.0014661010563478836, "for every s": 0.0008732058717250353, "criterion as follows": 0.0009310344469842923, "longer the": 0.0006290164566258502, "by the": 4.313605356170584e-06, "value t 0": 0.0010298199627877902, "rules that will": 0.0020596399255755804, "of convergence in": 0.0009310344469842923, "required to satisfy": 0.0008321458774498469, "converge": 0.0025375766040135568, "monitoring setting the": 0.0010298199627877902, "minimizing": 0.0001759382418530213, "optimal value": 0.0005042097552001021, "the action selected": 0.0010298199627877902, "networks": 7.435047625491984e-05, "only economically e": 0.0010298199627877902, "irrational after polynomial": 0.0010298199627877902, "distributed": -0.00020935085688887983, "that uses": 0.00036511734625786996, "the learner will": 0.0010298199627877902, "of common interest": 0.0010298199627877902, "so far": 0.0005361103382585787, "8": -0.0017244473340570078, "in ele the": 0.0010298199627877902, "it can accomplish": 0.0010298199627877902, "denition for": 0.0013879565332957013, "notation": 6.162369165004876e-06, "strategy 2": 0.0007421847985653504, "s choice of": 0.0008732058717250353, "of rationality": 0.001943809034733908, "setting the set": 0.0010298199627877902, "assume we consider": 0.0009310344469842923, "update following each": 0.0010298199627877902, "we had ages": 0.0010298199627877902, "appealing concept in": 0.0010298199627877902, "care about": 0.0006748149214226754, "learning algorithm itself": 0.0009310344469842923, "ensures the e": 0.0010298199627877902, "be an": 0.000574322679219938, "should become irrational": 0.0010298199627877902, "criterion for rational": 0.0010298199627877902, "the corresponding policies": 0.0009310344469842923, "common": -0.0005319563767368299, "iteration the players": 0.0010298199627877902, "agent within": 0.0008730815719568182, "which ensures the": 0.0010298199627877902, "extended discussion": 0.000971904517366954, "playing using": 0.0008730815719568182, "in general sum": 0.0009310344469842923, "obtained once the": 0.0009310344469842923, "learns a": 0.0007421847985653504, "learning algorithms is": 0.0008732058717250353, "out the existence": 0.0010298199627877902, "turns out": 0.0003296442778898719, "payo for player": 0.0010298199627877902, "average reward see": 0.0010298199627877902, "is straightforward": 0.00034336616306129136, "much more": 0.0002777034574655148, "elaborate only": 0.000971904517366954, "would have attained": 0.0010298199627877902, "for its": 0.00032591593593977075, "or equal to": 0.00042425064540523185, "after an exponential": 0.0018620688939685846, "the game is": 0.005825021142148929, "issues involved the": 0.0010298199627877902, "each agent receives": 0.0010298199627877902, "more challenging setting": 0.0010298199627877902, "is that any": 0.0007330505281739418, "his adversary would": 0.0010298199627877902, "shared selection algorithm": 0.0010298199627877902, "equilibrium and show": 0.0010298199627877902, "issues first the": 0.0010298199627877902, "the game in": 0.0009310344469842923, "reward for every": 0.0010298199627877902, "all the agents": 0.0008002740946718667, "and pretend": 0.000971904517366954, "now explain": 0.0007421847985653504, "players have a": 0.0010298199627877902, "su ciently": 0.00046046251587537234, "e polynomial time": 0.0010298199627877902, "punishment procedure for": 0.0010298199627877902, "game theorists despite": 0.0010298199627877902, "basic action we": 0.0010298199627877902, "and instead our": 0.0010298199627877902, "but in ai": 0.0010298199627877902, "advance how": 0.000971904517366954, "a hence": 0.0006427395698875594, "powers": 0.000390099633351153, "annual": 0.00021825391481015917, "leading to correlated": 0.0010298199627877902, "that behavior": 0.0008730815719568182, "obtained in the": 0.0005475136432016508, "common property": 0.000971904517366954, "agents will have": 0.0009310344469842923, "rigorous normative approach": 0.0010298199627877902, "will be discussed": 0.0005080852977998101, "polynomial bound": 0.0008152096437846543, "point": -0.0012625911937874722, "simple": -0.0007726511574686393, "value can be": 0.0005749794499375729, "most previous": 0.0006290164566258502, "agent this": 0.0008152096437846543, "simply": -6.389840877425322e-05, "that the learning": 0.0007742140246189059, "game is always": 0.0010298199627877902, "throughout": 0.00010705674809908032, "setting recall that": 0.0010298199627877902, "where all": 0.00036281071874830087, "ensures": 0.00014587597108980225, "is immediate": 0.0005221368030860054, "discussion in 10": 0.0010298199627877902, "2005 the netherlands": 0.0008732058717250353, "k times for": 0.0010298199627877902, "in t": 0.0006747014305737088, "no distribution": 0.0008152096437846543, "time convergence rate": 0.0010298199627877902, "in m": 0.000387471559992312, "j when the": 0.0016642917548996938, "involved are": 0.0006578931655429611, "in a": 4.6834526721389065e-05, "investigated by": 0.0006939782666478507, "in e": 0.0007543176731416702, "concepts are in": 0.0010298199627877902, "in g": 0.0010884321562449027, "case one": 0.0005221368030860054, "and this approach": 0.0010298199627877902, "partial information to": 0.0010298199627877902, "other agent this": 0.0010298199627877902, "understand": 0.00017417811437832562, "g to be": 0.0007330505281739418, "equilibrium existence": 0.000971904517366954, "resp player 2": 0.0010298199627877902, "near future and": 0.0010298199627877902, "th action": 0.001943809034733908, "in 1": 0.00025758704779950934, "because the side": 0.0009310344469842923, "in 2": 0.0002805523466765939, "in 4": 0.0002954867076473726, "in 7": 0.0003698290826886664, "well known": 0.00019522836659569394, "g and m": 0.0008732058717250353, "replaced": 0.000180829263347863, "behavior as": 0.0005842412659181877, "i e assuming": 0.0008321458774498469, "show the following": 0.000663411738084629, "of the third": 0.000624803884002311, "is another": 0.0004042861100519966, "the rst action": 0.0010298199627877902, "should be irrational": 0.0010298199627877902, "and a natural": 0.0008002740946718667, "of possible actions": 0.0010298199627877902, "and show that": 0.00044575545550825166, "appropriate here because": 0.0010298199627877902, "itself": -8.157781245205346e-05, "had the agents": 0.0010298199627877902, "be able to": 0.000567943721347027, "in m we": 0.0009310344469842923, "all t": 0.001099927676735512, "game theoretic literature": 0.0010298199627877902, "player repeated games": 0.0020596399255755804, "ele for any": 0.0020596399255755804, "veloso suggest": 0.000971904517366954, "a policy for": 0.002793103340952877, "and a novel": 0.0018620688939685846, "of exposition we": 0.0008321458774498469, "a game 8": 0.0010298199627877902, "notion of": 0.001818043794375222, "also be": 0.00013499360649377534, "s thus": 0.000549963838367756, "that will rapidly": 0.0010298199627877902, "the monetary payments": 0.0010298199627877902, "is the lack": 0.0007742140246189059, "context of games": 0.0010298199627877902, "following games": 0.000971904517366954, "games as a": 0.0009310344469842923, "that features algorithms": 0.0010298199627877902, "strictly dominated strategies": 0.0010298199627877902, "repeated games": 0.016522376795238217, "policies for players": 0.0010298199627877902, "part of": 0.0004597382343680479, "faithfulness in": 0.000971904517366954, "convergence in self": 0.0010298199627877902, "a game g": 0.0020596399255755804, "algorithm that": 0.0004952891408603564, "entry": 0.0004715596291988083, "is similar suppose": 0.0009310344469842923, "selection algorithm is": 0.0009310344469842923, "jeffrey shneidman": 0.001943809034733908, "examining": 0.0002550184271602697, "n g and": 0.0007521645399683924, "play some previously": 0.0010298199627877902, "agents 1 individual": 0.0010298199627877902, "min s": 0.0008152096437846543, "the players hence": 0.0010298199627877902, "ones they": 0.0008730815719568182, "criterion and": 0.0006427395698875594, "the agents 1": 0.0010298199627877902, "systems predicting": 0.0008730815719568182, "the agents 3": 0.0010298199627877902, "paid c where": 0.0010298199627877902, "agent interactions in": 0.0010298199627877902, "m trials the": 0.0010298199627877902, "of players the": 0.0010298199627877902, "deviation from the": 0.002256493619905177, "a two": 0.000272130787801713, "ciency a a": 0.0010298199627877902, "denition of ele": 0.0010298199627877902, "indeed an ele": 0.0010298199627877902, "about the distribution": 0.0008321458774498469, "what they": 0.0006427395698875594, "that all": 0.0005461128706374851, "is known proof": 0.0010298199627877902, "to better": 0.000444416512295841, "25 29": 0.0005748976023290408, "denote the t": 0.0010298199627877902, "for all t": 0.001285662152181123, "order to have": 0.0006428310760905615, "general results": 0.0006578931655429611, "these issues": 0.000929497775974384, "to a correlated": 0.0010298199627877902, "rows of": 0.0004986788606483227, "2 is irrational": 0.0010298199627877902, "an exponential": 0.0008739510701493671, "to devise an": 0.0009310344469842923, "player game is": 0.0010298199627877902, "reals": 0.0004646827409778002, "by using a": 0.00042203345812732713, "will attain a": 0.0020596399255755804, "response for": 0.000774103816216825, "cognitive": 0.0005748157780190026, "result theorem 1": 0.0008002740946718667, "follows": -0.0026223806147637647, "g then": 0.00041030656060455343, "and payos a": 0.0010298199627877902, "in a stochastic": 0.0009310344469842923, "so that each": 0.0005811431115841947, "mixed strategies": 0.001943809034733908, "the payos it": 0.0010298199627877902, "fundamental decision": 0.000971904517366954, "one of": 0.00013621619306239662, "covergent": 0.000872957307571399, "where the underlying": 0.0008321458774498469, "distribution on the": 0.0006013538961527255, "of these results": 0.0005875760798754402, "examples": -4.85235677441778e-05, "that despite": 0.0006164744968379118, "adversary to": 0.0006427395698875594, "the goals of": 0.0007330505281739418, "related work that": 0.0010298199627877902, "learning to coordinate": 0.0010298199627877902, "possible games that": 0.0010298199627877902, "some appropriate equilibrium": 0.0010298199627877902, "be obtained by": 0.00039949343125814357, "now on the": 0.0008732058717250353, "a vector": 0.0003151849303416359, "literature is": 0.0006939782666478507, "introducing side monetary": 0.0010298199627877902, "are lower": 0.0006049243473022664, "mapping from": 0.0004264387578012798, "than the": 0.00019366690789672403, "consisting of": 0.000235863380273182, "in the general": 0.0004707237014509277, "the folk theorems": 0.0010298199627877902, "run an": 0.0014843695971307007, "is irreducible i": 0.0010298199627877902, "agent designers": 0.0008730815719568182, "the agent performed": 0.0010298199627877902, "that in this": 0.0004969500605540478, "guido boella leendert": 0.0010298199627877902, "deviators": 0.000872957307571399, "learning algorithm by": 0.0009310344469842923, "each agent within": 0.0010298199627877902, "results to the": 0.000663411738084629, "after the other": 0.0007330505281739418, "with descriptive motivation": 0.0010298199627877902, "obtained by each": 0.0009310344469842923, "have attained had": 0.0010298199627877902, "call rationality stipulates": 0.0010298199627877902, "are lower than": 0.0007742140246189059, "algorithm is identical": 0.0008732058717250353, "ele because a": 0.0010298199627877902, "said to": 0.0002777034574655148, "both cases we": 0.0007330505281739418, "the maximal average": 0.0020596399255755804, "requirement it is": 0.0009310344469842923, "individually rational learning": 0.0010298199627877902, "has no information": 0.0009310344469842923, "reward only": 0.000971904517366954, "for both ele": 0.0010298199627877902, "will reach": 0.0006939782666478507, "monitoring setting since": 0.0010298199627877902, "we examine the": 0.0005578968604992618, "procedure leading": 0.000971904517366954, "learning procedures": 0.000971904517366954, "game theoretic": 0.0016304192875693086, "similar 3": 0.0008730815719568182, "work the notion": 0.0009310344469842923, "joint actions have": 0.0020596399255755804, "basic idea": 0.0003517324423933467, "choice of a": 0.001249607768004622, "to the design": 0.0006335389089667411, "1 denoted": 0.00154820763243365, "e we prove": 0.0010298199627877902, "145 168 may": 0.0010298199627877902, "actions in": 0.0005286223582497236, "game be": 0.000971904517366954, "approach is limited": 0.0008732058717250353, "following each": 0.0006578931655429611, "t mix in": 0.0010298199627877902, "exploration": 0.0007033647616889441, "because we": 0.0006747014305737088, "rst obstacle": 0.000971904517366954, "they are": 0.00015533430316054268, "framework for multi": 0.0009310344469842923, "constant": -0.00020847363897330673, "remaining sections we": 0.0010298199627877902, "the game theoretic": 0.0020596399255755804, "intuitive idea behind": 0.0010298199627877902, "to get close": 0.0009310344469842923, "their behavior": 0.0006164744968379118, "notation and": 0.0005221368030860054, "point about": 0.000774103816216825, "reward criterion as": 0.0010298199627877902, "designed by dierent": 0.0010298199627877902, "contexts notice also": 0.0010298199627877902, "stochastic games thus": 0.0010298199627877902, "formally": 0.00022701097808233676, "lead to": 0.0017916911390878283, "case that although": 0.0010298199627877902, "address these issues": 0.0007330505281739418, "is played then": 0.0010298199627877902, "theory literature": 0.001943809034733908, "advance how his": 0.0010298199627877902, "of the matrix": 0.0005159938685900292, "short period": 0.0007160765724402042, "monitoring case the": 0.0010298199627877902, "elds": 0.00047363083259041887, "that equilibrium a": 0.0010298199627877902, "we known": 0.000971904517366954, "28 2004 st": 0.0007742140246189059, "that converges in": 0.0010298199627877902, "is not bayesian": 0.0010298199627877902, "can dene the": 0.0008321458774498469, "the probability we": 0.0009310344469842923, "payoff in a": 0.0010298199627877902, "e g see": 0.000624803884002311, "corresponding value": 0.0006939782666478507, "leads to is": 0.0010298199627877902, "agent to": 0.0026315726621718443, "possible histories to": 0.0010298199627877902, "to recent results": 0.0010298199627877902, "b denote": 0.0006427395698875594, "we often": 0.0006049243473022664, "0 polynomial in": 0.0020596399255755804, "use g and": 0.0010298199627877902, "2007": 0.00022701097808233676, "2004": 0.00011490511844833866, "2005": 4.094535617019369e-05, "imperfect and perfect": 0.0010298199627877902, "nash equilibrium and": 0.0020596399255755804, "games provide": 0.001943809034733908, "game out of": 0.0010298199627877902, "average reward because": 0.0010298199627877902, "algorithms then the": 0.0010298199627877902, "algorithm of": 0.00037467912962542367, "as follows first": 0.0005119876058604116, "that people who": 0.0009310344469842923, "following algorithm that": 0.0010298199627877902, "t consists of": 0.0009310344469842923, "surplus we": 0.000971904517366954, "the nash equilibrium": 0.0010298199627877902, "and the approximation": 0.0008002740946718667, "required generalization is": 0.0010298199627877902, "the other player": 0.005586206681905754, "attention to": 0.00035389034454809447, "consistent with the": 0.0004536379033545901, "monitoring we": 0.003887618069467816, "the imperfect": 0.002619244715870455, "on on": 0.0006164744968379118, "works as follows": 0.0005633746356361924, "game might be": 0.0010298199627877902, "learner will necessarily": 0.0010298199627877902, "complicated a parameter": 0.0010298199627877902, "case of repeated": 0.0033285835097993876, "state is": 0.00038223374562649956, "should go beyond": 0.0010298199627877902, "adversary s action": 0.0010298199627877902, "denote the probabilistic": 0.0010298199627877902, "a a deviation": 0.0010298199627877902, "2007 rob": 0.000971904517366954, "that will eventually": 0.0009310344469842923, "where special attention": 0.0010298199627877902, "one is selected": 0.0008321458774498469, "a standard though": 0.0010298199627877902, "play column": 0.001943809034733908, "1 and 2": 0.0003241273924015625, "game the": 0.00154820763243365, "the future": 0.0003393324602016557, "obtained once": 0.0008730815719568182, "g2 are identical": 0.0010298199627877902, "previously unplayed": 0.000971904517366954, "length t": 0.0006164744968379118, "the agent acts": 0.0010298199627877902, "dealing with uncertainty": 0.0009310344469842923, "property pursued by": 0.0010298199627877902, "after all": 0.00045223161134026404, "players combined choices": 0.0010298199627877902, "the sum over": 0.0007010750178672042, "when facing": 0.000971904517366954, "this latter result": 0.0010298199627877902, "matrix to": 0.0005942188284548949, "in iteration l": 0.0020596399255755804, "g dened over": 0.0010298199627877902, "performed for the": 0.0007521645399683924, "algorithms that guarantee": 0.0009310344469842923, "ele exists": 0.002915713552100862, "in iteration": 0.0012854791397751187, "paper in": 0.0004333839769001314, "distributed computing": 0.00036745646293076414, "agent deviates": 0.000971904517366954, "is extended to": 0.0006335389089667411, "one shot game": 0.0020596399255755804, "case of strict": 0.0009310344469842923, "to date": 0.00045629221416883416, "ele is of": 0.0010298199627877902, "algorithms where": 0.0006748149214226754, "guarantee that agents": 0.0010298199627877902, "agents will behave": 0.0010298199627877902, "adversary s": 0.005728612579521634, "veloso their requirements": 0.0010298199627877902, "provide new basic": 0.0010298199627877902, "are identical": 0.000387471559992312, "denote the other": 0.0009310344469842923, "of policies": 0.0006939782666478507, "time 13 6": 0.0010298199627877902, "merit for": 0.000971904517366954, "is immediate but": 0.0010298199627877902, "theorem 6 under": 0.0010298199627877902, "times also when": 0.0010298199627877902, "cooperative multiagent": 0.000971904517366954, "should quickly lead": 0.0020596399255755804, "the fourth international": 0.0008002740946718667, "money to the": 0.0010298199627877902, "payo initialize construct": 0.0010298199627877902, "agents they compute": 0.0010298199627877902, "play column 2": 0.0010298199627877902, "selection algorithm": 0.0011497952046580816, "second action": 0.001943809034733908, "for players": 0.000971904517366954, "is by": 0.0003517324423933467, "corresponding game the": 0.0010298199627877902, "of rationality in": 0.0010298199627877902, "actual initially unknown": 0.0010298199627877902, "selected by the": 0.0006013538961527255, "2 p 145": 0.0007521645399683924, "bayesian normative": 0.000971904517366954, "themselves": 0.0008277475162294911, "irrationality as well": 0.0010298199627877902, "involved the rst": 0.0010298199627877902, "each particular action": 0.0010298199627877902, "any deviation": 0.0008730815719568182, "that guarantee that": 0.0008732058717250353, "the economically e": 0.0010298199627877902, "able to get": 0.0008321458774498469, "the other game": 0.0010298199627877902, "theory diers considerably": 0.0010298199627877902, "unknown such assumptions": 0.0010298199627877902, "of choosing": 0.0005221368030860054, "interest stochastic games": 0.0010298199627877902, "payos but also": 0.0010298199627877902, "the general case": 0.0008864289836066309, "theorem which": 0.0006290164566258502, "the identity of": 0.0017829102804223962, "trials the agents": 0.0010298199627877902, "in cooperative multi": 0.0010298199627877902, "outcome is obtained": 0.0010298199627877902, "denitions of possible": 0.0010298199627877902, "in games ts": 0.0010298199627877902, "not in": 0.0004880776670783302, "do": -0.0033716322189819834, "of rewards let": 0.0010298199627877902, "does not always": 0.0019284932282716848, "he is": 0.0005842412659181877, "only determines the": 0.0010298199627877902, "the size of": 0.00046572901048636797, "defect too 2": 0.0010298199627877902, "6 under": 0.000774103816216825, "strategies in order": 0.0009310344469842923, "ective of the": 0.0010298199627877902, "player using": 0.000971904517366954, "of possible probability": 0.0010298199627877902, "which the players": 0.0010298199627877902, "settings moreover we": 0.0010298199627877902, "an ele": 0.013606663243137355, "adopt the framework": 0.0010298199627877902, "structure as in": 0.0008321458774498469, "t is": 0.00018586800694598302, "states s we": 0.0010298199627877902, "a and": 0.00013807024133330608, "when player": 0.000971904517366954, "social laws proceedings": 0.0010298199627877902, "correspond": 6.684873073652178e-05, "payos in the": 0.0020596399255755804, "their algorithms": 0.0013496298428453508, "denes the": 0.0006049243473022664, "must arrive at": 0.0010298199627877902, "be modied": 0.0006748149214226754, "that given": 0.0007493582592508473, "treat the game": 0.0010298199627877902, "some time 13": 0.0010298199627877902, "above properties for": 0.0010298199627877902, "for player i": 0.0010298199627877902, "value after polynomial": 0.0010298199627877902, "the situation in": 0.0006428310760905615, "learning research": 0.0019282187096626782, "by a single": 0.0004591252002600493, "in game": 0.002619244715870455, "0 0": 0.0005698163701665834, "to some": 0.0005076010931091531, "refer to as": 0.0012670778179334821, "results provide a": 0.0008732058717250353, "resorting": 0.0005941342541838367, "the union": 0.00034133740538055095, "provide a more": 0.0014323570391208528, "decreased value": 0.000971904517366954, "the possible games": 0.0010298199627877902, "is trivial in": 0.0008002740946718667, "of iterations": 0.0007644674912529991, "in the folk": 0.0010298199627877902, "resp 2 can": 0.0010298199627877902, "game s matrix": 0.0010298199627877902, "treats the choice": 0.0010298199627877902, "descriptive": 0.002466364861087195, "positive negative or": 0.0010298199627877902, "players have": 0.00154820763243365, "agent receives": 0.0008152096437846543, "well and": 0.000542504923393336, "for player 1": 0.004119279851151161, "cient manner": 0.000774103816216825, "best response value": 0.0010298199627877902, "2 times we": 0.0010298199627877902, "m where": 0.001496036581944968, "maximin value 1": 0.0010298199627877902, "so by": 0.0004832040417809763, "by pv": 0.000971904517366954, "algorithms the rst": 0.0008732058717250353, "ability to view": 0.0010298199627877902, "as dictated": 0.0008152096437846543, "the bayesian": 0.0012098486946045329, "is p and": 0.0008732058717250353, "we need only": 0.0011886068536149307, "with k actions": 0.0020596399255755804, "the appropriate solution": 0.0010298199627877902, "g2 and": 0.000774103816216825, "matrix to start": 0.0010298199627877902, "loss of": 0.000252554184414257, "3 intuitively the": 0.0010298199627877902, "enforceable": 0.000872957307571399, "based on a": 0.00029604805547833653, "had we known": 0.0010298199627877902, "the following model": 0.0008002740946718667, "the form of": 0.00035035890857109845, "of great": 0.000549963838367756, "guarantee itself the": 0.0010298199627877902, "in more detail": 0.0004509656222210493, "is not in": 0.0009072758067091802, "approaches": -6.1623691650048665e-06, "and related elds": 0.0010298199627877902, "a payo vector": 0.0010298199627877902, "well an agent": 0.0010298199627877902, "interest if": 0.000971904517366954, "to adopt other": 0.0010298199627877902, "payo to the": 0.0010298199627877902, "policy tells": 0.000971904517366954, "directing the": 0.0008152096437846543, "with an": 0.0001327052786993835, "interaction": 0.00040395222998658746, "of games the": 0.0010298199627877902, "the past but": 0.0009310344469842923, "learning algorithm": 0.007595068927506704, "be individually": 0.0014321531448804085, "settings moreover": 0.000971904517366954, "not play": 0.000774103816216825, "what follows": 0.000464748887987192, "in addition for": 0.0007742140246189059, "rby player": 0.000971904517366954, "2 to deviate": 0.0010298199627877902, "history namely the": 0.0010298199627877902, "value which is": 0.000663411738084629, "strategic": 0.0010848554189690253, "the agents for": 0.0010298199627877902, "game itself may": 0.0010298199627877902, "in parallel": 0.0006373794605320186, "idea above": 0.000971904517366954, "l then with": 0.0010298199627877902, "features algorithms": 0.000971904517366954, "players have to": 0.0009310344469842923, "is required for": 0.000552614435925888, "framework for": 0.0004928711130681043, "networks with rational": 0.0010298199627877902, "action leading": 0.001943809034733908, "we are not": 0.0005005713348648543, "its detrimental eect": 0.0010298199627877902, "desired result 5": 0.0010298199627877902, "van der": 0.0006427395698875594, "moreover we believe": 0.0010298199627877902, "will be very": 0.0007330505281739418, "by and the": 0.0006749109941620578, "bayesian it does": 0.0010298199627877902, "act compute the": 0.0010298199627877902, "of the twenty": 0.0005875760798754402, "mix in time": 0.0010298199627877902, "which is": 6.168309066875428e-05, "adjusted with": 0.000971904517366954, "follows we often": 0.0010298199627877902, "interaction in": 0.0006748149214226754, "have done": 0.0006164744968379118, "innite": 0.00036977644547222914, "researches in": 0.0008152096437846543, "executed in": 0.000464748887987192, "technically speaking": 0.0008730815719568182, "by agent 1": 0.0010298199627877902, "their practical and": 0.0010298199627877902, "game where": 0.000971904517366954, "at any stage": 0.0007742140246189059, "on equilibrium": 0.000971904517366954, "a class of": 0.0003848863750022802, "only a polynomial": 0.0010298199627877902, "visited": 0.00034744822890409797, "the agents behavior": 0.0016642917548996938, "leading to": 0.0010424930631801534, "computed and": 0.0005286223582497236, "information is not": 0.0007161785195604264, "that modied": 0.0008730815719568182, "it is an": 0.0004536379033545901, "game played": 0.000971904517366954, "a of actions": 0.0008732058717250353, "allows side payments": 0.0010298199627877902, "their average": 0.0006290164566258502, "2 performs the": 0.0020596399255755804, "denote by nv": 0.0010298199627877902, "is the case": 0.000405331588255818, "have": -0.020950975381713574, "indeed in their": 0.0010298199627877902, "1 individual rationality": 0.0010298199627877902, "like a learning": 0.0010298199627877902, "after an": 0.0010572447164994472, "min": 0.0001259159397180222, "agent to deviate": 0.0010298199627877902, "incentive": 0.0006747188760310696, "monitoring setting proof": 0.0020596399255755804, "mix": 0.0029846464439052004, "consider the following": 0.0014304019011043524, "as models": 0.0007160765724402042, "tuple of": 0.0004933431890106373, "possible histories h": 0.0010298199627877902, "concepts introduced": 0.000971904517366954, "contains the": 0.00025008444186787576, "of partial information": 0.0010298199627877902, "in theoretical computer": 0.0007010750178672042, "as a": 6.163246370579966e-05, "other for": 0.0005221368030860054, "the values": 0.0003699026289338821, "prisoner": 0.0007739936391863359, "agent has an": 0.0009310344469842923, "payment": 0.0012327735099021723, "to if": 0.0006290164566258502, "imagine for example": 0.0010298199627877902, "and describe how": 0.0008321458774498469, "above work the": 0.0010298199627877902, "go beyond recommending": 0.0010298199627877902, "studied in": 0.0003134582012487072, "as a xed": 0.0009310344469842923, "the ai": 0.0013496298428453508, "action at": 0.00154820763243365, "value against such": 0.0010298199627877902, "e a vector": 0.0008321458774498469, "agents behavior will": 0.0010298199627877902, "agents adopt the": 0.0010298199627877902, "that mix in": 0.0010298199627877902, "to attain this": 0.0010298199627877902, "lead to rational": 0.0010298199627877902, "selection": 0.00020008635226453458, "see the above": 0.0010298199627877902, "to the agents": 0.0016005481893437334, "at the": 6.685824657007857e-05, "and this": 0.0002488608288383314, "increasing its": 0.0007421847985653504, "has not": 0.00028786948439001953, "well thus": 0.0007421847985653504, "games in any": 0.0010298199627877902, "natural number t": 0.0010298199627877902, "theorem 1 there": 0.0009310344469842923, "knowledge": -1.4788854253952322e-05, "order to remain": 0.0008732058717250353, "common interest games": 0.0020596399255755804, "autonomous agents and": 0.0013748045949038444, "polynominal time": 0.000971904517366954, "learning payoff functions": 0.0010298199627877902, "equilibrium": 0.021442681726899348, "we can show": 0.00053318373443515, "has an": 0.00022799513915820602, "t mix steps": 0.0010298199627877902, "to see the": 0.0005633746356361924, "we play against": 0.0010298199627877902, "by the other": 0.0006335389089667411, "behavior imagine for": 0.0010298199627877902, "be replaced by": 0.00048327283506710686, "one of nitely": 0.0010298199627877902, "that there is": 0.00027354771042724423, "is g2 and": 0.0010298199627877902, "need to show": 0.0005875760798754402, "the intuitive idea": 0.0010298199627877902, "learning algorithms of": 0.0009310344469842923, "motivation to": 0.0007160765724402042, "payos obtained in": 0.0010298199627877902, "assume the perfect": 0.0010298199627877902, "result is truly": 0.0010298199627877902, "approach the typical": 0.0010298199627877902, "exists": -0.0007040937116938614, "is the expected": 0.001249607768004622, "take an agent": 0.0010298199627877902, "future not exponentially": 0.0010298199627877902, "now we": 0.00026671552906703795, "i agent j": 0.0010298199627877902, "j when": 0.0013157863310859221, "correlated equilibrium reinforcement": 0.0010298199627877902, "in case one": 0.0008321458774498469, "study of learning": 0.0020596399255755804, "we formalize": 0.000557817444576059, "payos by in": 0.0010298199627877902, "to satisfy": 0.0003222656159195575, "state s i": 0.0007742140246189059, "the issue of": 0.0009537388223180847, "mixing time the": 0.0010298199627877902, "had we": 0.0008152096437846543, "ai and in": 0.0010298199627877902, "games our": 0.000971904517366954, "value that is": 0.0006749109941620578, "acts as": 0.0005221368030860054, "approach with an": 0.0009310344469842923, "irrational may": 0.000971904517366954, "gets in": 0.0008730815719568182, "that equilibrium notice": 0.0010298199627877902, "objective is the": 0.0017464117434500706, "complicated a": 0.000971904517366954, "payments is a": 0.0010298199627877902, "is that despite": 0.0010298199627877902, "equal": -0.000170004855872817, "to some appropriate": 0.0010298199627877902, "reward should": 0.000971904517366954, "equilibrium had": 0.002915713552100862, "the desired strategy": 0.0010298199627877902, "to the next": 0.0004093455120016892, "average payo from": 0.0010298199627877902, "consider the bayesian": 0.0009310344469842923, "ele algorithm when": 0.0010298199627877902, "otherwise": -0.00010847424595031267, "replaces its": 0.0008152096437846543, "relevant": 7.567032602744559e-05, "in polynomial": 0.0004230779228348551, "the game another": 0.0010298199627877902, "which they call": 0.0015484280492378119, "a learning equilibrium": 0.0010298199627877902, "is known": 0.00044941982539889664, "any case": 0.0004881890232438977, "0 and some": 0.0008732058717250353, "nitely": 0.0005041379917849015, "to a stationary": 0.0018620688939685846, "ciently finally note": 0.0010298199627877902, "mix steps": 0.000971904517366954, "payo matrix": 0.000971904517366954, "special classes of": 0.0008321458774498469, "of the agent": 0.0007330505281739418, "both agents": 0.002915713552100862, "they converge to": 0.0010298199627877902, "a times if": 0.0010298199627877902, "and act": 0.0008730815719568182, "repeated game": 0.006803331621568678, "cover the case": 0.0008321458774498469, "ones modeled in": 0.0010298199627877902, "imperfect monitoring setting": 0.0020596399255755804, "straightforward the": 0.0006578931655429611, "payos our rst": 0.0010298199627877902, "the maximal": 0.0007803103270961426, "conceptual contribution of": 0.0010298199627877902, "n player repeated": 0.0010298199627877902, "most times also": 0.0010298199627877902, "multi": 0.0005106433164467851, "to n player": 0.0010298199627877902, "polynomial in the": 0.0011751521597508803, "equilibrium the": 0.0008152096437846543, "value": -0.006766870944036152, "by work on": 0.0010298199627877902, "be discussed later": 0.0007161785195604264, "known proof": 0.000971904517366954, "in theoretical": 0.0005842412659181877, "is appropriate": 0.00047837713542937403, "notice also that": 0.0006874022974519222, "approximately obtain": 0.000971904517366954, "to compute the": 0.0009439568270063151, "e cient solution": 0.0016642917548996938, "dierent": 0.0010498447531571212, "player s total": 0.0010298199627877902, "denitely": 0.0006426480897324373, "the more general": 0.0005578968604992618, "in advance": 0.00041030656060455343, "der torre": 0.0008730815719568182, "but the": 0.0001531182572056227, "contexts notice": 0.000971904517366954, "game m where": 0.0020596399255755804, "before hand": 0.0008730815719568182, "will be economically": 0.0010298199627877902, "as his probabilistic": 0.0010298199627877902, "next state will": 0.0010298199627877902, "and understand the": 0.0008732058717250353, "76 may 2007": 0.0010298199627877902, "judgment": 0.0005041379917849015, "now that the": 0.000624803884002311, "deviate at": 0.000971904517366954, "learning near optimal": 0.0010298199627877902, "the outcome": 0.0005159204175055324, "following are": 0.00047837713542937403, "that an": 0.0005856850997870819, "uncertainty second the": 0.0010298199627877902, "with unique": 0.0008730815719568182, "do in that": 0.0010298199627877902, "sets": -0.0002488592358755069, "equals the probabilistic": 0.0010298199627877902, "total payo": 0.001943809034733908, "of a payo": 0.0010298199627877902, "takes an action": 0.0010298199627877902, "if it turns": 0.0010298199627877902, "have been proposed": 0.0003747324723261107, "agent thus": 0.000971904517366954, "i without loss": 0.0010298199627877902, "underlying": 0.0001434401312045024, "not of": 0.00045223161134026404, "plays his i": 0.0010298199627877902, "the perfect and": 0.0010298199627877902, "agents behavior": 0.0014843695971307007, "3 there exists": 0.0007521645399683924, "even more": 0.0003796766130365772, "and we follow": 0.0010298199627877902, "t must": 0.0005661109047770705, "recommending": 0.0006747188760310696, "is played": 0.002864306289760817, "behavior 2": 0.0008730815719568182, "this policy": 0.0032894658277148056, "of at least": 0.0005042815390490772, "behavior but an": 0.0010298199627877902, "ele algorithm of": 0.0010298199627877902, "response policy the": 0.0010298199627877902, "game that": 0.0008152096437846543, "stochastic games learning": 0.0010298199627877902, "they will": 0.00044065161687170207, "monitoring recall that": 0.0010298199627877902, "minimize the other": 0.0010298199627877902, "general model": 0.0005942188284548949, "that people": 0.0008152096437846543, "generalize our": 0.0006939782666478507, "a be the": 0.0005633746356361924, "themselves are required": 0.0010298199627877902, "like": -0.00038095221802833193, "success": 0.00022467793007595, "case the average": 0.0009310344469842923, "1 there": 0.0010682288761875633, "its payo theorem": 0.0010298199627877902, "equilibrium when": 0.000971904517366954, "k 2": 0.0014852438304426398, "known the adversary": 0.0010298199627877902, "yoav shoham thuc": 0.0010298199627877902, "and similarly for": 0.001285662152181123, "e ciently converge": 0.0010298199627877902, "i agent": 0.0008730815719568182, "of players": 0.001943809034733908, "we denote the": 0.000866891354704847, "and game matrix": 0.0020596399255755804, "no agent": 0.002322311448650475, "an instance of": 0.00044321449180331545, "classical": 0.00018129197857836914, "action by both": 0.0010298199627877902, "articial": 0.0011882685083676734, "computing july 25": 0.0008321458774498469, "is due": 0.00028344496914384004, "of the actual": 0.0005159938685900292, "the prescribed ele": 0.0010298199627877902, "2 plays his": 0.0010298199627877902, "desired strategy prole": 0.0010298199627877902, "conver": 0.0007739936391863359, "pre determined sequence": 0.0010298199627877902, "happens": 0.00019235481873811978, "g is played": 0.0010298199627877902, "and will not": 0.0007161785195604264, "it is not": 0.00021761355734897564, "that the game": 0.002793103340952877, "have multiple": 0.000542504923393336, "his i th": 0.0010298199627877902, "agent replaces": 0.000971904517366954, "assume some": 0.0007160765724402042, "assuming": 1.7273108027934463e-05, "punishment of deviators": 0.0010298199627877902, "in stochastic contexts": 0.0010298199627877902, "6 much of": 0.0010298199627877902, "monitoring case finally": 0.0010298199627877902, "and will": 0.00036281071874830087, "them the": 0.00039848399477585494, "dynamics of reinforcement": 0.0020596399255755804, "although": -0.00019454102780186466, "repeated games we": 0.0010298199627877902, "play a given": 0.0010298199627877902, "about": -0.0015576085706702045, "actual": 4.069606311030099e-05, "we elaborate only": 0.0010298199627877902, "is to approach": 0.0010298199627877902, "played then": 0.000971904517366954, "also allows side": 0.0010298199627877902, "not tell": 0.000774103816216825, "its detrimental": 0.000971904517366954, "ai perspective the": 0.0010298199627877902, "ts into one": 0.0010298199627877902, "about the identity": 0.0009310344469842923, "stage or the": 0.0010298199627877902, "introduced": -6.779667630156865e-05, "i for agent": 0.0010298199627877902, "compute the optimal": 0.0008002740946718667, "and show": 0.00029240195497445495, "faithfulness": 0.0007159746543399424, "maximal social": 0.000971904517366954, "is ergodic u": 0.0010298199627877902, "2 the learning": 0.0008732058717250353, "the corresponding game": 0.0010298199627877902, "of partial": 0.00043697553507468355, "an ele because": 0.0010298199627877902, "standard notion": 0.0008152096437846543, "a natural candidate": 0.0008002740946718667, "same algorithm": 0.0005942188284548949, "behavior of an": 0.0007161785195604264, "the term adversary": 0.0010298199627877902, "adversary and": 0.0006748149214226754, "player 2 will": 0.0020596399255755804, "case economic models": 0.0010298199627877902, "but does not": 0.0005286976176970826, "adopt other assumptions": 0.0010298199627877902, "ai we": 0.0008730815719568182, "is what": 0.00045223161134026404, "maximized it": 0.000971904517366954, "but": -0.007472605114247033, "instances in": 0.0005842412659181877, "repeated": 0.003235170066381589, "an innite number": 0.0008002740946718667, "that of best": 0.0010298199627877902, "its aim is": 0.0020596399255755804, "some t": 0.0007160765724402042, "this follows from": 0.0005633746356361924, "leads to": 0.0007434720277839321, "for players 1": 0.0010298199627877902, "motivation in": 0.000774103816216825, "be very": 0.00029393785638675104, "wish": 0.00035542083696517025, "j": -0.0009712654044657275, "the objective is": 0.0005875760798754402, "expected t": 0.000971904517366954, "and veloso consider": 0.0010298199627877902, "they converge": 0.000971904517366954, "agent this policy": 0.0010298199627877902, "ai speed": 0.000971904517366954, "shall take": 0.0008152096437846543, "are based on": 0.0010063179925635288, "we have been": 0.0005633746356361924, "a concrete algorithm": 0.0010298199627877902, "a general multiagent": 0.0010298199627877902, "uncertainty about the": 0.0009310344469842923, "g for every": 0.0008002740946718667, "set of actions": 0.0014021500357344085, "how his": 0.000971904517366954, "strategies now": 0.000971904517366954, "our impossibility": 0.000971904517366954, "strictly dominated": 0.000971904517366954, "new joint action": 0.0010298199627877902, "a bayesian approach": 0.0008321458774498469, "we relax the": 0.0008002740946718667, "45": 0.0001794949072254319, "on showing": 0.0006939782666478507, "43": 0.00018129197857836914, "should view": 0.0008152096437846543, "future and decreased": 0.0010298199627877902, "machine learning v": 0.002199151584521826, "assess the": 0.000464748887987192, "the general": 0.00040994034236554826, "equilibrium ele": 0.002915713552100862, "that agents": 0.0013496298428453508, "0 in": 0.0008726362601383686, "we borrow from": 0.0008732058717250353, "a player can": 0.0020596399255755804, "every 0 0": 0.0020596399255755804, "rational behavior": 0.0017461631439136364, "strategy for": 0.0004230779228348551, "to player 2": 0.0010298199627877902, "histories of length": 0.0010298199627877902, "model of repeated": 0.0010298199627877902, "0 is": 0.00019907679323198093, "e will": 0.0008730815719568182, "as high": 0.0005221368030860054, "h the set": 0.0008732058717250353, "in time": 0.0008041655073878682, "monetary payments formally": 0.0010298199627877902, "above the other": 0.0008321458774498469, "conference on": 0.0003699026289338821, "2 respectively": 0.0004736982533495064, "designer wants": 0.000971904517366954, "to coordinate": 0.0006748149214226754, "people i": 0.000971904517366954, "denote by pv": 0.0010298199627877902, "a correlated equilibrium": 0.0010298199627877902, "success we": 0.0008730815719568182, "quite some time": 0.0009310344469842923, "would like a": 0.0009310344469842923, "case is similar": 0.0008321458774498469, "game moreover as": 0.0010298199627877902, "term adversary to": 0.0010298199627877902, "its own much": 0.0010298199627877902, "by e m": 0.0010298199627877902, "length t is": 0.0009310344469842923, "part of its": 0.0008321458774498469, "a result if": 0.0008321458774498469, "under": -0.00044074871063315175, "following given": 0.0006748149214226754, "outcome associated with": 0.0010298199627877902, "was to": 0.0003956596676276662, "the second action": 0.0020596399255755804, "expected payoff": 0.000971904517366954, "not know": 0.0007969679895517099, "repeated games is": 0.0010298199627877902, "as desired no": 0.0010298199627877902, "special well": 0.000971904517366954, "every": -0.0022217372649262304, "irrational choice that": 0.0010298199627877902, "obtained and the": 0.0009310344469842923, "m dened over": 0.0010298199627877902, "first note that": 0.0005690630947869114, "at least 1": 0.0005119876058604116, "on the notion": 0.0006165622637081906, "that each can": 0.0010298199627877902, "an algorithm": 0.00041796841488010126, "the following instance": 0.0009310344469842923, "constitutes the major": 0.0010298199627877902, "u next": 0.0008730815719568182, "provide interesting": 0.0008730815719568182, "algorithm learns the": 0.0010298199627877902, "actions have been": 0.0020596399255755804, "thus we examine": 0.0010298199627877902, "the possible": 0.0006269164024974145, "h is the": 0.0005159938685900292, "consistent": 9.04146316739315e-05, "guidelines": 0.0004646827409778002, "stochastic game": 0.001943809034733908, "the agents adopt": 0.0010298199627877902, "the criterion for": 0.0007742140246189059, "2 steps": 0.0007160765724402042, "1 u": 0.00047837713542937403, "will use g": 0.0010298199627877902, "dened over the": 0.0017464117434500706, "lesser": 0.0004263780634150286, "are dierent": 0.0006049243473022664, "initially plays cooperate": 0.0010298199627877902, "learning rules": 0.0016304192875693086, "learning equilibrium and": 0.0010298199627877902, "specification": 0.00014906333536586383, "selected": 0.00012661233870547977, "like in the": 0.000663411738084629, "some action": 0.0007160765724402042, "criteria are attractive": 0.0010298199627877902, "shoham": 0.0007159746543399424, "choose an action": 0.0010298199627877902, "and the columns": 0.0007330505281739418, "to assess the": 0.0005578968604992618, "the expected payoff": 0.0010298199627877902, "case of imperfect": 0.0010298199627877902, "state not": 0.0008730815719568182, "with ele": 0.000971904517366954, "consists of the": 0.00040141596032567653, "formally part": 0.000971904517366954, "empty history": 0.000971904517366954, "the next iteration": 0.0006428310760905615, "always play cooperate": 0.0010298199627877902, "ele for": 0.004859522586834771, "the possibility that": 0.0005811431115841947, "play investigated": 0.000971904517366954, "not too concerned": 0.0010298199627877902, "stipulates": 0.0014319493086798849, "maximize u 1": 0.0010298199627877902, "size of the": 0.0005051802806122312, "result 5 pareto": 0.0010298199627877902, "repeatedly this is": 0.0010298199627877902, "do as": 0.00154820763243365, "and punishment can": 0.0010298199627877902, "player game": 0.0008730815719568182, "punishment": 0.0052377438454283935, "many states": 0.000774103816216825, "its payo": 0.003887618069467816, "by repeating the": 0.0008321458774498469, "useful to contrast": 0.0010298199627877902, "is economically": 0.000971904517366954, "some value": 0.0005842412659181877, "games with unique": 0.0010298199627877902, "b by": 0.0004881890232438977, "each iteration": 0.0007121525841250422, "a model of": 0.00047686941115904235, "player 2": 0.013606663243137355, "player 1": 0.014578567760504311, "not bayesian it": 0.0010298199627877902, "of self": 0.000542504923393336, "theorem 2 an": 0.0008732058717250353, "will lead": 0.0015477612525165972, "requirements for the": 0.0007010750178672042, "agent i by": 0.0010298199627877902, "average reward of": 0.005149099813938952, "the folk": 0.0017461631439136364, "would": -0.0021877587452786376, "m and let": 0.0007330505281739418, "each of which": 0.0004093455120016892, "observe the other": 0.0010298199627877902, "for the rst": 0.0006527573289679061, "past but": 0.0008730815719568182, "executed in order": 0.0008732058717250353, "non bayesian approach": 0.0009310344469842923, "it more": 0.000549963838367756, "than 1": 0.00035829109812661935, "we require": 0.0003560762920625211, "defect the": 0.001943809034733908, "times also": 0.0008152096437846543, "we wish": 0.0007121525841250422, "iterations at each": 0.0010298199627877902, "when adopted": 0.000971904517366954, "player i": 0.000971904517366954, "out so far": 0.0009310344469842923, "level probabilistic": 0.000971904517366954, "action selected": 0.000971904517366954, "agent systems": 0.001887049369877551, "size of": 0.0002593576394352413, "th action we": 0.0010298199627877902, "only on the": 0.0004073259353968379, "formally let be": 0.0010298199627877902, "the punishment of": 0.0010298199627877902, "follow normative criteria": 0.0010298199627877902, "will not": 0.0010653516258547697, "that this algorithm": 0.0013498219883241157, "during this": 0.00046915827274082977, "be played making": 0.0010298199627877902, "some desired solution": 0.0010298199627877902, "optimal among all": 0.0010298199627877902, "actually g1": 0.000971904517366954, "7 where": 0.0005842412659181877, "do so by": 0.0007742140246189059, "joint action can": 0.0020596399255755804, "if all the": 0.00048327283506710686, "learning algorithms should": 0.0020596399255755804, "once the exploration": 0.0010298199627877902, "deviates from the": 0.0008732058717250353, "reward only after": 0.0010298199627877902, "learns the": 0.0006578931655429611, "other player whom": 0.0010298199627877902, "actions the entry": 0.0010298199627877902, "guarantee": 0.0005211840974332669, "ai and these": 0.0010298199627877902, "will not play": 0.0009310344469842923, "issue our major": 0.0010298199627877902, "end": -7.172006560225121e-05, "the deviator": 0.000971904517366954, "2 g2 the": 0.0010298199627877902, "than this is": 0.0009310344469842923, "is justied": 0.0006939782666478507, "assumptions a pareto": 0.0010298199627877902, "be considered irrational": 0.0010298199627877902, "description": -1.2322890326095277e-06, "agents have perfect": 0.0010298199627877902, "in average reward": 0.0010298199627877902, "g to": 0.0003901551635480713, "rationality in many": 0.0010298199627877902, "a general": 0.0007733087454253063, "treated as": 0.0007396581653773328, "line with": 0.0011884376569097899, "standard though imperfect": 0.0010298199627877902, "r max": 0.006111571003697728, "parallel to that": 0.0020596399255755804, "be lower than": 0.0008732058717250353, "parallel": -1.2324738330009733e-05, "speed of": 0.0008739510701493671, "settings follow naturally": 0.0010298199627877902, "netherlands vincent": 0.000971904517366954, "shneidman david": 0.000971904517366954, "the proof now": 0.0010298199627877902, "algorithms": -0.0042673247758806925, "contrast our approach": 0.0008002740946718667, "hence a policy": 0.0010298199627877902, "to view its": 0.0010298199627877902, "know the": 0.00032777011999915245, "executed": 0.00022551610680449086, "over": -0.002035861471311523, "g 0 and": 0.0006527573289679061, "exists ele for": 0.0010298199627877902, "diers": 0.0005158469873294001, "dierent for player": 0.0010298199627877902, "all t t": 0.0008732058717250353, "dene u": 0.0008730815719568182, "let be a": 0.0004407143520107783, "approach to": 0.0006635263934969176, "probability of": 0.0010722206765171574, "ele and pareto": 0.0020596399255755804, "objective is": 0.0008395744333511804, "that features": 0.0008152096437846543, "the following assumptions": 0.0006335389089667411, "of nash ele": 0.0010298199627877902, "a two player": 0.0009310344469842923, "dene the value": 0.0010298199627877902, "to an appropriate": 0.0007521645399683924, "basic tools for": 0.0010298199627877902, "concerned with the": 0.0005690630947869114, "near optimal reinforcement": 0.0020596399255755804, "the issue": 0.0007913193352553324, "people who use": 0.0010298199627877902, "not bayesian": 0.000971904517366954, "that point": 0.0009125844283376683, "all t 0": 0.0009310344469842923, "quickly a": 0.0008730815719568182, "is to do": 0.0008732058717250353, "netherlands": 0.0004482110433929256, "where the": 0.00034860039143508857, "all that a": 0.0009310344469842923, "restrict our": 0.0004986788606483227, "for algorithms": 0.0006290164566258502, "of convergence of": 0.000663411738084629, "exists with": 0.0006939782666478507, "m hence we": 0.0009310344469842923, "each": -0.013665087846228245, "equilibrium is extended": 0.0010298199627877902, "fact that here": 0.0010298199627877902, "the expected payo": 0.004119279851151161, "will rapidly lead": 0.0010298199627877902, "return mixing": 0.004859522586834771, "lower average reward": 0.0010298199627877902, "criteria indeed": 0.000971904517366954, "performs k iterations": 0.0010298199627877902, "deviates either": 0.000971904517366954, "will be no": 0.0007521645399683924, "player 2 to": 0.0010298199627877902, "equilibrium or other": 0.0010298199627877902, "and he": 0.0007421847985653504, "actions available to": 0.0020596399255755804, "500 most": 0.000971904517366954, "a parameter that": 0.0007521645399683924, "games tr the": 0.0010298199627877902, "reinforcement learning a": 0.0010298199627877902, "agent can attain": 0.0010298199627877902, "ele in the": 0.003089459888363371, "interest games under": 0.0010298199627877902, "and move to": 0.0009310344469842923, "annual acm symposium": 0.0005475136432016508, "rapidly obtain": 0.0008730815719568182, "is the union": 0.0006087606573971396, "is quite": 0.0003067138737249001, "when this payo": 0.0010298199627877902, "notion of individually": 0.0010298199627877902, "associate": 0.00023582981019343917, "properties for a": 0.0009310344469842923, "theory a reinforcement": 0.0010298199627877902, "does not": 0.00016657147101236723, "on on line": 0.0010298199627877902, "hand": -0.00012442961793775344, "provide interesting examples": 0.0010298199627877902, "we denote": 0.0007214863858110905, "agent if": 0.0008152096437846543, "game being": 0.000971904517366954, "probability of failure": 0.0015484280492378119, "of best": 0.0006049243473022664, "possibility that the": 0.0007521645399683924, "the game moreover": 0.0010298199627877902, "generalization to n": 0.0010298199627877902, "as specied": 0.0007160765724402042, "values that the": 0.0008321458774498469, "mind that": 0.0006578931655429611, "g 11 and": 0.0010298199627877902, "equilibrium reinforcement learning": 0.0010298199627877902, "games which": 0.001943809034733908, "attain on": 0.001943809034733908, "value that": 0.0012692337685045654, "game from": 0.001943809034733908, "restrict": 0.00014587597108980225, "maximize u": 0.001943809034733908, "important line": 0.000971904517366954, "s u s": 0.0008732058717250353, "been proposed": 0.0005228946882082914, "without loss of": 0.00037148284442569784, "and an algorithmic": 0.0010298199627877902, "game as a": 0.0010298199627877902, "truly in": 0.000971904517366954, "is unknown but": 0.0010298199627877902, "equilibrium in average": 0.0010298199627877902, "and imperfect": 0.000774103816216825, "4 imperfect": 0.000971904517366954, "policy prole": 0.013606663243137355, "ele for the": 0.0020596399255755804, "too": -0.00014871363465050822, "payos in g2": 0.0010298199627877902, "spirit of equilibrium": 0.0010298199627877902, "exist then": 0.0007421847985653504, "denoted by p": 0.0006749109941620578, "zero then his": 0.0010298199627877902, "the existence of": 0.001974384907741417, "prole adjusted with": 0.0010298199627877902, "despite the": 0.0008331272286582561, "reward i e": 0.0010298199627877902, "and as quickly": 0.0010298199627877902, "that this": 0.00032546906137234026, "makes no assumptions": 0.0009310344469842923, "people play": 0.000971904517366954, "each agent can": 0.0020596399255755804, "impossible to obtain": 0.0008321458774498469, "the policy": 0.002971094142274475, "captures the": 0.0005099512042140099, "1 if the": 0.0004707237014509277, "we allow": 0.00039848399477585494, "motivation for learning": 0.0010298199627877902, "will learn": 0.000774103816216825, "every t t": 0.0020596399255755804, "improved after": 0.000971904517366954, "steps is": 0.0006049243473022664, "steps it": 0.0006578931655429611, "how his adversary": 0.0010298199627877902, "the side payments": 0.0020596399255755804, "classes": 0.0001916952263227597, "we follow": 0.00045629221416883416, "practical and theoretical": 0.0008321458774498469, "irrational choice": 0.000971904517366954, "t iterations undiscounted": 0.0010298199627877902, "compute the": 0.0009809232390656736, "players payos": 0.000971904517366954, "strategies the bottom": 0.0010298199627877902, "ele much of": 0.0010298199627877902, "are initially unknown": 0.0009310344469842923, "show that it": 0.0005378088736942846, "general non": 0.0006939782666478507, "shall take t": 0.0010298199627877902, "show that in": 0.0005005713348648543, "the repeated game": 0.0010298199627877902, "of this paper": 0.00021972781391269271, "constitutes the": 0.0005661109047770705, "this variable is": 0.0008321458774498469, "show that if": 0.0004899574431705119, "g1 since its": 0.0010298199627877902, "economics for": 0.000971904517366954, "to deviate and": 0.0010298199627877902, "made by": 0.000387471559992312, "respect to": 0.00031486465893767194, "agents will not": 0.0010298199627877902, "approach is": 0.0007216701256900564, "s choice": 0.0007160765724402042, "approach in": 0.001357329840806623, "we generalize": 0.000549963838367756, "itself as a": 0.0007742140246189059, "is to show": 0.0005201099482447018, "game be a": 0.0010298199627877902, "policy the": 0.0006049243473022664, "seem too": 0.0008152096437846543, "though": 1.2324738330009752e-05, "if we relax": 0.0008732058717250353, "there for": 0.0006939782666478507, "in the near": 0.001326823476169258, "histories to": 0.000971904517366954, "h is": 0.00030343449037016455, "underlying game": 0.000971904517366954, "intelligence and related": 0.0010298199627877902, "will eventually": 0.0010084195104002043, "literature on learning": 0.0009310344469842923, "our attention to": 0.0005378088736942846, "repeated multi agent": 0.0010298199627877902, "result theorem": 0.00046915827274082977, "equilibrium we": 0.0008730815719568182, "the sum": 0.00021204184070572162, "treats": 0.0004197274689931713, "theorists adopting": 0.000971904517366954, "too if": 0.000774103816216825, "the dierent": 0.0006164744968379118, "are in some": 0.0008732058717250353, "can observe the": 0.0010298199627877902, "to perform": 0.0002141035440250924, "the players combined": 0.0010298199627877902, "proposed it does": 0.0010298199627877902, "to deviate at": 0.0010298199627877902, "random": 8.44082258036532e-05, "following given large": 0.0010298199627877902, "indeed from the": 0.0008732058717250353, "is instructed": 0.0008730815719568182, "by more": 0.00046915827274082977, "to sets of": 0.0007161785195604264, "details what": 0.000971904517366954, "july": 0.0002753324523010835, "from now on": 0.00053318373443515, "practical and": 0.0006748149214226754, "both imperfect monitoring": 0.0010298199627877902, "game to be": 0.0010298199627877902, "what the": 0.0008461558456697102, "for nding a": 0.0010298199627877902, "of the repeated": 0.0010298199627877902, "is the criterion": 0.0010298199627877902, "special classes": 0.000774103816216825, "literature on": 0.0011497952046580816, "that after": 0.0008597459103893571, "nitely many states": 0.0009310344469842923, "step policy in": 0.0010298199627877902, "ele in stochastic": 0.0010298199627877902, "denote by": 0.0006669089831542823, "appropriate solution": 0.0008730815719568182, "irrational if it": 0.0010298199627877902, "learning algorithms provided": 0.0010298199627877902, "not know the": 0.0006087606573971396, "will treat": 0.0008152096437846543, "despite": 0.0006299068518942726, "irrational r rational": 0.0010298199627877902, "a be": 0.00036053561152535736, "work on single": 0.0010298199627877902, "a lower reward": 0.0010298199627877902, "a bi": 0.0007421847985653504, "threat that will": 0.0010298199627877902, "borrow from": 0.0008152096437846543, "that is its": 0.0009310344469842923, "c parkes specification": 0.0010298199627877902, "i e when": 0.0005875760798754402, "and decreased reward": 0.0010298199627877902, "specification faithfulness in": 0.0010298199627877902, "though denitely": 0.000971904517366954, "not devoid": 0.000971904517366954, "rst obtained": 0.0008730815719568182, "ramications we now": 0.0010298199627877902, "the following theorem": 0.0003747324723261107, "appears in": 0.0003240812532709715, "payo p i": 0.0010298199627877902, "at each state": 0.0008321458774498469, "when the game": 0.0010298199627877902, "games the": 0.002619244715870455, "the assumption that": 0.0003763816768240042, "policy determines": 0.0008730815719568182, "normalize both players": 0.0010298199627877902, "possible payos": 0.001943809034733908, "of the game": 0.002496437632349541, "imperfect monitoring in": 0.0010298199627877902, "where is the": 0.0004934134257972276, "of actions and": 0.0007330505281739418, "to is": 0.000557817444576059, "bound on": 0.0002694041520782948, "the fourth": 0.0004134042818545908, "approach": -0.006746744831224497, "agents stick": 0.001943809034733908, "for each possible": 0.0006335389089667411, "the e cient": 0.0015043290799367848, "by p now": 0.0010298199627877902, "however": -0.0012591824069795139, "who use": 0.0007421847985653504, "showing the": 0.00043697553507468355, "is we take": 0.0010298199627877902, "1 this": 0.000252554184414257, "the sets": 0.0003169286451286095, "improve": 3.843255582309425e-05, "2 m trials": 0.0010298199627877902, "stochastic games provide": 0.0020596399255755804, "participating": 0.0004263780634150286, "players": 0.013560692737112816, "also when": 0.0005748976023290408, "games": 0.026865982228700857, "learning equilibrium ele": 0.003089459888363371, "we say": 0.00024166982485121404, "prove rely on": 0.0010298199627877902, "what the suggested": 0.0010298199627877902, "this interval": 0.0006748149214226754, "response upon": 0.000971904517366954, "get the": 0.00032046858343152956, "its payos in": 0.0020596399255755804, "a deeper": 0.0007160765724402042, "policy prole adjusted": 0.0010298199627877902, "history notice": 0.000971904517366954, "st john": 0.0007421847985653504, "k 4": 0.000542504923393336, "response against stationary": 0.0010298199627877902, "values if employed": 0.0010298199627877902, "and then": 8.906845548247869e-05, "algorithm for": 0.0007019874665572554, "agent setting i": 0.0010298199627877902, "behavior will": 0.0007421847985653504, "conference": 3.4546216055868926e-05, "o line in": 0.0010298199627877902, "1 2": 0.0002672053664474361, "actions selected and": 0.0010298199627877902, "been": -0.003193590895495648, "quickly": 0.0010769694433525913, "idea is to": 0.0004093455120016892, "proceedings of the": 0.0006507398356440607, "expected": 0.00011096148800129792, "in that case": 0.00047686941115904235, "specification faithfulness": 0.000971904517366954, "a short period": 0.0007742140246189059, "requirement that the": 0.0006874022974519222, "use this idea": 0.0008732058717250353, "the details": 0.0003151849303416359, "of iterations at": 0.0010298199627877902, "question and": 0.000774103816216825, "should rapidly": 0.000971904517366954, "but also": 0.0005554069149310296, "games b introduction": 0.0010298199627877902, "act compute": 0.000971904517366954, "economic models based": 0.0010298199627877902, "they do": 0.00029704876608852796, "lesser interest if": 0.0010298199627877902, "be considered": 0.00024166982485121404, "earlier it is": 0.0008321458774498469, "lead to an": 0.0006428310760905615, "1 s": 0.0006786649204033114, "nash ele": 0.002915713552100862, "value may be": 0.0008002740946718667, "in the economically": 0.0010298199627877902, "n": -0.0036983205297065167, "monitoring recall": 0.000971904517366954, "and learning is": 0.0010298199627877902, "1 m": 0.0003901551635480713, "or zero": 0.000774103816216825, "procedure": -3.696867097828583e-06, "is that this": 0.000624803884002311, "equilibrium in addition": 0.0010298199627877902, "the concepts introduced": 0.0010298199627877902, "now follows": 0.0005842412659181877, "the following state": 0.0009310344469842923, "player i in": 0.0010298199627877902, "identical to that": 0.0006527573289679061, "value 1": 0.000464748887987192, "some outcome": 0.000971904517366954, "stationary policy": 0.001943809034733908, "in g 0": 0.0007330505281739418, "question is": 0.00039288397722888555, "a given set": 0.0005286976176970826, "is denoted by": 0.000405331588255818, "play algorithms": 0.000971904517366954, "about minimizing": 0.000971904517366954, "suggest": 0.00017771041848258512, "1 resp": 0.002081934799943552, "complex": -1.7273108027934456e-05, "deviations should quickly": 0.0010298199627877902, "polynomial in 1": 0.0008321458774498469, "denition of rationality": 0.0010298199627877902, "principles of": 0.00036511734625786996, "science here": 0.000971904517366954, "but many readers": 0.0010298199627877902, "said earlier": 0.0008730815719568182, "cooperate the": 0.001943809034733908, "agent is": 0.0006578931655429611, "may not notice": 0.0010298199627877902, "details what we": 0.0010298199627877902, "previous sections": 0.00042987295519467854, "the matrix correspond": 0.0010298199627877902, "follow the": 0.0003698290826886664, "we restrict our": 0.0005943034268074654, "value t": 0.0006049243473022664, "the following let": 0.0006874022974519222, "contrast our": 0.000542504923393336, "agent in": 0.0013157863310859221, "t t and": 0.002322642073856718, "in economics": 0.002915713552100862, "that maximizes": 0.0017527237977545634, "diers considerably": 0.000971904517366954, "that guarantee": 0.0006748149214226754, "of random": 0.0008027176385274169, "since our impossibility": 0.0010298199627877902, "exists an ele": 0.0010298199627877902, "strategy equilibrium": 0.000971904517366954, "equilibrium ele if": 0.0010298199627877902, "that of repeated": 0.0010298199627877902, "maximal average": 0.001943809034733908, "a common interest": 0.0010298199627877902, "polynomial in t": 0.0018620688939685846, "other solution": 0.0008152096437846543, "obstacle we": 0.0008730815719568182, "proposed": -0.000254817480339662, "the payo for": 0.0010298199627877902, "themselves can": 0.0008152096437846543, "games multiagent reinforcement": 0.0010298199627877902, "is described numerically": 0.0010298199627877902, "dened": 0.0011018717765828793, "pareto ele where": 0.0020596399255755804, "look at the": 0.00048327283506710686, "denes": 0.000390099633351153, "we normalize both": 0.0010298199627877902, "punishing without": 0.000971904517366954, "is 1": 0.00026671552906703795, "is 2": 0.0003956596676276662, "every repeated game": 0.0020596399255755804, "revealed game": 0.000971904517366954, "become irrational i": 0.0010298199627877902, "ele": 0.03020295099260322, "acm symposium": 0.00034133740538055095, "cooperative settings moreover": 0.0010298199627877902, "a 0": 0.0008503349074315202, "implementations r max": 0.0010298199627877902, "a shared": 0.0004482748456766825, "more specically": 0.0006427395698875594, "recent results on": 0.0008321458774498469, "also able": 0.0006939782666478507, "they run": 0.0017461631439136364, "the game a": 0.0010298199627877902, "the game g": 0.003089459888363371, "is a": 1.9719431158695015e-05, "machine learning and": 0.0016005481893437334, "at state the": 0.0010298199627877902, "u s and": 0.0008002740946718667, "player s policies": 0.0010298199627877902, "is p": 0.0004482748456766825, "time 13": 0.0008730815719568182, "algorithm if": 0.000549963838367756, "a i": 0.0005177308783751344, "and common interest": 0.0010298199627877902, "algorithm in": 0.0005126337077391306, "a a": 0.0005385613743057158, "they are obtained": 0.0008732058717250353, "a b": 0.0007778281736308609, "algorithm is": 0.001061087869609325, "assume that": 0.0001500413693056146, "let policy prole": 0.0010298199627877902, "adversary as using": 0.0010298199627877902, "with the ai": 0.0010298199627877902, "a t": 0.0006826748107611019, "basic tools": 0.000971904517366954, "other payos in": 0.0010298199627877902, "special attention": 0.0006578931655429611, "the joint": 0.0014800295670319118, "then each player": 0.0010298199627877902, "results to": 0.0013415663259342778, "however while in": 0.0010298199627877902, "rst which they": 0.0010298199627877902, "reward associated with": 0.0010298199627877902, "own thus": 0.000971904517366954, "will converge at": 0.0010298199627877902, "second action leading": 0.0010298199627877902, "matrix this is": 0.0010298199627877902, "this is called": 0.0006428310760905615, "may be known": 0.0008732058717250353, "this context": 0.000896549691353365, "solution concept": 0.001943809034733908, "to the requirement": 0.0007010750178672042, "algorithms satisfying the": 0.0010298199627877902, "conceptual contribution": 0.000971904517366954, "algorithmic": 0.0005639059120030127, "are based": 0.0007843420323124373, "of its action": 0.0010298199627877902, "can attain": 0.0008152096437846543, "tuple of learning": 0.0010298199627877902, "the rewards obtained": 0.0010298199627877902, "the xed sum": 0.0020596399255755804, "reward of": 0.004859522586834771, "to that player": 0.0020596399255755804, "clarke groves": 0.000971904517366954, "termed quasi": 0.000971904517366954, "least 1 this": 0.0010298199627877902, "of player 1": 0.0010298199627877902, "is not improved": 0.0009310344469842923, "of the players": 0.004119279851151161, "in line with": 0.0015043290799367848, "g repeatedly we": 0.0010298199627877902, "instance of the": 0.00044833866612737684, "update the reward": 0.0010298199627877902, "probability of choosing": 0.0007521645399683924, "ensure": 0.00012004714744661106, "and game": 0.0017461631439136364, "the others stick": 0.0010298199627877902, "with uncertainty second": 0.0010298199627877902, "are 1 the": 0.0007521645399683924, "learning equilibrium existence": 0.0010298199627877902, "obtaining": 0.00015390983237028235, "systems machine learning": 0.0010298199627877902, "and m to": 0.0010298199627877902, "cient if that": 0.0010298199627877902, "all employ the": 0.0010298199627877902, "be our benchmark": 0.0010298199627877902, "pre determined": 0.0013157863310859221, "in this paper": 0.00027514996914723786, "rely": 0.00018310191087925984, "u 1 m": 0.0010298199627877902, "impossibility result for": 0.0010298199627877902, "the policy ideally": 0.0010298199627877902, "a parameter": 0.0007543176731416702, "168 may 2007": 0.0010298199627877902, "adjusted with appropriate": 0.0010298199627877902, "algorithms will become": 0.0010298199627877902, "approach in their": 0.0009310344469842923, "u 1 u": 0.0007521645399683924, "repeated game rg": 0.0010298199627877902, "observe its action": 0.0010298199627877902, "unknown game": 0.000971904517366954, "dierent agents": 0.000971904517366954, "several economically e": 0.0010298199627877902, "algorithms regardless": 0.0008730815719568182, "line with the": 0.0016005481893437334, "payo it gets": 0.0010298199627877902, "to r max": 0.0020596399255755804, "each player s": 0.0010298199627877902, "rewards let": 0.000971904517366954, "but as": 0.00046915827274082977, "it observed": 0.000971904517366954, "a polynomial number": 0.002256493619905177, "simplifying": 0.00028195295600150634, "turn out": 0.0005354021517001512, "be the case": 0.0004865784002866409, "its payo alone": 0.0010298199627877902, "assumed repeat": 0.000971904517366954, "cient joint action": 0.0010298199627877902, "relevant games": 0.000971904517366954, "rby player 1": 0.0010298199627877902, "of stochastic": 0.0012580329132517005, "no": -0.0043482174126960186, "of steps does": 0.0010298199627877902, "against stationary": 0.000971904517366954, "when": -0.005426002694391829, "of g 0": 0.0007161785195604264, "policy formally assume": 0.0010298199627877902, "setting": 0.0007603522199289135, "formalize": 0.00032403512727420655, "an incentive": 0.0008152096437846543, "it obtained and": 0.0010298199627877902, "nv": 0.0007159746543399424, "this paper": 6.668785655029858e-05, "most work in": 0.0009310344469842923, "get that after": 0.0010298199627877902, "with uncertainty": 0.000774103816216825, "value he would": 0.0010298199627877902, "s payo": 0.004859522586834771, "algorithm this": 0.0004832040417809763, "point on they": 0.0010298199627877902, "to improve": 0.0002588654391875672, "previous sections dealt": 0.0010298199627877902, "rewards will be": 0.0010298199627877902, "longer": 7.699336254170508e-05, "policy prole for": 0.0010298199627877902, "we do it": 0.0010298199627877902, "our approach with": 0.0007330505281739418, "repeated multi": 0.000971904517366954, "the above a": 0.0010298199627877902, "we need": 0.0006980991124638621, "others": 5.361317158527199e-05, "parameters this policy": 0.0010298199627877902, "not be presented": 0.0008732058717250353, "pareto ele provide": 0.0010298199627877902, "it as in": 0.0010298199627877902, "able to extend": 0.0008732058717250353, "rob": 0.0005941342541838367, "the minimal": 0.0003393324602016557, "more specically we": 0.0008002740946718667, "is contrary": 0.0008730815719568182, "leads": 0.0001137467619226978, "by in a": 0.0010298199627877902, "behind the": 0.0003956596676276662, "we dene the": 0.0005378088736942846, "to react": 0.0007160765724402042, "row": 0.0004234710474167637, "understanding of": 0.0003771588365708351, "for removing": 0.0007421847985653504, "the judgment of": 0.0010298199627877902, "to view": 0.0005042097552001021, "s newfoundland canada": 0.0008002740946718667, "quasi": 0.0003746258021091093, "as the adversary": 0.0008321458774498469, "steps it will": 0.0010298199627877902, "1 plays his": 0.0010298199627877902, "algorithms should": 0.0013879565332957013, "with the common": 0.0008321458774498469, "are not too": 0.0007742140246189059, "several nash equilibria": 0.0010298199627877902, "dierent approach": 0.000774103816216825, "than the value": 0.0006749109941620578, "issues both ele": 0.0010298199627877902, "payments structure as": 0.0010298199627877902, "6 under the": 0.0008321458774498469, "prole which": 0.000971904517366954, "their algorithms will": 0.0010298199627877902, "in machine learning": 0.002619617615175106, "most work": 0.0014321531448804085, "in response to": 0.0005425821592878966, "above properties": 0.0006939782666478507, "level": -0.00013497439305704126, "the equilibrium": 0.0006748149214226754, "determines the payos": 0.0010298199627877902, "no information": 0.0005748976023290408, "a common property": 0.0010298199627877902, "be performed": 0.000260152159704593, "quick": 0.0003650653796557838, "1 we have": 0.0004591252002600493, "exist then we": 0.0010298199627877902, "satisfy the desired": 0.0010298199627877902, "we said": 0.0007160765724402042, "outcome is": 0.0008730815719568182, "cases the": 0.0002440388335391651, "game matrix to": 0.0010298199627877902, "by removal": 0.000971904517366954, "initially the": 0.0005099512042140099, "lead to some": 0.0008321458774498469, "improve robustness": 0.0008730815719568182, "e cient i": 0.0010298199627877902, "if that is": 0.0016642917548996938, "for learning in": 0.0016005481893437334, "to contrast our": 0.0009310344469842923, "since they": 0.0003517324423933467, "near future not": 0.0009310344469842923, "are required": 0.0003296442778898719, "or longer the": 0.0010298199627877902, "prole suitably modied": 0.0010298199627877902, "and agent 2": 0.0010298199627877902, "should an": 0.0008730815719568182, "ele and": 0.001943809034733908, "as a framework": 0.0007742140246189059, "to learning in": 0.0037241377879371693, "required to attain": 0.0010298199627877902, "work bowling and": 0.0010298199627877902, "approximated by e": 0.0010298199627877902, "due to": 6.715482486134023e-05, "happens after": 0.0008730815719568182, "this is easy": 0.0007161785195604264, "payo obtained so": 0.0010298199627877902, "follows first": 0.00045223161134026404, "1 deviates": 0.001943809034733908, "a technique": 0.00036053561152535736, "the induced": 0.000557817444576059, "game with": 0.0007421847985653504, "agent s ability": 0.0018620688939685846, "in self play": 0.0020596399255755804, "the rst": 0.0012607397213665436, "of strict imperfect": 0.0020596399255755804, "what happens": 0.0005286223582497236, "equal to the": 0.0006270056559715741, "vorobeychik michael p": 0.0010298199627877902, "identical payos": 0.000971904517366954, "equated quick": 0.000971904517366954, "able to do": 0.0007742140246189059, "close to the": 0.0011706321286696472, "of the action": 0.0014661010563478836, "learning in stochastic": 0.0010298199627877902, "terms of our": 0.0008321458774498469, "players is identical": 0.0010298199627877902, "played is initially": 0.0010298199627877902, "we known the": 0.0010298199627877902, "a survey": 0.0003496018060391435, "there is no": 0.0002080036883991781, "to believe": 0.0005748976023290408, "polynomial in": 0.002408152915582251, "plays row": 0.001943809034733908, "from the": 4.3139287537834656e-05, "to that context": 0.0010298199627877902, "it should be": 0.000360586940627226, "have learning": 0.000971904517366954, "to stochastic": 0.000774103816216825, "criteria": 0.000560284538414248, "all we had": 0.0010298199627877902, "where all the": 0.0006087606573971396, "time algorithm for": 0.000624803884002311, "and we were": 0.0010298199627877902, "follows given an": 0.0008002740946718667, "b is": 0.0006548549489492576, "theory and": 0.0003050667212128553, "attained": 0.0008811777991812431, "b if": 0.00039288397722888555, "players is indeed": 0.0010298199627877902, "t mix as": 0.0010298199627877902, "to the judgment": 0.0010298199627877902, "cases": -0.0006484609723679882, "b in": 0.00033539158148356945, "thus no agent": 0.0010298199627877902, "convergence after": 0.0008730815719568182, "technically speaking the": 0.0010298199627877902, "that is close": 0.0007161785195604264, "compute the values": 0.0007742140246189059, "is associated": 0.0003393324602016557, "players always receive": 0.0010298199627877902, "compute and": 0.0005942188284548949, "following constructive": 0.000971904517366954, "remains a threat": 0.0010298199627877902, "prescribed by": 0.0008730815719568182, "increased reward": 0.000971904517366954, "all other": 0.00025505472871573733, "prisoner s": 0.0008730815719568182, "rewards are based": 0.0020596399255755804, "and telling each": 0.0010298199627877902, "dened as over": 0.0010298199627877902, "with the goals": 0.0010298199627877902, "unknown e": 0.000971904517366954, "performed": -0.00016851161059092603, "started with": 0.0006290164566258502, "its policy in": 0.0010298199627877902, "iterations is not": 0.0010298199627877902, "ai and": 0.002322311448650475, "in ai we": 0.0010298199627877902, "requirements": 0.00014870095250983967, "and behave": 0.000971904517366954, "osprings thus in": 0.0010298199627877902, "payos in this": 0.0010298199627877902, "1": -0.04190195076342715, "fourth": 0.00022686218700514307, "algorithm with": 0.00034336616306129136, "to the": 1.787065076127813e-05, "innite number of": 0.0008002740946718667, "to the values": 0.0006087606573971396, "on equilibria concepts": 0.0010298199627877902, "paramount": 0.0006747188760310696, "irrational": 0.00785661576814259, "input r": 0.000774103816216825, "used in": 5.938838318472795e-05, "needs": -1.2322890326095277e-06, "deviating player": 0.000971904517366954, "contribution of this": 0.0005633746356361924, "2 will be": 0.0006874022974519222, "s newfoundland": 0.0007421847985653504, "is that learning": 0.0009310344469842923, "bound on them": 0.0010298199627877902, "as an": 9.590449746659696e-05, "reinforcement learning has": 0.0010298199627877902, "of possible payos": 0.0010298199627877902, "efficient learning": 0.0013496298428453508, "and telling": 0.000971904517366954, "formalize the": 0.0005099512042140099, "4 we": 0.00018956914887471784, "to each": 0.0001498868734990341, "payments for": 0.000971904517366954, "an e cient": 0.0024662490548327622, "done had we": 0.0010298199627877902, "extend our": 0.0005042097552001021, "theorem in repeated": 0.0010298199627877902, "learning algorithms themselves": 0.004119279851151161, "dealt with ele": 0.0010298199627877902, "g the": 0.00022689448055489468, "monitoring we were": 0.0010298199627877902, "own we use": 0.0010298199627877902, "ensures the": 0.0005942188284548949, "action set": 0.0008152096437846543, "mainly": 0.00016385653603096098, "possible payos our": 0.0010298199627877902, "19 23": 0.000549963838367756, "entry in row": 0.0009310344469842923, "some previously unplayed": 0.0010298199627877902, "an equilibrium": 0.0014843695971307007, "far in": 0.0006578931655429611, "not only": 0.00022254718490145105, "let be": 0.0008288847832376075, "a non": 0.00015556563472617218, "research in": 0.0013001519307003942, "payo from that": 0.0010298199627877902, "equilibrium equals": 0.000971904517366954, "deviate from that": 0.0010298199627877902, "for a given": 0.0002689917338826838, "most and similarly": 0.0020596399255755804, "knows only its": 0.0010298199627877902, "case one of": 0.0010298199627877902, "lack of": 0.00032591593593977075, "descriptive models": 0.000971904517366954, "our major": 0.000774103816216825, "agent or": 0.000971904517366954, "be close to": 0.0006428310760905615, "learning rule": 0.0016304192875693086, "used in case": 0.0008002740946718667, "games and common": 0.0010298199627877902, "steps is required": 0.0009310344469842923, "as strategies in": 0.0010298199627877902, "players follow the": 0.0010298199627877902, "execute": 0.0001621739657256426, "rational 2 the": 0.0010298199627877902, "4 we refer": 0.0010298199627877902, "they known": 0.001943809034733908, "best response": 0.004859522586834771, "monitoring is required": 0.0010298199627877902, "corresponding rg": 0.001943809034733908, "not depend": 0.00037223626733611355, "individually": 0.0009721053818226195, "as part": 0.000774943119984624, "the game matrix": 0.003089459888363371, "section uses the": 0.0010298199627877902, "rule is justied": 0.0010298199627877902, "to an economically": 0.0010298199627877902, "context of two": 0.0009310344469842923, "clear that no": 0.0010298199627877902, "games is more": 0.0010298199627877902, "approximated": 0.0005254274666946572, "science here no": 0.0010298199627877902, "own thus should": 0.0010298199627877902, "an innite": 0.000557817444576059, "there may be": 0.00044833866612737684, "desired learning algorithm": 0.0010298199627877902, "a b is": 0.0016425409296049525, "assumption the": 0.0005042097552001021, "attracted": 0.0005941342541838367, "out e ciently": 0.0010298199627877902, "a b in": 0.0007010750178672042, "as a game": 0.0010298199627877902, "prole will be": 0.0010298199627877902, "existence of ele": 0.0010298199627877902, "reward criterion": 0.000971904517366954, "the folk theorem": 0.0009310344469842923, "ignores the": 0.0005842412659181877, "theory": -0.0003477160826088038, "cooperative settings": 0.000971904517366954, "also allows": 0.0004736982533495064, "for each of": 0.00034754716063214585, "that for": 0.00038361798986638786, "to lead to": 0.0006749109941620578, "the strategy": 0.0004881890232438977, "and view the": 0.0010298199627877902, "which are": 9.042750208413418e-05, "of utility": 0.0008152096437846543, "its policy": 0.000971904517366954, "e ciency is": 0.0007742140246189059, "turn": 3.843255582309425e-05, "time the": 0.00036444250935222455, "agent reinforcement": 0.003492326287827273, "except in": 0.0006049243473022664, "plays this best": 0.0010298199627877902, "in self": 0.00154820763243365, "and a deviation": 0.0010298199627877902, "their practical": 0.0007421847985653504, "it is what": 0.0010298199627877902, "both players payos": 0.0010298199627877902, "that have": 0.00019907679323198093, "response value": 0.000971904517366954, "have been": 0.0002949901406398596, "york yevgeniy": 0.000971904517366954, "set of possible": 0.002600549741223509, "of possible histories": 0.005149099813938952, "given": -0.006135118563850692, "reward in": 0.000971904517366954, "the agents player": 0.0010298199627877902, "that an ele": 0.0020596399255755804, "replaced by": 0.0005177308783751344, "e ciently a": 0.0010298199627877902, "its agent as": 0.0010298199627877902, "ergodic u": 0.000971904517366954, "values one": 0.0006748149214226754, "empty history namely": 0.0010298199627877902, "is used": 8.501452792615033e-05, "we know that": 0.0003814312093656469, "the above consider": 0.0010298199627877902, "reward is": 0.0008730815719568182, "the above properties": 0.0007742140246189059, "deviate and": 0.000971904517366954, "addition we associate": 0.0010298199627877902, "is the maximal": 0.0006874022974519222, "we could": 0.000272130787801713, "the payos obtained": 0.0020596399255755804, "also need to": 0.0005578968604992618, "all employ": 0.0008730815719568182, "ciently we do": 0.0010298199627877902, "desired properties": 0.0013496298428453508, "known to": 0.00028786948439001953, "upon conver": 0.000971904517366954, "identical the": 0.0006427395698875594, "values each": 0.0006748149214226754, "the corresponding": 0.0004487374189303699, "trivial rests": 0.000971904517366954, "return mixing time": 0.005149099813938952, "require": -0.00019454102780186466, "r": 0, "pair of": 0.00019144089307331267, "outcome": 0.0010060315371144643, "and": 0, "the perfect monitoring": 0.003089459888363371, "in that equilibrium": 0.0020596399255755804, "is dened": 0.00036281071874830087, "the action set": 0.0009310344469842923, "how people play": 0.0010298199627877902, "equilibrium a policy": 0.0010298199627877902, "generalization": 0.00024589930444110806, "ease of": 0.0004832040417809763, "is no general": 0.0009310344469842923, "g2 increasing": 0.000971904517366954, "equilibrium of g1": 0.0010298199627877902, "equilibrium of g2": 0.0010298199627877902, "any": -0.005209939158494607, "on them the": 0.0008732058717250353, "its agent": 0.002915713552100862, "as much as": 0.0004677409380222729, "despite their": 0.0006427395698875594, "have been able": 0.0013055146579358122, "9 most of": 0.0010298199627877902, "h the": 0.0004264387578012798, "policies for": 0.0005221368030860054, "for the xed": 0.0010298199627877902, "multiple": -6.779667630156865e-05, "behavior we": 0.0005842412659181877, "his j th": 0.0010298199627877902, "term agent": 0.0008730815719568182, "agents designed by": 0.0010298199627877902, "algorithmic mechanism design": 0.0010298199627877902, "performance of": 0.00017245432551458553, "let us try": 0.0009310344469842923, "games provide a": 0.0020596399255755804, "rests on": 0.0007160765724402042, "adopt": 0.0012259938782672242, "select an action": 0.0010298199627877902, "prescribed strategies and": 0.0010298199627877902, "certain amount": 0.0005842412659181877, "example the following": 0.0006165622637081906, "include the": 0.0003002135720884527, "following games 1": 0.0010298199627877902, "by resorting to": 0.0008732058717250353, "equals the": 0.00045629221416883416, "and in the": 0.0003576004752760881, "high enough value": 0.0010298199627877902, "an extension to": 0.0005811431115841947, "note here": 0.0006427395698875594, "in reality": 0.0005042097552001021, "mixed strategies the": 0.0010298199627877902, "incentive to deviate": 0.0009310344469842923, "any point if": 0.0010298199627877902, "dealing with": 0.0006786649204033114, "time using redundancy": 0.0010298199627877902, "ele if for": 0.0010298199627877902, "1 is": 0.0001070719874938275, "a desired": 0.001099927676735512, "previous work": 0.00033539158148356945, "1 in": 0.0001342290361503653, "of social surplus": 0.0010298199627877902, "time convergence": 0.0008730815719568182, "its agent to": 0.0010298199627877902, "players play the": 0.0020596399255755804, "games and view": 0.0010298199627877902, "to remain": 0.0005286223582497236, "both criteria are": 0.0010298199627877902, "a natural": 0.0008122879116285782, "players would": 0.0008730815719568182, "criterion and an": 0.0009310344469842923, "from the game": 0.0010298199627877902, "reward associated": 0.000971904517366954, "identical the extension": 0.0010298199627877902, "game another": 0.000971904517366954, "learning articial": 0.000971904517366954, "in g2 resp": 0.0020596399255755804, "all agents stick": 0.0010298199627877902, "with a new": 0.0006165622637081906, "general multiagent learning": 0.0010298199627877902, "the desired properties": 0.0016005481893437334, "the behavior of": 0.0003517825181966487, "in which we": 0.0005042815390490772, "ignores": 0.000390099633351153, "action fassumed": 0.000971904517366954, "case we attempt": 0.0010298199627877902, "also show that": 0.0010085630780981543, "actions the": 0.0005748976023290408, "every game matrix": 0.0010298199627877902, "game consider the": 0.0009310344469842923, "following two adversary": 0.0010298199627877902, "suit however researches": 0.0010298199627877902, "is not an": 0.0004800375137323266, "because we need": 0.0008732058717250353, "to be considered": 0.0004707237014509277, "value after": 0.000774103816216825, "so we": 0.00022254718490145105, "existence of": 0.0014858674225810694, "but an": 0.0005842412659181877, "predicting how people": 0.0010298199627877902, "combination of the": 0.0009354818760445458, "much of the": 0.00053318373443515, "these are": 0.000520304319409186, "the above it": 0.0009310344469842923, "this average": 0.0007421847985653504, "self play and": 0.0010298199627877902, "that we are": 0.000435831200377543, "the above in": 0.0010298199627877902, "nash equilibrium in": 0.0010298199627877902, "agent that makes": 0.0009310344469842923, "of money to": 0.0010298199627877902, "15 12": 0.0006939782666478507, "as a result": 0.0009039712698378539, "information is": 0.0003002135720884527, "behavior the punishment": 0.0010298199627877902, "learning strategy leads": 0.0010298199627877902, "go beyond": 0.0006748149214226754, "adversary deviates either": 0.0010298199627877902, "agent knows": 0.000971904517366954, "attention is given": 0.0009310344469842923, "games the class": 0.0010298199627877902, "a payment to": 0.0010298199627877902, "foe q learning": 0.0010298199627877902, "for most": 0.0003560762920625211, "approach most previous": 0.0010298199627877902, "when adopted by": 0.0010298199627877902, "then there": 0.0002694041520782948, "1 denoted cooperate": 0.0020596399255755804, "captures the insight": 0.0010298199627877902, "equilibrium another": 0.000971904517366954, "67": 0.0008372484198428646, "knowledge of": 0.000633857290257219, "normalize both": 0.000971904517366954, "ciently": 0.0016408190589589783, "however researches in": 0.0010298199627877902, "each of whom": 0.0010298199627877902, "performs k": 0.000971904517366954, "these issues both": 0.0010298199627877902, "which the": 0.0002980873777871277, "be using": 0.0006939782666478507, "which an": 0.0013448245370300477, "that game": 0.000971904517366954, "equilibrium existence the": 0.0010298199627877902, "500": 0.0005360340344814285, "international joint": 0.0013496298428453508, "agent 2": 0.001943809034733908, "cognitive psychology experimental": 0.0010298199627877902, "these results are": 0.0006013538961527255, "requirement then": 0.0008730815719568182, "associated with a": 0.0012280365360050674, "0 we shall": 0.0008321458774498469, "spirit": 0.0013897929156163919, "0 of": 0.00035389034454809447, "case": -0.017027860062099387, "s policies": 0.0008730815719568182, "algorithmic framework for": 0.0010298199627877902, "thus in": 0.0003517324423933467, "game parameters": 0.000971904517366954, "the requirement that": 0.0005749794499375729, "r in addition": 0.0009310344469842923, "optimal average": 0.000971904517366954, "payo matrix moreover": 0.0010298199627877902, "the insight of": 0.0010298199627877902, "rational and": 0.000774103816216825, "play to": 0.000971904517366954, "or with incomplete": 0.0010298199627877902, "histories h is": 0.0010298199627877902, "g after": 0.0008152096437846543, "care about its": 0.0010298199627877902, "p i agent": 0.0010298199627877902, "associated with s": 0.0008732058717250353, "a policy determines": 0.0010298199627877902, "q learning in": 0.0009310344469842923, "of social": 0.0008152096437846543, "all agents of": 0.0010298199627877902, "too 2": 0.0008152096437846543, "associate a": 0.0004986788606483227, "future the": 0.0006290164566258502, "algorithm is close": 0.0010298199627877902, "the choice": 0.0004952891408603564, "algorithm described in": 0.0005475136432016508, "this is the": 0.0005361866637623172, "player cannot observe": 0.0010298199627877902, "after polynomially": 0.0008730815719568182, "we cannot provide": 0.0008321458774498469, "however to": 0.00047837713542937403, "well known prisoner": 0.0010298199627877902, "devoid": 0.0007739936391863359, "k 4 log": 0.0010298199627877902, "this learning": 0.0016304192875693086, "first the bayesian": 0.0010298199627877902, "above in order": 0.0009310344469842923, "its aim": 0.001943809034733908, "algorithm is pareto": 0.0010298199627877902, "minimize": 0.00040034180976127504, "prole that": 0.002915713552100862, "presented in": 0.00013575999445130304, "perspective we present": 0.0010298199627877902, "the results we": 0.000663411738084629, "more details what": 0.0010298199627877902, "g after playing": 0.0010298199627877902, "without": -0.0005469396863196594, "constant r": 0.0008730815719568182, "e ciently we": 0.0010298199627877902, "model": -0.0012844384259404562, "reward": 0.010921499782361049, "and let a": 0.000624803884002311, "researchers": 0.00039231345029526655, "in addition": 0.0005097075065811999, "1 we": 0.0002870556402232876, "we were interested": 0.0008321458774498469, "s i": 0.0007961552293507005, "captures": 0.00026801701724071423, "let a": 0.0006101334424257105, "actions": 0.004365078296203183, "i is instructed": 0.0010298199627877902, "state and potentially": 0.0010298199627877902, "of its strategy": 0.0009310344469842923, "assumptions made by": 0.0009310344469842923, "using them": 0.0006578931655429611, "let p": 0.0003002135720884527, "that denes": 0.0007421847985653504, "it would take": 0.0008321458774498469, "let t": 0.00034133740538055095, "we play": 0.000971904517366954, "0 1 there": 0.0008321458774498469, "the third international": 0.0007330505281739418, "policy as a": 0.0010298199627877902, "theorists adopting the": 0.0010298199627877902, "except": 1.4790702798380575e-05, "the value assumed": 0.0010298199627877902, "13 6": 0.0006427395698875594, "if its payos": 0.0010298199627877902, "rational learning": 0.000971904517366954, "thus after": 0.0006748149214226754, "of an": 0.00029547084423311537, "both imperfect": 0.000971904517366954, "be associated with": 0.0005811431115841947, "if player 1": 0.003089459888363371, "algorithm should": 0.0011884376569097899, "more general": 0.000485701831443146, "would take an": 0.0009310344469842923, "cases e 2": 0.0010298199627877902, "in the": 0.0, "learning for": 0.000557817444576059, "the adversary as": 0.0009310344469842923, "solution by": 0.0005661109047770705, "policies that": 0.0012098486946045329, "of such": 0.00016642364028409505, "do as follows": 0.0010298199627877902, "actual game played": 0.0010298199627877902, "agents of the": 0.0008732058717250353, "irreducible i": 0.000971904517366954, "order to use": 0.000624803884002311, "can show the": 0.0008321458774498469, "if for every": 0.0015995512033054502, "attained e": 0.000971904517366954, "major issues one": 0.0010298199627877902, "be close": 0.000542504923393336, "r in": 0.0003454193697900408, "the agent visited": 0.0010298199627877902, "p 145 168": 0.0010298199627877902, "out to": 0.0006669089831542823, "b is the": 0.0005159938685900292, "2 as models": 0.0010298199627877902, "e for": 0.0003393324602016557, "learning rule leads": 0.0010298199627877902, "treat the": 0.0009567542708587481, "a polynomial": 0.0014512428749932035, "e cient therefore": 0.0010298199627877902, "the payo it": 0.0020596399255755804, "themselves are not": 0.0007742140246189059, "agents stick to": 0.0020596399255755804, "provides": -9.177748410036118e-05, "and learning": 0.000542504923393336, "state is associated": 0.0008321458774498469, "game might": 0.000971904517366954, "wellman satinder singh": 0.0010298199627877902, "quickly the details": 0.0010298199627877902, "obtain a": 0.0004220360630027711, "assume that an": 0.0006874022974519222, "1 can not": 0.0010298199627877902, "its previous": 0.0006748149214226754, "which is approximately": 0.0008321458774498469, "from to 0": 0.0018620688939685846, "structure as": 0.0004736982533495064, "according to the": 0.0004986067303698616, "concerned with descriptive": 0.0010298199627877902, "then each": 0.0004933431890106373, "one of the": 0.0003057387278434914, "the perfect": 0.0024196973892090658, "time next to": 0.0010298199627877902, "on": 0, "nash ele but": 0.0010298199627877902, "of": 0, "based": -0.0028934180985197133, "discussed": -4.725607610261224e-05, "it to": 0.0002214738315017785, "adversary deviates": 0.001943809034733908, "by that": 0.00046915827274082977, "and that": 0.00011710764879029859, "a set of": 0.0003266820615948049, "should e": 0.000971904517366954, "or": -0.006983658460571192, "from the prescribed": 0.0010298199627877902, "greater than 1": 0.0005690630947869114, "prescribed learning algorithms": 0.0010298199627877902, "the expected average": 0.0010298199627877902, "actions that have": 0.0010298199627877902, "defect if the": 0.0010298199627877902, "2 e ciency": 0.0010298199627877902, "the agent knows": 0.0010298199627877902, "determine": -7.303374517714963e-05, "which both": 0.0005286223582497236, "thus in ai": 0.0010298199627877902, "that have been": 0.00042425064540523185, "of the adversary": 0.0021485355586812792, "strictly": 0.0001886117812523639, "there": -0.009446064264434974, "ele is an": 0.0010298199627877902, "strict": 0.0007284490533492956, "theorem which is": 0.0009310344469842923, "time we": 0.0003100542232769594, "deviates the": 0.000971904517366954, "we require that": 0.0005243422169685006, "equated": 0.0007159746543399424, "typically used": 0.0005748976023290408, "in designing": 0.0005159204175055324, "to what": 0.00046915827274082977, "work in machine": 0.0020596399255755804, "possible history": 0.000971904517366954, "sequence of mixed": 0.0020596399255755804, "here no": 0.0008730815719568182, "cases e": 0.0008152096437846543, "sum of rewards": 0.005149099813938952, "agent 1 s": 0.0010298199627877902, "to 6 9": 0.0010298199627877902, "t mix": 0.005831427104201724, "sense justied the": 0.0010298199627877902, "designed similarly": 0.000971904517366954, "a combination of": 0.0004509656222210493, "that it is": 0.0005085078501950955, "as high as": 0.0006335389089667411, "maximin values that": 0.0010298199627877902, "now on": 0.000464748887987192, "can be replaced": 0.0005690630947869114, "irrational i e": 0.0010298199627877902, "case of cooperative": 0.0010298199627877902, "updating their": 0.000971904517366954, "in games with": 0.0009310344469842923, "other agents stick": 0.0010298199627877902, "class of": 0.0010717591845545668, "player 2 notice": 0.0010298199627877902, "we normalize": 0.0006578931655429611, "policy we dene": 0.0010298199627877902, "can be carried": 0.0005811431115841947, "every t": 0.001099927676735512, "that there": 0.00043395874849645364, "every s": 0.0007160765724402042, "higher values for": 0.0008732058717250353, "but many": 0.000774103816216825, "accomplish on": 0.001943809034733908, "perfect monitoring case": 0.0010298199627877902, "to the corresponding": 0.00048327283506710686, "settings follow": 0.000971904517366954, "the agents have": 0.0008732058717250353, "in t 0": 0.0008321458774498469, "these results cannot": 0.0010298199627877902, "that within": 0.0006427395698875594, "descriptive purposes a": 0.0010298199627877902, "be known the": 0.0009310344469842923, "matrix g": 0.0014843695971307007, "to extend our": 0.000624803884002311, "we discuss the": 0.0004334456773524235, "matrix m": 0.0005221368030860054, "deviation": 0.0018761191206849996, "iteration the": 0.0005042097552001021, "are obtained by": 0.0004865784002866409, "initially do": 0.000971904517366954, "mix as well": 0.0010298199627877902, "following iterations if": 0.0010298199627877902, "every 0": 0.0013157863310859221, "he does": 0.0007160765724402042, "making it more": 0.0009310344469842923, "immediately rules out": 0.0010298199627877902, "two adversary policies": 0.0010298199627877902, "xed policy prole": 0.0010298199627877902, "is replaced by": 0.00042203345812732713, "the repeated": 0.0006427395698875594, "procedure leading to": 0.0010298199627877902, "discounting or with": 0.0010298199627877902, "response to the": 0.0006428310760905615, "purposes a normative": 0.0010298199627877902, "past but does": 0.0010298199627877902, "result the desired": 0.0010298199627877902, "are much": 0.0004197872166755902, "observations and": 0.0006427395698875594, "all": -0.01745914615142798, "game will": 0.000971904517366954, "time update": 0.000971904517366954, "agent will punish": 0.0010298199627877902, "lack": 0.00019235481873811978, "a standard": 0.0003134582012487072, "the desired learning": 0.0010298199627877902, "the return mixing": 0.004119279851151161, "players may": 0.0008730815719568182, "generalize": 0.00019235481873811978, "denition for player": 0.0020596399255755804, "follow": 0.00031859708963018657, "6 a game": 0.0010298199627877902, "is the empty": 0.0006749109941620578, "the other for": 0.0006527573289679061, "if that": 0.0010442736061720109, "the values each": 0.0010298199627877902, "can be obtained": 0.00030239751985769166, "all agents": 0.004453108791392102, "as strategies": 0.000971904517366954, "removal": 0.00032772346897154083, "importance to": 0.0005942188284548949, "any rationality requirement": 0.0010298199627877902, "corresponds to some": 0.0007742140246189059, "approximated by by": 0.0009310344469842923, "stochastic": 0.005982220325137007, "any strategy prole": 0.0010298199627877902, "then u": 0.0005748976023290408, "2 a": 0.00016052442754307283, "for imperfect monitoring": 0.0010298199627877902, "rapidly lead": 0.000971904517366954, "2 e": 0.00041656361432912804, "observed and": 0.000774103816216825, "far": -2.5885833397282175e-05, "total payo is": 0.0010298199627877902, "2 m": 0.00041656361432912804, "more constrained setting": 0.0010298199627877902, "taken a dierent": 0.0010298199627877902, "2 p": 0.0004967192070344544, "2 s": 0.0009833103599974575, "2 t": 0.0004072679530572796, "monitoring setting below": 0.0010298199627877902, "another appealing alternative": 0.0010298199627877902, "6 while the": 0.0008321458774498469, "has taken": 0.0006578931655429611, "present in this": 0.0006874022974519222, "more re": 0.000971904517366954, "would play algorithms": 0.0010298199627877902, "the history": 0.0016498915151032679, "over the": 0.0004889176478505444, "researchers have": 0.00044065161687170207, "bayes nash equilibrium": 0.0010298199627877902, "additional notation and": 0.0009310344469842923, "pareto optimal the": 0.0010298199627877902, "order to cover": 0.0009310344469842923, "attain at": 0.000971904517366954, "yevgeniy": 0.0007739936391863359, "sum game first": 0.0010298199627877902, "a mapping": 0.0003771588365708351, "in computer": 0.0007857679544577711, "games is said": 0.0010298199627877902, "rate": 0.000180829263347863, "design": -0.00014606749035429926, "game is otherwise": 0.0010298199627877902, "resp player": 0.000971904517366954, "conceptually the required": 0.0010298199627877902, "recommending behavior that": 0.0010298199627877902, "impossible to": 0.00037467912962542367, "what": -0.000661608568006508, "to choose": 0.0003117480856515576, "systems that": 0.0004230779228348551, "take in a": 0.0010298199627877902, "sum": 0.00038069645810958285, "in games started": 0.0010298199627877902, "available to": 0.0007696631738123888, "converge to if": 0.0010298199627877902, "to their long": 0.0010298199627877902, "ramications we": 0.000971904517366954, "multi agent interaction": 0.0020596399255755804, "expected average reward": 0.0010298199627877902, "would be similar": 0.0008732058717250353, "incomplete information and": 0.0009310344469842923, "time and": 0.00018771162611315464, "on a combination": 0.0008002740946718667, "setting the player": 0.0010298199627877902, "stage based": 0.0008730815719568182, "for a deviation": 0.0010298199627877902, "game played is": 0.0010298199627877902, "steps of": 0.0007077806890961889, "is similar to": 0.0003002563132006521, "markov games as": 0.0009310344469842923, "a more": 0.0005037354547808249, "by bowling": 0.000971904517366954, "can dene": 0.0005942188284548949, "devise an": 0.0008730815719568182, "always play": 0.003887618069467816, "ergodic u s": 0.0010298199627877902, "a mapping from": 0.0005749794499375729, "valuable but many": 0.0010298199627877902, "allows": -9.04146316739315e-05, "of an ele": 0.004119279851151161, "all agents use": 0.0020596399255755804, "state s": 0.0004986788606483227, "the imperfect monitoring": 0.003089459888363371, "of common": 0.0005099512042140099, "research in ai": 0.0020596399255755804, "namely the history": 0.0010298199627877902, "easy to see": 0.0007303386553136493, "of the times": 0.0015043290799367848, "its other payos": 0.0010298199627877902, "p and": 0.00021828498298308586, "of time": 0.0002440388335391651, "converge at": 0.0008730815719568182, "by one that": 0.0009310344469842923, "following the": 0.00029704876608852796, "notice a": 0.0008152096437846543, "it for": 0.00040135881926370846, "games a policy": 0.0010298199627877902, "game will eventually": 0.0010298199627877902, "knows": 0.0011394705381213347, "nash equilibrium or": 0.0010298199627877902, "2007 guido boella": 0.0010298199627877902, "23 43 may": 0.0010298199627877902, "justied the assumption": 0.0010298199627877902, "nash equilibrium of": 0.004119279851151161, "stick": 0.0020241566280932086, "known": -0.00214073070990076, "each particular": 0.000774103816216825, "mechanisms proceedings of": 0.0009310344469842923, "will punish": 0.000971904517366954, "this phase each": 0.0010298199627877902, "own we": 0.0008730815719568182, "equilibrium of learning": 0.0010298199627877902, "2 from now": 0.0010298199627877902, "played given": 0.000971904517366954, "because a": 0.00038223374562649956, "its return": 0.0008152096437846543, "aim is": 0.0009973577212966454, "with the general": 0.0007161785195604264, "matrix contains": 0.000971904517366954, "no agent has": 0.0020596399255755804, "ele conceptually the": 0.0010298199627877902, "steps of the": 0.0005243422169685006, "challenging": 0.00028486763453033367, "ele a": 0.001943809034733908, "and covergent": 0.000971904517366954, "action to perform": 0.0010298199627877902, "all agents that": 0.0010298199627877902, "an rg": 0.001943809034733908, "with rational nodes": 0.0010298199627877902, "goal": 6.909243211173785e-05, "time t 0": 0.0007742140246189059, "maximizes the average": 0.0010298199627877902, "value in g2": 0.0010298199627877902, "the policies and": 0.0009310344469842923, "e cient now": 0.0010298199627877902, "not obtain high": 0.0010298199627877902, "common knowledge the": 0.0010298199627877902, "0 0 1": 0.0011622862231683894, "long as the": 0.0004155626519889734, "in average": 0.0005942188284548949, "existence results": 0.000971904517366954, "social surplus": 0.001943809034733908, "and look": 0.0007160765724402042, "addition for every": 0.0009310344469842923, "require that": 0.00032777011999915245, "equilibrium behavior if": 0.0010298199627877902, "discuss the extension": 0.0020596399255755804, "short": 9.589084752388895e-05, "paper a non": 0.0010298199627877902, "adversary policies 1": 0.0010298199627877902, "denote the payo": 0.0010298199627877902, "is trivial": 0.00042987295519467854, "be used to": 0.00019557454141700323, "each can accomplish": 0.0010298199627877902, "major conceptual contribution": 0.0010298199627877902, "the algorithm described": 0.0005749794499375729, "action we take": 0.0010298199627877902, "general polynomial time": 0.0009310344469842923, "that makes": 0.0004832040417809763, "e punishment can": 0.0010298199627877902, "it it is": 0.0006874022974519222, "attention of researchers": 0.0010298199627877902, "coordinate e ciently": 0.0010298199627877902, "where the objective": 0.0008732058717250353, "choice that leads": 0.0010298199627877902, "moreover one": 0.0007421847985653504, "with unique strategy": 0.0010298199627877902, "to face": 0.0006578931655429611, "expected payoff in": 0.0010298199627877902, "behave according": 0.002322311448650475, "mechanism implementations r": 0.0010298199627877902, "player s average": 0.0010298199627877902, "ele does": 0.003887618069467816, "might": -1.972438954494502e-05, "outcome associated": 0.000971904517366954, "return": 0.00045888742050180585, "action we": 0.0013157863310859221, "of a two": 0.0006335389089667411, "the adversary quickly": 0.0010298199627877902, "sizes is": 0.0007160765724402042, "undiscounted average": 0.000971904517366954, "in order": 0.0003834450277989209, "framework": 7.39387276321988e-06, "does require": 0.0008730815719568182, "speaking the": 0.0005354021517001512, "should manifest in": 0.0010298199627877902, "reader there for": 0.0010298199627877902, "by by repeating": 0.0010298199627877902, "of the following": 0.0003002563132006521, "action with": 0.0007421847985653504, "irreducible": 0.000493272972217439, "xed sequence of": 0.0010298199627877902, "pretend that": 0.000971904517366954, "of this": 0.00011347983244106675, "s j when": 0.0008732058717250353, "xed sequence": 0.0008730815719568182, "series of random": 0.0009310344469842923, "identical for": 0.0006578931655429611, "moreover convergence": 0.000971904517366954, "of work": 0.0004264387578012798, "a resp b": 0.0010298199627877902, "game theory a": 0.0010298199627877902, "with perfect": 0.0020244447642680263, "goal is": 0.0008331103723965445, "in all following": 0.0010298199627877902, "the possible payos": 0.0010298199627877902, "they will also": 0.0008732058717250353, "monitoring setup all": 0.0010298199627877902, "reward of this": 0.0020596399255755804, "agent i in": 0.0020596399255755804, "we do": 0.00029021008313564957, "games exists": 0.000971904517366954, "a result of": 0.0004073259353968379, "a best response": 0.0020596399255755804, "pareto ele is": 0.0020596399255755804, "induced": 0.00018310191087925984, "desired solution": 0.0008730815719568182, "satinder": 0.000872957307571399, "quite simple and": 0.0008321458774498469, "large enough k": 0.0008732058717250353, "determined sequence": 0.000971904517366954, "game theory 8": 0.0010298199627877902, "exploration phase is": 0.0010298199627877902, "theory 8 is": 0.0010298199627877902, "have learning algorithms": 0.0010298199627877902, "of choosing each": 0.0010298199627877902, "make the simplifying": 0.0009310344469842923, "understand the": 0.00038223374562649956, "can online as": 0.0010298199627877902, "yevgeniy vorobeychik michael": 0.0010298199627877902, "can show": 0.0004197872166755902, "iterations undiscounted": 0.000971904517366954, "they do so": 0.0009310344469842923, "stages b if": 0.0010298199627877902, "r max 3": 0.0010298199627877902, "times now that": 0.0010298199627877902, "threat": 0.0005577380512591538, "behave according to": 0.002496437632349541, "can guarantee itself": 0.0010298199627877902, "repeated game m": 0.003089459888363371, "claim is": 0.0005842412659181877, "in polynomial time": 0.0004969500605540478, "an ele exists": 0.003089459888363371, "implementations r": 0.000971904517366954, "2 has": 0.000444416512295841, "number of actions": 0.0009310344469842923, "satisfy any": 0.000971904517366954, "concrete algorithm with": 0.0010298199627877902, "obtained by the": 0.0010011426697297085, "indeed from": 0.0008152096437846543, "least": -0.0005942418567844704, "setting the": 0.0007969679895517099, "bowling and": 0.002915713552100862, "in line": 0.0009866863780212745, "ele hold": 0.000971904517366954, "the players": 0.010063349610818725, "stochastic games technically": 0.0010298199627877902, "enable the": 0.0004881890232438977, "leading": 0.0005714283270424978, "economic models": 0.000774103816216825, "games first": 0.000971904517366954, "veloso consider": 0.000971904517366954, "to get": 0.0002313315344026334, "time of a": 0.0005159938685900292, "the agents": 0.013838362045768706, "involved the": 0.0005748976023290408, "extension of our": 0.0007521645399683924, "the criterion": 0.000549963838367756, "imperfect": 0.007578093321446702, "which game is": 0.0010298199627877902, "determines the": 0.0006786649204033114, "6 while": 0.0006578931655429611, "cient policy for": 0.0010298199627877902, "with every": 0.0004933431890106373, "of convergence": 0.0025497560210700496, "resp g1 since": 0.0010298199627877902, "t the": 0.000242850915721573, "b is economically": 0.0010298199627877902, "other assumptions made": 0.0010298199627877902, "contradicting ele": 0.000971904517366954, "then with respect": 0.0010298199627877902, "that will not": 0.0007742140246189059, "assume some xed": 0.0010298199627877902, "maximin values for": 0.0010298199627877902, "is a learning": 0.0018620688939685846, "g2 resp g1": 0.0020596399255755804, "k such that": 0.0010085630780981543, "model of partial": 0.0010298199627877902, "in order to": 0.0009466875554725916, "a function": 0.00028391737919083906, "motivation": 0.0008814974212663035, "polynomial number of": 0.002199151584521826, "payments will be": 0.0010298199627877902, "is instructed to": 0.0009310344469842923, "of deviators": 0.000971904517366954, "order to see": 0.0006874022974519222, "a repeated": 0.0029687391942614014, "thuc vu": 0.000971904517366954, "van der torre": 0.0009310344469842923, "possibility that": 0.0004933431890106373, "can be performed": 0.0004176903288490751, "0 in iteration": 0.0020596399255755804, "long as": 0.00025008444186787576, "o line": 0.0007160765724402042, "our rst": 0.0005748976023290408, "of strictly dominated": 0.0010298199627877902, "thus there may": 0.0010298199627877902, "learning to": 0.0005942188284548949, "a pre": 0.0004333839769001314, "computer science and": 0.001249607768004622, "that e cient": 0.0010298199627877902, "a strategy": 0.0005159204175055324, "now that": 0.0008145359061145592, "a value which": 0.0008002740946718667, "agent systems predicting": 0.0010298199627877902, "performs the sequence": 0.0020596399255755804, "were interested": 0.0007421847985653504, "games ts": 0.000971904517366954, "games tr": 0.0008730815719568182, "we have no": 0.0006087606573971396, "moreover we have": 0.0007330505281739418, "then we": 0.00015638609091360992, "of this theorem": 0.0006165622637081906, "reach": 0.00017069299103522766, "adopt the": 0.0009567542708587481, "react": 0.00044058889959062156, "76": 0.00030017084314280963, "case since the": 0.0007010750178672042, "the best it": 0.0009310344469842923, "probabilistic": 0.001551868023151106, "repeatedly we can": 0.0010298199627877902, "issues both": 0.000971904517366954, "the the": 0.0009403746037461217, "the best payo": 0.0010298199627877902, "reward this": 0.000971904517366954, "repeated game with": 0.0010298199627877902, "undiscounted average reward": 0.0010298199627877902, "that after o": 0.0009310344469842923, "that after k": 0.0009310344469842923, "are the": 6.780632707399592e-05, "corresponding rg m": 0.0020596399255755804, "performed e ciently": 0.0009310344469842923, "when this": 0.0004264387578012798, "2 s the": 0.0007742140246189059, "fassumed": 0.000872957307571399, "online as": 0.000971904517366954, "to contrast": 0.0008730815719568182, "iterations undiscounted average": 0.0010298199627877902, "will eventually lead": 0.0008732058717250353, "adversary would play": 0.0010298199627877902, "behavior we are": 0.0009310344469842923, "algorithms themselves should": 0.0020596399255755804, "its goal was": 0.0010298199627877902, "1 when the": 0.0013748045949038444, "to pay a": 0.0008732058717250353, "i e in": 0.0005243422169685006, "paper a": 0.0005042097552001021, "his": 0.000592733506216271, "and results provide": 0.0010298199627877902, "thus should an": 0.0010298199627877902, "go about": 0.000971904517366954, "denoted cooperate too": 0.0010298199627877902, "criterion as": 0.0007421847985653504, "will learn a": 0.0010298199627877902, "23 2004": 0.0006939782666478507, "p wellman satinder": 0.0010298199627877902, "this policy prole": 0.0010298199627877902, "both agents i": 0.0010298199627877902, "is indeed": 0.00041030656060455343, "then is that": 0.0010298199627877902, "respect to the": 0.00027080118542097386, "vincent": 0.0005424277094845126, "both cases": 0.0003771588365708351, "exists 1 the": 0.0010298199627877902, "the above side": 0.0010298199627877902, "a bi matrix": 0.0010298199627877902, "intelligence": 0.00022686218700514307, "they should": 0.0010199024084280198, "a basic action": 0.0009310344469842923, "note that if": 0.00041984698137044723, "sequence of actions": 0.0014661010563478836, "are": 0, "learning algorithms the": 0.0010298199627877902, "common interest stochastic": 0.0010298199627877902, "unknown below we": 0.0010298199627877902, "that would": 0.00033539158148356945, "learns": 0.0008266908852913467, "distinctive": 0.0005577380512591538, "setting is": 0.0005842412659181877, "may be classes": 0.0010298199627877902, "not only determines": 0.0009310344469842923, "action do as": 0.0010298199627877902, "but there are": 0.0006749109941620578, "reward is p": 0.0010298199627877902, "manner this": 0.0007421847985653504, "setting if": 0.000774103816216825, "to perform from": 0.0010298199627877902, "equilibrium notice that": 0.0010298199627877902, "an exponential number": 0.0014021500357344085, "initially": 0.0009647092988417288, "undiscounted": 0.000872957307571399, "is known to": 0.0004737656933058489, "jeffrey shneidman distributed": 0.0010298199627877902, "choose r": 0.0008152096437846543, "a b denote": 0.0009310344469842923, "o k 2": 0.0007521645399683924, "o k 4": 0.0009310344469842923, "c": -0.0017928441735717024, "paradigms": 0.0004646827409778002, "desired value the": 0.0010298199627877902, "1 during": 0.0007160765724402042, "desired values": 0.0008152096437846543, "rg the": 0.0008730815719568182, "context": -0.0002470748728376279, "value against": 0.0008730815719568182, "stipulates that": 0.0017461631439136364, "examples of ele": 0.0010298199627877902, "game from a": 0.0010298199627877902, "more ambitious": 0.000774103816216825, "important ramications we": 0.0010298199627877902, "more challenging": 0.0005942188284548949, "as well thus": 0.0008002740946718667, "individual rationality": 0.001943809034733908, "as the": 2.2185468814172872e-05, "though imperfect": 0.000971904517366954, "extension of": 0.0005151740955990187, "game that is": 0.0009310344469842923, "obstacle we face": 0.0010298199627877902, "that leads to": 0.0013748045949038444, "interesting examples": 0.000774103816216825, "is a function": 0.0007732836694749772, "settings what": 0.000971904517366954, "optimal among": 0.0008730815719568182, "pv": 0.0006747188760310696, "will not obtain": 0.0010298199627877902, "in multi agent": 0.002322642073856718, "cooperative interactions it": 0.0010298199627877902, "by pv i": 0.0010298199627877902, "due": -0.00017417811437832562, "strategy": 0.0006478582908318415, "whom": 0.0015856413606764766, "ciently a model": 0.0010298199627877902, "game theoretic approach": 0.0010298199627877902, "we cannot": 0.00030181687348044, "chooses some action": 0.0010298199627877902, "obtain high": 0.000774103816216825, "the common approach": 0.0008321458774498469, "some sense": 0.0005286223582497236, "game itself": 0.000971904517366954, "will all employ": 0.0010298199627877902, "the agent replaces": 0.0010298199627877902, "only its": 0.000774103816216825, "pair of actions": 0.0009310344469842923, "joint action do": 0.0010298199627877902, "trying to": 0.00037467912962542367, "most work on": 0.0008732058717250353, "time polynomial": 0.0012329489936758237, "initially knowing": 0.000971904517366954, "cient i": 0.0008152096437846543, "the agents will": 0.004119279851151161, "in t mix": 0.0010298199627877902, "2 plays": 0.0016304192875693086, "polynomially many stages": 0.0010298199627877902, "of exposition": 0.0006748149214226754, "is at least": 0.0003576004752760881, "as prescribed": 0.0008730815719568182, "8 2 the": 0.0009310344469842923, "is common knowledge": 0.0010298199627877902, "associates a payo": 0.0010298199627877902, "requirements are equivalent": 0.0009310344469842923, "policies that mix": 0.0010298199627877902, "deviators in games": 0.0010298199627877902, "obstacle": 0.00040720998722279956, "games thus we": 0.0010298199627877902, "our concepts and": 0.0010298199627877902, "well dened case": 0.0010298199627877902, "deviate from": 0.002864306289760817, "simply guess": 0.000971904517366954, "distributed mechanism implementations": 0.0010298199627877902, "criterion for": 0.0004933431890106373, "after the": 0.0003144178367497819, "so su": 0.000971904517366954, "equilibria because the": 0.0010298199627877902, "ele becomes": 0.000971904517366954, "can online": 0.000971904517366954, "game m and": 0.0010298199627877902, "9": -0.0019325410723093418, "proof of this": 0.0004865784002866409, "higher": -6.910159632532036e-05, "literature": 0.00043389698380125066, "and imperfect monitoring": 0.0010298199627877902, "side payment structure": 0.0010298199627877902, "question and the": 0.0009310344469842923, "induced markov chain": 0.0010298199627877902, "given game g": 0.0010298199627877902, "telling each": 0.000971904517366954, "consider games with": 0.0010298199627877902, "learning strategy": 0.0008730815719568182, "min s u": 0.0010298199627877902, "lower": -0.000592733506216271, "the t step": 0.0010298199627877902, "is described": 0.0002748967592131235, "the above": 0.0010549494721325667, "given class of": 0.0008002740946718667, "that of strict": 0.0009310344469842923, "natural question is": 0.0007330505281739418, "theorem 4 there": 0.0007521645399683924, "payos by": 0.000971904517366954, "should go": 0.0008152096437846543, "needs to": 0.00021828498298308586, "attention to the": 0.0005749794499375729, "with s": 0.00045629221416883416, "make the": 0.0002257994300382844, "classes of repeated": 0.0010298199627877902, "but an agent": 0.0008732058717250353, "with m": 0.0008206131212091069, "with k": 0.000888833024591682, "restrict our attention": 0.0006013538961527255, "rule leads to": 0.0010298199627877902, "associate a boolean": 0.0010298199627877902, "that the probability": 0.0010573952353941651, "their requirements are": 0.0009310344469842923, "with a": 4.4378424709504023e-05, "to be rational": 0.0009310344469842923, "ele in this": 0.0010298199627877902, "also technically": 0.0008730815719568182, "c can be": 0.000552614435925888, "theorem": -0.00029742726930101645, "will go about": 0.0010298199627877902, "that the actual": 0.0006749109941620578, "may be a": 0.0004934134257972276, "algorithms must arrive": 0.0010298199627877902, "noncooperative": 0.000872957307571399, "uses repeated": 0.000971904517366954, "entities and instead": 0.0010298199627877902, "above captures the": 0.0010298199627877902, "i e a": 0.0010468415851846466, "plays cooperate the": 0.0010298199627877902, "standard though": 0.000971904517366954, "requirement that": 0.0004881890232438977, "of values": 0.0003240812532709715, "the bayesian approach": 0.0008002740946718667, "to player 1": 0.0010298199627877902, "a correlated": 0.000971904517366954, "l then": 0.0009567542708587481, "show that an": 0.0007521645399683924, "non cooperative interactions": 0.0010298199627877902, "has taken a": 0.0009310344469842923, "that simple": 0.0007160765724402042, "that uses this": 0.0009310344469842923, "behavior the": 0.0005159204175055324, "themselves should be": 0.0020596399255755804, "policies and": 0.0006290164566258502, "function is termed": 0.0010298199627877902, "for k": 0.0003698290826886664, "we use": 0.00014214893056083226, "for a": 2.1569643768917328e-05, "approximation parameters and": 0.0010298199627877902, "reason to believe": 0.0007521645399683924, "section we develop": 0.0007330505281739418, "are natural": 0.0006748149214226754, "for t": 0.0007593532260731544, "of distributed": 0.0007696631738123888, "equilibrium we also": 0.0010298199627877902, "11 and in": 0.0009310344469842923, "to as": 0.0005361103382585787, "utility is assumed": 0.0010298199627877902, "a pre determined": 0.0008002740946718667, "themselves should": 0.001943809034733908, "to an": 0.0005964687081668377, "designing articial": 0.000971904517366954, "of content i": 0.0010298199627877902, "imagine for": 0.000971904517366954, "action in g": 0.0009310344469842923, "have an": 0.0003169286451286095, "exists in particular": 0.0009310344469842923, "looking for": 0.00047837713542937403, "we generalize our": 0.0008732058717250353, "g2 increasing its": 0.0010298199627877902, "e cient": 0.010360583864172228, "itself as": 0.0006290164566258502, "uses in fact": 0.0010298199627877902, "game more specically": 0.0010298199627877902, "systems p 261": 0.0010298199627877902, "only its action": 0.0010298199627877902, "discussion in": 0.00045223161134026404, "termed quasi linear": 0.0010298199627877902, "game to": 0.000971904517366954, "has not been": 0.00043109594775796693, "there are": 7.311415795208085e-05, "deeper notion": 0.000971904517366954, "systems distributed algorithmic": 0.0010298199627877902, "under strict imperfect": 0.0010298199627877902, "the columns correspond": 0.0009310344469842923, "for near optimal": 0.0010298199627877902, "stationary opponents": 0.000971904517366954, "minimizing the adversary": 0.0010298199627877902, "will always": 0.001777666049183364, "them the algorithm": 0.0010298199627877902, "will enable the": 0.0008321458774498469, "on single agent": 0.0010298199627877902, "for some": 0.0001588617838263315, "algorithms of the": 0.0007010750178672042, "1 we require": 0.0008321458774498469, "model of": 0.0006149105135483224, "strategies moreover we": 0.0010298199627877902, "and if player": 0.0010298199627877902, "motivation to deviate": 0.0010298199627877902, "specied is": 0.000971904517366954, "identical for player": 0.0010298199627877902, "it more re": 0.0010298199627877902, "reward stochastic games": 0.0010298199627877902, "3 e cient": 0.0009310344469842923, "i e punishment": 0.0010298199627877902, "playing each iteration": 0.0010298199627877902, "rows": 0.00023129860933368912, "10 the basic": 0.0010298199627877902, "question": 0.0001916952263227597, "long": -0.0001002730961047827, "payo from 9": 0.0010298199627877902, "tuomas sandholm awesome": 0.0010298199627877902, "approach used": 0.0006164744968379118, "sections": 6.684873073652178e-05, "fact that it": 0.0005943034268074654, "the player can": 0.0010298199627877902, "line algorithms in": 0.0010298199627877902, "all designed similarly": 0.0010298199627877902, "repeatedly": 0.0004762652725505423, "this idea in": 0.0009310344469842923, "for any perfect": 0.0020596399255755804, "given large enough": 0.0010298199627877902, "respectively the denition": 0.0010298199627877902, "to the desired": 0.0006527573289679061, "the adversary deviates": 0.0020596399255755804, "ective of": 0.000971904517366954, "an algorithmic framework": 0.0010298199627877902, "games which is": 0.0010298199627877902, "is that there": 0.0005633746356361924, "3 there": 0.0004736982533495064, "agent interactions": 0.0008152096437846543, "our setting": 0.0006748149214226754, "the entry": 0.0014074748182224893, "called": -0.0007074894305803176, "other player s": 0.0018620688939685846, "be unknown": 0.0007160765724402042, "associated": -0.0005389535377919358, "for the implications": 0.0010298199627877902, "in a multi": 0.0006165622637081906, "associates": 0.0008266908852913467, "obtained so": 0.000774103816216825, "of content": 0.0006939782666478507, "response to": 0.0004230779228348551, "learning equilibrium": 0.010690949691036494, "if adopted by": 0.0020596399255755804, "as a fundamental": 0.0008321458774498469, "rewards as desired": 0.0010298199627877902, "it does": 0.0005914343469906948, "exponentially far": 0.000971904517366954, "the end to": 0.0006749109941620578, "play as if": 0.0010298199627877902, "the design": 0.00022040572533156756, "that there exists": 0.0008575617980144327, "play defect if": 0.0010298199627877902, "on they": 0.000971904517366954, "when all": 0.00034133740538055095, "be similar": 0.0005748976023290408, "and of a": 0.0007010750178672042, "progressively higher": 0.000971904517366954, "single agent reinforcement": 0.0010298199627877902, "a and player": 0.0010298199627877902, "is in the": 0.000326578295499111, "by the fact": 0.0004591252002600493, "research in game": 0.0010298199627877902, "behavior with": 0.0006164744968379118, "on them": 0.0005099512042140099, "nash": 0.013931885505354045, "next state the": 0.0008321458774498469, "once": -0.00010564430466761943, "information and is": 0.0009310344469842923, "in case": 0.0002805523466765939, "random play": 0.001943809034733908, "be associated": 0.0004986788606483227, "the reward": 0.000971904517366954, "prole where": 0.000971904517366954, "on they run": 0.0010298199627877902, "s action if": 0.0010298199627877902, "issues": 0.00021732255163050236, "agents player 1": 0.0010298199627877902, "only determines": 0.0008730815719568182, "theorem 1": 0.0002640636595678254, "theorem 3": 0.0002640636595678254, "theorem 2": 0.00026805516912928936, "theorem 5": 0.00032046858343152956, "theorem 4": 0.00028638295103369663, "it is": 3.882535878405118e-05, "theorem 6": 0.00040135881926370846, "by dierent designers": 0.0010298199627877902, "theory diers": 0.000971904517366954, "in many settings": 0.0009310344469842923, "details are": 0.0004933431890106373, "we will not": 0.0005633746356361924, "game is unknown": 0.0010298199627877902, "complex and less": 0.0010298199627877902, "the ones they": 0.0010298199627877902, "algorithms must": 0.0006939782666478507, "will become": 0.00043697553507468355, "adversary would": 0.000774103816216825, "the matrix": 0.0003373507152868544, "it for the": 0.0006874022974519222, "monitoring settings follow": 0.0010298199627877902, "as long as": 0.0003290641512902361, "be the set": 0.00037148284442569784, "2 log k": 0.0010298199627877902, "monitoring in": 0.000774103816216825, "of convergence is": 0.0008002740946718667, "2 denoted defect": 0.0020596399255755804, "in mind": 0.00042987295519467854, "first to": 0.0004933431890106373, "rows of the": 0.000663411738084629, "maximal average reward": 0.0020596399255755804, "dealt": 0.0003746258021091093, "not devoid of": 0.0010298199627877902, "monitoring is": 0.000774103816216825, "model m": 0.0005842412659181877, "specically we adopt": 0.0010298199627877902, "combined choices some": 0.0010298199627877902, "and initially has": 0.0010298199627877902, "ele a normative": 0.0010298199627877902, "now we can": 0.0006013538961527255, "obtain maximal social": 0.0010298199627877902, "work on": 0.0021020090425603764, "6 much": 0.0008730815719568182, "they are all": 0.000624803884002311, "folk": 0.0030959745567453434, "concepts that": 0.0006939782666478507, "reduce the average": 0.0008002740946718667, "by agent": 0.002619244715870455, "policy i": 0.000971904517366954, "rst action leading": 0.0010298199627877902, "performed e": 0.0008152096437846543, "of distributed mechanism": 0.0010298199627877902, "been proposed before": 0.0010298199627877902, "67 n": 0.0019282187096626782, "for each": 0.00010381298607484958, "since its other": 0.0010298199627877902, "ciently a": 0.000971904517366954, "proof the intuitive": 0.0010298199627877902, "twenty third": 0.0007421847985653504, "can": 0, "did choose": 0.000971904517366954, "same learning rule": 0.0010298199627877902, "s payo is": 0.0010298199627877902, "desired": 0.0006127719797361421, "to the optimal": 0.0005875760798754402, "highly valuable but": 0.0010298199627877902, "to deviate from": 0.003089459888363371, "sections dealt with": 0.0010298199627877902, "a rigorous": 0.0006049243473022664, "repeated games and": 0.0020596399255755804, "we also show": 0.0010402198964894035, "deviate from it": 0.0010298199627877902, "i for": 0.000442947663003557, "longer the agents": 0.0010298199627877902, "response upon conver": 0.0010298199627877902, "other cases": 0.00046915827274082977, "games under": 0.000971904517366954, "action set of": 0.0009310344469842923, "amount of": 0.00018312797520821062, "quick with polynomial": 0.0010298199627877902, "see below": 0.0004881890232438977, "histories for": 0.0016304192875693086, "of states the": 0.0008321458774498469, "than or equal": 0.000435831200377543, "action in g1": 0.0010298199627877902, "use": -0.0055773805125915385, "from": -0.019205060766570775, "game is a": 0.0009310344469842923, "both agents is": 0.0010298199627877902, "below and any": 0.0010298199627877902, "of strictly": 0.000774103816216825, "quickly the": 0.0007421847985653504, "functions in infinite": 0.0010298199627877902, "are obtained": 0.00030343449037016455, "is by introducing": 0.0010298199627877902, "sandholm awesome a": 0.0010298199627877902, "from it": 0.00045629221416883416, "is similar we": 0.0009310344469842923, "cooperate": 0.0019325410723093418, "games multiagent": 0.000971904517366954, "explain these issues": 0.0010298199627877902, "first let us": 0.0006874022974519222, "but in": 0.0003151849303416359, "the minimal t": 0.0009310344469842923, "linear the": 0.0006427395698875594, "is truly in": 0.0010298199627877902, "of the number": 0.00031814603526610655, "time polynomial in": 0.0013498219883241157, "fourth international": 0.0007421847985653504, "column": 0.0003600249317215904, "best we could": 0.0010298199627877902, "with economic": 0.000971904517366954, "with how quickly": 0.0010298199627877902, "this is": 0.0001686316660882716, "proof": -0.00035745032151274957, "1 of": 0.0002791225337041977, "john s newfoundland": 0.0008002740946718667, "result for imperfect": 0.0010298199627877902, "a i one": 0.0009310344469842923, "mix we refer": 0.0010298199627877902, "g is replaced": 0.0010298199627877902, "assumptions": 0.00023494754117942015, "approach with": 0.0005286223582497236, "has an incentive": 0.0010298199627877902, "payoff in": 0.000971904517366954, "action if a": 0.0009310344469842923, "both ele and": 0.0020596399255755804, "that maximize": 0.0016304192875693086, "by game theorists": 0.0010298199627877902, "behavior before": 0.0008730815719568182, "against such": 0.0008730815719568182, "possible probability distributions": 0.0009310344469842923, "requirement it": 0.0008730815719568182, "requirements are": 0.0004832040417809763, "learning algorithms satisfying": 0.0010298199627877902, "side payments as": 0.0010298199627877902, "in advance how": 0.0010298199627877902, "denitely desirable ignores": 0.0010298199627877902, "instead": -0.00012442961793775344, "expected payos": 0.000971904517366954, "iteration g": 0.0008730815719568182, "for nding": 0.0012854791397751187, "by by": 0.0006578931655429611, "below we": 0.0006867323261225827, "normative guidelines": 0.000971904517366954, "iteration l": 0.0016304192875693086, "algorithm for near": 0.0010298199627877902, "for some nash": 0.0010298199627877902, "games technically": 0.000971904517366954, "natural requirements": 0.000971904517366954, "desired properties for": 0.0010298199627877902, "also take": 0.0006049243473022664, "their work on": 0.0009310344469842923, "and punishment": 0.000971904517366954, "using the algorithm": 0.0006165622637081906, "we shall": 0.00029393785638675104, "the algorithm will": 0.0006335389089667411, "july 25": 0.0012854791397751187, "results provide": 0.0006578931655429611, "g and if": 0.0010298199627877902, "n player": 0.000971904517366954, "either in the": 0.0007161785195604264, "1 if player": 0.0010298199627877902, "of two": 0.00012667955246027228, "folk theorem in": 0.0010298199627877902, "payo it": 0.002915713552100862, "payo is": 0.001943809034733908, "not exponentially": 0.0008730815719568182, "monitoring the": 0.0014321531448804085, "1 individual": 0.0008730815719568182, "following let p": 0.0010298199627877902, "nash equilibria": 0.0008730815719568182, "payo in": 0.000971904517366954, "now that we": 0.0006749109941620578, "taken a": 0.0007421847985653504, "pursued by learning": 0.0010298199627877902, "thus there": 0.0004333839769001314, "this theorem which": 0.0010298199627877902, "payos the proof": 0.0010298199627877902, "g 0 where": 0.0009310344469842923, "choose": 1.4788854253952322e-05, "theory and is": 0.0009310344469842923, "261 268": 0.000971904517366954, "ciently converge to": 0.0010298199627877902, "pareto ele conceptually": 0.0010298199627877902, "game associated with": 0.003089459888363371, "the adversary s": 0.00387107012309453, "a constant sum": 0.0010298199627877902, "value he": 0.000971904517366954, "unique equilibria since": 0.0010298199627877902, "the sequence": 0.0005639861833072123, "stochastic contexts notice": 0.0010298199627877902, "2 s actions": 0.0010298199627877902, "cient solution by": 0.0010298199627877902, "its agent s": 0.0010298199627877902, "for learning algorithms": 0.0008732058717250353, "by e i": 0.0009310344469842923, "the two distinctive": 0.0010298199627877902, "that case": 0.00040135881926370846, "cient policy": 0.000971904517366954, "are learning": 0.000971904517366954, "should be individually": 0.0010298199627877902, "payos obtained": 0.002915713552100862, "1 there bowling": 0.0010298199627877902, "one shot": 0.0017461631439136364, "related": -0.000662198012983593, "agent s reward": 0.0010298199627877902, "1 the learning": 0.0008732058717250353, "our": -0.00837118909222181, "joint conference": 0.0012580329132517005, "out": -0.0013222461318994551, "response for one": 0.0010298199627877902, "react online to": 0.0010298199627877902, "prole where is": 0.0010298199627877902, "the following": 0.00018994199533957994, "i associates a": 0.0020596399255755804, "notation and will": 0.0010298199627877902, "other more complex": 0.0009310344469842923, "there are special": 0.0008732058717250353, "for success we": 0.0010298199627877902, "to the agent": 0.0008002740946718667, "performs": 0.00020425732657871406, "actions and the": 0.0018620688939685846, "the value that": 0.000663411738084629, "in equilibrium 1": 0.0010298199627877902, "presented here": 0.0003848315869061944, "process k 2": 0.0010298199627877902, "be modied first": 0.0010298199627877902, "on equilibria": 0.000971904517366954, "the reader": 0.00060363374696088, "rational nodes": 0.000971904517366954, "such assumptions are": 0.0010298199627877902, "maintains": 0.0002161536574559961, "to start with": 0.0006749109941620578, "that makes an": 0.0010298199627877902, "laws proceedings": 0.000971904517366954, "matrix and move": 0.0010298199627877902, "york": 0.0005581656132285765, "games reinforcement": 0.000971904517366954, "policy that maximizes": 0.0010298199627877902, "agents behavior 2": 0.0010298199627877902, "modied game and": 0.0010298199627877902, "irrational after a": 0.0010298199627877902, "to the above": 0.0005119876058604116, "cases the denition": 0.0010298199627877902, "g": -0.006629834235633571, "rationality stipulates that": 0.0010298199627877902, "considerably from the": 0.0010298199627877902, "adversary quickly": 0.000971904517366954, "we have": 0.00013392278826656183, "we have a": 0.0003561269862954457, "hence": -0.00039461837777395124, "need to note": 0.0010298199627877902, "of such interactions": 0.0010298199627877902, "2004 new": 0.0006290164566258502, "called folk theorems": 0.0020596399255755804, "game is 2": 0.0010298199627877902, "and multiagent systems": 0.0014661010563478836, "its action": 0.002148229717320613, "choices some outcome": 0.0010298199627877902, "though denitely desirable": 0.0010298199627877902, "intuitively": 0.00015390983237028235, "t and": 0.000674129738098345, "as observed": 0.0006164744968379118, "best we": 0.0006939782666478507, "to attain": 0.0013157863310859221, "steps to approximately": 0.0010298199627877902, "remaining sections": 0.0007421847985653504, "ramications": 0.000872957307571399, "in this case": 0.0001771687703932998, "unknown": 0.0008796912092651065, "are all designed": 0.0009310344469842923, "select an": 0.0006049243473022664, "sandholm awesome": 0.000971904517366954, "been played is": 0.0010298199627877902, "their": -0.00493272972217439, "idea is that": 0.0005201099482447018, "optimal the": 0.0006164744968379118, "has attracted": 0.0008152096437846543, "deviations should": 0.000971904517366954, "more re ective": 0.0010298199627877902, "m u": 0.0012098486946045329, "class of games": 0.0020596399255755804, "tuple": 0.000205937800019403, "3 a": 0.00020102477059813996, "3 e": 0.000542504923393336, "its learning algorithm": 0.0010298199627877902, "policy i for": 0.0010298199627877902, "dynamics lead to": 0.0010298199627877902, "agent can receive": 0.0010298199627877902, "initially has": 0.000971904517366954, "3 r": 0.0005661109047770705, "game rg": 0.000971904517366954, "this approach": 0.00035547143067861717, "the reader there": 0.0010298199627877902, "designers there": 0.000971904517366954, "a learning algorithm": 0.0034370114872596114, "have adopted": 0.0005842412659181877, "it observe and": 0.0010298199627877902, "clear that": 0.0003151849303416359, "a payo p": 0.0010298199627877902, "individual": 0.00011490511844833866, "believe that e": 0.0010298199627877902, "agent to denote": 0.0010298199627877902, "another related point": 0.0010298199627877902, "prescribed by a": 0.0010298199627877902, "of a policy": 0.002793103340952877, "situation in": 0.00046046251587537234, "that will lead": 0.0010298199627877902, "for descriptive": 0.000971904517366954, "to minimize their": 0.0010298199627877902, "having a": 0.0003796766130365772, "is limited to": 0.0005749794499375729, "as in": 0.00015932122076453315, "spirit of on": 0.0010298199627877902, "as if": 0.0007857679544577711, "theoretic": 0.000458137749056106, "rule is": 0.00037223626733611355, "according to what": 0.0008321458774498469, "is replaced": 0.0003373507152868544, "which": 0, "a decreased": 0.000971904517366954, "time 14": 0.0008152096437846543, "generalization to": 0.0007421847985653504, "economics and a": 0.0020596399255755804, "who": 0.00013497439305704126, "and side payments": 0.0010298199627877902, "requirements for": 0.0004134042818545908, "is clear": 0.00030343449037016455, "agent i associates": 0.0010298199627877902, "of this algorithm": 0.0004969500605540478, "distributed implementations": 0.0008730815719568182, "reward of player": 0.0010298199627877902, "with imperfect monitoring": 0.0010298199627877902, "class": -0.00032756284936154956, "one for each": 0.00048327283506710686, "xed sum stochastic": 0.0010298199627877902, "basic idea is": 0.0005378088736942846, "of relevant": 0.0005354021517001512, "themselves can be": 0.0009310344469842923, "the basic": 0.00019238220020697928, "people who": 0.0006578931655429611, "cooperate it is": 0.0010298199627877902, "the now": 0.0007421847985653504, "show constructive existence": 0.0010298199627877902, "from 9": 0.0006427395698875594, "dene": 0.0007213836977402378, "to work in": 0.0006335389089667411, "utility function": 0.0008730815719568182, "simple and surprisingly": 0.0010298199627877902, "setting below": 0.000971904517366954, "distinctive aspects of": 0.0010298199627877902, "agents expected average": 0.0010298199627877902, "to a nash": 0.0018620688939685846, "sum stochastic games": 0.003089459888363371, "will behave": 0.0006939782666478507, "known 1": 0.0008730815719568182, "becomes irrational after": 0.0010298199627877902, "is similar 3": 0.0010298199627877902, "view the": 0.0007396581653773328, "by that game": 0.0010298199627877902, "agent plays this": 0.0010298199627877902, "nitely many": 0.0006939782666478507, "unplayed joint": 0.000971904517366954, "function agent": 0.000971904517366954, "agent we": 0.000971904517366954, "matrix correspond": 0.000971904517366954, "special attention is": 0.0009310344469842923, "the others": 0.0003771588365708351, "payments in all": 0.0010298199627877902, "description of": 0.00021204184070572162, "the players behave": 0.0010298199627877902, "behavior in a": 0.0016005481893437334, "iteration for ease": 0.0010298199627877902, "xed policy": 0.000971904517366954, "of individually": 0.0008152096437846543, "of actions": 0.003946745512085098, "game the game": 0.0010298199627877902, "ones": 1.4790702798380575e-05, "nodes proceedings of": 0.0010298199627877902, "2 times": 0.0006290164566258502, "about them they": 0.0010298199627877902, "ciently and punishment": 0.0010298199627877902, "is rational for": 0.0009310344469842923, "that maximizes u": 0.0010298199627877902, "given game": 0.000971904517366954, "is pareto optimal": 0.0010298199627877902, "a more ambitious": 0.0010298199627877902, "an agent in": 0.0016005481893437334, "that setting": 0.0008152096437846543, "when player 1": 0.0010298199627877902, "ages to": 0.000971904517366954, "more details": 0.00040135881926370846, "play defect": 0.000971904517366954, "view": -0.00012353743641881396, "knowing": 0.0003168835371517908, "requirement": 0.00023495896417335347, "initially unknown": 0.002619244715870455, "minimize their average": 0.0010298199627877902, "player the player": 0.0010298199627877902, "the history at": 0.0010298199627877902, "algorithm for its": 0.0009310344469842923, "above consider the": 0.0009310344469842923, "players for most": 0.0010298199627877902, "theorem 3 there": 0.0008321458774498469, "algorithms should e": 0.0010298199627877902, "inter actions such": 0.0010298199627877902, "exclude the": 0.0006290164566258502, "be able": 0.0004302831148813362, "hand these": 0.000774103816216825, "notice that": 0.0011966386501424727, "is that of": 0.0004737656933058489, "that will enable": 0.0008732058717250353, "stochastic games first": 0.0010298199627877902, "the context of": 0.0014647710024328921, "considering games": 0.000971904517366954, "any motivation": 0.000971904517366954, "of equilibrium we": 0.0010298199627877902, "of the agents": 0.0015043290799367848, "however to use": 0.0009310344469842923, "game in strategic": 0.0020596399255755804, "cooperate the adversary": 0.0020596399255755804, "spirit of work": 0.0010298199627877902, "always 0 and": 0.0010298199627877902, "ability": 0.0003777478191540665, "exists ele": 0.000971904517366954, "eect": 0.0003314917117816786, "repeated games with": 0.004119279851151161, "will not learn": 0.0010298199627877902, "games for": 0.0008730815719568182, "section 6 a": 0.0008321458774498469, "a normative approach": 0.003089459888363371, "our results to": 0.001990235214253887, "time and a": 0.0007330505281739418, "a deviation from": 0.002793103340952877, "implementations of vickrey": 0.0010298199627877902, "g then there": 0.0008002740946718667, "sections we": 0.00041030656060455343, "able to lead": 0.0009310344469842923, "setting our denition": 0.0010298199627877902, "each agent": 0.0052631453243436885, "that although a": 0.0009310344469842923, "we examine": 0.00041656361432912804, "agent designer": 0.000971904517366954, "when facing uncertainty": 0.0010298199627877902, "the return": 0.002336965063672751, "u next they": 0.0010298199627877902, "followed in": 0.0008730815719568182, "the long": 0.0004482748456766825, "can do": 0.00043697553507468355, "the following are": 0.000552614435925888, "employ the": 0.000557817444576059, "a game we": 0.0020596399255755804, "respect": -0.0002835465291456462, "action and its": 0.0020596399255755804, "plays his": 0.001943809034733908, "boella leendert": 0.000971904517366954, "this best": 0.000971904517366954, "do o line": 0.0010298199627877902, "be in one": 0.0007742140246189059, "would have obtained": 0.0018620688939685846, "are interested in": 0.00036829598867252344, "cient": 0.005050454320149744, "that is contrary": 0.0010298199627877902, "systems july": 0.000774103816216825, "non negative": 0.0003956596676276662, "describe how": 0.0003848315869061944, "player 2 using": 0.0010298199627877902, "i in the": 0.0004134631378172694, "agent to learn": 0.0010298199627877902, "as desired": 0.0005842412659181877, "rg a policy": 0.0010298199627877902, "algorithm in stochastic": 0.0010298199627877902, "of whom": 0.0007421847985653504, "knowing the": 0.000557817444576059, "the simplifying assumption": 0.0009310344469842923, "there exists an": 0.0004155626519889734, "are typical": 0.0006578931655429611, "not required to": 0.0006527573289679061, "unknown but": 0.0008730815719568182, "learn the outcome": 0.0010298199627877902, "present": -0.00019235481873811978, "should view the": 0.0010298199627877902, "that agents will": 0.0009310344469842923, "align": 0.0005041379917849015, "sum game in": 0.0020596399255755804, "choices": 0.0002039484841889661, "will": -0.02419862360567527, "the process": 0.00021101803150138556, "agents involved are": 0.0010298199627877902, "repeating the": 0.0005842412659181877, "45 76 may": 0.0010298199627877902, "the average": 0.0010861610701032379, "is an ele": 0.0010298199627877902, "no general": 0.0006939782666478507, "many stages": 0.000971904517366954, "knowledge the": 0.000549963838367756, "the research methodology": 0.0010298199627877902, "3 for the": 0.0005201099482447018, "optimal reinforcement learning": 0.0020596399255755804, "thus": -0.0021700706560837577, "algorithm will converge": 0.0020596399255755804, "m u 1": 0.0010298199627877902, "payos that": 0.000971904517366954, "thuc": 0.000872957307571399, "game and": 0.0014843695971307007, "of imperfect monitoring": 0.0010298199627877902, "given class despite": 0.0010298199627877902, "goals of multi": 0.0010298199627877902, "a probability of": 0.001990235214253887, "action repeatedly": 0.000971904517366954, "t mix is": 0.0010298199627877902, "13 6 much": 0.0010298199627877902, "is assumed": 0.0005334310581340759, "will necessarily converge": 0.0010298199627877902, "the theory": 0.00033345449157714114, "designers will": 0.0008730815719568182, "the value": 0.001001518358316561, "in any case": 0.0005475136432016508, "gets": 0.00019047610901416596, "expected average sum": 0.0010298199627877902, "by all agents": 0.0010298199627877902, "irrational if": 0.000971904517366954, "game matrix m": 0.0010298199627877902, "76 may": 0.000971904517366954, "eventually adopt behavior": 0.0010298199627877902, "agents should": 0.000971904517366954, "agents except in": 0.0010298199627877902, "go about minimizing": 0.0010298199627877902, "be rational agents": 0.0010298199627877902, "by removal of": 0.0010298199627877902, "initially the game": 0.0010298199627877902, "adjust its policy": 0.0010298199627877902, "hold here theorem": 0.0010298199627877902, "algorithm that converges": 0.0010298199627877902, "denote this interval": 0.0010298199627877902, "what happens after": 0.0009310344469842923, "best that each": 0.0010298199627877902, "more complex": 0.00029240195497445495, "quasi linear": 0.0008730815719568182, "of the previous": 0.0003831496416266841, "game matrix are": 0.0010298199627877902, "in particular work": 0.0010298199627877902, "of an agent": 0.0007521645399683924, "obtain": -0.0009448207513992888, "s policy as": 0.0010298199627877902, "about its": 0.000549963838367756, "to evolve our": 0.0010298199627877902, "an important": 0.00020004876243282348, "before while other": 0.0010298199627877902, "dened as": 0.0004197872166755902, "diers considerably from": 0.0010298199627877902, "is considered irrational": 0.0010298199627877902, "a novel e": 0.0020596399255755804, "cient therefore": 0.000971904517366954, "repeated games at": 0.0010298199627877902, "is irreducible": 0.0006578931655429611, "attractive": 0.00027072409997109604, "models of": 0.0006669089831542823, "alone the": 0.0007160765724402042, "learning algorithms then": 0.0010298199627877902, "identical": 0.00020472678085096843, "obtain maximal": 0.000971904517366954, "being played given": 0.0010298199627877902, "reinforcement learning ctr": 0.0010298199627877902, "a boolean": 0.00040135881926370846, "of irrationality": 0.000971904517366954, "best action repeatedly": 0.0010298199627877902, "term": -6.414640620786386e-05, "reinforcement learning": 0.009648402381349555, "know": -7.039907907354142e-05, "itself the": 0.00043697553507468355, "for a player": 0.0010298199627877902, "to if adopted": 0.0010298199627877902, "known the idea": 0.0010298199627877902, "ele is": 0.002915713552100862, "t steps or": 0.0010298199627877902, "that the learner": 0.0008732058717250353, "out of a": 0.0006335389089667411, "for t mix": 0.0010298199627877902, "is useful to": 0.0005201099482447018, "games with incomplete": 0.0010298199627877902, "also need": 0.000444416512295841, "because": -0.001469480103271368, "in this": 1.1092180026765947e-05, "several nash": 0.000971904517366954, "sequence": -0.00021956304059890955, "may not": 0.00018312797520821062, "1 500 the": 0.0010298199627877902, "recent results": 0.0006578931655429611, "a joint action": 0.0010298199627877902, "major claim": 0.000971904517366954, "unknown e cient": 0.0010298199627877902, "games stochastic": 0.001943809034733908, "extension of these": 0.0008732058717250353, "will all": 0.0008152096437846543, "prole is": 0.001943809034733908, "design friend or": 0.0010298199627877902, "lead": 0.0004367121096976002, "realistic": 0.000205937800019403, "the long term": 0.000663411738084629, "action a policy": 0.0010298199627877902, "run the policy": 0.0010298199627877902, "distributions over a": 0.0009310344469842923, "max will": 0.0008730815719568182, "choice of learning": 0.0010298199627877902, "on s we": 0.0008732058717250353, "setting first let": 0.0010298199627877902, "prole in": 0.001943809034733908, "players may be": 0.0009310344469842923, "that it attain": 0.0010298199627877902, "algorithm can be": 0.00044833866612737684, "information as": 0.0005661109047770705, "literature the concept": 0.0010298199627877902, "in both imperfect": 0.0010298199627877902, "on its previous": 0.0010298199627877902, "is close to": 0.0009296301076623074, "we introduce": 0.0002214738315017785, "algorithms that will": 0.0009310344469842923, "friend or": 0.000971904517366954, "of player": 0.000971904517366954, "only a": 0.00017773571533930859, "might be": 0.000485701831443146, "carried": 0.00027301757160748174, "extension": 0.0002093508568888798, "above work": 0.000774103816216825, "proof consider the": 0.0006749109941620578, "only o": 0.0005286223582497236, "many stages b": 0.0010298199627877902, "it turns": 0.0003848315869061944, "policy for": 0.002264443619108282, "outset": 0.0006747188760310696, "own": 0.0005352837404954015, "the designer": 0.000549963838367756, "algorithm this is": 0.0007161785195604264, "two distinctive aspects": 0.0010298199627877902, "manner this is": 0.0008732058717250353, "ciency": 0.001560398533404612, "ts into": 0.0008152096437846543, "the prescribed": 0.0013157863310859221, "van": 0.0002653473045919286, "matrix are assigned": 0.0010298199627877902, "the ai perspective": 0.0020596399255755804, "agent systems that": 0.0010298199627877902, "denoted by": 0.00022910148219702493, "on line algorithms": 0.0016005481893437334, "motivation for": 0.0004264387578012798, "decision that": 0.000774103816216825, "is the denition": 0.0008321458774498469, "formally assume some": 0.0010298199627877902, "an irrational": 0.000971904517366954, "algorithms in computer": 0.0020596399255755804, "quickly he": 0.000971904517366954, "we will": 0.00020850331493614993, "an agent using": 0.0010298199627877902, "done in order": 0.0008321458774498469, "for its agent": 0.0010298199627877902, "it may be": 0.0003546663244307511, "devise an e": 0.0010298199627877902, "subtle but": 0.0008730815719568182, "values that": 0.0004197872166755902, "made": -0.00011132479810086909, "if an": 0.0005757389687800391, "whether": -0.00010989689608291712, "motivated largely": 0.000971904517366954, "players behave": 0.001943809034733908, "below": -0.0003732888538132603, "spirit of game": 0.0010298199627877902, "satisfying the above": 0.0007742140246189059, "side payment": 0.000971904517366954, "context agents": 0.000971904517366954, "some pre": 0.0007160765724402042, "existence the": 0.000971904517366954, "this strategy": 0.0004933431890106373, "result if": 0.0006164744968379118, "let policy": 0.000971904517366954, "and initially": 0.000774103816216825, "result is": 0.00022254718490145105, "g1 and behave": 0.0010298199627877902, "and any": 0.0003240812532709715, "non bayesian normative": 0.0010298199627877902, "assume that initially": 0.0008732058717250353, "algorithms in the": 0.0006013538961527255, "procedure that will": 0.0009310344469842923, "t mix we": 0.0010298199627877902, "ele in": 0.004859522586834771, "similar in": 0.00046046251587537234, "of imperfect and": 0.0010298199627877902, "see by": 0.000774103816216825, "ele if": 0.000971904517366954, "noncooperative settings in": 0.0010298199627877902, "other": -0.01625386642291305, "the details are": 0.0008321458774498469, "his adversary": 0.000971904517366954, "information as closely": 0.0010298199627877902, "inter actions": 0.0008730815719568182, "that learning algorithms": 0.0010298199627877902, "ele it": 0.000971904517366954, "as we can": 0.0005811431115841947, "have perfect": 0.0008730815719568182, "relax the": 0.000542504923393336, "readers may not": 0.0009310344469842923, "guarantee a": 0.0006290164566258502, "the reward associated": 0.0010298199627877902, "that game s": 0.0010298199627877902, "ele exists and": 0.0010298199627877902, "have done had": 0.0010298199627877902, "not increase": 0.0005159204175055324, "2 t mix": 0.0010298199627877902, "proof consider": 0.00047837713542937403, "equilibrium in game": 0.0010298199627877902, "learning procedure": 0.0007421847985653504, "we make the": 0.0005286976176970826, "s average reward": 0.0020596399255755804, "fundamental work on": 0.0010298199627877902, "and in 7": 0.0008732058717250353, "deviates from": 0.002322311448650475, "success we wish": 0.0010298199627877902, "s the": 0.00022040572533156756}