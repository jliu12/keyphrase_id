{"to the transducer": 0.001412997877799242, "number of": 7.133801346001728e-05, "learning fundamentals of": 0.001412997877799242, "to learn useful": 0.001412997877799242, "could not": 0.00045471705861272453, "than their non": 0.001177670521728601, "the second": 0.0002394521175833716, "the most": 0.00027583526982847954, "values a": 0.0006214693208023149, "a hybrid": 0.001092581550731157, "yellow": 0.002330690999244645, "four": -0.00036368275587570544, "approach the": 0.000807148833775313, "learn independently from": 0.001412997877799242, "a few hundred": 0.0009126929338602609, "trash can": 0.026621811842948397, "pre processed": 0.001013492172364257, "different type": 0.0008433654142724929, "recycling a": 0.0013439565011394887, "reveals that": 0.0006069462075329354, "relies on using": 0.001412997877799242, "problem for several": 0.0012953547128852297, "be adapted": 0.0005655780229006622, "and thus there": 0.0009773255297405913, "show the": 0.00024733410938853056, "does an": 0.0009217509760058083, "a particular observation": 0.0011397700534482, "calculate": 0.00023055267149446444, "task figure shows": 0.001412997877799242, "a six": 0.0009707370964526472, "drop items": 0.0013439565011394887, "space bias is": 0.001412997877799242, "layered architecture combining": 0.001412997877799242, "exploited to": 0.0013759669926883369, "wall on the": 0.001412997877799242, "grant no iri": 0.0012265208479459286, "sensor uncertainty v": 0.001412997877799242, "element vector": 0.0011086075099259812, "concept2 concept3 concept4": 0.001412997877799242, "framework uses": 0.0010397031738864368, "four overlapping": 0.0013439565011394887, "signatures we": 0.0010397031738864368, "has to find": 0.0010826007236946758, "back left right": 0.002825995755598484, "11 18 the": 0.0012953547128852297, "updated": 0.00038456703137021024, "dimensional and noisy": 0.004238993633397726, "actions however for": 0.001412997877799242, "to learn to": 0.0010599041887614004, "below figure 13": 0.001412997877799242, "and move towards": 0.002355341043457202, "the robot navigating": 0.002825995755598484, "for learning": 0.0027667768915390803, "examples through": 0.0012263127867333846, "approach and proposes": 0.001412997877799242, "based source": 0.001157470080128191, "front near b": 0.001412997877799242, "updates": 0.00025502622541008783, "fairly well": 0.0008837126637559662, "features from local": 0.001412997877799242, "robot is": 0.003811210244387835, "cans could": 0.0013439565011394887, "been presented": 0.0006189654335108611, "processor figure": 0.000872702844207972, "left back": 0.0013439565011394887, "to learning": 0.0008525989995294478, "that occupancy": 0.0013439565011394887, "explicitly represented we": 0.001412997877799242, "probability that": 0.00039733375546185, "out any useful": 0.001412997877799242, "exploits a": 0.001013492172364257, "required to": 0.00046042802183641416, "than strict": 0.0010706929277613088, "sensors used": 0.0012263127867333846, "solution": -0.0002241220843985045, "easily collected": 0.0013439565011394887, "several hundred": 0.0024787917208853208, "robot which could": 0.001412997877799242, "vector": 2.0654128112283713e-05, "by contrast in": 0.0011087956007827721, "prone to specular": 0.001412997877799242, "markov": 0.002219699018985527, "original function": 0.0009365728948883588, "at most how": 0.001412997877799242, "errors e": 0.0009081111668589885, "human trainer": 0.0013439565011394887, "approach clearly": 0.0013439565011394887, "prior work on": 0.0009773255297405913, "high dimensional sensor": 0.002825995755598484, "presented examples it": 0.001412997877799242, "a sufficiently": 0.0005913666291750407, "improve camera turn": 0.001412997877799242, "pulse": 0.0013831538140792806, "decision trees or": 0.001177670521728601, "second": -0.0016663577944099797, "that can be": 0.0002876413898691188, "variables were used": 0.001412997877799242, "uses an": 0.0005565583063253017, "the sensory input": 0.001412997877799242, "department 3": 0.0013439565011394887, "even": -0.0013360264780393613, "is beyond the": 0.0007021104098709409, "probabilistic framework": 0.0009528025610969587, "errors": 0.0006515146999354741, "this research builds": 0.001412997877799242, "compass directions the": 0.001412997877799242, "specularities": 0.005529567846222089, "has to learn": 0.0012265208479459286, "be dependent on": 0.0009647109541934066, "smooth we": 0.0010706929277613088, "of robotics the": 0.001412997877799242, "depends on": 0.00020386361930943824, "5 ff": 0.0011086075099259812, "the reports": 0.001157470080128191, "new": -0.0026621408980945322, "net": 0.009927102002694557, "sonars were": 0.0013439565011394887, "uncertainty to": 0.001157470080128191, "frame grabber": 0.0012263127867333846, "robot testbed called": 0.001412997877799242, "aligment of": 0.0013439565011394887, "in details of": 0.0012953547128852297, "lab position d": 0.001412997877799242, "strengths as": 0.0013439565011394887, "coded feature": 0.0013439565011394887, "studied in two": 0.0012265208479459286, "the left or": 0.000887696035668378, "in many": 0.0002739040551599055, "hallways each local": 0.001412997877799242, "to this problem": 0.000580437697563854, "labeled examples of": 0.002825995755598484, "here": -0.0029339695518214516, "have found that": 0.0006641063390170443, "a teacher supervised": 0.001412997877799242, "reported": 0.00013101830440917, "tation such as": 0.001412997877799242, "class label estimating": 0.001412997877799242, "dimensional in": 0.0010397031738864368, "the study of": 0.0005777823180207654, "active": 0.0005318260327390027, "that is substantially": 0.001412997877799242, "ditions it": 0.0013439565011394887, "successful navigation": 0.0012263127867333846, "two robotics tasks": 0.001412997877799242, "in fact in": 0.000747247581202698, "7 one promising": 0.001412997877799242, "proceeds with capturing": 0.001412997877799242, "high level": 0.001485461477234209, "ranging from": 0.0005074090681964598, "for navigation we": 0.001412997877799242, "an accuracy of": 0.0010057508064281846, "has been": 0.00011871199450909564, "a navigation system": 0.001412997877799242, "reports": 0.002010919118615333, "20 2 south": 0.001412997877799242, "then used": 0.0005156873579901185, "testbed called": 0.0013439565011394887, "multi output net": 0.004238993633397726, "in a specified": 0.001039879574153469, "planner reactive": 0.0013439565011394887, "further processing phase": 0.001412997877799242, "represented we calculate": 0.001412997877799242, "programming mobile": 0.0012263127867333846, "models for mobile": 0.001412997877799242, "categories e": 0.0013439565011394887, "extremely challenging": 0.0026879130022789775, "detectors layer": 0.0013439565011394887, "based algorithm for": 0.0008405371151868688, "reliable observations": 0.0013439565011394887, "we calculate only": 0.001412997877799242, "florida computer science": 0.001412997877799242, "is fairly": 0.000577026606170962, "other than strict": 0.0012953547128852297, "the approach taken": 0.0007988727145907639, "interesting concepts in": 0.001412997877799242, "acknowledge the support": 0.0010057508064281846, "labeling examples to": 0.001412997877799242, "made it difficult": 0.001412997877799242, "successful traces starting": 0.002825995755598484, "specularities dominate almost": 0.001412997877799242, "descriptions however": 0.001157470080128191, "parts of": 0.00034520304794030795, "a discussion of": 0.0006062757282217702, "multitask learning a": 0.001412997877799242, "is not defined": 0.0009039491294179812, "optimized variant of": 0.001412997877799242, "flat surface angled": 0.001412997877799242, "undefined the net": 0.001412997877799242, "data rapid concept": 0.001412997877799242, "was tested by": 0.0012953547128852297, "of bias": 0.004477390378891143, "tainty which": 0.0013439565011394887, "learned knowledge can": 0.001412997877799242, "a north": 0.0010397031738864368, "concept4": 0.0012261047960979141, "is much": 0.0006183311714655839, "facilitate recognition": 0.0013439565011394887, "concept1": 0.0012261047960979141, "concept2": 0.0012261047960979141, "concept3": 0.0012261047960979141, "carried out": 0.0007551240494182668, "they require long": 0.001412997877799242, "type": -0.0003296295714117551, "until": -5.4542677090817896e-05, "decomposable": 0.001530142302074915, "learn a single": 0.001412997877799242, "of different": 0.0006447220382469803, "space biases 3": 0.001412997877799242, "human drivers as": 0.001412997877799242, "designer provides the": 0.0012953547128852297, "that even": 0.00042353538718151027, "standardized": 0.0006704073805038565, "a is given": 0.0008956300062288188, "successful": 0.0011228392573292654, "out certain": 0.001013492172364257, "expose": 0.0005529776841907936, "and contrast": 0.0009217509760058083, "model we": 0.00039656684508817093, "near or": 0.0021413858555226176, "trees 23 and": 0.001412997877799242, "from examples": 0.0007897242543278053, "outputs were": 0.0010706929277613088, "are interesting": 0.0008262639069617736, "picking up the": 0.0012953547128852297, "when the data": 0.0008291394238884059, "concept1 concept2 concept3": 0.001412997877799242, "10 using": 0.0008954780757782285, "robots 900000000000000000000000000000000011111111111111111111111111111111111111111111000000000000000000000000000000000000111111111111111111111111111111111111 sensor": 0.001412997877799242, "this results in": 0.0005872517174083484, "the alvinn": 0.0024526255734667692, "flexible navigation system": 0.001412997877799242, "circumstances": 0.0007563954882620376, "markov decision processes": 0.0022795401068964, "sensor representation original": 0.001412997877799242, "space could": 0.001013492172364257, "can net": 0.0013439565011394887, "room": 0.00045361872814018024, "layer planning figure": 0.001412997877799242, "setup": 0.0007563954882620376, "junk and deposit": 0.001412997877799242, "its environment under": 0.001412997877799242, "one hypotheses over": 0.001412997877799242, "similar neural network": 0.001412997877799242, "which are": 0.0002335063106742234, "or a": 0.00018505473946951303, "and consistent": 0.0007770287888915143, "2 2 navigation": 0.001412997877799242, "have also been": 0.0006310701423978614, "a process that": 0.0008405371151868688, "concepts": 0.003939754477990432, "wiping out any": 0.001412997877799242, "training also approaches": 0.001412997877799242, "the paper is": 0.0004106271848600875, "example": -0.004565907074824147, "tree approaches": 0.001157470080128191, "any useful information": 0.0012265208479459286, "also show": 0.0004557438286453504, "g near and": 0.001412997877799242, "a steering": 0.0012263127867333846, "programming": 2.8530365627327124e-05, "defined in states": 0.001412997877799242, "organized": 8.271764015351703e-05, "real data": 0.0007541286032508272, "was supported in": 0.0005713090990815192, "can be": 4.425271380169859e-06, "a very": 0.00023134881850209936, "on a human": 0.001412997877799242, "both these tasks": 0.001412997877799242, "an accuracy": 0.0007964395063592673, "the learning": 0.0012138924150658708, "examples converged": 0.0013439565011394887, "neural net can": 0.001412997877799242, "be in": 0.0003346359271355664, "restrict the presentation": 0.0012953547128852297, "00000000000000000000000000000011111111111111111111111110000000000000000000000000111111111111111111111111100000000000000000000000001111111111111111111111111000000111111000000111111000000111111 inputs": 0.0013439565011394887, "job of": 0.0006993597717998856, "to find trash": 0.001412997877799242, "the loop 3": 0.0012953547128852297, "near f": 0.0013439565011394887, "is halved": 0.0009707370964526472, "32x32 door": 0.0013439565011394887, "was supported": 0.0003706879053215327, "required to traverse": 0.0012953547128852297, "post this": 0.0012263127867333846, "and learn subfunctions": 0.001412997877799242, "feature": 0.0023480996566624173, "employ a": 0.0006214693208023149, "machine": 0.00011323896932201712, "how": -0.0020247844470110926, "first is": 0.0005243498648614615, "near s": 0.0010397031738864368, "possible observation door": 0.001412997877799242, "back and": 0.0006705211052503373, "millions of pixels": 0.001412997877799242, "g theocharous": 0.013439565011394887, "and robotic systems": 0.0011087956007827721, "by learning": 0.0017674253275119325, "were carried out": 0.0008291394238884059, "as noted": 0.0005228778271257987, "512 rather than": 0.001412997877799242, "trained to": 0.005067460861821285, "of uncertainties": 0.0010397031738864368, "i reports": 0.002314940160256382, "to realize many": 0.001412997877799242, "turn camera": 0.0013439565011394887, "example new objects": 0.001412997877799242, "find objects": 0.0012263127867333846, "to produce fairly": 0.001412997877799242, "pose a3 0": 0.001412997877799242, "to decompose the": 0.0009126929338602609, "were close to": 0.001412997877799242, "trash cans rapid": 0.001412997877799242, "approaches with decision": 0.001412997877799242, "concepts under": 0.0010397031738864368, "a draft of": 0.0009909470066802508, "different sensors are": 0.0012953547128852297, "grids raw sensor": 0.001412997877799242, "a simpler": 0.0005171034306485431, "detecting a": 0.0008183105262917859, "3 bits indicating": 0.002825995755598484, "to using": 0.0006092863925155239, "recycling or": 0.0013439565011394887, "right figure": 0.000872702844207972, "9501852": 0.0012261047960979141, "4 although we": 0.0012953547128852297, "discrete bayesian models": 0.001412997877799242, "facilitated through": 0.0013439565011394887, "maintain": 0.0001863317992992045, "mobile robots the": 0.001412997877799242, "abstract observation": 0.004031869503418466, "ethernet": 0.0005396598631594049, "can speed": 0.0009365728948883588, "operate": 0.0002783370076962827, "contrasted with those": 0.0012953547128852297, "is a normalization": 0.0009529642174527608, "of uncertainties machine": 0.001412997877799242, "bottom figure": 0.0021413858555226176, "7 the": 0.0002815685261761977, "were pre": 0.0011086075099259812, "feedback": 0.0003030353065250183, "grabber communication is": 0.001412997877799242, "the desired concept": 0.001412997877799242, "the robot to": 0.003533011565185803, "optimal values": 0.0007964395063592673, "defined in": 0.0005252213362271722, "blanco l": 0.0013439565011394887, "both tasks described": 0.001412997877799242, "values 2": 0.0008034263695325692, "most well": 0.0009365728948883588, "navigating mobile": 0.0013439565011394887, "is more": 0.00037733162487033826, "after the": 0.00021050432839780944, "are not": 6.392902843641928e-05, "and corresponding features": 0.001412997877799242, "is quite limited": 0.001177670521728601, "could be programmed": 0.001412997877799242, "before": -0.0002282938368354733, "experiments described": 0.0014677990598179111, "when the goal": 0.001177670521728601, "1 however": 0.000502086558834254, "detect trash": 0.0013439565011394887, "output neural": 0.0026879130022789775, "homes is": 0.0013439565011394887, "an unseen": 0.001013492172364257, "making it": 0.000593511402013939, "which restrict possible": 0.001412997877799242, "the form of": 0.0012778585201720701, "better": -0.0003345422321036606, "specified architecture the": 0.001412997877799242, "overlapping quadrants left": 0.001412997877799242, "concept learning in": 0.002355341043457202, "of decision": 0.0006705211052503373, "significant odometric errors": 0.001412997877799242, "most of": 0.0004484717822197485, "successful run when": 0.001412997877799242, "hidden": 0.0009718242358224563, "easier": 0.00041182105031027053, "front and back": 0.0012953547128852297, "using discrete event": 0.0012953547128852297, "receptacles are color": 0.001412997877799242, "robots for example": 0.001412997877799242, "combination": 0.00017380319422489785, "to do": 0.000259232391578513, "weakness": 0.0005020014016838411, "programmed or instructed": 0.001412997877799242, "purposes of": 0.0010607151857049066, "the effectiveness of": 0.0026075290876688183, "the direction": 0.0004466919402916898, "somewhat large burden": 0.001412997877799242, "inputs the": 0.001487440233296121, "effects": 0.0002677410815828291, "to converge it": 0.001412997877799242, "has some": 0.0005731297104135156, "real time robotics": 0.001412997877799242, "complex since we": 0.001412997877799242, "examples and the": 0.0010057508064281846, "of actuator and": 0.001412997877799242, "hypothesis space bias": 0.0025907094257704593, "a successful run": 0.0012953547128852297, "active topic": 0.0012263127867333846, "represents": -2.759101861711922e-05, "grammar": 0.0005155998940555883, "we believe that": 0.0004599840819150557, "their learning": 0.0013439565011394887, "also whether the": 0.001412997877799242, "the maximum": 0.00019231613375392365, "to learn high": 0.001412997877799242, "very near the": 0.0022795401068964, "human teacher": 0.0024526255734667692, "error such": 0.0009907789071032058, "a low": 0.00043431322336932046, "within about training": 0.001412997877799242, "testbed followed": 0.0013439565011394887, "observations one for": 0.001412997877799242, "of labeled": 0.0008525989995294478, "significant sensor": 0.0026879130022789775, "is to": 0.0002623969711393649, "32x32": 0.0009906108645477269, "sufficiently diverse collection": 0.001412997877799242, "afforded": 0.000754000698128159, "called pavlov the": 0.001412997877799242, "robustly predict features": 0.001412997877799242, "such as avoiding": 0.001412997877799242, "that have": 0.0002382544191706924, "ular robots": 0.0013439565011394887, "uncertainties machine learning": 0.001412997877799242, "class learning": 0.0010706929277613088, "human teacher to": 0.001412997877799242, "can in position": 0.001412997877799242, "a wireless": 0.0007832601051609397, "effectiveness of this": 0.0008658836593557804, "of its location": 0.001177670521728601, "ff prior": 0.004031869503418466, "from local occupancy": 0.001412997877799242, "the pomdp": 0.0013439565011394887, "examples are constructed": 0.0012953547128852297, "can placed in": 0.001412997877799242, "substantially": 0.0002903741227944372, "laboratory": 0.0003824459272259881, "are color": 0.001157470080128191, "extract": 0.0003261398627596022, "here such": 0.001013492172364257, "back opening back": 0.001412997877799242, "2 dimensional": 0.0006457442730738455, "above suggest that": 0.0011397700534482, "input dimensions": 0.001157470080128191, "have a": 9.669574426395791e-05, "easily converted into": 0.0011087956007827721, "dominate almost totally": 0.001412997877799242, "image processing": 0.001187022804027878, "results in better": 0.0009529642174527608, "probabilities v i": 0.001412997877799242, "the second form": 0.001177670521728601, "and multi": 0.0018644079624069447, "programmed obviously this": 0.001412997877799242, "one hypotheses": 0.0013439565011394887, "in part by": 0.0004642383912570252, "navigation architecture using": 0.001412997877799242, "d which is": 0.0008728509105201892, "environment were fairly": 0.001412997877799242, "colored trash receptacle": 0.001412997877799242, "reader": 0.00018437100852561632, "b introduction": 1.5006521337100489e-05, "size": -0.0002238283337451608, "learning an introduction": 0.001412997877799242, "2 two": 0.0006546338046551141, "above suggest": 0.0010706929277613088, "a reactive": 0.0019056051221939174, "rather than 2": 0.0011087956007827721, "pixels so": 0.0012263127867333846, "pursuit model": 0.0013439565011394887, "general strategies": 0.0012263127867333846, "underlying function approximator": 0.001412997877799242, "that takes into": 0.0009316462484985891, "predict features from": 0.001412997877799242, "sensory": 0.01927896247650405, "intersec": 0.001039526833456673, "neural network with": 0.001021962604845781, "as trash cans": 0.001412997877799242, "navigation using discrete": 0.001412997877799242, "detector the output": 0.001412997877799242, "direct policy learning": 0.001412997877799242, "sensors": 0.004764647813881982, "obstacles etc however": 0.001412997877799242, "a color camera": 0.001412997877799242, "readings figure": 0.0013439565011394887, "the partioning and": 0.001412997877799242, "learning feature detectors": 0.002825995755598484, "examples since": 0.0009907789071032058, "employs a further": 0.001412997877799242, "domain for": 0.0006916942228847701, "related concepts": 0.0019056051221939174, "hallway navigation": 0.0013439565011394887, "solving the problem": 0.0008133430731188866, "fairly easy": 0.0008837126637559662, "level features": 0.002026984344728514, "accommodated by": 0.0009365728948883588, "to find": 0.0012045981914658077, "obstacle avoidance": 0.001157470080128191, "net used": 0.0013439565011394887, "examples it is": 0.0011397700534482, "concepts simultaneously": 0.0024526255734667692, "moving": 0.0002282938368354733, "testbed called pavlov": 0.001412997877799242, "motor commands action": 0.001412997877799242, "is necessary since": 0.0009647109541934066, "than 1024 8": 0.001412997877799242, "labeled as to": 0.001412997877799242, "features": 0.0013068086810049302, "discontinuous distributions such": 0.001412997877799242, "hypotheses and": 0.0008837126637559662, "believes it could": 0.001412997877799242, "light variations": 0.0013439565011394887, "presentation here": 0.0010706929277613088, "set of": 0.0003108380996049459, "concepts could be": 0.001412997877799242, "has several": 0.0005810090920244843, "synthesize": 0.0005636424423664252, "floors": 0.0009526409595770983, "the current state": 0.0006293056693152161, "be easily accommodated": 0.0012953547128852297, "left right": 0.0030608037363982015, "pavlov can": 0.0026879130022789775, "these tasks": 0.0007387405675331519, "net used in": 0.001412997877799242, "generalizations a": 0.001157470080128191, "173": 0.000472878715871056, "a standardized function": 0.001412997877799242, "is complementary to": 0.0011087956007827721, "reasons we": 0.0007338995299089556, "6 outputs hidden": 0.001412997877799242, "can acquire useful": 0.001412997877799242, "real robot pavlov": 0.001412997877799242, "such an": 0.00029137429975815656, "service": 0.0002747471526969802, "similarly": -0.00010606088617358301, "11 opening": 0.0013439565011394887, "based reasoning and": 0.001412997877799242, "in observation data": 0.001412997877799242, "generate a combination": 0.001412997877799242, "beyond the scope": 0.0006497504327944296, "feasible to learn": 0.001412997877799242, "including offices": 0.0013439565011394887, "which will": 0.0003796686713245603, "such as": 0.0010382975029267745, "multiple output": 0.0009528025610969587, "9 sample local": 0.001412997877799242, "a known": 0.0005750676982296913, "a lifelong learning": 0.001412997877799242, "ranging": 0.0003340066195098403, "discrete probability distribution": 0.0012953547128852297, "pixels noisy due": 0.001412997877799242, "initially unobservable": 0.0013439565011394887, "since we": 0.00025797663703960036, "of a": 0.0, "called pavlov": 0.004031869503418466, "learning robots for": 0.001412997877799242, "not directly observable": 0.0012265208479459286, "a colored trash": 0.001412997877799242, "reports action": 0.0013439565011394887, "alvinn 22": 0.0026879130022789775, "somewhat": 0.0003648427789579999, "many different": 0.0005583269585823748, "noisy the": 0.001013492172364257, "the left": 0.0007739299111188012, "problem the": 0.000679713531705484, "multiple category learning": 0.001412997877799242, "distance": 0.00020352168860106418, "performed better on": 0.001412997877799242, "data collection": 0.0015928790127185345, "structure logical": 0.0013439565011394887, "ditions it seems": 0.001412997877799242, "bits": 0.0004506184863367159, "positions a": 0.0021413858555226176, "order to learn": 0.001177670521728601, "tree": 0.0005034371673332633, "9 b the": 0.0011397700534482, "until it": 0.0005115024387919628, "hsi values": 0.0026879130022789775, "c figure": 0.0005446340152121855, "hsi values hue": 0.001412997877799242, "idea is illustrated": 0.0012953547128852297, "function from such": 0.001412997877799242, "now serves": 0.0013439565011394887, "space and learning": 0.001412997877799242, "figure 3 this": 0.0009039491294179812, "run in these": 0.0012953547128852297, "approach could be": 0.0009219073640234544, "single output neural": 0.001412997877799242, "known pursuit steering": 0.001412997877799242, "office robot": 0.0012263127867333846, "are constructed": 0.0005565583063253017, "the training time": 0.0012953547128852297, "algorithm called grdt": 0.001412997877799242, "of 85 rapid": 0.001412997877799242, "supervised learning where": 0.0012953547128852297, "physically occupied region": 0.001412997877799242, "1 a nomad": 0.001412997877799242, "to implement a": 0.0006893286454678117, "artificial neural": 0.0009081111668589885, "of learning 20": 0.001412997877799242, "sensor uncer tainty": 0.001412997877799242, "seem": 0.00021223982276857213, "one more": 0.0005693146787156503, "in position": 0.0013833884457695401, "dozen": 0.0006992411558277349, "track the bottom": 0.001412997877799242, "described below were": 0.001412997877799242, "most of the": 0.0007190980218287581, "of the sensory": 0.0012953547128852297, "layer input": 0.001157470080128191, "these related": 0.0011086075099259812, "that could": 0.0004506632696548802, "we could": 0.00034945266426170216, "were fairly": 0.0010706929277613088, "encouraging 7 summary": 0.001412997877799242, "it directly": 0.0008837126637559662, "doors": 0.0019052819191541965, "to illustrate": 0.00035948801871575067, "when the": 0.0005012206551348241, "examples collected": 0.0013439565011394887, "to our neural": 0.001412997877799242, "provide detailed": 0.0010706929277613088, "the robot starting": 0.002825995755598484, "wall 2 3": 0.001412997877799242, "15 inputs": 0.0013439565011394887, "taxonomy of different": 0.001412997877799242, "introduction programming": 0.0012263127867333846, "right wall back": 0.004238993633397726, "real robot called": 0.001412997877799242, "net learning framework": 0.001412997877799242, "based architecture": 0.0016867308285449859, "learning behaviors": 0.001157470080128191, "object": 0.00023955877277045387, "directly learns a": 0.001412997877799242, "from sensor data": 0.001412997877799242, "robot has to": 0.004238993633397726, "to rote learning": 0.001412997877799242, "illustrate the": 0.00035757073401193715, "a ring": 0.0007652009340995504, "learn multiple": 0.0024526255734667692, "it continues": 0.0007897242543278053, "the concept": 0.0011181804464815367, "present the results": 0.0007340240462866124, "state estimation procedure": 0.004238993633397726, "difficult for a": 0.001021962604845781, "partic ular": 0.000872702844207972, "trained on 872": 0.002825995755598484, "stopped adjacent to": 0.001412997877799242, "helps to use": 0.001412997877799242, "images into 400": 0.001412997877799242, "the robot around": 0.001412997877799242, "observation": 0.0008219640112802918, "trained neural net": 0.002825995755598484, "complex function from": 0.001412997877799242, "purpose of": 0.0006904060958806159, "detectors": 0.007374481185542422, "testing the": 0.0005978790985189038, "are interesting tasks": 0.001412997877799242, "we are": 0.0001907307197965436, "an artificial neural": 0.0012265208479459286, "hits a smooth": 0.001412997877799242, "for state": 0.0007246032270542877, "applicable to other": 0.0009909470066802508, "four different": 0.000634544764829945, "using a": 0.0014476055336305723, "actual use": 0.0010706929277613088, "with which sensor": 0.001412997877799242, "when the robot": 0.002453041695891857, "find items of": 0.001412997877799242, "signatures": 0.0005155998940555883, "1 2 0": 0.0008658836593557804, "multiple sonar": 0.0013439565011394887, "by white while": 0.001412997877799242, "for finding": 0.00047636541130555675, "current systems navigation": 0.001412997877799242, "believe that": 0.0003556702752758457, "definite strengths": 0.0013439565011394887, "or containers could": 0.001412997877799242, "examples ffl": 0.0011086075099259812, "5 spatial": 0.0012263127867333846, "the missing components": 0.0012953547128852297, "realize many": 0.0013439565011394887, "robotic systems v": 0.0011397700534482, "the original input": 0.0009909470066802508, "their learning s": 0.001412997877799242, "a smooth flat": 0.001412997877799242, "is required": 0.0005780078036229281, "strategies studied": 0.0013439565011394887, "discussion of": 0.0003686683615353646, "a fairly": 0.0005731297104135156, "see 17": 0.0007246032270542877, "exploited to speed": 0.001412997877799242, "reinforcement learning an": 0.001412997877799242, "the ability": 0.000362071176040203, "also limited since": 0.001412997877799242, "it was only": 0.0011397700534482, "can acquire": 0.0009907789071032058, "13 shows": 0.0006486581696160977, "on decomposing": 0.0012263127867333846, "detector figure": 0.0013439565011394887, "for which": 0.0001909841097252406, "of pavlov": 0.0013439565011394887, "the first idea": 0.0011397700534482, "other approximators e": 0.001412997877799242, "is un": 0.0008837126637559662, "learning 25 are": 0.001412997877799242, "as some": 0.000634544764829945, "id3 decision": 0.0012263127867333846, "acquire useful": 0.0013439565011394887, "tions would": 0.0013439565011394887, "we have found": 0.0005713090990815192, "known in neural": 0.001412997877799242, "this task involves": 0.0012953547128852297, "direct policy": 0.0013439565011394887, "case of a": 0.00048069449339263934, "feedback while a": 0.001412997877799242, "perceive": 0.0007072561018364519, "two realistic": 0.0012263127867333846, "the framework of": 0.0006918115785384662, "approach which": 0.0005583269585823748, "concept previous": 0.0013439565011394887, "acquire new examples": 0.001412997877799242, "using pomdp s": 0.001412997877799242, "to label": 0.0007897242543278053, "sensor this is": 0.001412997877799242, "color camera and": 0.001412997877799242, "at every": 0.0005171034306485431, "state for example": 0.0009773255297405913, "could be in": 0.0009773255297405913, "20060010000 total epochs": 0.001412997877799242, "the net this": 0.001412997877799242, "differs from": 0.00044473608064922096, "the navigation system": 0.004238993633397726, "human designer provides": 0.001412997877799242, "representation computed": 0.0012263127867333846, "architecture chosen": 0.0013439565011394887, "the state": 0.0014857965518357556, "traverse across an": 0.001412997877799242, "however as": 0.00043247585596701806, "node 1": 0.0015082572065016544, "architecture": 0.0010233479657962418, "is able": 0.0021176769359075513, "event markov": 0.0013439565011394887, "be contrasted": 0.0009081111668589885, "can be trained": 0.002453041695891857, "right simultaneously learning": 0.001412997877799242, "tedious task": 0.0010706929277613088, "a normalization": 0.0007832601051609397, "specifies for": 0.001157470080128191, "traverse": 0.0003972663650691326, "architecture using partially": 0.001412997877799242, "map which": 0.0008837126637559662, "an office navigating": 0.001412997877799242, "nevertheless this": 0.0008623569375540945, "in a colored": 0.001412997877799242, "5 ff post": 0.001412997877799242, "related functions for": 0.001412997877799242, "testing": 0.00017919624741306352, "issue on": 0.0007652009340995504, "learning multi output": 0.001412997877799242, "over a period": 0.0018632924969971781, "assumes that": 0.000416660116871978, "result": -0.0004035059680381165, "odometric and": 0.0013439565011394887, "left although it": 0.001412997877799242, "doors and intersec": 0.001412997877799242, "to converge": 0.0005674367630990076, "a highly": 0.0005750676982296913, "data a": 0.001092581550731157, "from labeled training": 0.0012953547128852297, "problem where": 0.0005810090920244843, "form of a": 0.002437559066086877, "can but also": 0.001412997877799242, "artificial": 0.000304037505977001, "of determining": 0.0005413646011976051, "report on by": 0.001412997877799242, "iri": 0.0005829347797504038, "distances using the": 0.0012953547128852297, "several months see": 0.001412997877799242, "could not be": 0.0006439371750110811, "the context of": 0.0003792630375467587, "very near or": 0.001412997877799242, "studies on an": 0.0012953547128852297, "two approaches": 0.0005583269585823748, "right quadrants there": 0.001412997877799242, "avoiding obstacles etc": 0.001412997877799242, "shape salganicoff et": 0.001412997877799242, "run in": 0.0005288373163369861, "introduction learning one": 0.001412997877799242, "figure shows three": 0.0012265208479459286, "camera turn": 0.004031869503418466, "a single yellow": 0.001412997877799242, "coded feature detectors": 0.001412997877799242, "380": 0.0012377209058841675, "were collected by": 0.0011397700534482, "action go forward": 0.001412997877799242, "be easily": 0.0016172497489031635, "for selecting": 0.0006140604889952477, "of research": 0.00051288702773971, "robot around": 0.0013439565011394887, "modeling": 0.00011922419328504876, "picking": 0.001054479939150816, "these examples specularities": 0.001412997877799242, "00110011001101010011 001100000000000000000000000001111111111111111111111111000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111111110000011111000000000000000000000000011111111111111111111111110000011111": 0.0013439565011394887, "study is one": 0.0012953547128852297, "opening wall": 0.008063739006836932, "planner": 0.002201325167306628, "discrete time model": 0.0011087956007827721, "variant of the": 0.000627558497619122, "distinct regions": 0.0009707370964526472, "of occupancy": 0.0012263127867333846, "country": 0.0007156559879878064, "represented by white": 0.001412997877799242, "uncertainty": 0.0012917469223563008, "an adjacent": 0.000872702844207972, "learning methods": 0.0016692047246236218, "two advantages": 0.0008837126637559662, "contrast some recent": 0.001412997877799242, "system 22 for": 0.001412997877799242, "while a detailed": 0.0012953547128852297, "was it easy": 0.001412997877799242, "adapted": 0.00027033016681880426, "generalizing user": 0.0013439565011394887, "pre": 0.0006787740554587339, "the output": 0.0018735893682398552, "learning is impossible": 0.001412997877799242, "event based semi": 0.001412997877799242, "as trash": 0.0013439565011394887, "although we believe": 0.001177670521728601, "this approach could": 0.0011087956007827721, "over deeper": 0.0013439565011394887, "grids this": 0.001157470080128191, "is s mahadevan": 0.001412997877799242, "white we": 0.0012263127867333846, "height": 0.0003867821044335866, "environmental setup": 0.0013439565011394887, "a physically occupied": 0.001412997877799242, "pavlov 1 a": 0.001412997877799242, "of their": 0.00023210786354829725, "specified by the": 0.0012156519791460328, "exploration in": 0.0009907789071032058, "our system": 0.0005142819462320132, "256": 0.0003506226265365639, "this approach b": 0.0011397700534482, "platform 4": 0.0012263127867333846, "structure we": 0.0006265849827685552, "an office": 0.0009907789071032058, "be viewed as": 0.00044319614193501705, "right opening": 0.0026879130022789775, "some sort": 0.0007652009340995504, "space bias which": 0.001412997877799242, "receptacle the": 0.0013439565011394887, "the results": 0.0004461319763603468, "for these": 0.00025965230822482124, "trees over deeper": 0.001412997877799242, "test the net": 0.001412997877799242, "three": -0.0013089883799194308, "functions for ex": 0.001412997877799242, "learning based on": 0.0022175912015655443, "much": -0.0011778691879488225, "was then used": 0.0010057508064281846, "basic": -0.00018963584597808257, "burden on the": 0.000887696035668378, "image can contain": 0.001412997877799242, "this work": 0.00019131661464976625, "distinct training": 0.0013439565011394887, "learns a policy": 0.001412997877799242, "learning the rest": 0.001412997877799242, "switches are also": 0.0012953547128852297, "net despite significant": 0.001412997877799242, "not every action": 0.001412997877799242, "pulse hits a": 0.001412997877799242, "architecture 2 as": 0.001412997877799242, "among the": 0.000534656761842527, "deeper": 0.0005213289159674361, "navigation and learning": 0.001412997877799242, "will be made": 0.0008405371151868688, "for example a": 0.00046712753599268975, "task for example": 0.001021962604845781, "using an": 0.0006590675577946573, "observation ff post": 0.001412997877799242, "these con ditions": 0.001412997877799242, "10 by": 0.0008034263695325692, "recognize visual": 0.0013439565011394887, "which demonstrates that": 0.001412997877799242, "robot to maintain": 0.001412997877799242, "trainer provides the": 0.001412997877799242, "thrun and": 0.0013439565011394887, "and right each": 0.001412997877799242, "5 discusses the": 0.0009647109541934066, "image processing a": 0.0011087956007827721, "is learned since": 0.001412997877799242, "is in": 0.00012454497265531136, "execution system": 0.001157470080128191, "such as its": 0.0010826007236946758, "allowed compass directions": 0.001412997877799242, "alvinn 22 has": 0.001412997877799242, "employ": 0.0002625661276339196, "combines a": 0.0009217509760058083, "near": 0.0021697052693001252, "an active learning": 0.0012953547128852297, "based approaches with": 0.001412997877799242, "update starting off": 0.001412997877799242, "as well": 0.00019445741550765203, "convergence here": 0.0013439565011394887, "the action go": 0.001412997877799242, "actuator and": 0.0013439565011394887, "tractable section": 0.0013439565011394887, "ronment the pomdp": 0.001412997877799242, "we calculate": 0.00066081832163666, "layer local": 0.0013439565011394887, "meters odometric": 0.0013439565011394887, "representatives of": 0.0008433654142724929, "here for every": 0.001412997877799242, "details of the": 0.0010568459112357403, "neural net produces": 0.001412997877799242, "is": 0, "ir": 0.0004342395610180027, "10 the navigational": 0.001412997877799242, "it": 0, "and sensor errors": 0.001412997877799242, "task of": 0.0008894721612984419, "1024 8": 0.0012263127867333846, "cans": 0.009808838368783313, "pursuit steering model": 0.001412997877799242, "in": 0, "to synthesize": 0.0007541286032508272, "requires running the": 0.001412997877799242, "certain hypotheses and": 0.001412997877799242, "if": -0.004433677931488235, "environments including": 0.0013439565011394887, "is generally defined": 0.001412997877799242, "image of a": 0.0007542565517753014, "partioning and": 0.0013439565011394887, "make": -0.0008404624355337584, "been well studied": 0.0010826007236946758, "neural net to": 0.004238993633397726, "converge it": 0.0012263127867333846, "the bottom": 0.0008559109494484805, "months see figure": 0.001412997877799242, "lying on": 0.0008433654142724929, "to sufficiently": 0.0011086075099259812, "a specified trash": 0.001412997877799242, "generates four distinct": 0.001412997877799242, "0 20 2": 0.001177670521728601, "seems clear that": 0.0010599041887614004, "of the yellow": 0.0012953547128852297, "use an event": 0.0012953547128852297, "for providing": 0.0005156873579901185, "probabilistic navigation": 0.0013439565011394887, "templates": 0.0005046433607380987, "fairly": 0.0009161792600724251, "providing labeled examples": 0.001412997877799242, "learning for mobile": 0.01554297665579166, "some sample": 0.0009217509760058083, "value because": 0.0009365728948883588, "ingredients of": 0.0010397031738864368, "significant sensor noise": 0.001412997877799242, "that there": 0.00014578533431555956, "restrict the": 0.00048818009817504264, "prior when the": 0.001412997877799242, "identified the hsi": 0.001412997877799242, "declarative": 0.0009737649988576006, "represen tation such": 0.001412997877799242, "such as when": 0.0009909470066802508, "experimental studies": 0.000872702844207972, "inputs is": 0.0008346023623118109, "n khaleeli front": 0.001412997877799242, "mobile robot called": 0.001412997877799242, "relatively rapid training": 0.001412997877799242, "drop items inside": 0.001412997877799242, "differs from our": 0.0010599041887614004, "labeled training instances": 0.001412997877799242, "digital image processing": 0.001021962604845781, "or even": 0.0004175067704633859, "detectors we": 0.0011086075099259812, "d which": 0.000600103348117393, "missing components being": 0.001412997877799242, "landmarks such": 0.0013439565011394887, "872 hand labeled": 0.002825995755598484, "concept of": 0.000362071176040203, "knowledge or bias": 0.001412997877799242, "not be": 0.00013446595011144672, "strict consistency": 0.001157470080128191, "in robotics": 0.0019815578142064116, "methods in": 0.0003935274301807659, "can 4": 0.001157470080128191, "partition a": 0.0007488464497674484, "for all i": 0.0005972450651146496, "of steering": 0.0012263127867333846, "many circumstances because": 0.001412997877799242, "left": -0.0006555930724587473, "partially observable markov": 0.0025907094257704593, "4 5": 0.0004995059879601759, "to light variations": 0.001412997877799242, "4 2": 0.00013360717198500192, "just": -0.00020890620972126823, "4 0": 0.0005171034306485431, "knowledge based source": 0.001412997877799242, "node 1 doing": 0.001412997877799242, "is the aggregate": 0.001177670521728601, "navigation problem where": 0.001412997877799242, "recycling task pavlov": 0.001412997877799242, "n 2": 0.00012370422214331007, "platform section": 0.0013439565011394887, "cans a b": 0.001412997877799242, "system although": 0.0009365728948883588, "human": 0.0028015133586510536, "learning based": 0.0018731457897767177, "with significant sensor": 0.001412997877799242, "yet": 5.85860018896366e-05, "trash can was": 0.0025907094257704593, "previous": -0.000425902365371923, "of 85": 0.0010706929277613088, "strategies was": 0.0013439565011394887, "an abstract action": 0.001412997877799242, "that collecting and": 0.001412997877799242, "under uncertainty discrete": 0.001412997877799242, "features from": 0.0016214159433796539, "had": 8.167554256280814e-05, "rgb values of": 0.001412997877799242, "3 is": 0.00027479375950829443, "has been almost": 0.0012953547128852297, "output learning multi": 0.001412997877799242, "symbolic learning methods": 0.001412997877799242, "easy": -0.0001590913292603745, "in figure 10": 0.0005764690730021806, "is initially unobservable": 0.001412997877799242, "input units": 0.0009907789071032058, "has": 0, "23 and": 0.0005601128957225589, "concepts figure": 0.001157470080128191, "khaleeli 3": 0.0013439565011394887, "khaleeli 2": 0.0026879130022789775, "khaleeli 1": 0.0013439565011394887, "applicable to": 0.00043898269583821114, "4 s": 0.0007488464497674484, "in the alvinn": 0.001412997877799242, "with labeled examples": 0.001412997877799242, "possible": -0.00285819777479094, "given the state": 0.0012265208479459286, "over another e": 0.001412997877799242, "batch update starting": 0.001412997877799242, "capturing subsequent": 0.0013439565011394887, "model based": 0.0005601128957225589, "the robot s": 0.0021652014473893515, "white while black": 0.001412997877799242, "shows a successful": 0.0012953547128852297, "multi output": 0.006238219043318621, "observations s": 0.0012263127867333846, "number of training": 0.0008658836593557804, "tasks involving": 0.0010706929277613088, "by contrast": 0.0006372791512719589, "since all sensors": 0.001412997877799242, "left and": 0.00044473608064922096, "training phase": 0.001013492172364257, "than non learning": 0.001412997877799242, "a more flexible": 0.0009529642174527608, "robot as it": 0.002825995755598484, "post this is": 0.0012953547128852297, "multiple sonar readings": 0.001412997877799242, "network were": 0.0012263127867333846, "knowledge can be": 0.0009909470066802508, "navigation despite noisy": 0.001412997877799242, "algorithm called": 0.0006672272054388769, "by specular reflections": 0.001412997877799242, "pixel in": 0.0007595764743381157, "acknowledgements this research": 0.0009909470066802508, "takes into account": 0.000684465666466304, "learning grasping to": 0.001412997877799242, "robots the first": 0.001412997877799242, "pursuit steering": 0.0013439565011394887, "navigation system similarly": 0.001412997877799242, "user labeled training": 0.001412997877799242, "on a": 0.0002580388332218443, "opening in": 0.0013439565011394887, "systems v 39": 0.001177670521728601, "decomposable in": 0.0013439565011394887, "right": -0.0011660227034701739, "and noisy the": 0.001412997877799242, "results not": 0.0009081111668589885, "opposed to using": 0.0012265208479459286, "of training examples": 0.0008956300062288188, "sensor model is": 0.001412997877799242, "dimensional vector": 0.0007291894113705743, "of input": 0.00047522317659804645, "shows our": 0.000872702844207972, "which restrict": 0.0010706929277613088, "images with the": 0.0022795401068964, "in both examples": 0.001177670521728601, "specularities and other": 0.002825995755598484, "and pick up": 0.0012953547128852297, "of concepts": 0.0008346023623118109, "figure 14 shows": 0.0008591880780779472, "setup for": 0.0010706929277613088, "possible applications": 0.0009365728948883588, "models fast vision": 0.001412997877799242, "for": 0, "bottom": 0.0005991201816046961, "manually labeled": 0.0013439565011394887, "decomposed into a": 0.0008527436549416518, "the second strategy": 0.001039879574153469, "data has": 0.0006916942228847701, "after an": 0.0005810090920244843, "any criterion for": 0.001412997877799242, "by the user": 0.0006047387441135462, "since not every": 0.0012953547128852297, "taken in this": 0.0010057508064281846, "in fact": 0.00016506159155697532, "the framework": 0.0004810038155285948, "the hsi values": 0.001412997877799242, "front far": 0.004031869503418466, "sort that can": 0.001412997877799242, "curve for neural": 0.001412997877799242, "then sub": 0.0013439565011394887, "builds on a": 0.0011087956007827721, "also shows an": 0.0012265208479459286, "control architec": 0.0013439565011394887, "predicting": 0.00038824777280147167, "outputs hidden": 0.0013439565011394887, "learning algorithm called": 0.001412997877799242, "e g": 0.0018053341439223279, "layered control system": 0.001412997877799242, "reader to other": 0.001412997877799242, "limitations of the": 0.000777160622754577, "probability with which": 0.001177670521728601, "reactive architecture": 0.0013439565011394887, "across the": 0.00042441161427938937, "a human designer": 0.002453041695891857, "very noticeable in": 0.001412997877799242, "by additional training": 0.002825995755598484, "figure 9 illustrates": 0.0009773255297405913, "effectiveness of the": 0.0012729419538147443, "using spatial": 0.0009907789071032058, "is to partition": 0.0009316462484985891, "work in": 0.0003030867120053449, "probably the": 0.0007437201166480605, "sufficiently diverse": 0.0013439565011394887, "the distance": 0.0007320100906302224, "net feature detectors": 0.002825995755598484, "or instance based": 0.001412997877799242, "robots that": 0.0012263127867333846, "o": -0.00019816195163404284, "of different type": 0.0012265208479459286, "to make the": 0.00046640118366471773, "net does an": 0.001412997877799242, "the university of": 0.0005831325859193046, "new concepts": 0.001013492172364257, "in some details": 0.001412997877799242, "representation the effectiveness": 0.001412997877799242, "description e g": 0.0012265208479459286, "although the multi": 0.001412997877799242, "learning section": 0.001157470080128191, "work is": 0.0006361123799334361, "one pixel in": 0.001412997877799242, "methods have also": 0.0010826007236946758, "it possible to": 0.0005928942145642387, "a2 pose a3": 0.001412997877799242, "up litter": 0.0013439565011394887, "an id3": 0.0013439565011394887, "decision trees over": 0.001177670521728601, "space and": 0.0003920243363346696, "distribution is ff": 0.001412997877799242, "possibilities door wall": 0.001412997877799242, "necessary since": 0.0007964395063592673, "a large state": 0.0011087956007827721, "that could be": 0.000655760894139667, "to implement and": 0.0008291394238884059, "and intersec tions": 0.001412997877799242, "0 0 of": 0.002453041695891857, "often": -0.00040489557097796007, "right front": 0.0012263127867333846, "adapted to": 0.00051288702773971, "states where": 0.0008107079716898269, "desired target": 0.0010706929277613088, "robots robotics": 0.0013439565011394887, "data acknowledgements": 0.0013439565011394887, "it to other": 0.0011087956007827721, "support": -6.883527834986148e-06, "approximate": 0.00012089162764668104, "front or right": 0.001412997877799242, "constrain the set": 0.001412997877799242, "room for improvement": 0.0009909470066802508, "wiping out": 0.0013439565011394887, "grasping": 0.0009906108645477269, "tasks described": 0.001157470080128191, "will reflect away": 0.001412997877799242, "learning these": 0.0010397031738864368, "separate feature": 0.0013439565011394887, "recognition in voronoi": 0.001412997877799242, "currently an": 0.001013492172364257, "generalizing user labeled": 0.001412997877799242, "enable a more": 0.0012265208479459286, "generally less": 0.0009365728948883588, "each image generates": 0.001412997877799242, "february 2004": 0.0006772995603809331, "approaches to this": 0.0009419732139289226, "form": -0.001800322583933136, "task nevertheless": 0.0013439565011394887, "backpropagation algorithm": 0.0010706929277613088, "from different sensors": 0.0012953547128852297, "4 recycling": 0.0013439565011394887, "chosen for the": 0.0008184493641822325, "err figure": 0.0013439565011394887, "position d which": 0.001412997877799242, "into multiple": 0.0007338995299089556, "set of single": 0.0012953547128852297, "to complete the": 0.0005687830365613714, "in a subsequent": 0.0008591880780779472, "examples specularities dominate": 0.001412997877799242, "priori knowledge": 0.0007488464497674484, "space gray areas": 0.001412997877799242, "the quickprop": 0.0013439565011394887, "location in its": 0.0012953547128852297, "communication is": 0.0005548065944701884, "builds": 0.0003781977441310188, "detectors one each": 0.001412997877799242, "away from": 0.0004217943582731198, "100x100 color": 0.0013439565011394887, "is one where": 0.0019059284349055216, "inside": 0.00037660798055062035, "six element vector": 0.001412997877799242, "y meters": 0.0013439565011394887, "whether the": 0.00027748180165419403, "in the electrical": 0.0012953547128852297, "right top bottom": 0.001412997877799242, "id3 decision tree": 0.0012953547128852297, "generalization over another": 0.001412997877799242, "over a": 0.0005631370523523954, "in both updates": 0.001412997877799242, "a reactive layer": 0.001412997877799242, "examples": -0.001050010902826092, "behaviors implement a": 0.001412997877799242, "for learning optimal": 0.001412997877799242, "located adjacent to": 0.0012265208479459286, "state this assumes": 0.001412997877799242, "partially observable": 0.0033258225297779433, "that despite": 0.0008346023623118109, "errors the robot": 0.001412997877799242, "such a large": 0.0009316462484985891, "model to": 0.0004306553494041702, "the maximum value": 0.0007158988301961499, "the sonar": 0.0013439565011394887, "control structure for": 0.0012953547128852297, "multiple concepts simultaneously": 0.0025907094257704593, "including offices and": 0.001412997877799242, "than 10 by": 0.001412997877799242, "the backpropagation algorithm": 0.001177670521728601, "layer the": 0.0014583788227411486, "recycling where the": 0.001412997877799242, "learn related": 0.0013439565011394887, "based on scaling": 0.0012953547128852297, "vehicle for": 0.0009081111668589885, "learning the feature": 0.001412997877799242, "since not": 0.0009081111668589885, "is fairly well": 0.0012953547128852297, "could be adapted": 0.0010599041887614004, "floor": 0.002655524261985386, "for each state": 0.000794306715118076, "into multiple quadrants": 0.001412997877799242, "generally": 0.00012630918138409515, "hand labeled": 0.0024526255734667692, "specular reflections": 0.004031869503418466, "by the robot": 0.0011087956007827721, "in neural": 0.0009528025610969587, "additional training also": 0.001412997877799242, "computer science": 0.0006031820594387276, "and recycling task": 0.001412997877799242, "digital": 0.00019902482152893484, "out of": 0.0002815685261761977, "prediction of": 0.0006214693208023149, "is substantially": 0.0007157773884946746, "current camera": 0.0012263127867333846, "provided using": 0.0010706929277613088, "range that": 0.0009217509760058083, "section 5 discusses": 0.0008184493641822325, "fairly smooth": 0.0012263127867333846, "khaleeli 3 2": 0.001412997877799242, "in positions a": 0.001412997877799242, "left although": 0.0013439565011394887, "f front very": 0.001412997877799242, "models": -0.00010442767241899304, "the set": 0.0003134124713782691, "details of": 0.0010338077977066031, "the underlying": 0.0002996112537725951, "a result the": 0.0006125588532215851, "visual objects": 0.0010397031738864368, "strategy used": 0.0007652009340995504, "a probabilistic framework": 0.001177670521728601, "17 it is": 0.0009126929338602609, "computing computer": 0.0012263127867333846, "probabilistic navigation and": 0.001412997877799242, "g even a": 0.001412997877799242, "execution of an": 0.00084653211689172, "will reflect": 0.0010706929277613088, "optimized variant": 0.0013439565011394887, "readings figure 2": 0.001412997877799242, "work on concept": 0.0012953547128852297, "c1 pose": 0.0013439565011394887, "s 2 in": 0.0009647109541934066, "21 3 bias": 0.001412997877799242, "robot technology 7": 0.001412997877799242, "ingredients of the": 0.0012265208479459286, "for example tan": 0.001412997877799242, "investigated for": 0.0008954780757782285, "it performed": 0.0010397031738864368, "this approach is": 0.00048384461294260876, "learning where": 0.0009217509760058083, "such as alvinn": 0.001412997877799242, "concepts results": 0.0013439565011394887, "sonar signatures we": 0.001412997877799242, "first took various": 0.001412997877799242, "to accurately": 0.0006879834963441684, "time": -0.001275658699845673, "this problem": 0.0001980382545345598, "output space could": 0.001412997877799242, "predict features in": 0.0012953547128852297, "robot to dangerous": 0.001412997877799242, "at node": 0.000631851774969883, "learn a": 0.002369172762983416, "easing this": 0.0013439565011394887, "the bottom figure": 0.0022795401068964, "were labeled": 0.0011086075099259812, "here for": 0.0005413646011976051, "a taxonomy": 0.0007595764743381157, "those values": 0.0008433654142724929, "the on board": 0.001412997877799242, "the floor": 0.0008837126637559662, "concepts being": 0.0012263127867333846, "for robots a": 0.001412997877799242, "general the": 0.00041165347984768047, "slippage uneven floors": 0.001412997877799242, "topic for research": 0.001412997877799242, "our robot pavlov": 0.001412997877799242, "bias decomposition": 0.0013439565011394887, "good example": 0.0007964395063592673, "these reasons we": 0.0009419732139289226, "uneven": 0.000789590311950884, "the aggregate of": 0.001177670521728601, "viewed as": 0.0003329223412282485, "near err": 0.0013439565011394887, "figure shows our": 0.0012265208479459286, "are difficult": 0.000634544764829945, "experiment the": 0.0006240088185900783, "that bias": 0.0012263127867333846, "0": -0.003934312636365113, "finally": -0.0002073059054982253, "examples have not": 0.001412997877799242, "is given by": 0.0003503309520952537, "surface angled": 0.0013439565011394887, "the different": 0.0003428109805602289, "right each sensor": 0.001412997877799242, "a relatively": 0.00045677604970636396, "sensors avoid bump": 0.001412997877799242, "are studied": 0.0006738777284751093, "navigation architecture based": 0.001412997877799242, "this can is": 0.001412997877799242, "will show below": 0.0010826007236946758, "in many circumstances": 0.0011087956007827721, "followed by a": 0.0005675330367269512, "to recognize these": 0.001177670521728601, "figure 11 shows": 0.000747247581202698, "considerable trial and": 0.001412997877799242, "output by the": 0.0009419732139289226, "the robotic": 0.0012263127867333846, "geometrical": 0.0005396598631594049, "robot that could": 0.001412997877799242, "over multiple": 0.0007652009340995504, "pose d1 figure": 0.001412997877799242, "is shown": 0.0001779446623177183, "learning to recognize": 0.0010826007236946758, "context where": 0.0009528025610969587, "robot called pavlov": 0.002825995755598484, "learning vs single": 0.001412997877799242, "other sources for": 0.001412997877799242, "to show": 0.00020769095467997116, "simpler feature based": 0.001412997877799242, "sub sampling": 0.0011086075099259812, "autonomous navigation induction": 0.001412997877799242, "each sensor this": 0.001412997877799242, "true color value": 0.001412997877799242, "shape salganicoff": 0.0013439565011394887, "the desired": 0.0009062656445154554, "both problems": 0.0007897242543278053, "combined with the": 0.0006684317399421915, "all training examples": 0.0011087956007827721, "a multi": 0.0013001772323028157, "pentium processor figure": 0.001412997877799242, "o is the": 0.0008801129633255439, "many objects using": 0.001412997877799242, "a wall on": 0.001412997877799242, "boada d": 0.0013439565011394887, "directions the": 0.0007964395063592673, "on the right": 0.0004987046829938479, "find and pick": 0.001412997877799242, "d1 figure 16": 0.001412997877799242, "robotics the alvinn": 0.001412997877799242, "of the robot": 0.004330402894778703, "accommodated by additional": 0.001412997877799242, "by 2": 0.0004506632696548802, "navigation and recycling": 0.001412997877799242, "findings": 0.0005073230083137942, "insignificant": 0.0005428999532193917, "make it feasible": 0.0012265208479459286, "dealing": 0.0002941996362598552, "a separate set": 0.0010599041887614004, "definite strengths as": 0.001412997877799242, "prediction": 0.0006141395591907539, "was studied in": 0.0009316462484985891, "is an extremely": 0.0018078982588359625, "in the navigation": 0.004906083391783714, "robot temporarily": 0.0013439565011394887, "concept learning": 0.021817571105199298, "subsampled image": 0.0013439565011394887, "the hsi": 0.0013439565011394887, "figure 8 learning": 0.001412997877799242, "trash can which": 0.001412997877799242, "which the desired": 0.001039879574153469, "since we use": 0.0009773255297405913, "with several hundred": 0.001412997877799242, "shows only the": 0.0010826007236946758, "robot figure shows": 0.001412997877799242, "our robot": 0.001157470080128191, "mobile robot multitask": 0.001412997877799242, "ethernet system although": 0.001412997877799242, "and sensor uncer": 0.001412997877799242, "left right top": 0.001177670521728601, "period of": 0.0009715156107730856, "learning is": 0.0054828207361265775, "strategy used in": 0.001039879574153469, "current": -0.0003518063814573563, "suggest that": 0.0009135520994127279, "illustrates the basic": 0.0012265208479459286, "if sensor i": 0.001412997877799242, "in each direction": 0.0008956300062288188, "two robotics": 0.0013439565011394887, "that the sonar": 0.001412997877799242, "navigating to": 0.0024526255734667692, "department where much": 0.001412997877799242, "where we investigated": 0.001412997877799242, "traditional state": 0.001157470080128191, "filled": 0.00043058230745210023, "tasks described above": 0.0012953547128852297, "by q": 0.0006486581696160977, "show several": 0.001013492172364257, "have attempted": 0.0008623569375540945, "in particular by": 0.001021962604845781, "4 figure 15": 0.001412997877799242, "present the": 0.0006403970823306306, "maintain belief": 0.0013439565011394887, "9 a where": 0.001412997877799242, "3 image of": 0.001412997877799242, "by a": 1.771716087660685e-05, "learning from": 0.0021738096811628627, "shared structure": 0.002314940160256382, "the data is": 0.001255116995238244, "with those": 0.0004994807428611434, "along": -3.006689197145425e-05, "particular navigation run": 0.001412997877799242, "distinct regions and": 0.001412997877799242, "when a sonar": 0.001412997877799242, "it feasible to": 0.0010599041887614004, "box": 0.0003010434787842052, "reader to": 0.0005462907753655785, "grid in": 0.0007595764743381157, "additional training": 0.0019414741929052945, "occupancy grids were": 0.001412997877799242, "variations 10": 0.0013439565011394887, "bias acting": 0.0013439565011394887, "studied": 0.0003676878258332922, "the top figure": 0.0012953547128852297, "a2 pose": 0.0013439565011394887, "concepts in this": 0.0011087956007827721, "on 872 hand": 0.002825995755598484, "accomplished": 0.0006392137352776795, "simultaneous": 0.00028754381816292166, "robot testbed": 0.0026879130022789775, "and simultaneous": 0.0009217509760058083, "provided in addition": 0.001412997877799242, "2 two example": 0.001412997877799242, "teacher for providing": 0.001412997877799242, "studies": 0.0007142191208765178, "shallower decision": 0.0013439565011394887, "approach for learning": 0.0012953547128852297, "data the philosophy": 0.001412997877799242, "tasks": 0.0019295143021944455, "useful": -0.0002765050299771467, "of which is": 0.0005419974286394517, "the desired target": 0.0012265208479459286, "pentium": 0.00045159223660540243, "inputs the sub": 0.001412997877799242, "learning autonomous robots": 0.001412997877799242, "prefer": 0.0004252195666152243, "c2 trace the": 0.001412997877799242, "logical": 0.0004671848290441732, "action is": 0.0006372791512719589, "a set": 0.00019659208136719162, "robot learns": 0.0024526255734667692, "based methods": 0.0006265849827685552, "new features": 0.0007832601051609397, "net is able": 0.004238993633397726, "which combines a": 0.0012265208479459286, "starting position south": 0.001412997877799242, "some bleed": 0.0013439565011394887, "a feedforward": 0.0033258225297779433, "figure 6 learning": 0.001412997877799242, "runs on": 0.0006400562598342001, "several reasons sensory": 0.001412997877799242, "as some key": 0.0012953547128852297, "of hypotheses space": 0.001412997877799242, "of the engineering": 0.003679562543837785, "turret": 0.0012261047960979141, "addition although examples": 0.001412997877799242, "learning 25": 0.0013439565011394887, "induction of decision": 0.0009773255297405913, "single output learning": 0.001412997877799242, "learning 20": 0.0026879130022789775, "scenarios": 0.0003810202894068864, "selecting one generalization": 0.001412997877799242, "with the training": 0.001039879574153469, "find items": 0.0013439565011394887, "opposed": 0.0003164086905168396, "mainly focus": 0.001013492172364257, "a state": 0.00041497740689740804, "scope": 0.00026858453219880953, "robot with": 0.0011086075099259812, "thru": 0.0009906108645477269, "a simpler feature": 0.001412997877799242, "net despite": 0.0013439565011394887, "to dangerous": 0.0013439565011394887, "of a simpler": 0.0012265208479459286, "pavlov": 0.01995155069169706, "sharing": 0.00028106345688975554, "yet the neural": 0.001412997877799242, "of virtual sensors": 0.001412997877799242, "observation door": 0.0013439565011394887, "there are": 0.00014253306517382272, "key limitations ffl": 0.001412997877799242, "learns not": 0.0013439565011394887, "acceptable": 0.0003122119325467533, "apparent": 0.000300053763988856, "bias e": 0.0013439565011394887, "to create hard": 0.001412997877799242, "for ex ample": 0.0006943301413393709, "observable semi": 0.0013439565011394887, "the bias": 0.0007338995299089556, "visual": 0.0006567194973109232, "studied in machine": 0.001412997877799242, "mobile robots 900000000000000000000000000000000011111111111111111111111111111111111111111111000000000000000000000000000000000000111111111111111111111111111111111111": 0.001412997877799242, "yield fast learning": 0.001412997877799242, "in a ring": 0.001021962604845781, "14 s": 0.0010397031738864368, "is not explicitly": 0.0009647109541934066, "capturing": 0.00041828604422928216, "learning scenarios": 0.0013439565011394887, "valued": 0.0005961730421365296, "used in domains": 0.0012953547128852297, "values hue saturation": 0.001412997877799242, "finding invariances": 0.0013439565011394887, "avoiding": 0.00031535237792390536, "navigation robot learning": 0.001412997877799242, "the net": 0.004305217693584034, "the results suggest": 0.0012265208479459286, "believes": 0.0006842334867965392, "account both": 0.0009217509760058083, "study was carried": 0.001177670521728601, "values": -0.002583507334464093, "o ojs ff": 0.001412997877799242, "the net is": 0.004159518296613876, "near very": 0.004031869503418466, "making": 4.100241816959357e-05, "a hybrid declarative": 0.001412997877799242, "one set": 0.0006516207816749321, "concepts can be": 0.0010057508064281846, "times and succeeded": 0.001412997877799242, "9 16": 0.0008346023623118109, "east navigation": 0.005375826004557955, "is halved from": 0.001412997877799242, "grid was then": 0.001412997877799242, "predict": 0.00172526290897753, "experiments were": 0.0005258336588949284, "inputs 6 outputs": 0.001412997877799242, "right figure 5": 0.0012953547128852297, "7 a": 0.00045267962576384373, "sample": 0.0007988269088062615, "of these strategies": 0.0010599041887614004, "to program": 0.0006092863925155239, "figure 9 sample": 0.001412997877799242, "allowed": 8.742639133692214e-05, "estimation to localize": 0.001412997877799242, "mobile robots 7": 0.001412997877799242, "pulse hits": 0.0013439565011394887, "include ultrasound sonar": 0.001412997877799242, "or the": 0.00018310109020190367, "s mahadevan": 0.013439565011394887, "work on systems": 0.001412997877799242, "as alvinn": 0.0013439565011394887, "iri 9501852": 0.0013439565011394887, "approximate location": 0.001013492172364257, "200 platform": 0.0013439565011394887, "in such cases": 0.000655760894139667, "till": 0.0005302676407505448, "decomposition and sharing": 0.001412997877799242, "sensor reports from": 0.001412997877799242, "box are": 0.0010397031738864368, "on the human": 0.001412997877799242, "optimal": -1.7714155930732255e-05, "a nomad": 0.0036789383602001536, "situation this is": 0.001412997877799242, "rapid within task": 0.001412997877799242, "that a human": 0.001412997877799242, "inputs": 0.0013297253051104468, "problem sensory data": 0.001412997877799242, "designer": 0.0019786782501078097, "results for": 0.0007078012805523063, "attempted a": 0.0011086075099259812, "because it requires": 0.0009529642174527608, "pavlov to illustrate": 0.001412997877799242, "near b": 0.0013439565011394887, "missing components": 0.0012263127867333846, "some appropriate bias": 0.001412997877799242, "applications": -0.00037660798055062035, "generated by the": 0.0009416019212752498, "programmed or": 0.0012263127867333846, "system 11": 0.0009365728948883588, "framework formally": 0.0013439565011394887, "such": -0.017830995561859086, "data": -0.004059619931331865, "obstacles etc": 0.0013439565011394887, "difficult because": 0.0007770287888915143, "do not discuss": 0.0008728509105201892, "hypotheses and preference": 0.001412997877799242, "that the": 3.933574560150985e-06, "independent 0000000000000000000000000000000000000000000000000000000000000000111111111111111111111111111111111111111111111111111111111111111111111111 sensor": 0.001412997877799242, "a sonar pulse": 0.001412997877799242, "a single": 0.00017593303011641836, "layer with a": 0.001412997877799242, "wish to acknowledge": 0.0010826007236946758, "afforded by such": 0.001412997877799242, "as a local": 0.0009529642174527608, "q": -2.6560668390012828e-05, "which allows a": 0.0009773255297405913, "so": -0.0016693917312352374, "deposit": 0.0014145122036729038, "directions front": 0.0013439565011394887, "because it": 0.0005312058204042253, "and undergo": 0.0013439565011394887, "is not high": 0.001177670521728601, "were the six": 0.001412997877799242, "processes learning": 0.0013439565011394887, "prefer shallower decision": 0.001412997877799242, "was rejected in": 0.0012953547128852297, "from different angles": 0.001412997877799242, "induce features such": 0.001412997877799242, "concepts here": 0.0012263127867333846, "to successful navigation": 0.001412997877799242, "system 22": 0.001157470080128191, "local occupancy grids": 0.002825995755598484, "uses a hybrid": 0.001177670521728601, "also subservient": 0.0013439565011394887, "one multi output": 0.001412997877799242, "experiments": 8.364196356990114e-05, "11 18": 0.0008262639069617736, "and white": 0.0008107079716898269, "is prone to": 0.0010057508064281846, "both examples": 0.0009528025610969587, "differs": 0.00026087184090703777, "equip": 0.0008953261968644262, "make an abstract": 0.001412997877799242, "believe the": 0.0007246032270542877, "contrast some": 0.001157470080128191, "this research was": 0.0012283293459881186, "transducer the possibility": 0.001412997877799242, "input to the": 0.0006497504327944296, "thank": 7.236192845787167e-05, "computer science department": 0.000823711514802973, "interesting": 3.343645607316485e-05, "rote learning": 0.0012263127867333846, "trash e": 0.0013439565011394887, "partitioned we": 0.0013439565011394887, "algorithms which are": 0.0009529642174527608, "the specularities are": 0.002825995755598484, "current systems": 0.0009707370964526472, "0 2 south": 0.001412997877799242, "run with": 0.0006639936831495265, "5 limitations": 0.0011086075099259812, "policy": 0.0009151318637449627, "ours": 0.0003386285417018433, "and homes is": 0.001412997877799242, "main": -0.0002631746595675233, "salganicoff et al": 0.001412997877799242, "and state": 0.0006214693208023149, "discusses the limitations": 0.001412997877799242, "klingspor et": 0.0013439565011394887, "was placed in": 0.0011087956007827721, "it seems clear": 0.001021962604845781, "g see 5": 0.001177670521728601, "were prone to": 0.001412997877799242, "find and": 0.0008262639069617736, "smarter": 0.000852454393186244, "the concept thru": 0.001412997877799242, "grids raw": 0.0013439565011394887, "is very": 0.000224605946097145, "valued input variables": 0.001412997877799242, "it takes noticeably": 0.001412997877799242, "the philosophy adopted": 0.001412997877799242, "if the current": 0.0007812905079402834, "multiple classes using": 0.001412997877799242, "is more complex": 0.0007855213434982123, "its height": 0.0009907789071032058, "to our work": 0.0008184493641822325, "constrain the hypothesis": 0.001412997877799242, "architec ture with": 0.001412997877799242, "system could": 0.0008034263695325692, "is arguable that": 0.0012953547128852297, "of paramount": 0.0009528025610969587, "exploration in general": 0.001412997877799242, "our neural": 0.0013439565011394887, "summary this": 0.0008954780757782285, "work thrun and": 0.001412997877799242, "shows three successful": 0.001412997877799242, "back on": 0.0008034263695325692, "is impossible and": 0.001177670521728601, "or instructed more": 0.001412997877799242, "envi ronment the": 0.0012953547128852297, "net vs training": 0.001412997877799242, "variables were": 0.0009081111668589885, "concept it": 0.0011086075099259812, "the front and": 0.0010826007236946758, "1 dimensional": 0.0007033220515237973, "state distribution now": 0.001412997877799242, "one generalization over": 0.0012953547128852297, "recognize objects such": 0.001412997877799242, "either a": 0.00038611861009950034, "robot generates": 0.0013439565011394887, "experimental setup used": 0.0012953547128852297, "although most of": 0.001177670521728601, "figure 4 only": 0.0012953547128852297, "image into": 0.0007897242543278053, "fairly easy although": 0.001412997877799242, "for each direction": 0.0010599041887614004, "hybrid two": 0.0013439565011394887, "the invariants approach": 0.001412997877799242, "more accurate": 0.00045267962576384373, "both the system": 0.0011397700534482, "ones in the": 0.0008527436549416518, "those using": 0.0009365728948883588, "behavior simply chooses": 0.001412997877799242, "feasible to": 0.0007201345364976421, "on finding invariances": 0.001412997877799242, "trees over": 0.0010397031738864368, "can left front": 0.001412997877799242, "tasks navigation": 0.0012263127867333846, "3rd": 0.0004083139678272771, "vs one": 0.0012263127867333846, "ways of": 0.0005565583063253017, "reactive declarative": 0.0013439565011394887, "office engineering": 0.0013439565011394887, "possible abstract observations": 0.001412997877799242, "snapshots of the": 0.001039879574153469, "pavlov showing": 0.0013439565011394887, "nominal": 0.0005870525139763916, "department nodes 3": 0.001412997877799242, "called pavlov see": 0.001412997877799242, "bias free": 0.0013439565011394887, "each sensor is": 0.0012953547128852297, "dominate": 0.0004797522312196677, "sensor": 0.011443403409588168, "in either": 0.00041921083984002716, "using spatial decomposition": 0.001412997877799242, "pulse will": 0.0013439565011394887, "supervised concept": 0.002314940160256382, "conditions requires": 0.0013439565011394887, "after": -0.0005639578486255253, "complete the task": 0.0011397700534482, "make it": 0.0004427995236991089, "one for": 0.0003428109805602289, "of intelligent and": 0.0011397700534482, "board camera": 0.0013439565011394887, "p 173": 0.0007073760774262461, "labeled real": 0.0013439565011394887, "meters odometric plot": 0.001412997877799242, "possibility": 0.00014370723547951214, "quite": 5.518203723423844e-05, "obtained on": 0.0007073760774262461, "sample trajectories of": 0.0012953547128852297, "see 24": 0.0008262639069617736, "simply chooses": 0.001157470080128191, "input units and": 0.001412997877799242, "robot base which": 0.001412997877799242, "16 many": 0.001157470080128191, "for example the": 0.0009390370159390909, "inductive": 0.0007345405005574222, "reports from": 0.0019815578142064116, "training": 0.007480672203807958, "a process": 0.0004707210961828941, "curve for": 0.0027519339853766737, "related functions": 0.0011086075099259812, "net is still": 0.001412997877799242, "wish to": 0.00035253932089419714, "caruana": 0.0009526409595770983, "models for": 0.00039965180241839, "lab at": 0.0010397031738864368, "learn new": 0.0010706929277613088, "thing": 0.00045361872814018024, "simultaneously learning": 0.0013439565011394887, "001100000000000000000000000001111111111111111111111111000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111111110000011111000000000000000000000000011111111111111111111111110000011111 00000000000000000000000000000011111111111111111111111110000000000000000000000000111111111111111111111111100000000000000000000000001111111111111111111111111000000111111000000111111000000111111": 0.0013439565011394887, "need for": 0.00034580513518074184, "further work": 0.00066081832163666, "first": -0.0024181344354173955, "robots is to": 0.001412997877799242, "that is": 0.00011629801926281095, "that it": 0.0005420129223303995, "approach was rejected": 0.001412997877799242, "obliquely to": 0.0013439565011394887, "we thank": 0.0004740877121676709, "this graph": 0.0005479626095875345, "idea here is": 0.0009529642174527608, "on the": 7.375458755052455e-06, "13 this graph": 0.001412997877799242, "to synthesize new": 0.0012953547128852297, "one": -0.019617676737566626, "near f front": 0.001412997877799242, "as a type": 0.0009419732139289226, "range in": 0.0007770287888915143, "fast": 5.716200265523062e-05, "study of": 0.00031593351733984296, "a subsequent": 0.0006516207816749321, "robot repeated this": 0.001412997877799242, "decomposed into": 0.0010827292023952101, "assumes sensor": 0.0013439565011394887, "i2i given": 0.0013439565011394887, "actual human": 0.0013439565011394887, "the paper": 0.000544444439754741, "that in": 0.00025980877496180387, "takes noticeably": 0.0013439565011394887, "describe a relational": 0.001412997877799242, "little": 8.428366886114715e-05, "tan 26 developed": 0.001412997877799242, "of occupancy grids": 0.001412997877799242, "behavior based architecture": 0.002825995755598484, "robot learns only": 0.001412997877799242, "an adjacent east": 0.001412997877799242, "to localize": 0.000872702844207972, "dimensional concepts from": 0.001412997877799242, "of single": 0.0005913666291750407, "indicate": 4.2499715442402256e-05, "not only was": 0.001412997877799242, "2": 0, "draft": 0.0005364757540301568, "to maintain belief": 0.001412997877799242, "learning one more": 0.001412997877799242, "structures": 6.928177509877552e-05, "to maintain": 0.0004083832322832275, "of features": 0.00126908952965989, "also been": 0.00043156351621725415, "occupancy grid or": 0.001412997877799242, "is computed using": 0.0007542565517753014, "was trained using": 0.0012953547128852297, "procedure that": 0.0006372791512719589, "many objects": 0.0009528025610969587, "opening a": 0.0011086075099259812, "the rest": 0.0002421655119381332, "not discuss": 0.0007115262727613508, "26 developed": 0.0013439565011394887, "accurately": 0.00026512835785796554, "a north south": 0.0012265208479459286, "each for the": 0.0022795401068964, "robot over the": 0.001412997877799242, "little data we": 0.001412997877799242, "two categories": 0.0006672272054388769, "wheel slippage": 0.0013439565011394887, "a is": 0.00021227582613121313, "supervised concept learning": 0.002453041695891857, "can left": 0.0013439565011394887, "quickprop rapid concept": 0.001412997877799242, "vector as its": 0.001412997877799242, "the overall control": 0.004238993633397726, "11": -0.0018477711788624975, "10": -0.0032573997193163498, "13": -0.0014637718739027004, "12": -0.0008101921246948568, "15": -0.001278427470555359, "14": -0.0013829859375104972, "17": -0.000455089610638424, "16": -0.0007675603767863669, "19": -0.00019631153132480377, "18": -0.00017600052152134396, "pavlov showing the": 0.001412997877799242, "various snapshots of": 0.001412997877799242, "restrict possible": 0.0012263127867333846, "sets of": 0.0002370916942542949, "the belief": 0.000872702844207972, "not defined in": 0.001039879574153469, "values that were": 0.0011397700534482, "as doors and": 0.002825995755598484, "were": -0.003422964477125027, "example the": 0.0005396081944514467, "such as a": 0.0011662651718386092, "to speed sensory": 0.001412997877799242, "to ours": 0.0006457442730738455, "components being": 0.0010397031738864368, "figure 9 f": 0.001412997877799242, "a grammar which": 0.001412997877799242, "the study": 0.0004466919402916898, "learn subfunctions": 0.0013439565011394887, "locations": 0.00024609093452407523, "vision guided mobile": 0.001412997877799242, "observable semi markov": 0.001412997877799242, "space with so": 0.001412997877799242, "quadrants": 0.003884484998741076, "indicating the": 0.001191364016566928, "generated over": 0.0011086075099259812, "sensory learning s": 0.001412997877799242, "hundred real": 0.0026879130022789775, "probability distribution on": 0.001021962604845781, "occupied": 0.0010426578319348721, "technology 7": 0.001157470080128191, "shows only": 0.0008525989995294478, "to the net": 0.001039879574153469, "the labels": 0.0006092863925155239, "the effects": 0.0004083832322832275, "robots need to": 0.0012953547128852297, "represent temporally": 0.0013439565011394887, "on the test": 0.0008591880780779472, "the presented": 0.0006738777284751093, "concepts although we": 0.001412997877799242, "steering model": 0.0013439565011394887, "to port": 0.0008107079716898269, "quadrant the": 0.001013492172364257, "instructed": 0.0008181717354969602, "note": -0.0006265081020336994, "the probability with": 0.0011087956007827721, "in particular in": 0.0007988727145907639, "converged": 0.0005636424423664252, "performance": -9.908097581702142e-05, "nodes 3": 0.0008837126637559662, "6 9": 0.0005810090920244843, "organized as follows": 0.0003608369386470323, "200": 0.0007650786762302635, "sensor errors": 0.0013439565011394887, "details of a": 0.0009316462484985891, "trace": 0.0008404540075953159, "track": 0.00024689116366845857, "and distances": 0.0009707370964526472, "data acknowledgements this": 0.001412997877799242, "show below that": 0.0009419732139289226, "pose b1 pose": 0.001412997877799242, "event probabilistic model": 0.001412997877799242, "far fewer inputs": 0.001412997877799242, "mm faculty": 0.0013439565011394887, "navigation system was": 0.001412997877799242, "pair": -9.83228915252028e-07, "complete rapid concept": 0.001412997877799242, "approach and": 0.0004969104621112533, "thrun and mitchell": 0.001412997877799242, "bias investigated here": 0.001412997877799242, "bias to achieve": 0.001412997877799242, "has several hundred": 0.001412997877799242, "and other": 0.0011654971990326262, "where the robot": 0.005181418851540919, "system the": 0.000672725393223849, "is trained on": 0.0021652014473893515, "easy to": 0.0003675021414129034, "of feature": 0.0007291894113705743, "away from the": 0.0006002051640909454, "1 the": 0.00010004131776626533, "previous approaches which": 0.0012953547128852297, "and intersec": 0.0013439565011394887, "concept learning is": 0.002825995755598484, "navigation induction of": 0.001412997877799242, "6 s": 0.0007652009340995504, "easily converted": 0.0009707370964526472, "is facilitated through": 0.001412997877799242, "desired output": 0.0009081111668589885, "training set": 0.0006516207816749321, "and picking": 0.0009707370964526472, "6 illustrates the": 0.0009909470066802508, "discusses some": 0.0008262639069617736, "a similar neural": 0.001412997877799242, "traditional state estimators": 0.001412997877799242, "illustrate the effectiveness": 0.0009909470066802508, "show": -0.0023744139001293713, "be viewed": 0.0003550404693828346, "that spatial decomposition": 0.001412997877799242, "1 learning feature": 0.001412997877799242, "describe a": 0.00039656684508817093, "front far c": 0.001412997877799242, "is trained": 0.001745405688415944, "programmable autonomous vehicle": 0.001412997877799242, "front far d": 0.001412997877799242, "is often very": 0.0021198083775228007, "problem tractable": 0.0010397031738864368, "tainty which allows": 0.001412997877799242, "left front": 0.0024526255734667692, "original sensory space": 0.001412997877799242, "and corresponding": 0.000593511402013939, "to different parts": 0.0012953547128852297, "is the probability": 0.0006207360845490545, "image intensity": 0.0009081111668589885, "implement a similar": 0.001412997877799242, "as to": 0.00032897392462734055, "quite difficult in": 0.0012953547128852297, "to use in": 0.0008291394238884059, "we restrict the": 0.0007855213434982123, "alvinn exploits": 0.0013439565011394887, "realize many of": 0.001412997877799242, "going": 0.00023435744794202238, "black": 0.000643527810341208, "navigation given that": 0.001412997877799242, "quickprop": 0.0024522095921958283, "teacher for": 0.001157470080128191, "labeled examples": 0.004764012805484793, "the starting": 0.0004956383297929675, "descriptions however a": 0.001412997877799242, "depends on a": 0.0007988727145907639, "four virtual": 0.001157470080128191, "a ring two": 0.001412997877799242, "abstract observations in": 0.001412997877799242, "on scaling": 0.0010397031738864368, "is undefined": 0.0007488464497674484, "reports feature f": 0.002825995755598484, "the purposes of": 0.0012995008655888591, "rest of the": 0.00039586993425977764, "the recycling domain": 0.001412997877799242, "the entire": 0.0002417719164892848, "another other": 0.0013439565011394887, "just cited": 0.001157470080128191, "concept thru door": 0.001412997877799242, "using multiple single": 0.001412997877799242, "than traditional": 0.0008525989995294478, "work this": 0.0006576990239911289, "and deposit": 0.0022172150198519623, "hypotheses over": 0.0013439565011394887, "right wall": 0.004629880320512764, "can from the": 0.0012953547128852297, "of inputs": 0.0006265849827685552, "room for": 0.0007201345364976421, "error over": 0.0009217509760058083, "in this work": 0.00057516526655311, "class approach described": 0.001412997877799242, "across the country": 0.001412997877799242, "epochs comparing multi": 0.001412997877799242, "strategies for picking": 0.0012953547128852297, "the left and": 0.0006093897665217193, "color coded": 0.0022172150198519623, "not high": 0.0010397031738864368, "yield": 0.0001472334854233849, "summary": 0.00014960103603323309, "motors turret": 0.0013439565011394887, "infers a symbolic": 0.001412997877799242, "degree of freedom": 0.0008347439643413854, "for several": 0.00044183835550954694, "were used": 0.0004175067704633859, "net feature": 0.005375826004557955, "based approach": 0.00048696509187993325, "3 shows": 0.00038684771632577214, "where": -0.012534566756101968, "of freedom afforded": 0.001412997877799242, "vision": 0.00036860583298015164, "4 recycling the": 0.001412997877799242, "9 b": 0.001368699113876979, "detector figure 8": 0.001412997877799242, "driving is a": 0.001412997877799242, "using the quickprop": 0.001412997877799242, "it uses": 0.000458857097148134, "source of inductive": 0.001412997877799242, "concepts simultaneously using": 0.002825995755598484, "studied on": 0.001013492172364257, "trained using the": 0.001177670521728601, "training patterns": 0.0011086075099259812, "14 because it": 0.001412997877799242, "very well": 0.0005565583063253017, "by the trained": 0.0025907094257704593, "14 environmental": 0.0013439565011394887, "based maps by": 0.001412997877799242, "camera of": 0.001157470080128191, "can be contrasted": 0.0012265208479459286, "task of recognizing": 0.0012953547128852297, "real robot platform": 0.001412997877799242, "close to": 0.00025260263641748923, "fact in": 0.0006291989168691914, "research since there": 0.001412997877799242, "g see": 0.0013344544108777538, "limited e g": 0.0012953547128852297, "paramount importance": 0.0009907789071032058, "both studies in": 0.001412997877799242, "each sensor": 0.0020794063477728737, "figures are": 0.0008183105262917859, "and noisy training": 0.001412997877799242, "representatives": 0.0006290922006349871, "navigated": 0.001039526833456673, "label": 0.0005371690643976191, "office engineering computing": 0.001412997877799242, "distribution is": 0.001048699729722923, "way either the": 0.001412997877799242, "systems such": 0.000577026606170962, "introduction programming mobile": 0.001412997877799242, "for picking up": 0.001412997877799242, "geometric": 0.00025585345892878896, "represent temporally extended": 0.001412997877799242, "probably the most": 0.0009316462484985891, "across": 0.0004924945748866597, "nevertheless this approach": 0.0011087956007827721, "observation can": 0.0009528025610969587, "and preference": 0.001157470080128191, "using an artificial": 0.0012265208479459286, "able to make": 0.0009126929338602609, "the camera turn": 0.001412997877799242, "c figure 12": 0.0011087956007827721, "base which": 0.0012263127867333846, "layer requires": 0.0013439565011394887, "an actual mobile": 0.001412997877799242, "b d figure": 0.0012953547128852297, "js": 0.0005428999532193917, "khaleeli 1 4": 0.001412997877799242, "to traverse": 0.0006672272054388769, "tractable section 4": 0.001412997877799242, "invariants approach could": 0.001412997877799242, "train four separate": 0.001412997877799242, "action commands neural": 0.001412997877799242, "data 20060010000": 0.0013439565011394887, "five figure": 0.0012263127867333846, "each region": 0.0007115262727613508, "in feature": 0.0008837126637559662, "from high dimensional": 0.002825995755598484, "js for all": 0.0012953547128852297, "requires using": 0.0012263127867333846, "tractable": 0.0004556665315238027, "multiple concepts using": 0.001412997877799242, "many": -0.00187706274386285, "accurate and": 0.0006291989168691914, "output with": 0.001816222333717977, "use a discrete": 0.0011397700534482, "to machine learning": 0.0012265208479459286, "s": -0.014727091238945285, "the actual": 0.0002370916942542949, "environmental setup for": 0.001412997877799242, "tasks their": 0.0012263127867333846, "generate a": 0.0004019963390390999, "or so synthetic": 0.001412997877799242, "pomdp s": 0.0026879130022789775, "of the approach": 0.000747247581202698, "of possible": 0.00041247935337390386, "grids were": 0.0012263127867333846, "detectors are": 0.0010397031738864368, "there is": 3.6774737870162646e-05, "among": -0.00012834571856525545, "model specifies for": 0.001412997877799242, "on our real": 0.0012953547128852297, "does an accurate": 0.001412997877799242, "cans we": 0.0013439565011394887, "combining a probabilistic": 0.001412997877799242, "is input": 0.0008623569375540945, "although somewhat": 0.001157470080128191, "b front far": 0.001412997877799242, "con ditions it": 0.001412997877799242, "odometric plot": 0.0013439565011394887, "these conditions requires": 0.001412997877799242, "engineering building": 0.0036789383602001536, "3 25 mm": 0.001412997877799242, "nodes 3 4": 0.001412997877799242, "concept learning learning": 0.001412997877799242, "for improvement in": 0.0011397700534482, "approximately the number": 0.0012265208479459286, "it is also": 0.0004025893062382929, "the robot maintains": 0.001412997877799242, "combines": 0.000321763905170604, "user labeled": 0.0013439565011394887, "a robot": 0.0024787917208853208, "capable": 0.00031853588071854686, "for example": 0.0003409483341175578, "west": 0.0005529776841907936, "t rapid concept": 0.001412997877799242, "active area of": 0.0009773255297405913, "is defined": 0.00017412633765931916, "in each case": 0.0005914669628413412, "combined": 8.637720970220658e-05, "dimensional but": 0.0013439565011394887, "could have": 0.0005199682495302577, "not learned": 0.0013439565011394887, "applicable when the": 0.001177670521728601, "labeled real data": 0.001412997877799242, "ee department": 0.0013439565011394887, "engineering department where": 0.001412997877799242, "object such": 0.0009528025610969587, "left right figure": 0.0012953547128852297, "enable": 0.00024133794001012057, "several distinct": 0.0009707370964526472, "finding invariances across": 0.001412997877799242, "ronment": 0.0007337750557688759, "the sensors": 0.0009365728948883588, "department main office": 0.001412997877799242, "approach is that": 0.0006002051640909454, "distances using": 0.0011086075099259812, "the sensory": 0.006131563933666923, "to numerous": 0.0011086075099259812, "readings": 0.0006704073805038565, "scale this": 0.0009707370964526472, "work to": 0.0005303575928524533, "was carried": 0.0007387405675331519, "successful approaches": 0.001157470080128191, "noisy training data": 0.001412997877799242, "bayesian": 0.0004868824994288003, "as the focus": 0.001177670521728601, "dependent on human": 0.001412997877799242, "those": -0.0005285429504906886, "navigation domain": 0.0026879130022789775, "rejected in": 0.001013492172364257, "training time": 0.0008954780757782285, "successive runs on": 0.0012953547128852297, "sensors by": 0.0013439565011394887, "total epochs curve": 0.001412997877799242, "net was trained": 0.002825995755598484, "be the": 7.598328313495206e-05, "engineering": 0.0007349515703601704, "accurately predict features": 0.001412997877799242, "above is": 0.0004361677962358004, "of a trash": 0.001412997877799242, "containers could": 0.0013439565011394887, "specularities dominate": 0.0013439565011394887, "promising": 0.00033746407450184875, "situation": 8.32392625204715e-05, "architecture based": 0.0009707370964526472, "c3 south": 0.0013439565011394887, "can was placed": 0.001412997877799242, "of several hundred": 0.001177670521728601, "investigates how mobile": 0.001412997877799242, "3 the study": 0.0012953547128852297, "eventually": 0.0006781575692853991, "see figure 3": 0.0006310701423978614, "obscured by": 0.0010706929277613088, "see figure 1": 0.000580437697563854, "could be partitioned": 0.0012953547128852297, "faculty office robot": 0.001412997877799242, "detection the": 0.0007964395063592673, "an accurate": 0.0005693146787156503, "uncertainty discrete": 0.0013439565011394887, "errors and odometry": 0.001412997877799242, "regularity": 0.0004165894486024949, "state estimation and": 0.001412997877799242, "inputs concept1 concept2": 0.001412997877799242, "used is novel": 0.001412997877799242, "detailed comments on": 0.0012265208479459286, "either inside the": 0.001412997877799242, "colored trash can": 0.001412997877799242, "technology": 0.00014137262858564283, "action go": 0.0013439565011394887, "processing program we": 0.001412997877799242, "a and b": 0.0007826864995804489, "due to specularities": 0.002825995755598484, "different": -0.002285399213849685, "a dozen or": 0.0012953547128852297, "decomposition and multiple": 0.001412997877799242, "how mobile": 0.001157470080128191, "system similarly a": 0.001412997877799242, "offices and homes": 0.001412997877799242, "for autonomous driving": 0.001412997877799242, "subsequent across": 0.0013439565011394887, "v i": 0.0008723355924716008, "the modeling": 0.0006546338046551141, "same": -0.002097723467483205, "biases 3": 0.0012263127867333846, "that it is": 0.00030514746457642244, "order to drop": 0.0012953547128852297, "that using": 0.0004931194694266732, "the templates": 0.0008837126637559662, "of a run": 0.0009647109541934066, "returning to node": 0.001412997877799242, "builds on": 0.0007541286032508272, "d pose d1": 0.001412997877799242, "the number": 0.000236301731607158, "and learning multiple": 0.001412997877799242, "multiple quadrants and": 0.001412997877799242, "extended": -6.11248838133111e-05, "can 4 figure": 0.001412997877799242, "i the sensor": 0.001412997877799242, "tasks we begin": 0.001412997877799242, "complete the": 0.00041165347984768047, "section 5": 0.00014666858562315912, "section 6": 0.00022646328528114334, "section 7": 0.00035757073401193715, "trained to detect": 0.0012953547128852297, "if a percept": 0.001412997877799242, "section 2": 0.0001262308890178431, "section 3": 9.563120702669e-05, "turn is improved": 0.001412997877799242, "when the trash": 0.002825995755598484, "running": 0.00023411983750645953, "observations in particular": 0.001412997877799242, "general the decision": 0.0012953547128852297, "1 within": 0.0009707370964526472, "robot learning is": 0.004238993633397726, "totally": 0.0007976171157270955, "the 380": 0.0013439565011394887, "be a": 8.403667433437302e-05, "non learning robots": 0.001412997877799242, "policy whereas": 0.0013439565011394887, "across related functions": 0.001412997877799242, "soda cans could": 0.001412997877799242, "undefined": 0.0020737695590348445, "sonar pulse will": 0.001412997877799242, "sufficiently constrain the": 0.001412997877799242, "a top": 0.0006291989168691914, "approach b introduction": 0.0009219073640234544, "all sensors predict": 0.001412997877799242, "can contain millions": 0.001412997877799242, "below two": 0.0010397031738864368, "suggest that high": 0.001412997877799242, "state helps speed": 0.001412997877799242, "belief state": 0.0026879130022789775, "easing": 0.0008953261968644262, "each image": 0.0006807892368766817, "examples using quickprop": 0.001412997877799242, "it is arguable": 0.0012953547128852297, "observation can be": 0.001021962604845781, "values of the": 0.000821254369720175, "by the": 1.770127142125073e-05, "are better representatives": 0.001412997877799242, "approach described here": 0.0010826007236946758, "14 s mahadevan": 0.001412997877799242, "simultaneously using a": 0.002825995755598484, "in by": 0.0008107079716898269, "being": -0.0005929959896099955, "steering behavior from": 0.001412997877799242, "a hallway navigation": 0.001412997877799242, "provided in": 0.0005258336588949284, "rest": 6.774594416107434e-05, "the lab at": 0.001412997877799242, "few hundred": 0.0008346023623118109, "the overall function": 0.001412997877799242, "the special": 0.0004051647809330684, "patterns was used": 0.001412997877799242, "described below": 0.000988749410981708, "net has": 0.0009907789071032058, "not every": 0.0007437201166480605, "do in": 0.0006576990239911289, "but once again": 0.0012953547128852297, "of digital": 0.0006639936831495265, "predicting the features": 0.001412997877799242, "a logical description": 0.0012953547128852297, "front or": 0.0012263127867333846, "quickprop rapid": 0.0013439565011394887, "2 s 2": 0.0010057508064281846, "robot pavlov either": 0.001412997877799242, "at most": 0.0002090944421597446, "high level planner": 0.001412997877799242, "where much of": 0.001412997877799242, "far near": 0.004031869503418466, "and difficult": 0.0007710139595398186, "envi ronment": 0.0008525989995294478, "of paramount importance": 0.0010599041887614004, "4": 0, "behavior by": 0.000872702844207972, "rapid concept": 0.013439565011394887, "generalizations a strength": 0.001412997877799242, "9 here we": 0.001412997877799242, "y i2i given": 0.001412997877799242, "learn ing klingspor": 0.001412997877799242, "d blanco": 0.0013439565011394887, "the input or": 0.001021962604845781, "dimensional as in": 0.001412997877799242, "sensor and": 0.0025577969985883437, "for recycling task": 0.001412997877799242, "around": 0.00011535478501490415, "space e g": 0.0010057508064281846, "decomposed": 0.0006843178809489342, "learning how": 0.0022172150198519623, "system used": 0.0008346023623118109, "i can": 0.00046202115651286204, "for every": 0.00023363204003769682, "several hundred real": 0.002825995755598484, "shallower": 0.001039526833456673, "have spatial": 0.0010706929277613088, "facilitate learning 6": 0.001412997877799242, "grid": 0.0022266960615702617, "preference": 0.0005046433607380987, "system uses": 0.0007338995299089556, "show that bias": 0.001412997877799242, "given that the": 0.0006706348685868236, "concept learning for": 0.01554297665579166, "on two realistic": 0.001412997877799242, "can was": 0.0024526255734667692, "that collecting": 0.0013439565011394887, "so little": 0.001157470080128191, "of mobile robot": 0.001412997877799242, "and action": 0.0007710139595398186, "focus of sensory": 0.001412997877799242, "back and right": 0.001412997877799242, "serves": 0.00033173088434737666, "facing": 0.0006239029826303446, "up litter lying": 0.001412997877799242, "useful information yet": 0.001412997877799242, "be partitioned we": 0.001412997877799242, "random weights": 0.001157470080128191, "either": -0.0008486933099803548, "where the": 0.0006016680823076925, "values into high": 0.001412997877799242, "easily combined": 0.0012263127867333846, "places a somewhat": 0.001412997877799242, "beyond the": 0.0004352383371715153, "specifies": 0.0005566740153925654, "quickprop method": 0.0013439565011394887, "to an active": 0.0010826007236946758, "even a coarsely": 0.001412997877799242, "work except": 0.0011086075099259812, "speed learning sensory": 0.001412997877799242, "neural net correctly": 0.002825995755598484, "a combination of": 0.0010712163271829583, "probabilistic planning and": 0.001412997877799242, "necessary for robots": 0.001412997877799242, "just the concept": 0.001412997877799242, "classes using a": 0.0012265208479459286, "c pose c1": 0.001412997877799242, "specified": 0.00022999964602968205, "images": 0.0030816646945161586, "constant that": 0.0007710139595398186, "examples collected from": 0.001412997877799242, "in unstructured environments": 0.001412997877799242, "2 i f": 0.001412997877799242, "pre specified architecture": 0.001412997877799242, "far d": 0.0013439565011394887, "far e": 0.0013439565011394887, "near in": 0.0010706929277613088, "dimensions": 0.0002335924145220866, "strict consistency with": 0.0012953547128852297, "out on pavlov": 0.001412997877799242, "well studied work": 0.001412997877799242, "24 among the": 0.001412997877799242, "successful traces": 0.0026879130022789775, "that sonars": 0.0013439565011394887, "the sensor registers": 0.001412997877799242, "are generated": 0.0004352383371715153, "the limitations": 0.0006265849827685552, "critical": 0.00013387054079141454, "decomposition": 0.0016012303356964968, "which is color": 0.001412997877799242, "such as locating": 0.0012953547128852297, "introduction learning": 0.0012263127867333846, "output with 3": 0.001412997877799242, "latter work and": 0.001412997877799242, "known the": 0.0006214693208023149, "where a human": 0.002453041695891857, "refer": 4.424768671013886e-06, "deeper ones": 0.0013439565011394887, "be one of": 0.0007615602934733865, "free learning is": 0.001412997877799242, "researchers have attempted": 0.0012953547128852297, "methods described": 0.0007338995299089556, "trace of a": 0.0018438147280469088, "grammar which": 0.001157470080128191, "different parts of": 0.0008801129633255439, "an opening": 0.0012263127867333846, "the focus of": 0.0013548289475553447, "rotating the": 0.0009081111668589885, "the inputs": 0.0005185303358808077, "can perceive": 0.0012263127867333846, "pose c3 south": 0.001412997877799242, "the basic ingredients": 0.001412997877799242, "biases": 0.0006915769070396403, "net to": 0.003811210244387835, "quite limited e": 0.001412997877799242, "the multi": 0.0005397514085136305, "trash can opening": 0.001412997877799242, "we focus": 0.0003920243363346696, "inputs 6": 0.0013439565011394887, "by scaling and": 0.0012953547128852297, "trees inductive learning": 0.001412997877799242, "voronoi based maps": 0.001412997877799242, "navigation robot navigation": 0.001412997877799242, "except the": 0.0005101280194599199, "into black": 0.0012263127867333846, "describing the": 0.0009392237526228961, "required to find": 0.0009647109541934066, "be easily collected": 0.001412997877799242, "additional training robot": 0.001412997877799242, "values 2 in": 0.0012953547128852297, "believes it": 0.001157470080128191, "notes 1": 0.0007387405675331519, "a visual image": 0.001412997877799242, "homes is tedious": 0.001412997877799242, "receptacle see figure": 0.001412997877799242, "the templates were": 0.0012953547128852297, "unobservable to the": 0.001412997877799242, "training instances": 0.0009528025610969587, "recognizing many objects": 0.001412997877799242, "kalman filters": 0.0012263127867333846, "to port it": 0.001412997877799242, "level features figure": 0.001412997877799242, "state and": 0.0004158170065315799, "both examples the": 0.0011397700534482, "almost totally obscured": 0.001412997877799242, "able to accurately": 0.0010826007236946758, "preclassified training examples": 0.001412997877799242, "recognize these features": 0.001412997877799242, "the likelihood": 0.0005601128957225589, "part by an": 0.0010599041887614004, "image": 0.001653479147952984, "these related concepts": 0.001412997877799242, "single output": 0.002618108532623916, "data we": 0.0010637809044712976, "net figure 14": 0.001412997877799242, "these observations are": 0.002043925209691562, "learned in the": 0.0012953547128852297, "space biases": 0.0012263127867333846, "6 learning": 0.0013439565011394887, "other irregularities": 0.0026879130022789775, "the reader to": 0.0006383083195550878, "transfer across": 0.0012263127867333846, "actuator errors": 0.0013439565011394887, "main office": 0.0013439565011394887, "given the task": 0.0011397700534482, "was trained on": 0.001021962604845781, "her": 0.0004165894486024949, "studies alvinn": 0.0013439565011394887, "while a": 0.00048696509187993325, "pomdp s 4": 0.001412997877799242, "two example tasks": 0.001412997877799242, "a discrete probability": 0.0012265208479459286, "a lifelong": 0.0012263127867333846, "pavlov has a": 0.001412997877799242, "which the": 0.00010285368240778783, "is facing a": 0.001412997877799242, "easily used": 0.0009907789071032058, "two tasks involving": 0.001412997877799242, "investigates how": 0.0012263127867333846, "represents occupied space": 0.001412997877799242, "to learn new": 0.001177670521728601, "layer local occupancy": 0.001412997877799242, "learning of": 0.0013477554569502185, "complete": -0.0002362312843265813, "001100000000000000000000000001111111111111111111111111000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111111110000011111000000000000000000000000011111111111111111111111110000011111": 0.0012261047960979141, "figure 12 sample": 0.0012265208479459286, "be using": 0.0008262639069617736, "and sharing used": 0.001412997877799242, "001100000000000000000000000001111111111111111111111111000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111111110000011111000000000000000000000000011111111111111111111111110000011111 00000000000000000000000000000011111111111111111111111110000000000000000000000000111111111111111111111111100000000000000000000000001111111111111111111111111000000111111000000111111000000111111 inputs": 0.001412997877799242, "so synthetic": 0.0013439565011394887, "robots for": 0.0012263127867333846, "wiping": 0.0012261047960979141, "systems navigation is": 0.001412997877799242, "learning the second": 0.0012265208479459286, "challenging problem for": 0.001177670521728601, "occupancy grid data": 0.001412997877799242, "unreliable": 0.0005128000387594285, "the object is": 0.0007653307612006872, "relatively insignificant": 0.001157470080128191, "with": 0, "systems v": 0.00035820794236454527, "bias which ranks": 0.001412997877799242, "called pavlov to": 0.001412997877799242, "reported in this": 0.0007438462992263857, "rough geometrical": 0.0013439565011394887, "arranged": 0.0004577361363835267, "represent concepts": 0.001157470080128191, "of their learning": 0.001412997877799242, "science and engineering": 0.00080838360373212, "with capturing subsequent": 0.001412997877799242, "single output nets": 0.001412997877799242, "and the outputs": 0.0010826007236946758, "specularities are relatively": 0.001412997877799242, "multi class approach": 0.001412997877799242, "produced more": 0.0010706929277613088, "difficult in": 0.0008262639069617736, "rough geometrical aligment": 0.001412997877799242, "variant of": 0.00041921083984002716, "robots 3 is": 0.001412997877799242, "that occupancy information": 0.001412997877799242, "learn interesting concepts": 0.001412997877799242, "bits indicating the": 0.002825995755598484, "observations one": 0.001157470080128191, "l moreno symbolic": 0.001412997877799242, "decision trees inductive": 0.001412997877799242, "section 6 discusses": 0.0009039491294179812, "could be easily": 0.0018632924969971781, "demonstrates that despite": 0.001412997877799242, "detailed": 0.00032670217025123255, "a collection": 0.00036799941167873145, "we provide": 0.00041165347984768047, "3 this task": 0.0012953547128852297, "front very": 0.0013439565011394887, "figure 12": 0.000414141285867163, "certain": -8.952969634003432e-05, "figure 10": 0.00135474394020293, "figure 11": 0.0007650216070990419, "10 the": 0.0010670108258275372, "al": 2.6560668390012814e-05, "figure 14": 0.0010121284686900039, "general": -0.002017833883847315, "we will mainly": 0.0010599041887614004, "as": 0, "novel in that": 0.0012265208479459286, "at": -0.0085827335726854, "various snapshots": 0.0013439565011394887, "total epochs": 0.0013439565011394887, "they expose the": 0.0012953547128852297, "adjacent east west": 0.001412997877799242, "studied topic 1": 0.001412997877799242, "fill": 0.0003713023833232557, "tedious": 0.0009786398481939724, "again": -0.00010770077808194839, "reflections in a": 0.001412997877799242, "as reinforcement": 0.0012263127867333846, "ee department figure": 0.001412997877799242, "representation we investigate": 0.001412997877799242, "images and": 0.0006189654335108611, "discussion of two": 0.0012953547128852297, "be trained to": 0.004906083391783714, "drivers": 0.0006139563403370056, "ethernet system": 0.0013439565011394887, "hybrid": 0.000600107527977712, "thresholded": 0.000724480329627718, "recycling task is": 0.001412997877799242, "prior when": 0.0013439565011394887, "spatial": 0.0022266960615702617, "avoiding obstacles": 0.0012263127867333846, "feature detectors shaded": 0.001412997877799242, "investigated here": 0.0010706929277613088, "unobservable": 0.0007650711510374575, "decision processes": 0.002026984344728514, "o ojs": 0.0013439565011394887, "active area": 0.0008954780757782285, "using model based": 0.0012265208479459286, "human provided example": 0.001412997877799242, "net a": 0.0009528025610969587, "are more invariant": 0.001412997877799242, "for recognizing sonar": 0.001412997877799242, "accuracy of": 0.0003890504850603517, "900000000000000000000000000000000011111111111111111111111111111111111111111111000000000000000000000000000000000000111111111111111111111111111111111111": 0.0012261047960979141, "a1": 0.0004917890795456392, "provided using a": 0.0012953547128852297, "a3": 0.0006239029826303446, "a2": 0.0005046433607380987, "under these con": 0.001412997877799242, "b pose b1": 0.001412997877799242, "g theocharous n": 0.014129978777992418, "10 using an": 0.001412997877799242, "there is much": 0.0009529642174527608, "learning concepts from": 0.001412997877799242, "the percepts in": 0.001412997877799242, "defined in every": 0.001412997877799242, "occupancy grid representation": 0.001412997877799242, "this places": 0.0009528025610969587, "necessary to": 0.0005117937214059846, "which rules out": 0.0012265208479459286, "were run onboard": 0.001412997877799242, "human designer ffl": 0.001412997877799242, "in some": 0.00040153273048860257, "as illustrated": 0.0004981912247994427, "partitioned": 0.00022235486399323985, "network produced": 0.0012263127867333846, "deposit them": 0.0013439565011394887, "for research since": 0.001412997877799242, "propose a lifelong": 0.001412997877799242, "architecture chosen for": 0.001412997877799242, "occur when a": 0.0010599041887614004, "represent discontinuous": 0.0013439565011394887, "supervised learning": 0.0015420279190796371, "starting": 0.00011516019993224779, "original": -0.0003686733733028623, "features in addition": 0.0012953547128852297, "the robot must": 0.0012265208479459286, "represent": -0.0001230072545087807, "ff post scale": 0.002825995755598484, "specular environment testing": 0.001412997877799242, "problem are being": 0.001412997877799242, "mahadevan": 0.008725548281217767, "cans rapid concept": 0.001412997877799242, "unseen set": 0.0013439565011394887, "is computed": 0.00033752132031601365, "b3 figure 15": 0.001412997877799242, "trash can the": 0.001412997877799242, "the possible": 0.00035253932089419714, "and mitchell 27": 0.001412997877799242, "learning the": 0.002109966154571392, "of determining if": 0.0011087956007827721, "reasoning": 0.00026945586531834865, "20 40 epochs": 0.001412997877799242, "this paper is": 0.00032115158009345644, "robot through": 0.0012263127867333846, "net the": 0.0008433654142724929, "a belief state": 0.001412997877799242, "partioning": 0.0009215946410370149, "tr": 0, "and error such": 0.001412997877799242, "to": 0, "separate set": 0.0009707370964526472, "and odometry": 0.0013439565011394887, "than 2": 0.0005101280194599199, "200 mobile": 0.0012263127867333846, "promising avenue towards": 0.001412997877799242, "would be applicable": 0.0012953547128852297, "probability thus": 0.0010706929277613088, "detectors in state": 0.001412997877799242, "much of": 0.0013141197893701037, "a relatively rapid": 0.001412997877799242, "a where": 0.00047522317659804645, "office navigating robot": 0.001412997877799242, "is 512": 0.001157470080128191, "returning": 0.00041158366073644443, "synthesize new": 0.0012263127867333846, "learning methods described": 0.001412997877799242, "recognizing sonar signatures": 0.001412997877799242, "and noisy due": 0.001412997877799242, "tasks were": 0.0008954780757782285, "each quadrant": 0.001013492172364257, "occupied region having": 0.001412997877799242, "the approximate": 0.0005087636134908786, "infra red ir": 0.001412997877799242, "simultaneously learning these": 0.001412997877799242, "b the trash": 0.001412997877799242, "ensures that": 0.0003734108296631311, "the sensor representation": 0.001412997877799242, "trash can and": 0.0012953547128852297, "the main categories": 0.001412997877799242, "an acronym": 0.0010706929277613088, "features even": 0.0010706929277613088, "involving learning": 0.0013439565011394887, "odometric errors 14": 0.001412997877799242, "contrast in": 0.0007710139595398186, "this assumes sensor": 0.001412997877799242, "than strict consistency": 0.0012953547128852297, "shows the experimental": 0.0010826007236946758, "applicable": 0.0003558289634881104, "occupancy grid map": 0.001412997877799242, "large": -0.00055486947786685, "only the observation": 0.001412997877799242, "pomdp approach uses": 0.001412997877799242, "decision tree based": 0.002355341043457202, "robot maintains": 0.0013439565011394887, "the solution e": 0.0011397700534482, "occupancy grids this": 0.001412997877799242, "building see figure": 0.001412997877799242, "it helps": 0.0008525989995294478, "test examples": 0.0009081111668589885, "navigation robot": 0.0026879130022789775, "based autonomous": 0.0013439565011394887, "through of": 0.0011086075099259812, "the idea here": 0.0010599041887614004, "by generalizing user": 0.001412997877799242, "their non": 0.0009365728948883588, "bias is generally": 0.001412997877799242, "197": 0.0005302676407505448, "robots are going": 0.001412997877799242, "robotics applications": 0.0011086075099259812, "khaleeli20601001401800 20 40": 0.001412997877799242, "the first is": 0.0006125588532215851, "on spatial": 0.001790956151556457, "similar to our": 0.0008184493641822325, "in general in": 0.0008728509105201892, "approximator in both": 0.001412997877799242, "the corridors": 0.0013439565011394887, "100x100 images": 0.0013439565011394887, "further": -0.0004641369930858929, "in addition although": 0.0012265208479459286, "near b front": 0.001412997877799242, "their work": 0.0006189654335108611, "platform 4 s": 0.001412997877799242, "encoding the sensor": 0.001412997877799242, "capability of": 0.0006140604889952477, "and multi task": 0.001412997877799242, "resolve the": 0.0006954851132481282, "far near in": 0.001412997877799242, "methods in the": 0.0007988727145907639, "used to": 0.0003273115767200634, "section": -0.0038396862127434966, "are simplifying the": 0.001412997877799242, "clearly has": 0.0010706929277613088, "saturation intensity which": 0.001412997877799242, "00000000000000000000000000000011111111111111111111111110000000000000000000000000111111111111111111111111100000000000000000000000001111111111111111111111111000000111111000000111111000000111111 inputs concept1": 0.001412997877799242, "the current": 0.0005242796752079946, "behavior from": 0.0009217509760058083, "the results for": 0.0010568459112357403, "applications of": 0.0003905320792594806, "judicious": 0.0007156559879878064, "state into several": 0.001412997877799242, "of south florida": 0.0012953547128852297, "organized as": 0.00027479375950829443, "8s 2 s": 0.0012953547128852297, "method": -0.00019834435909713737, "contrast": 0.00012834571856525545, "speed rapid concept": 0.001412997877799242, "b l boada": 0.001412997877799242, "studied form": 0.001157470080128191, "human designer carefully": 0.001412997877799242, "type of": 0.00044921189219429, "task learning and": 0.001412997877799242, "freedom afforded by": 0.001412997877799242, "concept description": 0.001013492172364257, "that have the": 0.0007130528122063535, "component": 2.1660367169591883e-05, "380 test": 0.0013439565011394887, "hypotheses over another": 0.001412997877799242, "comparison of different": 0.0009529642174527608, "able to complete": 0.0009909470066802508, "the belief state": 0.001412997877799242, "is near": 0.0006993597717998856, "a feedforward neural": 0.003679562543837785, "training examples converged": 0.001412997877799242, "provides the basic": 0.0010826007236946758, "approach b": 0.0008262639069617736, "of the colored": 0.001412997877799242, "robot technology": 0.0013439565011394887, "idea in": 0.0006738777284751093, "generalizing": 0.0004893199240969862, "for mobile robots": 0.012537470587930201, "partition the": 0.000458857097148134, "to facilitate recognition": 0.001412997877799242, "pavlov the images": 0.001412997877799242, "free learning": 0.0012263127867333846, "far c left": 0.001412997877799242, "transformed into hsi": 0.001412997877799242, "is arguable": 0.0012263127867333846, "2 in both": 0.0010057508064281846, "prior": 0.0006663216803675575, "event based": 0.0008346023623118109, "only was it": 0.001412997877799242, "in such": 0.00024493650607273885, "pick": 0.00031960686763883974, "action": 0.001277707096115769, "layered architecture": 0.001157470080128191, "layer output": 0.0012263127867333846, "idea is": 0.001448284704160812, "two tasks learning": 0.001412997877799242, "is quite difficult": 0.001177670521728601, "first present the": 0.0010057508064281846, "state this": 0.0006546338046551141, "a wireless ethernet": 0.001412997877799242, "followed": 0.00013101830440917, "not been": 0.0007537289331502556, "or undefined": 0.0021413858555226176, "5 9": 0.0005496498068625872, "5 6": 0.0009769304737148982, "the use of": 0.00026237198360590225, "in both positions": 0.001412997877799242, "klingspor": 0.0012261047960979141, "which rules": 0.0010706929277613088, "decision trees for": 0.0010057508064281846, "multiple concepts": 0.0033258225297779433, "through exploration in": 0.001412997877799242, "obviously this": 0.0008107079716898269, "improved by the": 0.0009909470066802508, "to successfully learn": 0.001412997877799242, "as kalman": 0.0013439565011394887, "idea here": 0.000872702844207972, "cling both": 0.0013439565011394887, "it tried": 0.0013439565011394887, "layered control": 0.0012263127867333846, "journal of intelligent": 0.000887696035668378, "readily": 0.0003340066195098403, "output err very": 0.001412997877799242, "seems necessary to": 0.0011397700534482, "v 39": 0.0005731297104135156, "bayesian models for": 0.0012953547128852297, "training examples": 0.004738345525966832, "better performance": 0.0004969104621112533, "we begin in": 0.0010057508064281846, "distinct": 0.00020782728200046546, "job of predicting": 0.0012265208479459286, "1 doing": 0.001157470080128191, "net produces": 0.0013439565011394887, "two": 0, "it can represent": 0.0012953547128852297, "quadrants there are": 0.001412997877799242, "comparing": 0.0001298823548507322, "6": -0.00785299345309599, "more invariant rapid": 0.001412997877799242, "height and": 0.0007964395063592673, "6 related": 0.0007157773884946746, "clearly demonstrated": 0.0009707370964526472, "more": -0.008953261968644264, "receptacles from color": 0.001412997877799242, "the experiments": 0.001963872588145129, "is a 1200": 0.0012953547128852297, "door": 0.00366887527884438, "the behaviors": 0.0008107079716898269, "sensory concepts is": 0.001412997877799242, "near the inputs": 0.001412997877799242, "controller 2 1": 0.001412997877799242, "continues to be": 0.0009909470066802508, "training also": 0.0013439565011394887, "phase to extract": 0.001412997877799242, "west corridor": 0.0013439565011394887, "tested": 0.00018048271923285961, "several distinct regions": 0.0012953547128852297, "nomad": 0.003325258448616176, "if it": 0.00016691886565747238, "color camera": 0.0012263127867333846, "particular": -0.0011025593641707302, "up the trash": 0.001412997877799242, "ffl need": 0.0012263127867333846, "the human": 0.0012531699655371105, "it r navigating": 0.001412997877799242, "architecture 2": 0.0009528025610969587, "i reports feature": 0.002825995755598484, "the approximate location": 0.0010826007236946758, "correctly predicts": 0.0022172150198519623, "temporarily loses": 0.0013439565011394887, "environments and add": 0.001412997877799242, "standardized function approximator": 0.001412997877799242, "is recycling": 0.0013439565011394887, "science": 5.221383620949654e-05, "navigating to lab": 0.001412997877799242, "described here such": 0.001412997877799242, "robot employs a": 0.001412997877799242, "east navigation to": 0.005651991511196968, "type of hypotheses": 0.001412997877799242, "if the": 2.2157791758619884e-05, "effectiveness in": 0.0009365728948883588, "learn": 0.006176318285770956, "strategies": 0.0012678941775723933, "ture with the": 0.001412997877799242, "in that": 0.0005880216183048074, "net has been": 0.001412997877799242, "system uses a": 0.0009647109541934066, "been investigated": 0.0007115262727613508, "right hidden": 0.0013439565011394887, "motor commands": 0.0013439565011394887, "detectors for recognizing": 0.001412997877799242, "subfunctions": 0.0009526409595770983, "in the context": 0.00038740092575387225, "labeled with the": 0.0008405371151868688, "show that spatial": 0.001412997877799242, "process that is": 0.0008527436549416518, "states": -2.3635603953614547e-05, "obliquely": 0.001039526833456673, "input or": 0.0007387405675331519, "to wheel slippage": 0.001412997877799242, "here would be": 0.0012265208479459286, "input e g": 0.001412997877799242, "were run": 0.0006372791512719589, "to learning behaviors": 0.001412997877799242, "predict 85 of": 0.001412997877799242, "bias strategies studied": 0.001412997877799242, "invariant rapid concept": 0.001412997877799242, "huge": 0.00045361872814018024, "the total": 0.00017223234201766124, "learn to recognize": 0.001412997877799242, "robots 11 opening": 0.001412997877799242, "domains where it": 0.001412997877799242, "experimental setup": 0.0007710139595398186, "receptacle": 0.0024522095921958283, "detailed experimental study": 0.001412997877799242, "on partially observable": 0.001412997877799242, "to induce": 0.0008183105262917859, "the images": 0.002365466516700163, "maps": 0.00020591052515513526, "spatial decomposition and": 0.004238993633397726, "authors wish to": 0.0007898582421551431, "instances of a": 0.0008184493641822325, "sequence of": 0.00018603576827444838, "cling": 0.0012261047960979141, "task this approach": 0.001412997877799242, "followed by": 0.0003122648947066425, "implement and": 0.0007437201166480605, "trash can 4": 0.001412997877799242, "more applicable": 0.0010397031738864368, "are all": 0.0003256434912382994, "to find a": 0.00044448739263723666, "tested by running": 0.001412997877799242, "department where": 0.0013439565011394887, "overall planner": 0.0013439565011394887, "13 electrical engineering": 0.001412997877799242, "state which is": 0.0009647109541934066, "is given": 0.00014402439087101603, "than 1024": 0.0013439565011394887, "variant": 0.00022679770563380553, "work is complementary": 0.001412997877799242, "to successfully operate": 0.001412997877799242, "flat surface": 0.0012263127867333846, "2 a hybrid": 0.001412997877799242, "of true": 0.0007338995299089556, "successfully operate": 0.0013439565011394887, "s 8s 2": 0.001412997877799242, "same set of": 0.0006328522719948063, "faculty": 0.0006575874739531386, "is not approximately": 0.0012265208479459286, "pre programmed obviously": 0.001412997877799242, "of bias decomposition": 0.001412997877799242, "either inside": 0.0012263127867333846, "predict the": 0.0005381522116980043, "using multiple": 0.0007073760774262461, "taken in": 0.0005693146787156503, "learning from examples": 0.0009909470066802508, "few high": 0.001157470080128191, "missing pieces": 0.0013439565011394887, "with the partioning": 0.001412997877799242, "ranks one hypotheses": 0.001412997877799242, "the loop": 0.0009261748823202838, "requires dealing with": 0.001412997877799242, "both in machine": 0.001412997877799242, "current state": 0.0005381522116980043, "would enable": 0.0008525989995294478, "authors wish": 0.0007201345364976421, "chooses one of": 0.001021962604845781, "of weights figure": 0.001412997877799242, "using the": 0.00017002769957482863, "i 2 i": 0.0015383700484564245, "the control architecture": 0.001412997877799242, "using a procedural": 0.0012265208479459286, "a teacher": 0.0010706929277613088, "3 2 multi": 0.001412997877799242, "net feature detector": 0.002825995755598484, "multitask learning": 0.001157470080128191, "e g soda": 0.002825995755598484, "robots to": 0.002314940160256382, "with the ability": 0.0009316462484985891, "an introduction learning": 0.001412997877799242, "learning learning": 0.0008623569375540945, "rules out certain": 0.001177670521728601, "the most well": 0.001021962604845781, "then y i2i": 0.001412997877799242, "right far near": 0.001412997877799242, "encountered by the": 0.0011087956007827721, "learning here is": 0.001412997877799242, "objects for": 0.0006843495569384895, "paper": -0.0076864622840619465, "through": -0.0008292236219929012, "orientation of the": 0.000823711514802973, "filters": 0.00045159223660540243, "processing program": 0.0012263127867333846, "freedom afforded": 0.0013439565011394887, "its": -0.003873808503836824, "we could have": 0.0008527436549416518, "learning sensory concepts": 0.004238993633397726, "24": -9.163975175211971e-05, "25": -0.00021106714866065104, "26": -6.112140532904656e-05, "27": -3.801252805818262e-05, "20": -0.001026075817897445, "21": -0.0002792599189962879, "22": -0.00043639996475298417, "23": -0.00010553357433032552, "in all cases": 0.0005590151618030607, "wall back opening": 0.004238993633397726, "found that": 0.0007373367230707292, "system was": 0.0006639936831495265, "move towards trash": 0.001412997877799242, "dependent on": 0.00041001176617621693, "this problem are": 0.0009647109541934066, "figure 3 image": 0.001412997877799242, "and deposit them": 0.001412997877799242, "4 1 2": 0.0006994784280217723, "calculate only": 0.001157470080128191, "hidden units": 0.0009365728948883588, "14 because": 0.0010397031738864368, "robot as": 0.0024526255734667692, "is based": 0.0003288890779264134, "for navigation the": 0.001412997877799242, "good": -5.051466145111922e-05, "b and": 0.000256726815886584, "the probabilities": 0.0005892470628878294, "circumstances because": 0.0012263127867333846, "propose": 0.00010015146311056003, "engineering building see": 0.001412997877799242, "provide a relatively": 0.0012265208479459286, "for robots to": 0.001412997877799242, "effectiveness of": 0.0021397773736212015, "halved from the": 0.001412997877799242, "walls": 0.0006704073805038565, "decomposable in some": 0.001412997877799242, "or instance": 0.0010706929277613088, "begin in section": 0.001021962604845781, "below 4 experimental": 0.0012953547128852297, "have found": 0.00046741243794731264, "easily": -0.0007120176792154771, "b3 figure": 0.0013439565011394887, "trace the": 0.0007437201166480605, "synthetic examples": 0.0012263127867333846, "the judicious": 0.0011086075099259812, "generated by": 0.0005277776960610426, "is of paramount": 0.0011087956007827721, "here we study": 0.0010826007236946758, "2 south": 0.0026879130022789775, "the rough": 0.0009528025610969587, "system could itself": 0.001412997877799242, "this would": 0.00038611861009950034, "labeling": 0.0008873802993648441, "specifies for each": 0.0012265208479459286, "red ir": 0.0013439565011394887, "being investigated": 0.0009217509760058083, "learning multi": 0.0013439565011394887, "each possible": 0.0006291989168691914, "study was": 0.0007832601051609397, "sensory data is": 0.002825995755598484, "found": -0.0005260944633402461, "image into multiple": 0.001412997877799242, "can be exploited": 0.0014149921874542658, "two strategies provide": 0.001412997877799242, "v i is": 0.000794306715118076, "starting off with": 0.0012953547128852297, "indicating the distance": 0.001412997877799242, "planning and": 0.0007710139595398186, "models journal of": 0.001412997877799242, "n khaleeli to": 0.001412997877799242, "other junk": 0.0013439565011394887, "in both problems": 0.0012953547128852297, "a smooth": 0.000577026606170962, "hard": 8.900324484561946e-05, "idea": -5.901009937281146e-05, "maintains at every": 0.001412997877799242, "input space": 0.0008837126637559662, "sensor uncertainty": 0.0013439565011394887, "the pomdp approach": 0.001412997877799242, "of these": 0.00010759083823455401, "we will show": 0.00046932316724806957, "having a low": 0.0012265208479459286, "b the": 0.0005381309292645347, "the paper 2": 0.0008591880780779472, "discrete event": 0.0013615784737533634, "and odometry is": 0.001412997877799242, "recognize landmarks such": 0.001412997877799242, "net was": 0.0026879130022789775, "of prior": 0.0008262639069617736, "trainers for": 0.0013439565011394887, "the situation": 0.00038978996000702085, "based on partially": 0.001412997877799242, "focus primarily on": 0.0010599041887614004, "collecting and labeling": 0.001412997877799242, "state estimators such": 0.001412997877799242, "only was": 0.0013439565011394887, "research": -0.0005466588701367749, "wall right opening": 0.001412997877799242, "section 4": 0.00010366168197071998, "acting": 0.00044563597599098887, "structure for solving": 0.001412997877799242, "feature detector": 0.0022172150198519623, "i and the": 0.000561408532790537, "recognizing sonar": 0.0013439565011394887, "the controller": 0.0007115262727613508, "robotics in service": 0.001412997877799242, "idea is used": 0.0011397700534482, "right opening back": 0.002825995755598484, "feature detectors and": 0.001412997877799242, "applications of mobile": 0.001412997877799242, "with labeled": 0.0011086075099259812, "results obtained": 0.0004857578053865428, "make the concept": 0.0012953547128852297, "takes into": 0.0005978790985189038, "belief": 0.0015301244952762353, "collection of obstacle": 0.001412997877799242, "shared representation the": 0.0012265208479459286, "trash can is": 0.002825995755598484, "to node 1": 0.001039879574153469, "of bumper switches": 0.001412997877799242, "very noticeable": 0.0012263127867333846, "specifies most of": 0.001412997877799242, "possible observation": 0.001157470080128191, "and also subservient": 0.001412997877799242, "labeled examples is": 0.0012265208479459286, "e g the": 0.0009598300492945916, "correctly predict": 0.0019815578142064116, "till it is": 0.0012953547128852297, "cans and": 0.0026879130022789775, "to detect trash": 0.001412997877799242, "these con": 0.0012263127867333846, "prior work": 0.0007157773884946746, "pose b3": 0.0013439565011394887, "neural net does": 0.001412997877799242, "need for a": 0.000730869328480087, "on rapid within": 0.001412997877799242, "laboratory for recycling": 0.001412997877799242, "along one of": 0.0011087956007827721, "the philosophy": 0.0008954780757782285, "3 describes": 0.0005731297104135156, "radially in a": 0.001412997877799242, "create hard": 0.0013439565011394887, "on manually": 0.001157470080128191, "conducted": 0.0006141395591907539, "feature prediction is": 0.001412997877799242, "out any": 0.0009217509760058083, "is of": 0.0002509705828624383, "bumper": 0.0012261047960979141, "wall the second": 0.001412997877799242, "new circumstances much": 0.001412997877799242, "grdt which": 0.0013439565011394887, "and sharing": 0.0009707370964526472, "is on": 0.00038831363332272726, "idea in the": 0.001021962604845781, "opening in order": 0.001412997877799242, "phase in": 0.0006214693208023149, "her detailed": 0.0013439565011394887, "of a priori": 0.0010826007236946758, "learning a": 0.0006993597717998856, "decomposable functions the": 0.001412997877799242, "robots the": 0.0012263127867333846, "noted earlier alvinn": 0.001412997877799242, "inside it r": 0.001412997877799242, "the limitations of": 0.0007217338535499443, "explaining the": 0.0008183105262917859, "number": -0.0030226680442717447, "oriented along one": 0.001412997877799242, "instances": 0.00039262306264960755, "science department 3": 0.001412997877799242, "done": -0.00013847205095092883, "no iri": 0.0011086075099259812, "the images into": 0.0025907094257704593, "learning s": 0.0024526255734667692, "back opening wall": 0.007064989388996209, "able to predict": 0.001039879574153469, "experimental results": 0.0006940285349294567, "are critical": 0.0008433654142724929, "improve camera": 0.0013439565011394887, "we then sub": 0.001412997877799242, "even when": 0.0007751587678916164, "one generalization": 0.001157470080128191, "introduction": -0.003325258448616176, "hybrid declarative": 0.0013439565011394887, "images into": 0.001745405688415944, "of features it": 0.0012265208479459286, "provide sufficient": 0.0018435019520116167, "sensor noise": 0.0011086075099259812, "extended actions": 0.0013439565011394887, "can finder a": 0.001412997877799242, "is initially": 0.0006164961457553095, "will show": 0.0003693394169128829, "on the order": 0.0006383083195550878, "supervised neural net": 0.001412997877799242, "trash cans learning": 0.001412997877799242, "facing a wall": 0.001412997877799242, "robots 7 the": 0.001412997877799242, "task three": 0.0013439565011394887, "to decompose": 0.0007073760774262461, "data we also": 0.0010599041887614004, "ranks one": 0.0012263127867333846, "overall function": 0.0013439565011394887, "in the two": 0.0005650584880304405, "ff prior s": 0.001412997877799242, "trash can figure": 0.001412997877799242, "in our case": 0.0005791051442447116, "inside the": 0.00044183835550954694, "learning 4": 0.0010397031738864368, "employs a": 0.0006705211052503373, "independent 0000000000000000000000000000000000000000000000000000000000000000111111111111111111111111111111111111111111111111111111111111111111111111": 0.0013439565011394887, "part": -0.0002405536652031531, "of the trash": 0.006476773564426147, "three successive": 0.0010397031738864368, "over all": 0.0003143541654356793, "focusing": 0.00044958658351803546, "challenging problem sensory": 0.001412997877799242, "follows we begin": 0.0009909470066802508, "believe": 0.0004941749868891421, "1 note that": 0.0005224783574967281, "paper we": 0.000407112426121077, "maintains at": 0.0010397031738864368, "b": 0, "different locations in": 0.0011087956007827721, "planner reactive behaviors": 0.001412997877799242, "general in": 0.0007291894113705743, "in machine": 0.0014976928995348968, "approximators e g": 0.001412997877799242, "tedious task nevertheless": 0.001412997877799242, "mobile robots": 0.01387090469944488, "4 describes": 0.0006189654335108611, "ing klingspor et": 0.001412997877799242, "add new features": 0.0012953547128852297, "similar neural": 0.0013439565011394887, "of trash can": 0.001412997877799242, "back on track": 0.0012953547128852297, "for autonomous": 0.0009081111668589885, "proceeds with": 0.0009365728948883588, "of predicting": 0.0008525989995294478, "sensory values": 0.0013439565011394887, "direction of the": 0.0006439371750110811, "have not": 0.00033235403449135035, "for learning with": 0.0010826007236946758, "the task and": 0.0009647109541934066, "example a": 0.0007228449558989955, "function front": 0.0013439565011394887, "robot and are": 0.001412997877799242, "such as doors": 0.002825995755598484, "data is": 0.0014909072619753822, "of inductive": 0.0008346023623118109, "for the": 0.0, "was tested": 0.0007832601051609397, "in favor": 0.0006546338046551141, "model of actuator": 0.001412997877799242, "learning which": 0.0010397031738864368, "angled obliquely to": 0.001412997877799242, "hypotheses space biases": 0.001412997877799242, "2 navigation robot": 0.001412997877799242, "learning context": 0.001013492172364257, "strategies to speed": 0.001412997877799242, "decomposition each": 0.0012263127867333846, "uses a": 0.0011925483482398572, "comparison of the": 0.000585868219173452, "little data": 0.0012263127867333846, "as when": 0.0007157773884946746, "figure 10 feature": 0.001412997877799242, "supervised neural": 0.0012263127867333846, "at four different": 0.001177670521728601, "entire policy": 0.0013439565011394887, "blanco": 0.001039526833456673, "provide detailed experimental": 0.001412997877799242, "smaller network with": 0.001412997877799242, "l boada": 0.0013439565011394887, "back left": 0.0024526255734667692, "detectors in": 0.001013492172364257, "in partic ular": 0.0009419732139289226, "majority": 0.00030504395458165424, "recognizing": 0.0008991731670360709, "computed using": 0.0004969104621112533, "mobile robots 3": 0.001412997877799242, "near very near": 0.004238993633397726, "example tan 26": 0.001412997877799242, "s an": 0.0007338995299089556, "an active area": 0.001021962604845781, "grabber communication": 0.0013439565011394887, "real robot figure": 0.001412997877799242, "nets although the": 0.001412997877799242, "appropriate bias": 0.0012263127867333846, "decomposable functions": 0.0012263127867333846, "type approach the": 0.001412997877799242, "the training set": 0.0007542565517753014, "approaches to": 0.001617472199370649, "we first present": 0.0007438462992263857, "multi output neural": 0.001412997877799242, "planner with a": 0.001412997877799242, "it has been": 0.0004393724882427005, "7 summarizes the": 0.001021962604845781, "by using hidden": 0.001412997877799242, "also approaches": 0.001157470080128191, "most": -0.0023312148715398965, "but eventually gets": 0.0012953547128852297, "opening or": 0.0024526255734667692, "significant": 9.256659969587334e-05, "and prediction": 0.0008183105262917859, "being investigated ranging": 0.001412997877799242, "on the latter": 0.0010599041887614004, "extremely": 0.00042875781523592536, "environment testing the": 0.001412997877799242, "for research": 0.0006954851132481282, "although examples": 0.0013439565011394887, "of the judicious": 0.001412997877799242, "apparent that the": 0.0008801129633255439, "mobile robots a": 0.0025907094257704593, "can six boolean": 0.001412997877799242, "trees is that": 0.0012265208479459286, "sometimes": 0.00013674089640076597, "for speeding": 0.0009907789071032058, "landmarks such as": 0.001412997877799242, "which is initially": 0.0011397700534482, "robot navigation using": 0.002825995755598484, "finder a": 0.0013439565011394887, "robot learning fundamentals": 0.001412997877799242, "reflections": 0.0023156348169459493, "task is": 0.0009392237526228961, "and frame": 0.0009217509760058083, "designer ffl": 0.0012263127867333846, "the corridors for": 0.001412997877799242, "the navigation task": 0.004238993633397726, "learned 3 accelerating": 0.001412997877799242, "net this": 0.0010706929277613088, "exploited to facilitate": 0.001412997877799242, "of detecting a": 0.0012265208479459286, "ojs": 0.0012261047960979141, "training times": 0.0010397031738864368, "noisy due to": 0.002453041695891857, "to make recognition": 0.001412997877799242, "their non learning": 0.001412997877799242, "trajectories of the": 0.0010599041887614004, "actual range in": 0.001412997877799242, "in that we": 0.0007898582421551431, "converge": 0.000304037505977001, "fast vision guided": 0.001412997877799242, "right top": 0.0009081111668589885, "256 possible": 0.0013439565011394887, "err very near": 0.001412997877799242, "a3 0 3": 0.001412997877799242, "15 and figure": 0.0012953547128852297, "image intensity can": 0.001412997877799242, "carefully": 0.00031853588071854686, "of two categories": 0.0012265208479459286, "approximators": 0.0009215946410370149, "networks": 0.00012649099627635128, "to rote": 0.0013439565011394887, "pre processed selected": 0.001412997877799242, "real valued": 0.0012138924150658708, "for learning grasping": 0.001412997877799242, "technology 7 one": 0.001412997877799242, "an explicit": 0.0004466919402916898, "tan 26": 0.0013439565011394887, "training examples collected": 0.001412997877799242, "a knowledge based": 0.0010057508064281846, "execution layer with": 0.001412997877799242, "robot pavlov": 0.0026879130022789775, "robot believes": 0.0013439565011394887, "are relatively insignificant": 0.0012953547128852297, "actual human drivers": 0.001412997877799242, "near err figure": 0.001412997877799242, "easily accommodated by": 0.0012953547128852297, "8": -0.0025597908084956642, "from each": 0.0007454536309876911, "it takes": 0.00046523782410889047, "robot over": 0.0013439565011394887, "eventually finds the": 0.0012953547128852297, "17 figure 14": 0.001412997877799242, "output values that": 0.001412997877799242, "the experimental results": 0.0006497504327944296, "work finally section": 0.0010826007236946758, "localize the": 0.0009081111668589885, "controller 2": 0.0013439565011394887, "other junk and": 0.001412997877799242, "dependent": 7.442188392481762e-05, "set of features": 0.0017317673187115608, "based on a": 0.0003604067746639586, "1200 dimensional vector": 0.001412997877799242, "total error": 0.0009081111668589885, "state helps": 0.0013439565011394887, "not approximately": 0.0011086075099259812, "compass": 0.0008344608083154893, "to improve camera": 0.001412997877799242, "by selecting one": 0.001412997877799242, "of the percepts": 0.001412997877799242, "system similarly": 0.0011086075099259812, "such cases the": 0.0008801129633255439, "figure 5 spatial": 0.001412997877799242, "other environments and": 0.001412997877799242, "resolve": 0.0003853266801399659, "using the output": 0.001177670521728601, "be an": 0.00023516443784900602, "22 for autonomous": 0.001412997877799242, "converted into symbolic": 0.001412997877799242, "in by additional": 0.001412997877799242, "learning provide": 0.0013439565011394887, "state the robot": 0.001412997877799242, "sensory concept": 0.012095608510255398, "test the effectiveness": 0.0022175912015655443, "to fill": 0.0006807892368766817, "sensor i 2": 0.001412997877799242, "made it": 0.0007387405675331519, "bias acting under": 0.001412997877799242, "irregularities and": 0.0012263127867333846, "common": -6.570241395435364e-05, "14 environmental setup": 0.001412997877799242, "25 are": 0.0008954780757782285, "a shared representation": 0.004238993633397726, "from the presented": 0.001177670521728601, "the laboratory": 0.001013492172364257, "history of prior": 0.001412997877799242, "images were transformed": 0.001412997877799242, "locating": 0.0004917890795456392, "6 s mahadevan": 0.001412997877799242, "structures the overall": 0.001412997877799242, "set": -0.006515102625464256, "learns a": 0.0008954780757782285, "using partially observable": 0.0012953547128852297, "robustly predict": 0.0013439565011394887, "which will eventually": 0.0012953547128852297, "recycling where": 0.0013439565011394887, "hue saturation intensity": 0.001412997877799242, "before it is": 0.0007340240462866124, "is provided using": 0.0012953547128852297, "see": -0.003052656735357921, "in actual real": 0.001412997877799242, "of a neural": 0.0010599041887614004, "boada d blanco": 0.001412997877799242, "much more": 0.0006704200804838001, "two categories e": 0.001412997877799242, "phase in the": 0.0009039491294179812, "sonar readings figure": 0.001412997877799242, "of detecting": 0.0007073760774262461, "produced more accurate": 0.0012265208479459286, "to specular": 0.0013439565011394887, "halved": 0.0007435939768725096, "itself acquire": 0.0013439565011394887, "learning 20 among": 0.001412997877799242, "concepts using a": 0.001412997877799242, "currently": 8.167554256280814e-05, "top decision tree": 0.001412997877799242, "ff post": 0.006719782505697444, "similar to": 0.00012119063208994456, "not be easily": 0.0011087956007827721, "related work finally": 0.0010599041887614004, "by a discussion": 0.0011397700534482, "i is the": 0.00040523352283685754, "dangerous situations": 0.0011086075099259812, "to dangerous situations": 0.001412997877799242, "avoidance": 0.0005213289159674361, "recycling task we": 0.001412997877799242, "active learning context": 0.001412997877799242, "multi category": 0.0013439565011394887, "available": -9.322684143186135e-05, "a good example": 0.0008801129633255439, "a human trainer": 0.001412997877799242, "actuator and sensor": 0.001412997877799242, "known the figures": 0.001412997877799242, "complementary": 0.0003810202894068864, "determine the": 0.0002332502301738862, "prior s 8s": 0.001412997877799242, "few missing pieces": 0.001412997877799242, "we show below": 0.000887696035668378, "tree approach for": 0.0012953547128852297, "it is able": 0.00084653211689172, "the figure also": 0.0009529642174527608, "that the human": 0.0010826007236946758, "is challenging because": 0.0012953547128852297, "investigate the effectiveness": 0.0012265208479459286, "faculty office": 0.0013439565011394887, "which sensor": 0.0012263127867333846, "concept learning section": 0.001412997877799242, "markov decision process": 0.002355341043457202, "special issue": 0.0007964395063592673, "improved": 6.366358322745184e-05, "conducted we": 0.001157470080128191, "the allowed compass": 0.001412997877799242, "avoidance algorithms": 0.0013439565011394887, "trees inductive": 0.0013439565011394887, "second strategy used": 0.001412997877799242, "it stopped adjacent": 0.001412997877799242, "navigation the bottom": 0.001412997877799242, "comments on": 0.0004956383297929675, "more accurate and": 0.001021962604845781, "based source of": 0.001412997877799242, "some bleed through": 0.001412997877799242, "requires running": 0.0013439565011394887, "belief state is": 0.001412997877799242, "three times and": 0.0012265208479459286, "a procedural": 0.0009217509760058083, "synthesize new examples": 0.001412997877799242, "the short": 0.0006843495569384895, "khaleeli 2 4": 0.001412997877799242, "demonstrates that": 0.0006023554586211942, "task learning 6": 0.001412997877799242, "figure 9 e": 0.001177670521728601, "task and subsequently": 0.001412997877799242, "possible to port": 0.001412997877799242, "described here": 0.0011784941257756588, "simple": -0.000321763905170604, "real valued inputs": 0.001412997877799242, "recycling": 0.010847990508101361, "reinforcement learning": 0.0019056051221939174, "particular by learning": 0.001412997877799242, "dimensional": 0.0010414978728284481, "probability distribution": 0.000577026606170962, "we found that": 0.0005650584880304405, "simply": -7.597039587526157e-05, "the 100x100 images": 0.001412997877799242, "predict features": 0.0036789383602001536, "done by selecting": 0.001177670521728601, "reports feature": 0.0026879130022789775, "is learned": 0.0009365728948883588, "prediction is": 0.0007033220515237973, "of the navigation": 0.0011397700534482, "we provide detailed": 0.0012953547128852297, "learning is one": 0.001412997877799242, "objects or containers": 0.001412997877799242, "find trash": 0.0026879130022789775, "ensures": 0.00018962523312842793, "14 shows the": 0.0009219073640234544, "collected from": 0.0007541286032508272, "1024 8 s": 0.001412997877799242, "front very near": 0.001412997877799242, "solution in": 0.00048818009817504264, "create": 0.00013674089640076597, "data generated": 0.000872702844207972, "a real robot": 0.0038860641386556888, "learning depends": 0.0013439565011394887, "bottom figure shows": 0.0025907094257704593, "in a": 2.581508167172871e-05, "of learning concepts": 0.001412997877799242, "each quadrant the": 0.0012265208479459286, "the decision tree": 0.0018078982588359625, "by generalizing": 0.001013492172364257, "door or": 0.0013439565011394887, "two disjoint quadrants": 0.001412997877799242, "pose a1 pose": 0.001412997877799242, "of pixels noisy": 0.001412997877799242, "kalman": 0.000754000698128159, "large state": 0.0008623569375540945, "afforded by": 0.0009217509760058083, "to recognize visual": 0.001412997877799242, "general forms of": 0.001177670521728601, "model specifies": 0.0010706929277613088, "be easily converted": 0.0011397700534482, "experimental results obtained": 0.0009647109541934066, "computed by": 0.0003416245722115272, "representation we": 0.0007201345364976421, "successful navigation despite": 0.001412997877799242, "task we have": 0.0012265208479459286, "thresholded the images": 0.001412997877799242, "only feature detectors": 0.001412997877799242, "cans learning alvinn": 0.001412997877799242, "task nevertheless this": 0.001412997877799242, "architecture for solving": 0.001412997877799242, "and returning to": 0.001412997877799242, "reliable": 0.0002642714752453443, "effects of": 0.0007722372201990007, "to other environments": 0.001412997877799242, "is probably": 0.000600103348117393, "concepts from limited": 0.001412997877799242, "well known": 0.0002324881439137171, "with decision tree": 0.0012265208479459286, "also been investigated": 0.0010599041887614004, "sensory concepts from": 0.002825995755598484, "performance as": 0.0005830336660574013, "bias to speed": 0.001412997877799242, "error": 6.70771007134302e-05, "wireless ethernet system": 0.001412997877799242, "detect and move": 0.002825995755598484, "combination of the": 0.0005764690730021806, "the trash receptacles": 0.001412997877799242, "of instances is": 0.001177670521728601, "rgb values": 0.0012263127867333846, "un known": 0.0011086075099259812, "same location and": 0.0012265208479459286, "behaviors camera turn": 0.001412997877799242, "dimensional as": 0.0012263127867333846, "all i": 0.0004969104621112533, "it tried to": 0.001412997877799242, "a subsequent across": 0.001412997877799242, "simplifying the presentation": 0.0012953547128852297, "with far": 0.0012263127867333846, "motors": 0.0009215946410370149, "to a neural": 0.0012265208479459286, "encountered": 0.00031853588071854686, "a multi output": 0.002453041695891857, "itself": -1.4757696232976561e-05, "processing a robust": 0.001412997877799242, "be able to": 0.0003608369386470323, "all cases": 0.0004536956778820191, "to 1 note": 0.0012265208479459286, "in actual": 0.0016214159433796539, "we thresholded the": 0.001412997877799242, "is easy to": 0.0003262505311894494, "has to induce": 0.001412997877799242, "other environments": 0.0010397031738864368, "an accurate job": 0.001412997877799242, "can contain": 0.0006916942228847701, "map sensory": 0.0013439565011394887, "other litter and": 0.001412997877799242, "primarily on": 0.0007387405675331519, "robots 21": 0.0013439565011394887, "872": 0.0016689216166309786, "2 as illustrated": 0.0012953547128852297, "the grdt": 0.0013439565011394887, "smaller network": 0.0012263127867333846, "sensor i reports": 0.002825995755598484, "pose a2 pose": 0.001412997877799242, "difficult to": 0.0010762618585290695, "corridor": 0.0019812217290954537, "observation model": 0.001157470080128191, "been well": 0.0008183105262917859, "architecture for robot": 0.001412997877799242, "structure this": 0.0007488464497674484, "2 ff post": 0.001412997877799242, "khaleeli front back": 0.001412997877799242, "the rgb": 0.0010706929277613088, "pre specified": 0.0017674253275119325, "nets vs one": 0.001412997877799242, "a type of": 0.0007812905079402834, "active learning": 0.0009365728948883588, "has clearly": 0.0011086075099259812, "domain to train": 0.001412997877799242, "finds the trash": 0.001412997877799242, "subservient behaviors": 0.0013439565011394887, "9501852 the": 0.0013439565011394887, "the strategies provide": 0.001412997877799242, "now present the": 0.0008658836593557804, "partially observable semi": 0.001412997877799242, "particular observation will": 0.001412997877799242, "based approaches": 0.0006772995603809331, "purpose": 8.400087222608734e-05, "of supervised": 0.0009528025610969587, "1 pavlov": 0.0026879130022789775, "aggregate": 0.00042172281920285635, "pulse will reflect": 0.001412997877799242, "a pragmatic approach": 0.001177670521728601, "the electrical engineering": 0.0012953547128852297, "recent": 5.4542677090817896e-05, "non learning": 0.0022172150198519623, "labeled patterns": 0.0013439565011394887, "task": 0.0016259406680687938, "approach taken": 0.0006916942228847701, "robots need": 0.0012263127867333846, "for ex": 0.0006140604889952477, "action a": 0.0007541286032508272, "the ee department": 0.001412997877799242, "there are 256": 0.0012953547128852297, "announced that": 0.0011086075099259812, "values hue": 0.0013439565011394887, "d figure 9": 0.0010599041887614004, "and robotic": 0.0010397031738864368, "i2i": 0.0008032901031876688, "the inputs to": 0.00084653211689172, "of a few": 0.0007130528122063535, "traces starting": 0.0024526255734667692, "new examples to": 0.001412997877799242, "spatial decomposition the": 0.001412997877799242, "y": -0.0003245304548104451, "bias strategies": 0.0013439565011394887, "or undefined these": 0.001412997877799242, "the system": 0.00018866581243516913, "onboard the robot": 0.001412997877799242, "uncer tainty": 0.0012263127867333846, "overall control": 0.004031869503418466, "trees is": 0.0006772995603809331, "observation is": 0.0005101280194599199, "diverse collection": 0.0013439565011394887, "better on the": 0.0010599041887614004, "sufficient bias to": 0.002825995755598484, "human trainer provides": 0.001412997877799242, "the robotic system": 0.001412997877799242, "shape": 0.0002634174067090446, "programming mobile robots": 0.001412997877799242, "output err": 0.0013439565011394887, "predict the same": 0.001412997877799242, "g prefer": 0.0013439565011394887, "denote the": 0.00019164945286656674, "4 observations one": 0.001412997877799242, "and add": 0.0005750676982296913, "the object": 0.0008595026280744356, "not just the": 0.0008405371151868688, "is input to": 0.0010599041887614004, "set of labeled": 0.0010826007236946758, "learning for": 0.008924641399776726, "somewhat tedious": 0.0010706929277613088, "1 the robot": 0.0012265208479459286, "the observation probability": 0.0012953547128852297, "the route planner": 0.001412997877799242, "study of bias": 0.001412997877799242, "main categories of": 0.001412997877799242, "it can": 0.00025641072222609565, "are noticeable": 0.0013439565011394887, "source": 6.468242139231747e-05, "rgb": 0.0007768969997482151, "sampling was": 0.001013492172364257, "location": 0.00039476198935128496, "also unreliable": 0.0013439565011394887, "pose c3": 0.0013439565011394887, "input": -0.0005556612759623114, "pose c1": 0.0013439565011394887, "khaleeli figure 9": 0.001412997877799242, "are able": 0.0004133086117730371, "after the execution": 0.0008658836593557804, "a sequence of": 0.00034346483958208493, "8 an": 0.0007437201166480605, "by caruana": 0.0013439565011394887, "model is specified": 0.0012265208479459286, "f are examples": 0.001412997877799242, "fill in": 0.0006428774807200497, "task learning": 0.0024526255734667692, "images which": 0.0008183105262917859, "find the trash": 0.001412997877799242, "entire floor": 0.0026879130022789775, "process models machine": 0.001412997877799242, "and frame grabber": 0.001412997877799242, "thus if sensor": 0.001412997877799242, "easily collected similarly": 0.001412997877799242, "32x32 door wall": 0.001412997877799242, "of two tasks": 0.0012265208479459286, "is a combination": 0.0008347439643413854, "pavlov is an": 0.001412997877799242, "behaviors camera": 0.0013439565011394887, "grids free space": 0.001412997877799242, "necessary since not": 0.001412997877799242, "d": -0.0019176412058330384, "semi": 0.0005826497615584575, "low occupancy probability": 0.001412997877799242, "grid or": 0.0010397031738864368, "follows": -0.000356874856558719, "figure 2 illustrates": 0.00080838360373212, "experimental study": 0.0007291894113705743, "examples converged to": 0.001412997877799242, "the images 100x100": 0.001412997877799242, "that is much": 0.0009316462484985891, "learning to find": 0.001412997877799242, "focus on": 0.00030967930079381644, "can robustly predict": 0.001412997877799242, "paper investigates how": 0.001412997877799242, "reactive behavior": 0.001157470080128191, "new features figure": 0.001412997877799242, "focus of": 0.001089268030424371, "smarter and easier": 0.001412997877799242, "to label the": 0.001021962604845781, "each local": 0.0007488464497674484, "to create": 0.0004019963390390999, "adjacent east": 0.0013439565011394887, "opening right opening": 0.001412997877799242, "methods": -0.0003693709311649946, "detectors shaded": 0.0013439565011394887, "one of": 0.00025775413446763, "rejected in favor": 0.001177670521728601, "use a common": 0.0010826007236946758, "it is received": 0.0009909470066802508, "back": 0.0005611910481469245, "useful information": 0.0006705211052503373, "distribution on the": 0.000823711514802973, "these strategies": 0.0008837126637559662, "robotics tasks where": 0.001412997877799242, "have also": 0.00036337447101637035, "and figure": 0.0015345073163758884, "them in": 0.00039733375546185, "b1": 0.0005461981208921447, "b2": 0.0006091830535751379, "b3": 0.0007435939768725096, "items inside it": 0.0012953547128852297, "out using": 0.0007770287888915143, "difficult to employ": 0.001412997877799242, "describing the two": 0.0012953547128852297, "data is not": 0.0008591880780779472, "scale": 0.00027968052429558403, "8s 2": 0.0010397031738864368, "decision": 0.002085759321408197, "door opening": 0.0013439565011394887, "two sets": 0.0004486675246498633, "learning one": 0.0011086075099259812, "valued input": 0.0012263127867333846, "task and": 0.001209272318169717, "as it tried": 0.001412997877799242, "and its": 0.00012091213513228694, "the planning": 0.0009081111668589885, "trash receptacles are": 0.001412997877799242, "is not directly": 0.0008728509105201892, "machine learning an": 0.0012265208479459286, "found the": 0.0005214173517462262, "specular environment": 0.0013439565011394887, "be": 0, "to employ": 0.0007033220515237973, "we investigated sensory": 0.001412997877799242, "than the": 8.27316719839078e-05, "they expose": 0.0012263127867333846, "as its height": 0.001412997877799242, "section 7 summarizes": 0.0009909470066802508, "behavior simply": 0.0012263127867333846, "an explicit probabilistic": 0.0012953547128852297, "structure we study": 0.001412997877799242, "grant no": 0.0006705211052503373, "constructed by": 0.0004810038155285948, "to this": 0.0001568143949037159, "a probabilistic planning": 0.001412997877799242, "of virtual": 0.0006486581696160977, "at 0 0": 0.0021198083775228007, "net using batch": 0.001412997877799242, "obscured": 0.0008032901031876688, "by": 0, "recycling the second": 0.001412997877799242, "times or": 0.000872702844207972, "output neural nets": 0.001412997877799242, "200 platform 4": 0.001412997877799242, "ular robots that": 0.001412997877799242, "paper were": 0.0007541286032508272, "outputs were the": 0.001412997877799242, "the occupancy grid": 0.001412997877799242, "limitations of": 0.001092581550731157, "the strategies": 0.0008262639069617736, "learn hierarchical concept": 0.001412997877799242, "vector if": 0.0009365728948883588, "for robots": 0.0022172150198519623, "since all": 0.00043156351621725415, "for navigation given": 0.001412997877799242, "stopped adjacent": 0.0013439565011394887, "strategies to": 0.0007488464497674484, "quadrants and": 0.0010706929277613088, "computational": -2.9497528344418623e-06, "neural networks": 0.0006265849827685552, "decomposing the": 0.0008525989995294478, "into": -0.006200066866030678, "directly learns": 0.0013439565011394887, "sensory state": 0.0026879130022789775, "nsf": 0.0002668506653086295, "post scale this": 0.001412997877799242, "will eventually": 0.0006140604889952477, "appropriate": -4.3998662031129686e-05, "model however as": 0.001412997877799242, "examples are": 0.0005258336588949284, "also be": 0.00016598907557488122, "primarily": 0.0002838200262250284, "observation model specifies": 0.001412997877799242, "learning how to": 0.002355341043457202, "multiple category": 0.0012263127867333846, "it possible": 0.000494374705490854, "uncertainties": 0.000724480329627718, "totally obscured": 0.0013439565011394887, "d blanco l": 0.001412997877799242, "are more": 0.00032290483736034415, "uncer": 0.001039526833456673, "model we present": 0.0009647109541934066, "2 3 abstract": 0.0012953547128852297, "specifically": 0.00013387054079141454, "of examples ffl": 0.001412997877799242, "the goal is": 0.0005687830365613714, "them with the": 0.00084653211689172, "feature detectors for": 0.005651991511196968, "variation in observation": 0.001412997877799242, "output net vs": 0.001412997877799242, "an acronym for": 0.0011397700534482, "forward": 0.00019295143021944453, "favor of a": 0.0011087956007827721, "related tasks their": 0.001412997877799242, "prediction is accomplished": 0.001412997877799242, "offices and": 0.0012263127867333846, "is based on": 0.0005315826969807662, "comments on a": 0.0009316462484985891, "state space": 0.0016438878287626034, "partition the state": 0.0012953547128852297, "output layer": 0.001013492172364257, "every action": 0.001013492172364257, "it relies on": 0.0010057508064281846, "learning 20 and": 0.001412997877799242, "one promising": 0.001157470080128191, "a computational cost": 0.001177670521728601, "detectors for probabilistic": 0.001412997877799242, "12 describe a": 0.0012265208479459286, "in robot learning": 0.001412997877799242, "current sensor": 0.0013439565011394887, "basic idea": 0.00047751450315164086, "ir sensors": 0.0013439565011394887, "based studies alvinn": 0.001412997877799242, "output learning": 0.0026879130022789775, "approaches seem more": 0.001412997877799242, "the output space": 0.0012953547128852297, "actuator uncertainty to": 0.001412997877799242, "0000000000000000000000000000000000000000000000000000000000000000111111111111111111111111111111111111111111111111111111111111111111111111 sensor reports": 0.001412997877799242, "considerable": 0.00028567490173121067, "reinforcement learning 25": 0.001412997877799242, "40 epochs comparing": 0.001412997877799242, "approaches to robot": 0.001412997877799242, "in figure": 0.0008405430600322588, "to recognize": 0.003522912592778428, "an actual": 0.0018494884372659284, "in both studies": 0.0012953547128852297, "the experimental setup": 0.001021962604845781, "figure 2 a": 0.0005543204292900327, "20 to": 0.0006879834963441684, "up": -0.0013878574814143916, "is an": 0.00011107051705853331, "un": 0.00036331284033946795, "exploration": 0.00040192815784184085, "a colored": 0.0013439565011394887, "the lab": 0.001013492172364257, "circumstances because they": 0.001412997877799242, "using a logical": 0.0012265208479459286, "autonomous": 0.0018226661260952108, "an active topic": 0.001412997877799242, "they are": 0.00010690521972731431, "is illustrated": 0.00043156351621725415, "network with several": 0.001412997877799242, "there are interesting": 0.001177670521728601, "below that": 0.0006486581696160977, "robot navigation the": 0.0012265208479459286, "function approximator": 0.002314940160256382, "constant": -9.375675421726982e-05, "noisy sensing and": 0.001412997877799242, "defined": -0.000615645490738467, "the behaviors camera": 0.001412997877799242, "can and announced": 0.001412997877799242, "a robust robot": 0.001412997877799242, "an observation o": 0.001412997877799242, "figure 11 a": 0.0007988727145907639, "single": -0.0012027683260157657, "diverse": 0.0004820994576323383, "control strategy as": 0.001412997877799242, "learn hierarchical": 0.0013439565011394887, "for a multi": 0.0010057508064281846, "but once": 0.000872702844207972, "ultrasound sonar": 0.0013439565011394887, "successfully learn": 0.0013439565011394887, "and some researchers": 0.0012953547128852297, "same location": 0.0007595764743381157, "the high level": 0.0006868803310078682, "image can": 0.0007652009340995504, "f 2 q": 0.0012953547128852297, "slower to converge": 0.001412997877799242, "the sensor and": 0.0011397700534482, "some definite strengths": 0.001412997877799242, "saturation intensity": 0.0013439565011394887, "fundamentals of": 0.0007115262727613508, "from actual": 0.0009907789071032058, "substantially larger": 0.0009528025610969587, "concepts using": 0.0012263127867333846, "were transformed into": 0.0012265208479459286, "and easier to": 0.0009316462484985891, "bump figure 4": 0.001412997877799242, "priori": 0.00031117444266368533, "coded": 0.0013310704490472661, "effects of the": 0.0014042208197418819, "corridor or an": 0.001412997877799242, "from labeled": 0.0020794063477728737, "was directly": 0.0011086075099259812, "experiments were carried": 0.0009773255297405913, "was done by": 0.0008591880780779472, "speeding up learning": 0.001412997877799242, "variation in": 0.000600103348117393, "explaining": 0.000571115303593364, "and multiple category": 0.001412997877799242, "current camera image": 0.001412997877799242, "khaleeli 2 2": 0.001412997877799242, "sonar pulse": 0.0026879130022789775, "this task three": 0.001412997877799242, "filters 14 because": 0.001412997877799242, "robots": 0.014203964514068357, "in pose c2": 0.001412997877799242, "learning s mahadevan": 0.002825995755598484, "in favor of": 0.0007277706970731944, "learning a knowledge": 0.001412997877799242, "net to learn": 0.002825995755598484, "detectors are all": 0.001412997877799242, "5 limitations of": 0.0012953547128852297, "e g see": 0.001554321245509154, "due to wheel": 0.001412997877799242, "a priori": 0.00044183835550954694, "85 rapid": 0.0013439565011394887, "rules a process": 0.001412997877799242, "abilities such": 0.0012263127867333846, "environment testing": 0.0013439565011394887, "far c": 0.0013439565011394887, "for further": 0.00043898269583821114, "so that we": 0.0006310701423978614, "of examples": 0.0011701623080033216, "space to yield": 0.0012953547128852297, "labeled training": 0.0021413858555226176, "algorithm": -0.0010069706712890734, "function learning": 0.0010706929277613088, "robots 17": 0.0013439565011394887, "has a": 8.116882834996679e-05, "robots 15": 0.0013439565011394887, "figures are labeled": 0.001412997877799242, "seem more": 0.0009707370964526472, "sensory input": 0.0012263127867333846, "robots 11": 0.0013439565011394887, "13 21 this": 0.001412997877799242, "tradeoff": 0.0004003624224649576, "examples of": 0.0009622117678176531, "grid data we": 0.001412997877799242, "2004": 1.4265182813663562e-05, "a symbolic concept": 0.001412997877799242, "representation can speed": 0.001412997877799242, "the input size": 0.0009219073640234544, "recognition in": 0.0008433654142724929, "having": -4.7502963545889e-05, "function front back": 0.001412997877799242, "approximators e": 0.0013439565011394887, "models journal": 0.0013439565011394887, "general approaches": 0.002026984344728514, "illustrates": 0.00042761501069332546, "difficult to create": 0.0012265208479459286, "very near": 0.00693545234972244, "autonomous robots": 0.0010706929277613088, "sub sampled": 0.0012263127867333846, "results": -0.004942908563209947, "and engineering department": 0.0012953547128852297, "illustrated": 0.0002654550085426012, "ffl decomposable": 0.0013439565011394887, "by running the": 0.001636898728364465, "indicate that occupancy": 0.001412997877799242, "7 summary": 0.0008623569375540945, "the action": 0.0005365667592471254, "directions the navigation": 0.001412997877799242, "same camera invariances": 0.001412997877799242, "to move": 0.0004931194694266732, "the purpose": 0.0007427307386171045, "input dimensions is": 0.001412997877799242, "dimensional sensory concepts": 0.001412997877799242, "commands neural": 0.0013439565011394887, "department figure": 0.0012263127867333846, "error such as": 0.0011397700534482, "sensor reports": 0.0026879130022789775, "9501852 the authors": 0.001412997877799242, "most how": 0.0013439565011394887, "moving the robot": 0.001412997877799242, "speeding up": 0.0007437201166480605, "helps": 0.000616178495829302, "the allowed": 0.0007897242543278053, "one where the": 0.0009039491294179812, "position a pose": 0.001412997877799242, "general approaches to": 0.0025907094257704593, "indicating": 0.0005067588281249172, "avoid motors turret": 0.001412997877799242, "and behaviors to": 0.001412997877799242, "learn a complex": 0.001412997877799242, "random": 6.162928897546766e-05, "a normalization constant": 0.0010826007236946758, "front left back": 0.001412997877799242, "models fast": 0.0012263127867333846, "assumes sensor reports": 0.001412997877799242, "state is": 0.0004663220655674039, "presented the": 0.0005496498068625872, "continues": 0.00026945586531834865, "teacher supervised": 0.0013439565011394887, "easing this programming": 0.001412997877799242, "was trained": 0.001816222333717977, "abstract action a": 0.001412997877799242, "uses an explicit": 0.0012953547128852297, "include ultrasound": 0.0013439565011394887, "commands action reports": 0.001412997877799242, "3 bias is": 0.001412997877799242, "sufficiently constrain": 0.0013439565011394887, "subservient": 0.0011084194828720588, "engineering department nodes": 0.001412997877799242, "reactive behavior based": 0.001412997877799242, "categories": 0.000933523327991056, "however as the": 0.0008658836593557804, "human designer specifies": 0.001412997877799242, "entire": 0.00016362803127245367, "providing labeled": 0.0013439565011394887, "sharing used to": 0.001412997877799242, "problem for": 0.00033178715761020066, "results the": 0.00039733375546185, "generated over an": 0.001412997877799242, "concepts is difficult": 0.001412997877799242, "integrating": 0.000300053763988856, "two advantages of": 0.0012265208479459286, "fewer": 0.00018371990532810935, "functions the": 0.0005074090681964598, "reports from different": 0.001412997877799242, "feature detectors we": 0.001412997877799242, "5 spatial decomposition": 0.001412997877799242, "learning an entire": 0.0012953547128852297, "256 possible abstract": 0.001412997877799242, "specularities are": 0.0024526255734667692, "1 spatial decomposition": 0.001412997877799242, "to achieve": 0.00027213393847785617, "pose b1": 0.0013439565011394887, "pose b2": 0.0013439565011394887, "a probabilistic": 0.0011424243698003305, "in figure 9": 0.0020899134299869125, "image generates four": 0.001412997877799242, "dimensional and": 0.0025300962428174787, "as in the": 0.0003215120511083389, "representations incur": 0.0013439565011394887, "provided example": 0.0013439565011394887, "detecting a trash": 0.001412997877799242, "categories e g": 0.001412997877799242, "a procedural reactive": 0.001412997877799242, "380 labeled patterns": 0.001412997877799242, "execution of": 0.0003191248780767641, "to the special": 0.0008801129633255439, "learning approach": 0.0017674253275119325, "indicate that": 0.00033810289289654106, "reports grids raw": 0.001412997877799242, "service robot learning": 0.001412997877799242, "feature based approach": 0.0010826007236946758, "cans we now": 0.001412997877799242, "the direction of": 0.0005987190271236737, "abstract observations": 0.0026879130022789775, "illustrates the variation": 0.001412997877799242, "of bumper": 0.0013439565011394887, "at every step": 0.0009219073640234544, "navigation task pavlov": 0.001412997877799242, "presented above": 0.0007115262727613508, "has a color": 0.0012265208479459286, "a state estimation": 0.001412997877799242, "learning sensory": 0.004031869503418466, "science department": 0.0007541286032508272, "and the invariants": 0.0012953547128852297, "is that the": 0.000620493542125603, "learning and the": 0.0009909470066802508, "learning we provide": 0.001412997877799242, "2 in actuality": 0.001412997877799242, "some researchers": 0.0007595764743381157, "some interesting way": 0.001412997877799242, "is often": 0.0012722247598668723, "such a": 0.0001971263384017775, "a percept is": 0.001412997877799242, "thank lynn ryan": 0.001412997877799242, "state estimator are": 0.001412997877799242, "once again spatial": 0.001412997877799242, "state and action": 0.0011397700534482, "navigation system onboard": 0.001412997877799242, "3 abstract observations": 0.001412997877799242, "called grdt which": 0.001412997877799242, "paper proposes": 0.0008183105262917859, "far d right": 0.001412997877799242, "objects": 0.0009298736868429107, "invariances across related": 0.001412997877799242, "which is a": 0.0003797330874547477, "on using": 0.0006843495569384895, "the state into": 0.0012953547128852297, "addition pavlov has": 0.001412997877799242, "observation o": 0.0013439565011394887, "despite significant": 0.0036789383602001536, "intersec tions would": 0.001412997877799242, "to an acceptable": 0.0012953547128852297, "39": 0.00016658042009188938, "for the neural": 0.0012953547128852297, "can is colored": 0.001412997877799242, "ctr": -0.00030605469725330473, "based on those": 0.001021962604845781, "building over a": 0.001412997877799242, "mobile robot navigation": 0.004238993633397726, "as ff prior": 0.001412997877799242, "robot is not": 0.001412997877799242, "because they are": 0.0006190704497024985, "virtual sensors": 0.004031869503418466, "a belief": 0.0009907789071032058, "multiple single": 0.0012263127867333846, "limitations ffl": 0.0013439565011394887, "an entire floor": 0.001412997877799242, "implement": 0.00028445376896712386, "perceived geometric": 0.0013439565011394887, "e g far": 0.001412997877799242, "involves": 0.00011042182184925433, "within task": 0.0013439565011394887, "reflections before": 0.0013439565011394887, "and homes": 0.0012263127867333846, "paper is": 0.00030880803589407053, "switches are": 0.0009081111668589885, "where a": 0.0004890778760966719, "mobile robots 11": 0.001412997877799242, "mobile robots 13": 0.001412997877799242, "ring two": 0.0012263127867333846, "mobile robots 15": 0.001412997877799242, "in some interesting": 0.001412997877799242, "mobile robots 17": 0.001412997877799242, "the robot": 0.030693563983060123, "variables the": 0.0004718367548188342, "to find objects": 0.001412997877799242, "to use": 0.0002810485008655981, "by 2 ff": 0.001412997877799242, "net symbolic learning": 0.001412997877799242, "multitask": 0.0009906108645477269, "order to implement": 0.0008728509105201892, "the purpose of": 0.0009089061877113141, "preclassified training": 0.0013439565011394887, "b pose": 0.0013439565011394887, "about training": 0.0012263127867333846, "robot lab18": 0.0013439565011394887, "be a fairly": 0.0012953547128852297, "from color images": 0.001412997877799242, "one of the": 0.000606864537371809, "believe many interesting": 0.001412997877799242, "different approaches": 0.0013410422105006746, "task is recycling": 0.001412997877799242, "expose the": 0.000872702844207972, "up the": 0.000346408871480994, "other than": 0.00038179665107752485, "propose a": 0.00039277451762902583, "found the trash": 0.001412997877799242, "proposes some": 0.0010397031738864368, "two strategies": 0.0016366210525835718, "recognizers we believe": 0.001412997877799242, "obstacle avoidance algorithms": 0.001412997877799242, "an actual run": 0.0025907094257704593, "both the": 0.00017160320808795249, "on": 0, "21 3": 0.0007595764743381157, "24 among": 0.0013439565011394887, "an active": 0.0017370207227370635, "scale is": 0.0008107079716898269, "robot learning introduction": 0.001412997877799242, "khaleeli specifically": 0.0013439565011394887, "can learn hierarchical": 0.001412997877799242, "train": 0.001048521863418696, "how is": 0.0008623569375540945, "figure shows some": 0.0012953547128852297, "that the designer": 0.0010057508064281846, "the robot this": 0.0012953547128852297, "abstract action": 0.0012263127867333846, "region having": 0.0010706929277613088, "nomad 200 platform": 0.001412997877799242, "litter lying on": 0.001412997877799242, "images into black": 0.001412997877799242, "process models fast": 0.001412997877799242, "account": 6.979433896949236e-05, "state space e": 0.001412997877799242, "f": -0.0012819852414732206, "this": 0, "two tasks were": 0.001412997877799242, "topic 1": 0.0013439565011394887, "dozen or so": 0.0012953547128852297, "pick up litter": 0.001412997877799242, "study is": 0.000595682008283464, "four possibilities": 0.0010397031738864368, "yellow color and": 0.001412997877799242, "is impossible": 0.0004845581350670879, "decision trees 23": 0.001412997877799242, "carefully structures the": 0.001412997877799242, "behavior based": 0.0037462915795534353, "features that sensor": 0.001412997877799242, "handle transfer across": 0.001412997877799242, "state distribution is": 0.002825995755598484, "197 february": 0.001013492172364257, "a local occupancy": 0.004238993633397726, "her detailed comments": 0.001412997877799242, "an abstract observation": 0.004238993633397726, "distribution ff post": 0.001412997877799242, "object is near": 0.001412997877799242, "process": -0.0005550700589413734, "by such an": 0.0010057508064281846, "purposes": 0.00028274525717128567, "pieces": 0.000372663598598409, "high": -0.0020857593214081978, "we also": 0.00012007758000460841, "the walls": 0.001013492172364257, "3 accelerating sensory": 0.001412997877799242, "employs": 0.00037960427704516325, "to learn related": 0.001412997877799242, "of the university": 0.0009419732139289226, "distributions such": 0.0010397031738864368, "neural network": 0.0034039461843834084, "undefined these": 0.0013439565011394887, "grid and one": 0.001412997877799242, "odometric": 0.006130523980489571, "sampled the": 0.0010397031738864368, "plot of three": 0.001412997877799242, "concepts from sensor": 0.001412997877799242, "advantage however of": 0.001412997877799242, "also possible to": 0.0007438462992263857, "g prefer shallower": 0.001412997877799242, "here the": 0.0006647080689827007, "observable markov": 0.0024526255734667692, "labeled examples since": 0.001412997877799242, "learning scenarios a": 0.001412997877799242, "modeling of": 0.0005381522116980043, "regions": 0.00022235486399323985, "a multi class": 0.0011397700534482, "subfunctions for each": 0.001412997877799242, "1 dimensional rather": 0.001412997877799242, "a decomposition each": 0.001412997877799242, "intelligent": 0.0003607145380572605, "was directly observable": 0.001412997877799242, "standardized function": 0.0013439565011394887, "variations 10 using": 0.001412997877799242, "behaviors such": 0.0009907789071032058, "update starting": 0.0013439565011394887, "philosophy": 0.000571115303593364, "is color": 0.001157470080128191, "collection": 0.00043080311232779355, "difficult because the": 0.001021962604845781, "of multiple classes": 0.0012265208479459286, "net correctly predicts": 0.002825995755598484, "because they": 0.0010465215638180755, "grid in figure": 0.0012953547128852297, "method 8 an": 0.001412997877799242, "trash can although": 0.001412997877799242, "setup for finding": 0.001412997877799242, "robot neural network": 0.001412997877799242, "it navigated": 0.0013439565011394887, "better representatives": 0.0013439565011394887, "for neural": 0.0008623569375540945, "on pavlov include": 0.001412997877799242, "so that": 0.00010501089201123384, "a behavior": 0.0008346023623118109, "curve for training": 0.002825995755598484, "research builds on": 0.001412997877799242, "actual mobile": 0.0012263127867333846, "in figure 5": 0.00039084634498055246, "are 256": 0.001157470080128191, "provided that a": 0.001021962604845781, "interesting way either": 0.001412997877799242, "robot": 0.035077891105361324, "element": 3.8012528058182624e-05, "contrasted with": 0.0008837126637559662, "implement a collection": 0.001412997877799242, "training data acknowledgements": 0.001412997877799242, "color images": 0.0019056051221939174, "decision trees is": 0.001039879574153469, "type of bias": 0.0012953547128852297, "relational learning": 0.0010706929277613088, "subsequently": 0.000300053763988856, "registers a range": 0.001412997877799242, "promising avenue": 0.0012263127867333846, "useful concepts": 0.0013439565011394887, "represen tation": 0.0009365728948883588, "collection of examples": 0.0012953547128852297, "corresponding features as": 0.001412997877799242, "produces": 0.00012312364372166491, "aligment of the": 0.001412997877799242, "move": 0.0005280015645640318, "which can": 0.00019634483268719983, "rapid training phase": 0.001412997877799242, "value out": 0.0011086075099259812, "are examples of": 0.0008035626821164737, "produced": 0.0001242434841028843, "which are better": 0.0011397700534482, "however a": 0.0004371016452995968, "in pose": 0.0011086075099259812, "that it directly": 0.001177670521728601, "reflections in": 0.0010397031738864368, "work this research": 0.0011397700534482, "up learning based": 0.002825995755598484, "almost totally wiping": 0.001412997877799242, "al 12 describe": 0.0012953547128852297, "of possible hypotheses": 0.001412997877799242, "generated during": 0.0008107079716898269, "0 3": 0.0004437654151870332, "0 2": 0.0003175236941308891, "this framework": 0.000577026606170962, "the problem": 0.00010447082379275636, "extract the rough": 0.001412997877799242, "obtained on a": 0.0009909470066802508, "the presented examples": 0.001412997877799242, "0 4": 0.00046961187631144803, "chosen": -8.585322612989181e-05, "useful concepts under": 0.001412997877799242, "other behaviors implement": 0.001412997877799242, "in the short": 0.0011087956007827721, "been presented the": 0.0012265208479459286, "cost in actual": 0.0012953547128852297, "features such as": 0.0015462538723628467, "selected pixels": 0.001157470080128191, "our real": 0.0009907789071032058, "human drivers": 0.0013439565011394887, "sensor noise the": 0.001412997877799242, "pavlov is": 0.004031869503418466, "often high": 0.0012263127867333846, "loop in the": 0.0007898582421551431, "hundred at most": 0.001412997877799242, "planning layer requires": 0.001412997877799242, "is able to": 0.002493523414969239, "distribution is updated": 0.001412997877799242, "are generated from": 0.0009219073640234544, "indicating the direction": 0.0012265208479459286, "manually labeled real": 0.001412997877799242, "challenging because it": 0.001412997877799242, "the idea": 0.0006287083308713586, "presented examples": 0.0011086075099259812, "an acceptable range": 0.001177670521728601, "could itself acquire": 0.001412997877799242, "17 it": 0.0007710139595398186, "use of feature": 0.0012265208479459286, "the underlying state": 0.0012265208479459286, "rotation": 0.00043985537530225066, "realize": 0.00042877863325190105, "along one": 0.0008525989995294478, "all sensors": 0.0011086075099259812, "resolve the situation": 0.001412997877799242, "february": 0.0001672009488674975, "is required to": 0.0010167945046283132, "door wall": 0.0026879130022789775, "behaviors from scalar": 0.001412997877799242, "the test data": 0.0009647109541934066, "identified": 0.00016410855262240597, "environment were": 0.0012263127867333846, "so synthetic examples": 0.001412997877799242, "architecture the": 0.0005413646011976051, "sufficiently": 0.00037660798055062035, "the most successful": 0.0009773255297405913, "the data": 0.0006074499859905295, "boolean variables were": 0.001412997877799242, "models machine learning": 0.0012265208479459286, "to handle transfer": 0.001412997877799242, "paper we investigate": 0.001588613430236152, "traces": 0.0007824210021246888, "are also provided": 0.0010826007236946758, "to equip them": 0.001412997877799242, "rapid within": 0.0013439565011394887, "to correctly": 0.0013759669926883369, "pieces of this": 0.001412997877799242, "doing": 0.00021797799257946434, "the right simultaneously": 0.001412997877799242, "label the": 0.0006639936831495265, "programmed": 0.0010793197263188098, "for probabilistic": 0.0008107079716898269, "tasks we": 0.0007710139595398186, "accomplished by using": 0.0010599041887614004, "simultaneous learning of": 0.001412997877799242, "every state": 0.0007201345364976421, "to correctly predict": 0.0022175912015655443, "of supervised learning": 0.0010826007236946758, "predicting the": 0.000634544764829945, "of features that": 0.0010599041887614004, "better on": 0.0007541286032508272, "and right quadrants": 0.001412997877799242, "is also possible": 0.0006684317399421915, "to complete rapid": 0.001412997877799242, "if sensor": 0.001157470080128191, "we then": 0.000263036032639723, "map the current": 0.001412997877799242, "pose a1": 0.0013439565011394887, "can in": 0.0011424243698003305, "pose a3": 0.0013439565011394887, "pose a2": 0.0013439565011394887, "a robot that": 0.001177670521728601, "its output with": 0.001412997877799242, "sometimes a contradictory": 0.001412997877799242, "gets back on": 0.001412997877799242, "sensory data": 0.0024526255734667692, "reports grids": 0.0013439565011394887, "that directly": 0.0008034263695325692, "fast learning": 0.001157470080128191, "can is": 0.0031191095216593105, "robot has": 0.0033258225297779433, "original sensory": 0.0026879130022789775, "state estimators": 0.0013439565011394887, "produce fairly": 0.0013439565011394887, "red": 0.00043609381933684585, "more difficult to": 0.000651731338305688, "2 in": 0.00037469646148038347, "drivers as": 0.0013439565011394887, "category learning": 0.0026879130022789775, "input layer": 0.0010706929277613088, "litter lying": 0.0013439565011394887, "examples to speed": 0.001412997877799242, "was started at": 0.0012953547128852297, "tation such": 0.0013439565011394887, "on pavlov": 0.005375826004557955, "g sonar": 0.0013439565011394887, "approaches": 0.00014265182813663564, "recycling task in": 0.001412997877799242, "labels generated by": 0.0012953547128852297, "unstructured environments": 0.0013439565011394887, "out using a": 0.001039879574153469, "four distinct training": 0.001412997877799242, "likelihood": 0.00036200976641061677, "bleed": 0.0011084194828720588, "etc however": 0.0009365728948883588, "grids where the": 0.001412997877799242, "for details of": 0.0010057508064281846, "new examples through": 0.001412997877799242, "order to": 0.00028769150587789336, "system based": 0.0007157773884946746, "picking up objects": 0.001412997877799242, "currently an active": 0.001412997877799242, "could": -0.001901165766324183, "learning algorithm": 0.0006879834963441684, "measured until": 0.0013439565011394887, "the human designer": 0.0025907094257704593, "through the modeling": 0.001412997877799242, "ff prior when": 0.001412997877799242, "weights the": 0.0007157773884946746, "fewer inputs the": 0.001412997877799242, "previous approaches": 0.0007033220515237973, "networks 19": 0.0013439565011394887, "labels and": 0.0007964395063592673, "through the hallways": 0.001412997877799242, "facilitate": 0.0006349396800887352, "south": 0.002509716265375693, "based architecture 2": 0.001412997877799242, "learning section 3": 0.0012953547128852297, "we investigated": 0.0007710139595398186, "model is": 0.0003127854605005481, "easily than non": 0.001412997877799242, "trees or instance": 0.001412997877799242, "first present": 0.0006639936831495265, "sonar signatures": 0.0013439565011394887, "were close": 0.0013439565011394887, "example the action": 0.0012953547128852297, "preference bias": 0.0012263127867333846, "all cases the": 0.0007405102499664257, "integrating over multiple": 0.001412997877799242, "goal is to": 0.0004412750319230504, "challenging problem": 0.0016867308285449859, "sensor registers": 0.0013439565011394887, "possibility exists that": 0.0012265208479459286, "test data": 0.0006993597717998856, "started at the": 0.001039879574153469, "given by 2": 0.0008405371151868688, "difficult easing this": 0.001412997877799242, "and other junk": 0.001412997877799242, "has already pre": 0.001412997877799242, "while black": 0.0013439565011394887, "collection requires": 0.0024526255734667692, "across related tasks": 0.001412997877799242, "system": -0.0039477049403786775, "normalization constant that": 0.001412997877799242, "position c": 0.003212078783283926, "position b": 0.001157470080128191, "position a": 0.0008525989995294478, "for each region": 0.0009773255297405913, "the order of": 0.0008147477103347201, "research was conducted": 0.0010826007236946758, "position d": 0.0021413858555226176, "work and": 0.000458857097148134, "programmable": 0.0005213289159674361, "which is": 0.00013797849513701011, "since there": 0.00036468572323013323, "door wall opening": 0.002825995755598484, "addition pavlov": 0.0013439565011394887, "learning strategies for": 0.0012953547128852297, "cans rapid": 0.0013439565011394887, "to lab": 0.006719782505697444, "east west corridor": 0.001412997877799242, "output units": 0.001013492172364257, "acquire": 0.001054479939150816, "source of": 0.00043898269583821114, "environmental": 0.0006239029826303446, "left right hidden": 0.001412997877799242, "a and": 0.0003514246629577748, "door by generalizing": 0.001412997877799242, "detectors layer behavior": 0.001412997877799242, "task involves": 0.001157470080128191, "using an image": 0.001412997877799242, "to speed rapid": 0.001412997877799242, "variables making": 0.0013439565011394887, "appropriate bias 20": 0.001412997877799242, "22 has clearly": 0.001412997877799242, "epochs": 0.0022952134531123727, "can from different": 0.001412997877799242, "pose c2": 0.0026879130022789775, "position 5": 0.0012263127867333846, "particular observation": 0.0010706929277613088, "traverse across": 0.0013439565011394887, "often also limited": 0.001412997877799242, "to be a": 0.0003379661979830226, "from local": 0.0007541286032508272, "transducer": 0.0008181717354969602, "the robot believes": 0.001412997877799242, "the features in": 0.001021962604845781, "although most": 0.0008954780757782285, "leading to": 0.00039887620986657805, "an abstract": 0.0021033346355797135, "o is": 0.000631851774969883, "trees or": 0.0008525989995294478, "e and": 0.00036799941167873145, "collecting": 0.00044176341684680785, "sample images with": 0.002825995755598484, "s encoding": 0.001157470080128191, "every five figure": 0.001412997877799242, "of its environment": 0.0011087956007827721, "sensory concepts": 0.008063739006836932, "longer when the": 0.0012953547128852297, "represented by": 0.0002716933246145656, "junk and": 0.0012263127867333846, "bias investigated": 0.0013439565011394887, "uses a state": 0.001412997877799242, "that some form": 0.0012265208479459286, "images with": 0.0014492064541085754, "have": 0, "by integrating over": 0.0011397700534482, "concept previous work": 0.001412997877799242, "values into": 0.001724713875108189, "approaches to bias": 0.0012953547128852297, "clearly": -6.807011379313131e-05, "viewed": 0.0001525798919056139, "feature detectors in": 0.001412997877799242, "is facilitated": 0.0009528025610969587, "system the robot": 0.0012953547128852297, "hsi values of": 0.001412997877799242, "distance far near": 0.001412997877799242, "acting under uncertainty": 0.001412997877799242, "figure 10 the": 0.0021926079854402607, "several hundred input": 0.001412997877799242, "a behavior based": 0.001412997877799242, "now serves as": 0.001412997877799242, "to map": 0.0005637380560122889, "322": 0.0007337750557688759, "decomposing": 0.0005333456404817513, "recognize features the": 0.001412997877799242, "available is": 0.0008346023623118109, "shows some bleed": 0.001412997877799242, "input layer local": 0.001412997877799242, "nomad 200": 0.0036789383602001536, "accuracy": 0.00014487936532005605, "robot is still": 0.001412997877799242, "one more thing": 0.001412997877799242, "possible hypotheses 3": 0.001412997877799242, "collected by": 0.0007770287888915143, "designer carefully structures": 0.001412997877799242, "is huge": 0.0009707370964526472, "examples to be": 0.0012953547128852297, "the engineering building": 0.004238993633397726, "these features from": 0.001412997877799242, "illustrated in": 0.0007280581909673208, "reactive layer the": 0.001412997877799242, "as a": 4.62373518562359e-05, "1 4 1": 0.0008291394238884059, "is received by": 0.0008956300062288188, "of inductive bias": 0.001177670521728601, "4 5 6": 0.0013325115771706472, "trash receptacles from": 0.001412997877799242, "discontinuous distributions": 0.0013439565011394887, "limited e": 0.0012263127867333846, "is to learn": 0.002931976589221774, "can opening": 0.0013439565011394887, "robots to be": 0.001412997877799242, "each for": 0.0016214159433796539, "neural nets where": 0.001412997877799242, "ex ample": 0.0005978790985189038, "from different": 0.0010699896127276541, "for recycling or": 0.001412997877799242, "1 the experiments": 0.001177670521728601, "studied in": 0.0008233069596953609, "were transformed": 0.0010706929277613088, "are also": 0.00019466018519090483, "eventually resolve the": 0.0012953547128852297, "output generated by": 0.0012265208479459286, "the basic idea": 0.0005566527342700465, "both studies": 0.0011086075099259812, "from labeled examples": 0.001412997877799242, "totally obscured by": 0.001412997877799242, "fact": -0.00023282943604160686, "pavlov the results": 0.001412997877799242, "since data": 0.0009217509760058083, "it in": 0.0003627218358225084, "its route": 0.0009907789071032058, "is represented": 0.00035757073401193715, "recycling the": 0.0013439565011394887, "11 shows the": 0.00080838360373212, "at the": 3.155928700727015e-05, "to localize the": 0.001021962604845781, "supported": -2.808595030336518e-05, "variables making it": 0.001412997877799242, "as we will": 0.0005777823180207654, "tree approaches seem": 0.001412997877799242, "rotating": 0.0005564639104117459, "labeling e g": 0.001412997877799242, "robot multitask": 0.0013439565011394887, "has not": 0.00034884052127269184, "limitations ffl need": 0.001412997877799242, "as to the": 0.0008133430731188866, "rough": 0.0004893199240969862, "every human provided": 0.001412997877799242, "it is": 2.212672870620889e-05, "output space": 0.001157470080128191, "task pavlov": 0.0026879130022789775, "feature prediction": 0.0013439565011394887, "registers a": 0.0008346023623118109, "is novel in": 0.0011397700534482, "a door or": 0.001412997877799242, "iri 9501852 the": 0.001412997877799242, "knowledge": 0.00016060285772644383, "applications has": 0.0009528025610969587, "neural net a": 0.0012953547128852297, "9 16 many": 0.001412997877799242, "learning 6 s": 0.001412997877799242, "still able": 0.0019414741929052945, "ffl need for": 0.001412997877799242, "several component abilities": 0.001412997877799242, "took various snapshots": 0.001412997877799242, "errors e g": 0.001177670521728601, "and engineering": 0.0005978790985189038, "grabber": 0.0011084194828720588, "robot this state": 0.001412997877799242, "turn behavior by": 0.001412997877799242, "a contradictory labeling": 0.001412997877799242, "being learned in": 0.0012953547128852297, "decomposition and multi": 0.002825995755598484, "post after the": 0.001412997877799242, "23 and neural": 0.001412997877799242, "in positions": 0.0009081111668589885, "where the effects": 0.001177670521728601, "into hsi values": 0.001412997877799242, "generated during an": 0.0012265208479459286, "in addition pavlov": 0.001412997877799242, "handle": 0.00011700951142453162, "more thing tr": 0.001412997877799242, "is substantially larger": 0.0010826007236946758, "f then y": 0.001412997877799242, "work by caruana": 0.001412997877799242, "scenarios a": 0.001013492172364257, "train but it": 0.001412997877799242, "architecture based on": 0.0010599041887614004, "for 322 leading": 0.001412997877799242, "invariants approach": 0.0013439565011394887, "the left although": 0.001412997877799242, "also unreliable due": 0.001412997877799242, "challenging because": 0.001013492172364257, "2 learning": 0.0009528025610969587, "each region the": 0.001039879574153469, "can but eventually": 0.001412997877799242, "output generated": 0.001157470080128191, "and labeling": 0.0011086075099259812, "examples is": 0.0007291894113705743, "figure 16 results": 0.001412997877799242, "areas": 0.00023743845616073218, "our environment were": 0.001412997877799242, "the variation in": 0.0008956300062288188, "find objects such": 0.001412997877799242, "opening back opening": 0.004238993633397726, "the current camera": 0.0012953547128852297, "in current": 0.0006954851132481282, "opening right": 0.0013439565011394887, "et al 15": 0.0008184493641822325, "alvinn system the": 0.001412997877799242, "regions and learn": 0.001412997877799242, "the form": 0.0005473570037497119, "900000000000000000000000000000000011111111111111111111111111111111111111111111000000000000000000000000000000000000111111111111111111111111111111111111 sensor representation": 0.001412997877799242, "the hypothesis": 0.0005429920482072152, "into high level": 0.001412997877799242, "a combination": 0.0009053592515276875, "is a wall": 0.001412997877799242, "this would be": 0.0007372369477455303, "the country": 0.0009907789071032058, "wall on": 0.0013439565011394887, "robot which": 0.0011086075099259812, "a pragmatic": 0.0009365728948883588, "temporarily": 0.0004893199240969862, "exists": -6.876952308483114e-05, "the robot is": 0.004330402894778703, "significant sensor and": 0.001412997877799242, "frame": 0.0002720877827895119, "traces starting at": 0.0025907094257704593, "conducted over a": 0.001412997877799242, "hard coded feature": 0.001412997877799242, "possible to": 0.00037997716669548374, "10 feature prediction": 0.001412997877799242, "in our work": 0.002241742743608094, "intensity": 0.0009835781590912785, "methods described here": 0.0011397700534482, "which use": 0.000631851774969883, "recy cling": 0.0013439565011394887, "undergo multiple reflections": 0.001412997877799242, "wall or": 0.0013439565011394887, "from the sensor": 0.001177670521728601, "bias 20": 0.0013439565011394887, "by specular": 0.0013439565011394887, "exploited": 0.0005845587217207959, "than 10": 0.0005750676982296913, "based autonomous navigation": 0.001412997877799242, "2 i can": 0.0012953547128852297, "a discussion": 0.0004857578053865428, "one promising avenue": 0.001412997877799242, "with the maximum": 0.0008291394238884059, "a pair of": 0.00047606466618720273, "eventually gets": 0.0009707370964526472, "a pose": 0.001157470080128191, "c in figure": 0.0009773255297405913, "section 4 describes": 0.0007130528122063535, "invariant": 0.00024212443909011114, "the authors wish": 0.000794306715118076, "5 6 and": 0.0007731269361814234, "image input": 0.0012263127867333846, "to learn a": 0.0027118473882539436, "380 labeled": 0.0013439565011394887, "details here": 0.0009365728948883588, "free space is": 0.0012953547128852297, "these strategies was": 0.001412997877799242, "procedural reactive declarative": 0.001412997877799242, "environment this made": 0.001412997877799242, "pavlov see figure": 0.001412997877799242, "produces a": 0.00042441161427938937, "the system just": 0.001412997877799242, "updated to ff": 0.001412997877799242, "hits a": 0.0010397031738864368, "a grammar": 0.0009217509760058083, "smooth we found": 0.001412997877799242, "is a very": 0.0005886458922766477, "by caruana 3": 0.001412997877799242, "be learned": 0.0007541286032508272, "representation the idea": 0.001412997877799242, "size is": 0.0003740970594881401, "on our": 0.000464159640045616, "range 1 within": 0.001412997877799242, "as any criterion": 0.001412997877799242, "use in many": 0.0012265208479459286, "observable": 0.002510007008419206, "learning task this": 0.0012953547128852297, "a neural": 0.002246539349302345, "opposed to": 0.0004486675246498633, "pavlov either inside": 0.001412997877799242, "to recognize features": 0.001412997877799242, "observations are used": 0.0012265208479459286, "insignificant the neural": 0.001412997877799242, "13 shows the": 0.000823711514802973, "here would": 0.0009528025610969587, "be the approximately": 0.001412997877799242, "etc": 0.00025185625750422206, "figures": 0.00013387054079141454, "con ditions": 0.0009707370964526472, "produce 4 training": 0.001412997877799242, "reflections the": 0.0012263127867333846, "attributes": 0.00031535237792390536, "are independent": 0.0004175067704633859, "figure 8 shows": 0.0006293056693152161, "d pose": 0.001157470080128191, "thru door": 0.0013439565011394887, "starting at": 0.0016912141680368669, "the output generated": 0.001412997877799242, "just the": 0.00042885136923718554, "control system": 0.0007338995299089556, "estimator are pre": 0.001412997877799242, "f 2": 0.00045990605238462056, "use in": 0.00040121184181610283, "to determine the": 0.00037324589523553205, "right far e": 0.001412997877799242, "robot starting position": 0.001412997877799242, "generally less than": 0.0010826007236946758, "consistency with the": 0.0010057508064281846, "trace of": 0.0013032415633498643, "employ a top": 0.001412997877799242, "network with": 0.001106142977434748, "shared structure we": 0.001412997877799242, "and neural": 0.0008346023623118109, "loop in": 0.0005637380560122889, "on a distinguished": 0.001412997877799242, "the figures are": 0.0010826007236946758, "communication is provided": 0.0012953547128852297, "recognize these": 0.0010397031738864368, "however of using": 0.001412997877799242, "in these occupancy": 0.001412997877799242, "probability thus if": 0.001412997877799242, "approximator in": 0.0024526255734667692, "a complex function": 0.0011397700534482, "recognizers": 0.0008344608083154893, "is easy": 0.0002359337601841021, "we thresholded": 0.0013439565011394887, "observations the observation": 0.001412997877799242, "processing phase": 0.0009081111668589885, "learning optimal values": 0.001412997877799242, "received by the": 0.0007217338535499443, "figure 13": 0.0009114876572907008, "setup used to": 0.0012953547128852297, "a coarsely": 0.0013439565011394887, "and proceeds": 0.0008034263695325692, "the modeling of": 0.0008291394238884059, "were conducted": 0.0006954851132481282, "reasons sensory": 0.0013439565011394887, "human trainers for": 0.001412997877799242, "angled": 0.001039526833456673, "subsequent images": 0.0010706929277613088, "features it": 0.0009217509760058083, "explicitly represented": 0.0009528025610969587, "category learning are": 0.001412997877799242, "sonar readings": 0.0013439565011394887, "an observation": 0.0007437201166480605, "was it": 0.001157470080128191, "figure 16": 0.0013410422105006746, "that rapid": 0.0010706929277613088, "learning where a": 0.0012265208479459286, "of several": 0.0011347856994384157, "with the missing": 0.0011397700534482, "behaviors and state": 0.001412997877799242, "sensors arranged": 0.0013439565011394887, "cling both these": 0.001412997877799242, "angles": 0.0004797522312196677, "for much of": 0.0010057508064281846, "c3": 0.0006344371419051095, "c2": 0.0010146460166275883, "c1": 0.000472878715871056, "an": 0, "right quadrants": 0.0013439565011394887, "an acceptable": 0.0006738777284751093, "occupancy grid was": 0.001412997877799242, "homes": 0.0009215946410370149, "multi": 0.0005777951548808878, "system onboard pavlov": 0.001412997877799242, "where it": 0.00041001176617621693, "experiments below figure": 0.001412997877799242, "work thrun": 0.0013439565011394887, "represent concepts although": 0.001412997877799242, "concept descriptions": 0.001013492172364257, "the navigational system": 0.001412997877799242, "can we use": 0.0010599041887614004, "ojs ff prior": 0.001412997877799242, "value": -0.0006161784958293021, "moving the": 0.0006639936831495265, "layer requires the": 0.001412997877799242, "we investigate two": 0.002355341043457202, "presented the neural": 0.001412997877799242, "partic ular robots": 0.001412997877799242, "focusing on": 0.0006189654335108611, "for several reasons": 0.0008591880780779472, "this task": 0.0010607151857049066, "odometric and sensor": 0.001412997877799242, "detailed comparison of": 0.0012265208479459286, "learning their work": 0.001412997877799242, "et al": 0.00043458315367669696, "dominate almost": 0.0013439565011394887, "learning counterparts": 0.0013439565011394887, "40 epochs": 0.0013439565011394887, "behaviors implement": 0.0013439565011394887, "present below two": 0.001412997877799242, "manually": 0.0003838813398644444, "almost": 6.509192937927587e-05, "the reports from": 0.001412997877799242, "actuator errors e": 0.001412997877799242, "learning 4 although": 0.001412997877799242, "of the original": 0.00042244468269751143, "the set of": 0.0006577851554300437, "of the desired": 0.0016071253642329475, "up objects": 0.0013439565011394887, "research e": 0.001157470080128191, "and other irregularities": 0.002825995755598484, "vs": 0.0007552280034668051, "perceive features": 0.0013439565011394887, "study how": 0.0015304018681991007, "driving is": 0.0012263127867333846, "for further work": 0.001021962604845781, "detailed comments": 0.0009081111668589885, "etc we": 0.0006993597717998856, "the latter": 0.00023210786354829725, "are 256 possible": 0.001412997877799242, "al 15 extended": 0.0012953547128852297, "decision processes learning": 0.001412997877799242, "examples both in": 0.001412997877799242, "items inside": 0.0012263127867333846, "to bias sensory": 0.001412997877799242, "in figure 4": 0.00037324589523553205, "landmarks": 0.0009215946410370149, "recycling or in": 0.001412997877799242, "1 note": 0.00043247585596701806, "in actual use": 0.0012953547128852297, "and b the": 0.0006706348685868236, "autonomous vehicle": 0.001157470080128191, "invariances based": 0.0013439565011394887, "are trained": 0.0009707370964526472, "subsequently describe the": 0.001412997877799242, "by learning how": 0.002825995755598484, "snapshots of": 0.0008525989995294478, "is very high": 0.0008728509105201892, "we are focusing": 0.0012265208479459286, "significant odometric and": 0.001412997877799242, "component abilities": 0.0013439565011394887, "the total error": 0.0009909470066802508, "for recycling": 0.004031869503418466, "policy is quite": 0.001412997877799242, "would amount": 0.001157470080128191, "to constrain the": 0.0008801129633255439, "two approaches on": 0.0012953547128852297, "and d the": 0.00084653211689172, "to extract the": 0.0008347439643413854, "each direction": 0.0015540575777830286, "the context": 0.0002621859949868647, "prior the": 0.001013492172364257, "tree type approach": 0.001412997877799242, "sub sampling was": 0.001412997877799242, "robotic": 0.001508001396256318, "deposit it": 0.0013439565011394887, "successfully operate in": 0.001412997877799242, "involving learning sensory": 0.001412997877799242, "a majority": 0.0007073760774262461, "are relatively": 0.0005429920482072152, "learning curve for": 0.0034193101603446, "context of robotics": 0.001412997877799242, "off": 0.00010824390477080125, "neural": 0.015351559888980354, "nevertheless": 0.00022382833374516074, "as predicted by": 0.0009419732139289226, "well as in": 0.000730869328480087, "we now present": 0.000684465666466304, "is capable of": 0.0006820837232369924, "interesting tasks": 0.0013439565011394887, "or bias is": 0.001412997877799242, "patterns": 0.0003294499912594281, "backpropagation": 0.000852454393186244, "be made denote": 0.001412997877799242, "state estimation": 0.0066516450595558866, "feature f": 0.0019056051221939174, "door or if": 0.001412997877799242, "sets": -0.00010933177402735497, "environment this": 0.0007897242543278053, "position": 0.0009303721779947734, "markov model": 0.0008346023623118109, "dimensional rather": 0.0013439565011394887, "data with 380": 0.001412997877799242, "occupancy grid": 0.01075165200911591, "camera and": 0.0007832601051609397, "c2 pose": 0.0013439565011394887, "that sonars were": 0.001412997877799242, "system although most": 0.001412997877799242, "less": -0.00020941078677846181, "possible abstract": 0.0012263127867333846, "for speeding up": 0.0010826007236946758, "in actuality": 0.001013492172364257, "lynn ryan for": 0.001412997877799242, "in two": 0.0002712534699259036, "decision tree type": 0.001412997877799242, "except the templates": 0.001412997877799242, "presentation rapid concept": 0.001412997877799242, "underlying": 0.0001832795035042394, "and back quadrants": 0.001412997877799242, "predicts": 0.0009154722727670534, "support of": 0.0005047289660579865, "methods have": 0.0005243498648614615, "localize": 0.0007072561018364519, "i f js": 0.001412997877799242, "training the trash": 0.001412997877799242, "the direct": 0.000494374705490854, "learning 5": 0.001157470080128191, "predict 85": 0.0013439565011394887, "b2 pose b3": 0.001412997877799242, "the navigational": 0.0011086075099259812, "a distinguished history": 0.001412997877799242, "sharing used": 0.0013439565011394887, "transducer the": 0.0012263127867333846, "produce 4": 0.0013439565011394887, "is prone": 0.0009217509760058083, "new objects or": 0.001412997877799242, "directions for further": 0.0009773255297405913, "of an": 6.240221178479252e-05, "for mobile": 0.007519019793222662, "add": 5.959937022352248e-05, "for all": 7.779413704385667e-05, "g see 24": 0.0012953547128852297, "decision process": 0.0018731457897767177, "features even when": 0.0012953547128852297, "that the walls": 0.001412997877799242, "with 380 labeled": 0.001412997877799242, "that were": 0.0003740970594881401, "probability in figure": 0.001412997877799242, "learn interesting": 0.0013439565011394887, "sample images": 0.0022172150198519623, "short term robots": 0.001412997877799242, "the details here": 0.001177670521728601, "and orientation": 0.0007541286032508272, "of each possible": 0.0011087956007827721, "recognition easier": 0.0013439565011394887, "well as": 0.0002921590879725445, "consistent results not": 0.001412997877799242, "a few high": 0.0012953547128852297, "five": 0.00016534245013996308, "9 c in": 0.001412997877799242, "labeling e": 0.0013439565011394887, "ranging from supervised": 0.001412997877799242, "are independent 0000000000000000000000000000000000000000000000000000000000000000111111111111111111111111111111111111111111111111111111111111111111111111": 0.001412997877799242, "based approach similar": 0.001412997877799242, "experiments below": 0.0009217509760058083, "from such a": 0.0008728509105201892, "a result": 0.00024137887944014773, "converted into": 0.0006046361590848585, "career award": 0.0008433654142724929, "university of": 0.00036337447101637035, "relational learning algorithm": 0.001412997877799242, "robot to map": 0.001412997877799242, "on finding": 0.0007652009340995504, "most successful approaches": 0.0012953547128852297, "contradictory labeling e": 0.001412997877799242, "accelerating": 0.001340814761007713, "seems necessary": 0.001013492172364257, "camera turn is": 0.001412997877799242, "tions would enable": 0.001412997877799242, "robotics is": 0.0026879130022789775, "planning figure": 0.0012263127867333846, "powerful than": 0.0007488464497674484, "become": 0.0, "we are simplifying": 0.001412997877799242, "probabilistic model": 0.0015082572065016544, "floors etc": 0.0013439565011394887, "in feature detection": 0.0012953547128852297, "the possibility": 0.0003640290954836604, "grid 32x32": 0.0013439565011394887, "step a": 0.0006069462075329354, "data we use": 0.0011397700534482, "totally wiping out": 0.001412997877799242, "actions we study": 0.001412997877799242, "for the recycling": 0.002825995755598484, "grids": 0.0028508554539133143, "such studies can": 0.0012953547128852297, "sensors and": 0.0008837126637559662, "induce features": 0.0013439565011394887, "easily than": 0.0011086075099259812, "specifically a pragmatic": 0.001412997877799242, "khaleeli figure": 0.0013439565011394887, "navigating robot neural": 0.001412997877799242, "ir sensors arranged": 0.001412997877799242, "d figure": 0.0005731297104135156, "to find items": 0.001412997877799242, "robust layered control": 0.001412997877799242, "for a human": 0.0011087956007827721, "tr ctr": 0.00025260263641748923, "recognition": 0.0008972043759211298, "color value because": 0.001412997877799242, "will be": 0.00010305807350979579, "action reports": 0.0013439565011394887, "proposes two": 0.0011086075099259812, "learn high": 0.0013439565011394887, "paper notes 1": 0.001412997877799242, "find a": 0.00030358736828242774, "critical to": 0.0006772995603809331, "hallways": 0.0012261047960979141, "avoid": 8.899737600661162e-05, "more difficult": 0.0004427995236991089, "and prediction of": 0.0011397700534482, "does": -0.0005073230083137942, "training robot": 0.0013439565011394887, "department figure 10": 0.001412997877799242, "16 many different": 0.001412997877799242, "belief estimates": 0.0013439565011394887, "navigation and": 0.0028097186846650765, "in both tasks": 0.001412997877799242, "strengths as well": 0.001412997877799242, "and learning to": 0.001412997877799242, "than non": 0.0009365728948883588, "sonars": 0.0024522095921958283, "noise": 0.00031325405101684966, "the approximately the": 0.001412997877799242, "shows an": 0.0009573410813463005, "selecting": 0.0004447097279864797, "is specified": 0.0010015582880538588, "front back left": 0.002825995755598484, "g in the": 0.0007130528122063535, "it seems": 0.0004297513140372178, "is more powerful": 0.0010599041887614004, "control system for": 0.0011087956007827721, "is also unreliable": 0.001412997877799242, "phase to": 0.0007201345364976421, "although": -0.0011170396759851515, "the order": 0.0004954715295245504, "that robots": 0.0012263127867333846, "20060010000": 0.001039526833456673, "both tasks": 0.0008954780757782285, "our real robot": 0.001412997877799242, "noisy": 0.0021804690966842296, "below were": 0.001157470080128191, "about": -0.0002335924145220866, "structure for": 0.0005034031207103129, "actual": 0.0001274500403323639, "or a visual": 0.001412997877799242, "disjoint quadrants 00110011001101010011": 0.001412997877799242, "left or on": 0.001412997877799242, "planner with": 0.0013439565011394887, "estimation using": 0.0008183105262917859, "b the neural": 0.001412997877799242, "and add new": 0.001412997877799242, "6 discusses some": 0.0012265208479459286, "inputs to our": 0.0011397700534482, "synthetic examples are": 0.001412997877799242, "over an actual": 0.001412997877799242, "logical representations incur": 0.001412997877799242, "paradigms mobile robot": 0.001412997877799242, "for providing labeled": 0.001412997877799242, "that some": 0.00037272681549384556, "times and": 0.0004663220655674039, "to handle": 0.00033178715761020066, "the backpropagation": 0.0011086075099259812, "some appropriate": 0.000872702844207972, "work is that": 0.0008347439643413854, "is difficult for": 0.0009909470066802508, "of inputs is": 0.0011087956007827721, "lynn ryan": 0.0013439565011394887, "4 13": 0.0006486581696160977, "run which demonstrates": 0.001412997877799242, "bias 20 to": 0.001412997877799242, "here we": 0.0005613091617938051, "to use a": 0.0004953002027150228, "presented above suggest": 0.001412997877799242, "the sensor as": 0.0012953547128852297, "trainer provides": 0.0013439565011394887, "22 for": 0.0006457442730738455, "method 8": 0.0008623569375540945, "example tan": 0.0013439565011394887, "1 4": 0.00030109454638026695, "task for": 0.0006993597717998856, "for training neural": 0.001412997877799242, "picking up": 0.002026984344728514, "6 and": 0.00029280767034927806, "located adjacent": 0.001157470080128191, "11 a neural": 0.001412997877799242, "trained to recognize": 0.004238993633397726, "an optimized variant": 0.001412997877799242, "sensor values a": 0.001412997877799242, "one where a": 0.0012953547128852297, "and consistent results": 0.001412997877799242, "predicts features": 0.0013439565011394887, "processor": 0.0001378942431851159, "realistic tasks navigation": 0.001412997877799242, "noticeable in these": 0.001412997877799242, "neural net using": 0.001412997877799242, "27 propose": 0.0012263127867333846, "robot believes it": 0.001412997877799242, "on two": 0.0004352383371715153, "purpose of sensory": 0.001412997877799242, "can from": 0.0024526255734667692, "examples provided that": 0.001412997877799242, "can we": 0.000600103348117393, "bump": 0.0009526409595770983, "of the specularities": 0.002825995755598484, "grasping to an": 0.001412997877799242, "with so": 0.0008837126637559662, "bias decomposition and": 0.001412997877799242, "onboard pavlov which": 0.001412997877799242, "order of several": 0.0012265208479459286, "are able to": 0.0004870477123570083, "is un known": 0.0012953547128852297, "the rest of": 0.0003341199573515472, "function": -0.0013299403973409778, "the robot and": 0.0011397700534482, "directly observable from": 0.002825995755598484, "opening a door": 0.0012953547128852297, "such as trash": 0.001412997877799242, "accurately predict": 0.0008433654142724929, "steering model we": 0.001412997877799242, "instances is": 0.0008623569375540945, "but": -0.0028290244073458076, "were used to": 0.0006641063390170443, "a robust": 0.0012047109172423885, "route measured until": 0.001412997877799242, "repeated": 0.0001659609227465951, "this made it": 0.0010826007236946758, "basic ingredients of": 0.001412997877799242, "updated to": 0.0007073760774262461, "convergence": 0.0002101156088834396, "learn useful": 0.0013439565011394887, "incur a computational": 0.001412997877799242, "produce fairly reliable": 0.001412997877799242, "strategies was studied": 0.001412997877799242, "cans a": 0.0013439565011394887, "partially": 0.0005492101051934644, "lynn": 0.000852454393186244, "award grant": 0.0013439565011394887, "in the lab": 0.0012265208479459286, "left front or": 0.001412997877799242, "learn independently": 0.0013439565011394887, "places": 0.0003122119325467533, "items of": 0.0008623569375540945, "all that": 0.0006046361590848585, "wish": 0.00020870756982880895, "as avoiding obstacles": 0.001412997877799242, "variations": 0.0002476937471630957, "all that is": 0.0008184493641822325, "reinforcement": 0.001508001396256318, "labeled patterns was": 0.001412997877799242, "placed": 0.0004388596025095966, "also whether": 0.001157470080128191, "and typically": 0.0008837126637559662, "is represented by": 0.0005093037082612842, "d right far": 0.001412997877799242, "were labeled as": 0.0012265208479459286, "problem": -0.003039676927126019, "conducted we thank": 0.001412997877799242, "markov decision": 0.003811210244387835, "detectors for": 0.004053968689457028, "other approximators": 0.0013439565011394887, "known in": 0.0005496498068625872, "the electrical": 0.001013492172364257, "network produced more": 0.001412997877799242, "neural network based": 0.001177670521728601, "been almost totally": 0.001412997877799242, "recognize": 0.00221163499788091, "our work to": 0.001021962604845781, "b1 pose": 0.0013439565011394887, "denote": -7.44218839248176e-05, "or in": 0.0003720450007329649, "of bias e": 0.001412997877799242, "some form": 0.0006189654335108611, "camera and frame": 0.001412997877799242, "computational cost in": 0.0011397700534482, "be applicable to": 0.00084653211689172, "or if": 0.0004437654151870332, "very near figure": 0.001412997877799242, "ing": 0.0002335924145220866, "navigating robot": 0.0013439565011394887, "proceeds": 0.00023899171751537755, "contain millions of": 0.001412997877799242, "able to produce": 0.0009647109541934066, "images which will": 0.001412997877799242, "maps by": 0.0010706929277613088, "its height and": 0.001177670521728601, "clear that some": 0.0012953547128852297, "hard coded": 0.0009528025610969587, "predict a wall": 0.001412997877799242, "building was": 0.0013439565011394887, "virtual": 0.0006452858912722282, "6 learning multiple": 0.001412997877799242, "on manually labeled": 0.001412997877799242, "state s an": 0.001177670521728601, "compares": 0.0002659880794681955, "details": -9.059117545761372e-05, "a separate": 0.00041165347984768047, "the robot eventually": 0.001412997877799242, "another e g": 0.0011397700534482, "out": -0.0012751311270504393, "the effects of": 0.0004927864950948161, "each direction and": 0.001177670521728601, "example of the": 0.0005900509154676838, "is often also": 0.0012953547128852297, "them in a": 0.0007438462992263857, "framework of supervised": 0.001412997877799242, "robot neural": 0.0013439565011394887, "could have a": 0.001021962604845781, "navigation using model": 0.001412997877799242, "of the labels": 0.0009529642174527608, "and refer the": 0.0011087956007827721, "both sensor and": 0.001412997877799242, "variation": 0.0002066074354338352, "we believe the": 0.0008184493641822325, "mobile robots 21": 0.001412997877799242, "will mainly focus": 0.001177670521728601, "avoid bump": 0.0013439565011394887, "to yield": 0.0005273294080774565, "detector the": 0.0009528025610969587, "observation data": 0.0013439565011394887, "rapid training": 0.0013439565011394887, "paper see": 0.0009217509760058083, "examples can": 0.0007652009340995504, "floor of the": 0.0038860641386556888, "approaches involving": 0.0012263127867333846, "learn have spatial": 0.001412997877799242, "also provided": 0.0007832601051609397, "and refer": 0.0007710139595398186, "somewhat tedious task": 0.001412997877799242, "new objects": 0.0009217509760058083, "net architecture chosen": 0.001412997877799242, "the real robot": 0.001412997877799242, "post after": 0.0024526255734667692, "cans or": 0.0013439565011394887, "that ensures that": 0.0009647109541934066, "are color coded": 0.001412997877799242, "on using a": 0.001177670521728601, "is much room": 0.001412997877799242, "a smaller network": 0.001412997877799242, "8 s mahadevan": 0.001412997877799242, "prediction of uncertainties": 0.001412997877799242, "limited": 0.0002302946717686987, "the images front": 0.001412997877799242, "and actuator": 0.0026879130022789775, "based reasoning": 0.0008837126637559662, "trash receptacle see": 0.001412997877799242, "c pose": 0.0013439565011394887, "common underlying": 0.001157470080128191, "robotic system could": 0.001412997877799242, "easier to program": 0.0012265208479459286, "grid representation computed": 0.001412997877799242, "how is it": 0.001412997877799242, "and the set": 0.000585868219173452, "eventually finds": 0.0012263127867333846, "close to 1": 0.0007158988301961499, "sensor and actuator": 0.002825995755598484, "robot till": 0.0013439565011394887, "specified trash receptacle": 0.001412997877799242, "a1 pose a2": 0.001412997877799242, "pavlov include ultrasound": 0.001412997877799242, "learning introduction": 0.001157470080128191, "task figure": 0.0010397031738864368, "developed an": 0.0006400562598342001, "however for the": 0.0013937707798634025, "same set": 0.0005273294080774565, "high dimensional": 0.006916942228847701, "wireless ethernet": 0.0013439565011394887, "is accomplished": 0.0011462594208270312, "problem sensory": 0.0013439565011394887, "engineering computing computer": 0.001412997877799242, "sensor values": 0.0034724102403845734, "component abilities such": 0.001412997877799242, "features the": 0.0006576990239911289, "sensor registers a": 0.001412997877799242, "from preclassified": 0.0013439565011394887, "5 9 here": 0.001412997877799242, "under": -0.0007007772435662598, "learning their": 0.0012263127867333846, "representation computed by": 0.001412997877799242, "spatial regularity": 0.0013439565011394887, "the input data": 0.0007653307612006872, "images front left": 0.001412997877799242, "4 behavior based": 0.001412997877799242, "summarizes": 0.0002838200262250284, "easy although": 0.0013439565011394887, "state is a": 0.0009039491294179812, "its location in": 0.0012265208479459286, "pixels noisy": 0.0013439565011394887, "relatively insignificant the": 0.001412997877799242, "and 3 bits": 0.0012953547128852297, "helps to": 0.0006214693208023149, "and train but": 0.001412997877799242, "results suggest": 0.00066081832163666, "although it takes": 0.001412997877799242, "every": -0.0009647571510972227, "quadrants and learn": 0.001412997877799242, "speed sensory learning": 0.001412997877799242, "considerable trial": 0.0013439565011394887, "actuator uncertainty": 0.0013439565011394887, "learned from": 0.0007338995299089556, "the hallways": 0.0013439565011394887, "3rd floor": 0.0012263127867333846, "scope of this": 0.0006157850289127014, "proposes two strategies": 0.001412997877799242, "inputs is 512": 0.001412997877799242, "was used to": 0.00120642961027805, "in states": 0.0009081111668589885, "sensor as a": 0.0012953547128852297, "five figure 11": 0.001412997877799242, "distinguished history of": 0.001412997877799242, "require long": 0.001157470080128191, "approximator we show": 0.001412997877799242, "quickprop method 8": 0.001412997877799242, "undefined figure": 0.0012263127867333846, "announced": 0.0006771846859643148, "ture with": 0.0013439565011394887, "and would amount": 0.001412997877799242, "feature detector the": 0.001412997877799242, "0 of the": 0.001461738656960174, "training time for": 0.0011087956007827721, "across an entire": 0.001412997877799242, "tasks where we": 0.001412997877799242, "robot navigating": 0.0026879130022789775, "pragmatic": 0.0006239029826303446, "limited training data": 0.0012953547128852297, "as its": 0.000816766464566455, "for training": 0.0015191529486762315, "consistent": 0.00011206104219925227, "robot must map": 0.001412997877799242, "estimates": 0.0001942913366502871, "direct": 1.8700218159774934e-05, "right hidden layer": 0.001412997877799242, "sensor values motor": 0.001412997877799242, "outputs hidden units": 0.001412997877799242, "16 results for": 0.001412997877799242, "north south corridor": 0.001412997877799242, "requires dealing": 0.0013439565011394887, "net for": 0.0009217509760058083, "and rotating": 0.0011086075099259812, "dealing with significant": 0.001412997877799242, "filters 14": 0.0013439565011394887, "the advantage": 0.00038037560342653044, "to specularities and": 0.002825995755598484, "front left": 0.0026879130022789775, "selected": 6.264587914960111e-05, "already pre specified": 0.001412997877799242, "is it": 0.0004371016452995968, "back opening": 0.008063739006836932, "by an nsf": 0.0009126929338602609, "four overlapping quadrants": 0.001412997877799242, "is organized as": 0.00035869464009825603, "robot to move": 0.0012953547128852297, "which infers a": 0.001412997877799242, "of intelligent": 0.0007595764743381157, "above": -0.0006703063728717777, "weights figure 8": 0.0012953547128852297, "to recognize objects": 0.001177670521728601, "2 by": 0.0004019963390390999, "denote the set": 0.0005441773745236624, "amount to rote": 0.001412997877799242, "simultaneously": 0.00042761501069332546, "objects using": 0.0007770287888915143, "a discrete time": 0.0008801129633255439, "learned since the": 0.001412997877799242, "do in the": 0.001021962604845781, "explicit probabilistic": 0.0012263127867333846, "a 1200": 0.0012263127867333846, "the planning layer": 0.001412997877799242, "because they expose": 0.001412997877799242, "introduction to": 0.00035129942436477814, "and pick": 0.0009707370964526472, "boolean variables the": 0.001177670521728601, "pursuit": 0.0015537939994964302, "numerous specular errors": 0.001412997877799242, "reflect away": 0.0013439565011394887, "represented": -1.966457830504056e-06, "the labels and": 0.001177670521728601, "different paradigms": 0.0011086075099259812, "epochs a": 0.0013439565011394887, "some directions for": 0.0010599041887614004, "interesting tasks where": 0.001412997877799242, "and in": 0.00012230619303404925, "obtained": -0.00019028781567749636, "report on": 0.0005978790985189038, "in current systems": 0.001177670521728601, "neural net learning": 0.0012265208479459286, "items": 0.0007162943759291024, "study": -0.0003942144837261218, "6 illustrates": 0.0008433654142724929, "0 20": 0.0006457442730738455, "markov model to": 0.0012265208479459286, "only necessary": 0.0007541286032508272, "designer has already": 0.001412997877799242, "applicable when": 0.0008954780757782285, "a hybrid two": 0.001412997877799242, "colored yellow": 0.0013439565011394887, "based semi markov": 0.001412997877799242, "second strategy": 0.0009707370964526472, "collection requires the": 0.001412997877799242, "environment the belief": 0.001412997877799242, "undefined figure 7": 0.001412997877799242, "involving considerable trial": 0.001412997877799242, "percept is": 0.0012263127867333846, "output units despite": 0.001412997877799242, "by describing the": 0.0018632924969971781, "discontinuous": 0.0005020014016838411, "output labels generated": 0.001412997877799242, "robot with labeled": 0.001412997877799242, "sonars were prone": 0.001412997877799242, "highly": 0.0001327275042713006, "logical description of": 0.001412997877799242, "learning provide a": 0.001412997877799242, "action commands": 0.0013439565011394887, "is novel": 0.0009528025610969587, "can the": 0.0006576990239911289, "approaches seem": 0.0013439565011394887, "total": -0.00024178325529336205, "correctly predict features": 0.001412997877799242, "determining if a": 0.0009773255297405913, "learning alvinn": 0.0013439565011394887, "found that sonars": 0.001412997877799242, "plot": 0.00033286587543088957, "facilitated through the": 0.001412997877799242, "this updated state": 0.001412997877799242, "5 this": 0.0005446340152121855, "would": -0.0013781766095613806, "multi class learning": 0.0012265208479459286, "with several": 0.0005565583063253017, "which ranks": 0.001157470080128191, "to detect and": 0.0015977454291815278, "semi markov model": 0.0012953547128852297, "chooses": 0.00030706977959537695, "20 among": 0.0013439565011394887, "steering": 0.0022952134531123727, "add new": 0.0007595764743381157, "navigated the": 0.0013439565011394887, "only feature": 0.0012263127867333846, "system based on": 0.0007898582421551431, "state estimator": 0.0012263127867333846, "totally wiping": 0.0013439565011394887, "focusing on rapid": 0.001412997877799242, "7 one": 0.000872702844207972, "vs single output": 0.001412997877799242, "often very high": 0.0025907094257704593, "state into": 0.0009528025610969587, "certain hypotheses": 0.0013439565011394887, "its location": 0.0008262639069617736, "it in a": 0.0007855213434982123, "award": 0.0004619427947156244, "and subsequently": 0.0006672272054388769, "shows our robot": 0.001412997877799242, "concept learning scenarios": 0.001412997877799242, "program robots is": 0.001412997877799242, "using a known": 0.001412997877799242, "13 this": 0.0007710139595398186, "the specularities": 0.004031869503418466, "must": -0.00032394141194081876, "the outputs": 0.0006291989168691914, "units despite the": 0.001412997877799242, "as in our": 0.000823711514802973, "the rgb values": 0.001412997877799242, "desired concept": 0.0013439565011394887, "err": 0.0013984823116554698, "used to label": 0.001021962604845781, "mm": 0.0005636424423664252, "examples is probably": 0.001412997877799242, "work": -0.005583319810089669, "identified the": 0.0007387405675331519, "the overall learning": 0.0012265208479459286, "robot s mahadevan": 0.001412997877799242, "to learn have": 0.001412997877799242, "pavlov to": 0.0013439565011394887, "sufficient bias": 0.0026879130022789775, "one of four": 0.0009419732139289226, "y meters odometric": 0.001412997877799242, "expose the robot": 0.001412997877799242, "sensor data": 0.0018435019520116167, "preference bias which": 0.001412997877799242, "then used to": 0.0006684317399421915, "contradictory labeling": 0.0013439565011394887, "laboratory for": 0.0008525989995294478, "doors and openings": 0.001412997877799242, "sensor errors the": 0.001412997877799242, "g far": 0.0013439565011394887, "cited": 0.0004893199240969862, "move towards": 0.0018731457897767177, "of steering to": 0.001412997877799242, "3 1 spatial": 0.001412997877799242, "of the sensor": 0.0009126929338602609, "vs single": 0.001157470080128191, "requires the robot": 0.002825995755598484, "either a north": 0.001412997877799242, "set of weights": 0.0010057508064281846, "feasible": 0.00020176120537208895, "handle transfer": 0.0013439565011394887, "of data": 0.0002699384266648019, "teacher to": 0.0011086075099259812, "is apparent": 0.0006916942228847701, "where the robotic": 0.001412997877799242, "describe the results": 0.0010599041887614004, "provide": -0.0004791175455409078, "vision guided": 0.0013439565011394887, "of obstacle avoidance": 0.0012953547128852297, "white we then": 0.001412997877799242, "far": 5.309956661613644e-05, "much of their": 0.001177670521728601, "input variables making": 0.001412997877799242, "based algorithm": 0.0005712121849001653, "adjacent": 0.0006781575692853991, "used in the": 0.0005771630358252904, "learning which can": 0.001412997877799242, "approximator we": 0.0013439565011394887, "actuality": 0.0008953261968644262, "rotation and": 0.0008107079716898269, "that directly learning": 0.001412997877799242, "as predicted": 0.0007652009340995504, "in two tasks": 0.001412997877799242, "here to": 0.000631851774969883, "much more difficult": 0.0008291394238884059, "limited training": 0.0022172150198519623, "description": -2.9496970717618494e-06, "colored yellow avoid": 0.001412997877799242, "undefined the": 0.0010397031738864368, "4 training": 0.001157470080128191, "similarly for the": 0.0008133430731188866, "earlier": 3.55254576372041e-05, "specularities are noticeable": 0.001412997877799242, "lab": 0.0035734858604114864, "policy is": 0.0006916942228847701, "example of": 0.00023059178136240245, "nominal directions": 0.0013439565011394887, "the effectiveness": 0.002194913479191056, "very near f": 0.001412997877799242, "err figure 13": 0.001412997877799242, "observations are generated": 0.001412997877799242, "generated from": 0.0005087636134908786, "accomplished using": 0.0009217509760058083, "recycling robot": 0.0013439565011394887, "non learning counterparts": 0.001412997877799242, "these two approaches": 0.0009419732139289226, "8 s": 0.000872702844207972, "s encoding the": 0.001412997877799242, "recognize and find": 0.001412997877799242, "independently from": 0.0008183105262917859, "is to fill": 0.001177670521728601, "2 s": 0.0008039926780781998, "difficult to do": 0.0011087956007827721, "hypotheses": 0.002041569839136386, "description of the": 0.00041616824845435173, "loses the trash": 0.001412997877799242, "into high": 0.001157470080128191, "algorithms": -0.00017536482111341536, "related tasks": 0.0010397031738864368, "figure 6": 0.00046194009982864116, "of sensory concept": 0.002825995755598484, "second form of": 0.001177670521728601, "the sonar pulse": 0.001412997877799242, "order": -0.0024223797542575333, "provides the robot": 0.001412997877799242, "a period of": 0.0014434677070998886, "unreliable due": 0.0012263127867333846, "5 6 in": 0.0010057508064281846, "office": 0.0012347509822093334, "is ff": 0.0007710139595398186, "over": -0.0031445405533250693, "limited since data": 0.001412997877799242, "draft of": 0.0007770287888915143, "port it to": 0.0012953547128852297, "e left": 0.0012263127867333846, "first is based": 0.0012265208479459286, "a navigation": 0.0011086075099259812, "19 concept": 0.0013439565011394887, "the approximately": 0.0009528025610969587, "desired concept supervised": 0.001412997877799242, "system for": 0.00030916558573279194, "trial and error": 0.0008956300062288188, "nets": 0.001418636147613168, "deposit them in": 0.001412997877799242, "actuality the state": 0.001412997877799242, "just cited the": 0.001412997877799242, "label the images": 0.0012953547128852297, "approach to": 0.0001666086780087837, "although we": 0.0009414421923657882, "be programmed or": 0.001412997877799242, "space bias": 0.0024526255734667692, "85 rapid concept": 0.001412997877799242, "data 20060010000 total": 0.001412997877799242, "context where the": 0.0012953547128852297, "by the sensor": 0.0011397700534482, "behavior by learning": 0.001412997877799242, "space e": 0.0008525989995294478, "overall control structure": 0.001412997877799242, "based on finding": 0.0011397700534482, "model unlike": 0.0011086075099259812, "400": 0.0003912105010623444, "refer the": 0.0005750676982296913, "of predicting the": 0.0010599041887614004, "approximately oriented along": 0.001412997877799242, "defined as any": 0.001177670521728601, "then": -0.0024098703095630065, "them": -0.0004671848290441732, "epochs curve for": 0.001412997877799242, "larger than": 0.0002932873435853503, "that a particular": 0.0008347439643413854, "dimensional rather than": 0.001412997877799242, "experiments reported in": 0.0008801129633255439, "pixels so that": 0.001412997877799242, "for 322": 0.0013439565011394887, "task 4": 0.0018731457897767177, "concepts could": 0.0012263127867333846, "independently from each": 0.0012265208479459286, "actual run with": 0.001412997877799242, "temporarily loses the": 0.001412997877799242, "they": -0.0014904785485816679, "concept learning depends": 0.001412997877799242, "data collection requires": 0.002825995755598484, "navigated the loop": 0.001412997877799242, "information yet the": 0.001412997877799242, "to represent": 0.0006308117456282768, "lifelong": 0.001039526833456673, "of mobile": 0.0006916942228847701, "observable from the": 0.002453041695891857, "symbolic rules a": 0.001412997877799242, "figure also shows": 0.0009039491294179812, "much room": 0.0011086075099259812, "invariants": 0.00044958658351803546, "to speed": 0.003034731037664677, "l": -0.00034440626058144944, "provide a": 0.0002626106681135861, "of four possibilities": 0.001412997877799242, "filling": 0.000571115303593364, "we restrict": 0.00048818009817504264, "follows we": 0.00042795547472424027, "each": -0.015242255353233572, "determine the approximate": 0.001177670521728601, "visual image into": 0.001412997877799242, "that it uses": 0.0008801129633255439, "corridor for": 0.0013439565011394887, "work except the": 0.001412997877799242, "a real": 0.0010374154055422255, "to train four": 0.001412997877799242, "deposit it in": 0.001412997877799242, "the output labels": 0.001412997877799242, "of accelerating": 0.0011086075099259812, "the hypothesis space": 0.0010826007236946758, "navigation domain to": 0.001412997877799242, "burden seems necessary": 0.001412997877799242, "odometry": 0.0011084194828720588, "with the": 1.7701324094357114e-05, "learning behaviors from": 0.001412997877799242, "n khaleeli specifically": 0.001412997877799242, "and also": 0.00032953377889732865, "robot s pentium": 0.001412997877799242, "lifelong learning": 0.0013439565011394887, "on the underlying": 0.0008291394238884059, "bias e g": 0.001412997877799242, "combining": 0.00010824390477080125, "every state for": 0.0012953547128852297, "3 describes the": 0.0007653307612006872, "placed in positions": 0.001412997877799242, "are decision trees": 0.0012953547128852297, "area of research": 0.0009219073640234544, "capable of": 0.0004609607164120234, "the six": 0.0005850811540016608, "at 0": 0.001191364016566928, "10 the figure": 0.0012953547128852297, "network": 0.0004372585138013152, "driving": 0.0005495565826755345, "researchers have": 0.0005619164728262171, "advantage however": 0.001157470080128191, "units right": 0.0013439565011394887, "input space and": 0.0011087956007827721, "represent discontinuous distributions": 0.001412997877799242, "trainers": 0.0011084194828720588, "route measured": 0.0013439565011394887, "or wall the": 0.001412997877799242, "in the form": 0.0013200138918130658, "original sensory state": 0.001412997877799242, "dimensional e": 0.0012263127867333846, "helps speed learning": 0.001412997877799242, "some related work": 0.0009529642174527608, "sonar is": 0.0013439565011394887, "separate set of": 0.0010599041887614004, "could be": 0.0014596186766658984, "the solution": 0.0002638888480305213, "the hallways each": 0.001412997877799242, "we study two": 0.0011397700534482, "exploits a pursuit": 0.001412997877799242, "is beyond": 0.0006240088185900783, "tasks were decomposable": 0.001412997877799242, "free": 9.500592709177804e-05, "of a grammar": 0.0011397700534482, "route planner and": 0.001412997877799242, "20060010000 total": 0.0013439565011394887, "each state": 0.0011620181840489687, "counterparts for example": 0.001412997877799242, "khaleeli": 0.011034943164881227, "detecting": 0.00028567490173121067, "starting off": 0.0012263127867333846, "net can": 0.0019056051221939174, "of trash": 0.0024526255734667692, "experiment the direct": 0.001412997877799242, "robots 17 figure": 0.001412997877799242, "the trash can": 0.022021030119048903, "between using": 0.0010706929277613088, "to ff post": 0.001412997877799242, "camera of pavlov": 0.001412997877799242, "by the neural": 0.002453041695891857, "test data a": 0.0011397700534482, "for neural net": 0.001177670521728601, "on a draft": 0.0010057508064281846, "be dependent": 0.0008183105262917859, "current state distribution": 0.001412997877799242, "and sensor": 0.0016867308285449859, "speed sensory concept": 0.001412997877799242, "9 sample": 0.0013439565011394887, "a local": 0.001019570297558226, "studies can be": 0.0012265208479459286, "bleed through": 0.0013439565011394887, "soda": 0.002971832593643181, "sonar and infra": 0.0012953547128852297, "angles and": 0.000872702844207972, "generalizations": 0.0004640809155476435, "bumper switches are": 0.001412997877799242, "already": -6.010644843776831e-05, "4 figure": 0.000631851774969883, "actuality the": 0.0013439565011394887, "to other sources": 0.001177670521728601, "computational cost": 0.0005913666291750407, "results the experiments": 0.0012265208479459286, "encouraging": 0.00048447595085150663, "of the overall": 0.0013412697371736472, "restrict": 0.00039262306264960755, "placed in the": 0.0007158988301961499, "reactive architecture for": 0.001412997877799242, "would enable a": 0.0012953547128852297, "show the two": 0.0011397700534482, "occupancy": 0.010488617337416026, "another": -0.0005961730421365296, "adjacent to the": 0.0017602259266510877, "objects based on": 0.0010599041887614004, "high dimensional concepts": 0.001412997877799242, "maximum value out": 0.001412997877799242, "illustrate": 0.00010445310486063412, "easier here we": 0.001412997877799242, "specified much": 0.0013439565011394887, "for details": 0.00048818009817504264, "in our environment": 0.0022795401068964, "related work": 0.0006361123799334361, "top": 0.00026858908902010293, "shows some": 0.0014976928995348968, "actual real": 0.0013439565011394887, "approximately": 0.0002792599189962879, "sensor represen tation": 0.001412997877799242, "are pre": 0.000872702844207972, "opening or undefined": 0.001412997877799242, "observations": 0.0016696605586304716, "alvinn 22 uses": 0.001412997877799242, "go forward": 0.0012263127867333846, "level planner with": 0.001412997877799242, "recycling task 4": 0.001412997877799242, "discuss the details": 0.001039879574153469, "near and": 0.0010397031738864368, "designer ffl decomposable": 0.001412997877799242, "single yellow colored": 0.001412997877799242, "n khaleeli 1": 0.001412997877799242, "despite the": 0.0005115024387919628, "of decision trees": 0.0008728509105201892, "work finally": 0.0008954780757782285, "which ranks one": 0.001412997877799242, "output of the": 0.0005928942145642387, "25 mm": 0.0012263127867333846, "7 summarizes": 0.0008954780757782285, "took": 0.00033173088434737666, "rejected": 0.0004556665315238027, "invariances based on": 0.001412997877799242, "on the floor": 0.001177670521728601, "behaviors in partic": 0.001412997877799242, "to complete": 0.0008266172235460742, "incur": 0.0004324025052451783, "near or far": 0.001412997877799242, "can be learned": 0.0009316462484985891, "only the": 0.00030940902828548655, "9 illustrates the": 0.0010826007236946758, "position c pose": 0.001412997877799242, "of bias investigated": 0.001412997877799242, "planning figure 2": 0.0012953547128852297, "work section 6": 0.001177670521728601, "level planner": 0.0013439565011394887, "it easy to": 0.00080838360373212, "partioning and multi": 0.001412997877799242, "procedure is more": 0.002825995755598484, "paper proposes two": 0.001412997877799242, "target": 0.0001659609227465951, "the goal": 0.00031858991564318105, "a pair": 0.00033521004024190005, "could itself": 0.001157470080128191, "the aggregate": 0.0006639936831495265, "adopt the framework": 0.001412997877799242, "avoidance algorithms which": 0.001412997877799242, "quadrants 00110011001101010011": 0.0013439565011394887, "there are two": 0.0003569959542365469, "can although it": 0.001412997877799242, "navigation using": 0.002314940160256382, "classes": 9.16397517521197e-05, "two general forms": 0.001412997877799242, "the distance and": 0.0010826007236946758, "contrasted": 0.0006842334867965392, "and their": 0.00021837732189320723, "real robot testbed": 0.002825995755598484, "7 summary this": 0.0012953547128852297, "is accomplished using": 0.0012265208479459286, "odometric trace": 0.0026879130022789775, "two ways of": 0.0010057508064281846, "of our": 0.00012007758000460841, "experimental results the": 0.0008035626821164737, "predict a": 0.0008433654142724929, "network with far": 0.001412997877799242, "the nominal": 0.0008346023623118109, "with a reactive": 0.002825995755598484, "designer specifies": 0.0013439565011394887, "raw": 0.0004619427947156244, "on concept learning": 0.001412997877799242, "wall right wall": 0.005651991511196968, "achieve rapid learning": 0.001412997877799242, "few missing": 0.0013439565011394887, "of this paper": 0.0013347060762297926, "and recy": 0.0013439565011394887, "front back": 0.002314940160256382, "relatively": 0.00011818511105918638, "15 extended": 0.001157470080128191, "strength": 0.00043058230745210023, "positions a and": 0.002825995755598484, "within about": 0.0010397031738864368, "and the input": 0.0008133430731188866, "in both": 0.001567064120497078, "latter": 4.549931930031875e-05, "examples reinforcement learning": 0.001412997877799242, "components being filled": 0.001412997877799242, "is on learning": 0.001412997877799242, "approach is": 0.0004514378592169107, "oriented": 0.00018242138947899996, "related concepts figure": 0.0012953547128852297, "mobile robot technology": 0.001412997877799242, "and some": 0.000350682104505442, "based on decomposing": 0.001412997877799242, "effectiveness": 0.0015351207535727338, "consistency with": 0.0008034263695325692, "direction each observation": 0.001412997877799242, "shaded box are": 0.001412997877799242, "time robotics": 0.0013439565011394887, "the designer has": 0.0010057508064281846, "sample local occupancy": 0.001412997877799242, "entire policy is": 0.001412997877799242, "the top": 0.00034580513518074184, "collected by running": 0.0012953547128852297, "but eventually": 0.0010706929277613088, "1 spatial": 0.0012263127867333846, "of the net": 0.00084653211689172, "temporally extended actions": 0.001412997877799242, "latter work": 0.0011086075099259812, "optimized": 0.0002617176137059002, "involving": 0.000334401897734995, "on by": 0.0008525989995294478, "phase": 0.00022412208439850454, "acknowledgements": 0.00021366420691220343, "left back and": 0.001412997877799242, "perceived geometric attributes": 0.001412997877799242, "formally called": 0.0012263127867333846, "unstructured environments including": 0.001412997877799242, "objects such as": 0.0017054873098833036, "by using the": 0.0004277302945566978, "a very well": 0.0012953547128852297, "learning counterparts for": 0.001412997877799242, "khaleeli specifically a": 0.001412997877799242, "behaviors in": 0.0008433654142724929, "partition": 0.00031599667707087634, "the sub": 0.00051288702773971, "grdt which infers": 0.001412997877799242, "a mobile robot": 0.0011397700534482, "images the data": 0.0012265208479459286, "the learned": 0.0008183105262917859, "to make": 0.0007169065816776404, "soda cans": 0.004031869503418466, "how mobile robots": 0.001412997877799242, "capable of determining": 0.0012953547128852297, "more powerful": 0.000553071488717374, "we found": 0.0004200683230017812, "grid and": 0.0007770287888915143, "5 discusses": 0.0007488464497674484, "85 of": 0.0009528025610969587, "scale is a": 0.0012953547128852297, "back quadrants of": 0.001412997877799242, "the trash": 0.023299942947934308, "the laboratory for": 0.0012953547128852297, "specular errors": 0.0013439565011394887, "labels": 0.0006307047558478107, "was rejected": 0.0010706929277613088, "hundred input": 0.0013439565011394887, "examples specularities": 0.0013439565011394887, "general strategies to": 0.001412997877799242, "possible generalizations": 0.001157470080128191, "are critical to": 0.0011087956007827721, "engineering department main": 0.001412997877799242, "output nets although": 0.001412997877799242, "colored images": 0.0012263127867333846, "overlapping quadrants": 0.0013439565011394887, "the high degree": 0.0009909470066802508, "scale o": 0.0013439565011394887, "d1": 0.0005564639104117459, "uncertainty v i": 0.001412997877799242, "actual run in": 0.001412997877799242, "4 1": 0.000254152166986696, "training a": 0.0009081111668589885, "situations": 0.00017855478021912944, "robot pavlov 1": 0.001412997877799242, "to using a": 0.0009529642174527608, "number of input": 0.000823711514802973, "overall control strategy": 0.001412997877799242, "of a sequence": 0.0006706348685868236, "at node 1": 0.0011087956007827721, "to an accuracy": 0.001177670521728601, "rotation and image": 0.001412997877799242, "two ways": 0.0005007791440269294, "abstract observations the": 0.001412997877799242, "do": -0.0008912719519819777, "pavlov which": 0.0013439565011394887, "00110011001101010011": 0.0012261047960979141, "location and its": 0.0012953547128852297, "very well studied": 0.001412997877799242, "to the trash": 0.0038860641386556888, "is ff prior": 0.001412997877799242, "it r": 0.0010706929277613088, "robot employs": 0.0012263127867333846, "despite": 0.0013472793265917433, "report": 0.00014841556038683895, "onboard": 0.0019052819191541965, "using pomdp": 0.0013439565011394887, "generally defined as": 0.001412997877799242, "career award grant": 0.001412997877799242, "learned in": 0.0008525989995294478, "directly learning an": 0.001412997877799242, "runs": 0.00013101830440917, "overall learning": 0.001157470080128191, "the case of": 0.0002718862328776842, "by i and": 0.0010599041887614004, "the likelihood of": 0.0007021104098709409, "example a robot": 0.001412997877799242, "or an adjacent": 0.001412997877799242, "wall the": 0.0010706929277613088, "irregularities": 0.001704908786372488, "sample local": 0.0013439565011394887, "describes the": 0.0006808889472048411, "a knowledge": 0.0007291894113705743, "into a": 0.000301631070878981, "navigation problem": 0.0012263127867333846, "can six": 0.0013439565011394887, "taxonomy of": 0.0008034263695325692, "net specular": 0.0013439565011394887, "or instructed": 0.0013439565011394887, "corridors for navigation": 0.001412997877799242, "overall function learning": 0.001412997877799242, "tation": 0.00047064125881922673, "towards the": 0.0005007791440269294, "output of": 0.00041835700030124645, "even when the": 0.0012348403883278216, "under these conditions": 0.0009419732139289226, "4 observations": 0.0012263127867333846, "planner and": 0.001157470080128191, "b and figure": 0.0011087956007827721, "specified architecture": 0.0013439565011394887, "detection": 0.00018698791815570387, "investigated for sensory": 0.001412997877799242, "depends": -3.7017226258483366e-05, "after an abstract": 0.001412997877799242, "specular reflections the": 0.001412997877799242, "a range": 0.00047295893278638616, "sub sampled the": 0.001412997877799242, "the percepts": 0.0013439565011394887, "robot learning": 0.008063739006836932, "pose b3 figure": 0.001412997877799242, "the probabilities v": 0.001412997877799242, "sensing and actions": 0.001412997877799242, "wall a c": 0.001412997877799242, "of our approach": 0.0005943328552515203, "training neural net": 0.001412997877799242, "are being": 0.0005142819462320132, "the probability": 0.0006613153186365759, "aggregate of": 0.0009528025610969587, "refer the reader": 0.0006728658761679748, "away": 0.00019698772389952157, "accomplished using a": 0.0012953547128852297, "forward is not": 0.001412997877799242, "the short term": 0.0010599041887614004, "and their effectiveness": 0.0012953547128852297, "from supervised": 0.001157470080128191, "examples provided": 0.0011086075099259812, "scaling and rotating": 0.001412997877799242, "dimensional but once": 0.001412997877799242, "description e": 0.0011086075099259812, "has been well": 0.0010057508064281846, "was placed": 0.0009528025610969587, "teacher supervised concept": 0.001412997877799242, "can generate": 0.000593511402013939, "approach": -0.0059508283972631495, "pieces of": 0.0005892470628878294, "approaches are": 0.0005637380560122889, "we": -0.03373818433388209, "use a standardized": 0.001412997877799242, "basic ingredients": 0.0013439565011394887, "right and": 0.0006140604889952477, "however": -0.0034266918215601835, "here to explaining": 0.001412997877799242, "showing the": 0.0005381522116980043, "r navigating": 0.0013439565011394887, "value out of": 0.001177670521728601, "in details": 0.0008623569375540945, "example tasks": 0.001157470080128191, "in every": 0.0008577027384743711, "behavior from labeled": 0.001412997877799242, "improve": 2.511807512187112e-05, "of such a": 0.0004775955202034142, "received": 0.0001734644738625163, "decompose the": 0.0006843495569384895, "here the robot": 0.001412997877799242, "runs on pavlov": 0.001412997877799242, "labels and proceeds": 0.001412997877799242, "within task learning": 0.001412997877799242, "a few missing": 0.001412997877799242, "learning approach was": 0.001412997877799242, "each of": 0.00011482386084616878, "the ee": 0.0011086075099259812, "and actuator uncertainty": 0.001412997877799242, "of bias studied": 0.001412997877799242, "layered": 0.001048521863418696, "post after an": 0.001412997877799242, "2 p 173": 0.0009126929338602609, "towards the trash": 0.001412997877799242, "bias is necessary": 0.001412997877799242, "input variables": 0.0007437201166480605, "large burden on": 0.001412997877799242, "sensory values into": 0.001412997877799242, "locating and picking": 0.001412997877799242, "con": 0.000205215163579489, "to program robots": 0.001412997877799242, "this state": 0.0006639936831495265, "position south east": 0.001412997877799242, "left right far": 0.001412997877799242, "approach could not": 0.001412997877799242, "using some appropriate": 0.001412997877799242, "data the": 0.0008151476698866444, "right wall a": 0.001412997877799242, "1 learning": 0.0009707370964526472, "estimation procedure that": 0.001412997877799242, "run when the": 0.001177670521728601, "e g in": 0.0013074693012414108, "obviously this places": 0.001412997877799242, "output net": 0.0036789383602001536, "begin by describing": 0.0009419732139289226, "it navigated the": 0.001412997877799242, "net is slower": 0.001412997877799242, "algorithm for": 0.0001538037047429985, "the 3rd floor": 0.0012953547128852297, "different sensors": 0.001157470080128191, "reveals that it": 0.0011087956007827721, "the features": 0.0011274761120245779, "1 2": 0.00010799059037934707, "near s mahadevan": 0.001412997877799242, "grid 32x32 door": 0.001412997877799242, "been": -0.0026066445798371804, "strategies provide sufficient": 0.002825995755598484, "require long training": 0.001412997877799242, "occupancy grids free": 0.001412997877799242, "the approach the": 0.0010826007236946758, "tasks involving learning": 0.001412997877799242, "flexible": 0.00026087184090703777, "occupancy probability": 0.0012263127867333846, "studies alvinn 22": 0.001412997877799242, "containers": 0.0009215946410370149, "scenarios a hallway": 0.001412997877799242, "examples of the": 0.0014494523323668226, "concept3 concept4": 0.0013439565011394887, "succeeded despite": 0.0013439565011394887, "or so": 0.0008346023623118109, "the details": 0.00037272681549384556, "objects or": 0.0008107079716898269, "to ours in": 0.001021962604845781, "4 13 21": 0.0012953547128852297, "that even when": 0.0009316462484985891, "but also": 0.00030358736828242774, "this paper see": 0.001039879574153469, "the main": 0.0001607631730772931, "8 shows": 0.0005034031207103129, "visual image": 0.0012263127867333846, "equip them": 0.0013439565011394887, "using quickprop rapid": 0.001412997877799242, "are going to": 0.0007372369477455303, "shows some sample": 0.001177670521728601, "the outputs were": 0.0012265208479459286, "opening back": 0.004031869503418466, "east": 0.0028748508150135943, "still able to": 0.002079759148306938, "wall opening undefined": 0.001412997877799242, "in the recycling": 0.002825995755598484, "alvinn system": 0.0026879130022789775, "n": -0.007872215867865871, "algorithms which": 0.0005892470628878294, "proposes some directions": 0.001412997877799242, "also provided in": 0.001177670521728601, "underlying state space": 0.001412997877799242, "where it is": 0.0005764690730021806, "lab18 y": 0.0013439565011394887, "1 a": 0.00016691886565747238, "d the top": 0.001412997877799242, "procedure": -6.201992076443532e-05, "place recognition in": 0.001412997877799242, "our work as": 0.0011397700534482, "right each": 0.0012263127867333846, "trash receptacle": 0.0026879130022789775, "on an": 0.00047573261673146465, "even sometimes a": 0.001412997877799242, "each of which": 0.0005012989789129786, "object such as": 0.001039879574153469, "tions": 0.00016906879144473665, "g decision": 0.0010706929277613088, "1200 dimensional": 0.0013439565011394887, "need": -0.0006544941899597154, "epochs comparing": 0.0013439565011394887, "a further processing": 0.0012953547128852297, "17 figure": 0.0010706929277613088, "the robot repeated": 0.001412997877799242, "research e g": 0.001412997877799242, "examples available": 0.0010706929277613088, "uncertainties machine": 0.0013439565011394887, "ffl decomposable functions": 0.001412997877799242, "parts of its": 0.0011397700534482, "2 3": 0.00012566825784304556, "15 and": 0.0004578137845830829, "the capability of": 0.000777160622754577, "many interesting": 0.0007595764743381157, "suggest": 0.00038456703137021024, "examples encountered by": 0.001412997877799242, "insignificant the": 0.001013492172364257, "ojs ff": 0.0013439565011394887, "the tradeoff": 0.0007033220515237973, "complex": 1.7702087235607275e-05, "described above is": 0.0008035626821164737, "the execution": 0.00030509570079956467, "two disjoint": 0.0006516207816749321, "the local occupancy": 0.001412997877799242, "several": -0.002143926087025286, "based on spatial": 0.0022175912015655443, "somewhat large": 0.0012263127867333846, "feature f then": 0.001412997877799242, "wheel": 0.000852454393186244, "independent": -9.694572235110896e-05, "robot starting at": 0.001412997877799242, "training data": 0.001327987366299053, "paradigms mobile": 0.0013439565011394887, "combination of": 0.0005705165174893305, "is quite": 0.000707572608522887, "trajectories": 0.0005912663295432267, "in better performance": 0.0010826007236946758, "counterparts": 0.0004868824994288003, "hand": -0.0003099578956143036, "to constrain": 0.0007387405675331519, "robot till it": 0.001412997877799242, "color and based": 0.001412997877799242, "off with a": 0.0010826007236946758, "to facilitate": 0.0009788058600426906, "sensors avoid": 0.0013439565011394887, "the task": 0.0015415681805633513, "3 accelerating": 0.0012263127867333846, "example a dozen": 0.001412997877799242, "concept learning which": 0.001412997877799242, "can although": 0.0012263127867333846, "the environment": 0.0005047289660579865, "normalization": 0.00044369014968242206, "g the concept": 0.001412997877799242, "bias sensory concept": 0.001412997877799242, "the starting position": 0.001039879574153469, "supervised learning of": 0.0011087956007827721, "20 and": 0.0004918725043258845, "on concept": 0.0010397031738864368, "multiple reflections": 0.0012263127867333846, "two general": 0.0031588970173112214, "describing the real": 0.001412997877799242, "the trained neural": 0.0025907094257704593, "the output of": 0.0005120496923579847, "bias which rules": 0.001412997877799242, "s mahadevan g": 0.014129978777992418, "first took": 0.0013439565011394887, "different parts": 0.0007897242543278053, "net does": 0.0011086075099259812, "turn camera sensors": 0.001412997877799242, "the": 0, "see figure 10": 0.0017317673187115608, "or because": 0.0006843495569384895, "2 s encoding": 0.001412997877799242, "and shape salganicoff": 0.001412997877799242, "bias free learning": 0.001412997877799242, "successive runs": 0.001157470080128191, "for state estimation": 0.001412997877799242, "see 5": 0.0006486581696160977, "a contradictory": 0.0011086075099259812, "accelerating sensory concept": 0.002825995755598484, "on an actual": 0.0012265208479459286, "proposes": 0.0008648050104903566, "image and moving": 0.001412997877799242, "wall back": 0.004031869503418466, "16 show": 0.0010706929277613088, "the entire floor": 0.001412997877799242, "distinguished history": 0.0012263127867333846, "camera image and": 0.001412997877799242, "in a majority": 0.0011087956007827721, "likelihood of": 0.000593511402013939, "it relies": 0.0009217509760058083, "example the feature": 0.001177670521728601, "high dimensional and": 0.0038860641386556888, "25 are difficult": 0.001412997877799242, "despite significant odometric": 0.002825995755598484, "that a": 0.00010859939987652678, "learning here": 0.0013439565011394887, "e and figure": 0.001412997877799242, "is colored yellow": 0.001412997877799242, "learning for robots": 0.0012953547128852297, "rotating the image": 0.001412997877799242, "easy to implement": 0.0007855213434982123, "transformed": 0.00024133794001012057, "board": 0.0005461981208921447, "an artificial": 0.0007488464497674484, "the sensor uncertainty": 0.001412997877799242, "the feature": 0.001895555324909649, "openings": 0.0011084194828720588, "reasons sensory data": 0.001412997877799242, "we now": 0.00020145203981078978, "is improved": 0.0006879834963441684, "a shared": 0.0024470146501067267, "4 describes the": 0.0008184493641822325, "learning framework to": 0.001412997877799242, "the experiments described": 0.0017054873098833036, "approach was": 0.0006291989168691914, "ensures that rapid": 0.0012953547128852297, "each direction each": 0.001412997877799242, "pixel in every": 0.0012953547128852297, "under uncertainty": 0.0009707370964526472, "trash e g": 0.001412997877799242, "is a": 7.867165644547467e-06, "direction and thus": 0.0012953547128852297, "can also": 0.00018180479566022278, "become very": 0.0008262639069617736, "machine learning and": 0.0009419732139289226, "a detailed comparison": 0.0010826007236946758, "sensory space": 0.0013439565011394887, "input data has": 0.0012265208479459286, "yellow avoid": 0.0013439565011394887, "4 only one": 0.0012953547128852297, "as it": 0.0005243719899737294, "a recycling robot": 0.001412997877799242, "is s": 0.0005601128957225589, "much room for": 0.0012265208479459286, "in domains where": 0.0011087956007827721, "investigated sensory": 0.0013439565011394887, "this is shown": 0.000747247581202698, "a common underlying": 0.0012265208479459286, "a b": 0.00020699158191656939, "a c": 0.00034520304794030795, "quadrants of the": 0.001177670521728601, "its route measured": 0.001412997877799242, "temporally": 0.0006575874739531386, "been investigated for": 0.0011397700534482, "6 in figure": 0.001039879574153469, "offices": 0.000852454393186244, "algorithm is": 0.0002059454548455772, "such as kalman": 0.001412997877799242, "the rough geometrical": 0.001412997877799242, "burden on": 0.0007770287888915143, "hierarchical concept": 0.0013439565011394887, "bias is specified": 0.001412997877799242, "feature detectors layer": 0.001412997877799242, "the neural net": 0.020725675406163675, "such an approximator": 0.001412997877799242, "that can perceive": 0.001412997877799242, "a smaller": 0.00041001176617621693, "philosophy adopted": 0.0013439565011394887, "the actual range": 0.0012953547128852297, "successfully": 0.00048267588002024115, "the invariants": 0.0008433654142724929, "3 bias": 0.0012263127867333846, "and labeling examples": 0.001412997877799242, "observations in each": 0.0012265208479459286, "features for 322": 0.001412997877799242, "meters": 0.0006842334867965392, "are labeled with": 0.0008591880780779472, "collection requires running": 0.001412997877799242, "robotics applications has": 0.001412997877799242, "areas indicate": 0.001157470080128191, "weights the total": 0.001412997877799242, "more applicable when": 0.001412997877799242, "importance to machine": 0.001412997877799242, "the user": 0.000310194142263639, "predicts the": 0.0007437201166480605, "possibility exists": 0.001157470080128191, "pavlov include": 0.0013439565011394887, "a draft": 0.0008623569375540945, "finds the": 0.0006164961457553095, "of actuator": 0.0013439565011394887, "sonar and": 0.0012263127867333846, "were the": 0.0005913666291750407, "comments": 0.00012368324110156254, "odometry is": 0.0012263127867333846, "the university": 0.0005034031207103129, "clearly demonstrated that": 0.0012953547128852297, "allows a": 0.00048218123871081716, "22 uses a": 0.0012953547128852297, "hypotheses bias to": 0.001412997877799242, "percept is a": 0.001412997877799242, "recycling task figure": 0.001412997877799242, "front near": 0.0013439565011394887, "adapted to new": 0.0012265208479459286, "by the probabilities": 0.0012265208479459286, "experiments reported": 0.0007338995299089556, "of this research": 0.0007615602934733865, "values into a": 0.001177670521728601, "was conducted we": 0.001412997877799242, "is a discrete": 0.0008527436549416518, "pose": 0.004838409128324757, "was used": 0.0010960331052222874, "hidden layer": 0.0009907789071032058, "behaviors such as": 0.0010826007236946758, "features effects of": 0.001412997877799242, "white while": 0.0012263127867333846, "and action the": 0.0012953547128852297, "net is": 0.006898855500432756, "the different approaches": 0.0011397700534482, "was started": 0.0009907789071032058, "discuss the": 0.000346408871480994, "post": 0.0013170870335452232, "which allows": 0.00048336597935908464, "examples of occupancy": 0.001412997877799242, "neural nets vs": 0.001412997877799242, "and simultaneous learning": 0.001412997877799242, "9 e and": 0.0012953547128852297, "to drop": 0.0007291894113705743, "turret turn camera": 0.001412997877799242, "9 here": 0.0011086075099259812, "layer planning": 0.0013439565011394887, "subsequent across the": 0.001412997877799242, "four virtual sensors": 0.001412997877799242, "in state estimation": 0.002825995755598484, "we study how": 0.0021652014473893515, "the observation model": 0.0012265208479459286, "months": 0.0012279126806740111, "labeled data reveals": 0.001412997877799242, "a pursuit model": 0.001412997877799242, "on 872": 0.0026879130022789775, "the 3rd": 0.0006046361590848585, "the probability that": 0.0004927864950948161, "top figure shows": 0.001412997877799242, "are simplifying": 0.0013439565011394887, "the judicious use": 0.001412997877799242, "become very noticeable": 0.001412997877799242, "guided mobile robot": 0.001412997877799242, "two general strategies": 0.001412997877799242, "robust layered": 0.0013439565011394887, "that ensures": 0.0007652009340995504, "is shown in": 0.0003303384486573886, "tradeoff between": 0.0006023554586211942, "over all training": 0.001412997877799242, "decomposed into four": 0.0012953547128852297, "of the grdt": 0.001412997877799242, "it had": 0.0007033220515237973, "is updated to": 0.0008591880780779472, "task three times": 0.001412997877799242, "the scope of": 0.0005215058175337637, "run on pavlov": 0.001412997877799242, "the focus": 0.0010607151857049066, "moreno symbolic": 0.0013439565011394887, "summarizes the": 0.0004894029300213453, "it has": 0.0001511133593637514, "basic idea in": 0.0010057508064281846, "avoid bump figure": 0.001412997877799242, "examples to": 0.0012973163392321955, "197 february 2004": 0.001412997877799242, "the special issue": 0.0010826007236946758, "task involves several": 0.001412997877799242, "find trash cans": 0.001412997877799242, "learn one set": 0.001412997877799242, "sensor representation the": 0.001412997877799242, "in this paper": 0.0006541943695431643, "biases 3 1": 0.001412997877799242, "noticeable in figure": 0.001177670521728601, "and picking up": 0.0012953547128852297, "that the neural": 0.0012953547128852297, "concept learning here": 0.001412997877799242, "how pavlov": 0.0026879130022789775, "both problems we": 0.0012953547128852297, "showing the robot": 0.001412997877799242, "from the recycling": 0.001412997877799242, "floor e": 0.0013439565011394887, "typically data": 0.0013439565011394887, "corridor for state": 0.001412997877799242, "q i": 0.0010202560389198398, "of an abstract": 0.000887696035668378, "way": -0.00030911314923589016, "of the behaviors": 0.0010826007236946758, "consistent results": 0.0010706929277613088, "speed learning": 0.0013439565011394887, "was": -0.00781631209832405, "convergence here for": 0.001412997877799242, "the transducer": 0.001157470080128191, "favor of": 0.0006576990239911289, "learning optimal": 0.0012263127867333846, "north south": 0.0009217509760058083, "journal of": 0.00019432429531638555, "trash and": 0.0013439565011394887, "acceptable range": 0.0010706929277613088, "other irregularities and": 0.001412997877799242, "attempted": 0.00042877863325190105, "adjacent to": 0.0011462594208270312, "400 pixels so": 0.001412997877799242, "shows a": 0.00034340657582643063, "26 developed an": 0.001412997877799242, "a strength": 0.0010706929277613088, "environment under these": 0.001412997877799242, "wireless": 0.00047064125881922673, "action the probability": 0.001412997877799242, "results presented above": 0.001177670521728601, "because the data": 0.0009909470066802508, "to traverse across": 0.001412997877799242, "image and": 0.0005674367630990076, "impossible and": 0.001013492172364257, "irregularities and typically": 0.001412997877799242, "true": -7.133392804356537e-05, "the robot generates": 0.001412997877799242, "and very near": 0.001412997877799242, "f js": 0.0013439565011394887, "algorithm for learning": 0.001021962604845781, "on human": 0.0006993597717998856, "was conducted": 0.0007595764743381157, "which can also": 0.0009219073640234544, "maximum": -7.082041280074509e-05, "tasks learning": 0.0013439565011394887, "is probably the": 0.0009039491294179812, "quadrants left": 0.0013439565011394887, "direction and": 0.0006372791512719589, "units right front": 0.001412997877799242, "simplifying": 0.00038824777280147167, "since there is": 0.0005900509154676838, "detectors and": 0.0009707370964526472, "2 south east": 0.002825995755598484, "electrical engineering": 0.001745405688415944, "features as predicted": 0.001412997877799242, "prone to": 0.0014315547769893492, "simply chooses one": 0.001412997877799242, "were carried": 0.0007541286032508272, "is 512 rather": 0.001412997877799242, "it was": 0.0002765826035276945, "computing": -0.00018112773965319902, "odometry is also": 0.001412997877799242, "as locating": 0.0012263127867333846, "abstract": 0.0010906437622968247, "approaches which": 0.0008623569375540945, "ctr b l": 0.001412997877799242, "only one of": 0.000655760894139667, "addition although": 0.0011086075099259812, "learning are able": 0.001412997877799242, "output with the": 0.0011397700534482, "state the": 0.0003846680015569265, "deeper ones in": 0.001412997877799242, "22 uses": 0.001157470080128191, "distributions": 0.0002533794140624586, "studied here would": 0.001412997877799242, "and actuator errors": 0.001412997877799242, "constructed": 5.4542677090817896e-05, "the features effects": 0.001412997877799242, "and are critical": 0.001412997877799242, "decision tree approaches": 0.001412997877799242, "no": -0.0005495565826755345, "whereas": 9.005656971873942e-05, "when": -0.005032737605079897, "eventually resolve": 0.0012263127867333846, "human designer": 0.004282771711045235, "class approach": 0.0012263127867333846, "labeled data": 0.0009907789071032058, "being filled in": 0.0012265208479459286, "test": 0.0, "performed better": 0.000872702844207972, "represented we": 0.0011086075099259812, "system was tested": 0.0012953547128852297, "node": 0.00014369553141582145, "3 abstract": 0.0012263127867333846, "degree of": 0.00032181848768208333, "of three": 0.00034460259923553435, "pre programmed": 0.0012263127867333846, "inductive learning from": 0.001412997877799242, "space is represented": 0.001412997877799242, "reactive declarative structure": 0.001412997877799242, "update": 0.00015138572171369423, "image input to": 0.001412997877799242, "filling in details": 0.001412997877799242, "it to": 0.00025383321843281065, "position south": 0.0013439565011394887, "generates 4 observations": 0.001412997877799242, "of single output": 0.0012953547128852297, "to improve": 0.00028433066784270953, "actual run": 0.002314940160256382, "called partially": 0.001157470080128191, "loop 3": 0.0009707370964526472, "experimental findings from": 0.001412997877799242, "readily than their": 0.001412997877799242, "longer": 5.909255552959319e-05, "pentium processor": 0.0009707370964526472, "detailed experimental": 0.002314940160256382, "39 n": 0.0005731297104135156, "to be an": 0.000561408532790537, "value because they": 0.0012953547128852297, "doors and": 0.0024526255734667692, "color images the": 0.001412997877799242, "into symbolic rules": 0.001412997877799242, "to machine": 0.0007541286032508272, "20 40": 0.0007770287888915143, "specular reflections in": 0.001412997877799242, "research was": 0.0010516673177898568, "output by": 0.0007710139595398186, "extends the supervised": 0.001412997877799242, "2 as": 0.00038831363332272726, "result the sensor": 0.001412997877799242, "concept": 0.004026210184443858, "sensor this": 0.0011086075099259812, "input data": 0.0005830336660574013, "set of random": 0.0009647109541934066, "invariances across": 0.0013439565011394887, "high degree of": 0.000747247581202698, "are hypothesis space": 0.001412997877799242, "of random": 0.0004906336953483374, "up learning": 0.004031869503418466, "focus": 0.00030594902543622167, "pick up": 0.0008954780757782285, "switches": 0.00044176341684680785, "with which": 0.0004578137845830829, "and one": 0.00028433066784270953, "variables the rgb": 0.001412997877799242, "overall planner reactive": 0.001412997877799242, "and d": 0.0002971593103671511, "operate in": 0.0006916942228847701, "environment under": 0.0011086075099259812, "learns not just": 0.001412997877799242, "as opposed to": 0.0005254268733934785, "more flexible navigation": 0.001412997877799242, "detectors we restrict": 0.001412997877799242, "the feature detectors": 0.004238993633397726, "graph": 1.9686596209761537e-05, "a1 pose": 0.0013439565011394887, "our work except": 0.001412997877799242, "for recycling a": 0.001412997877799242, "door opening wall": 0.001412997877799242, "environment": 0.00043975797682169535, "tasks where examples": 0.001412997877799242, "model of steering": 0.001412997877799242, "data generated during": 0.001412997877799242, "that despite significant": 0.001412997877799242, "short term": 0.0007710139595398186, "easily combined with": 0.001412997877799242, "test examples the": 0.001412997877799242, "experimental findings": 0.0011086075099259812, "starting at 0": 0.002355341043457202, "from actual human": 0.001412997877799242, "khaleeli to light": 0.001412997877799242, "robust robot": 0.0013439565011394887, "advantage": 1.4265182813663562e-05, "their effectiveness": 0.0008262639069617736, "wall opening": 0.0026879130022789775, "occupied space gray": 0.001412997877799242, "feature detector figure": 0.001412997877799242, "system onboard": 0.0013439565011394887, "and 3": 0.00021983114546880977, "robot eventually finds": 0.001412997877799242, "and find": 0.0006639936831495265, "not been presented": 0.0012953547128852297, "observation o is": 0.001412997877799242, "t rapid": 0.0012263127867333846, "the navigation domain": 0.002825995755598484, "the sensory concept": 0.001412997877799242, "the sensory state": 0.001412997877799242, "converged to an": 0.0012953547128852297, "on systems": 0.000872702844207972, "virtual sensors and": 0.001412997877799242, "involves several component": 0.001412997877799242, "is still": 0.000529488931254783, "robots robotics in": 0.001412997877799242, "random weights the": 0.001412997877799242, "perceived": 0.0005789087042364873, "concept descriptions however": 0.001412997877799242, "on those values": 0.0012265208479459286, "presented": -0.0005260944633402461, "6 related work": 0.0007898582421551431, "robots 13": 0.0013439565011394887, "p": -0.0005955809767352478, "were fairly smooth": 0.001412997877799242, "concept learn": 0.0013439565011394887, "a relational": 0.0007291894113705743, "whether the object": 0.001177670521728601, "environments including offices": 0.001412997877799242, "show that": 0.00016911871277241835, "investigate two": 0.0022172150198519623, "and multi class": 0.001412997877799242, "three successful": 0.0026879130022789775, "0000000000000000000000000000000000000000000000000000000000000000111111111111111111111111111111111111111111111111111111111111111111111111 sensor": 0.0013439565011394887, "for a mobile": 0.0011087956007827721, "estimators such as": 0.0012265208479459286, "learned since": 0.001157470080128191, "a decomposition": 0.0006457442730738455, "slower": 0.00034334833183460113, "ff prior the": 0.001412997877799242, "into account both": 0.0009909470066802508, "from our work": 0.0010057508064281846, "ex ample given": 0.001412997877799242, "to determine": 0.00017603037741982083, "feature detectors": 0.012732170881410102, "c note": 0.0007157773884946746, "g decision trees": 0.001177670521728601, "region having a": 0.0012953547128852297, "only one": 0.0002017954311914905, "cost": -2.2154033652826357e-05, "f js for": 0.001412997877799242, "only necessary to": 0.0009039491294179812, "an extremely challenging": 0.002825995755598484, "figure 13 this": 0.0012953547128852297, "port": 0.0004165894486024949, "purpose of learning": 0.001412997877799242, "encountered by": 0.0009217509760058083, "limited training examples": 0.001412997877799242, "recycling domain": 0.0013439565011394887, "single concept it": 0.001412997877799242, "a specified": 0.0005479626095875345, "not been encouraging": 0.001412997877799242, "receptacle the trash": 0.001412997877799242, "cited the number": 0.001412997877799242, "position c and": 0.001412997877799242, "the sub sampling": 0.0012953547128852297, "feature f in": 0.001412997877799242, "detect and": 0.0013909702264962565, "examples ffl filling": 0.001412997877799242, "it is difficult": 0.0005738707591956328, "is currently": 0.00047983361412572704, "n 2 p": 0.0002968846274685851, "learning grasping": 0.0013439565011394887, "shared": 0.0007039547905767934, "simple partition": 0.0013439565011394887, "to learn multiple": 0.002825995755598484, "specified trash": 0.0013439565011394887, "is currently an": 0.0011397700534482, "arranged radially": 0.0013439565011394887, "hsi": 0.0019052819191541965, "domains where": 0.0009217509760058083, "state for": 0.0006164961457553095, "hierarchical concept descriptions": 0.001412997877799242, "learning an": 0.002651137991267899, "due to": 0.0002623236658129735, "in its": 0.00025506948685629824, "thus there are": 0.0008133430731188866, "both positions": 0.0013439565011394887, "and recycling": 0.0013439565011394887, "studied on a": 0.0012265208479459286, "capability of learning": 0.001412997877799242, "system just": 0.0012263127867333846, "another e": 0.0009907789071032058, "program we identified": 0.001412997877799242, "can figure 3": 0.001412997877799242, "compass directions": 0.0013439565011394887, "hybrid declarative reactive": 0.001412997877799242, "the capability": 0.000634544764829945, "teacher": 0.0023687709358526524, "rest of": 0.0002509705828624383, "locations in": 0.000634544764829945, "noticeable": 0.0009885817126419891, "b1 pose b2": 0.001412997877799242, "show below": 0.0015304018681991007, "robots can": 0.001157470080128191, "wall or undefined": 0.001412997877799242, "mainly focus on": 0.0011087956007827721, "draft of this": 0.000887696035668378, "the robot has": 0.003533011565185803, "trial": 0.0005073230083137942, "distance far": 0.0013439565011394887, "easier to": 0.00040919586641565266, "instances is often": 0.0012953547128852297, "maintain belief estimates": 0.001412997877799242, "state space with": 0.0011397700534482, "domains": 0.0002634174067090446, "system just cited": 0.001412997877799242, "noticeably": 0.0006344371419051095, "navigation": 0.01760040613589779, "acronym for": 0.001013492172364257, "implement a": 0.0011166539171647495, "solution e g": 0.0011397700534482, "detectors for navigation": 0.002825995755598484, "a where the": 0.0008035626821164737, "can was directly": 0.001412997877799242, "our work in": 0.0009126929338602609, "concept learning from": 0.002825995755598484, "extended the": 0.0006457442730738455, "data is often": 0.0038860641386556888, "this state estimation": 0.001412997877799242, "estimator are": 0.0012263127867333846, "large state space": 0.0011397700534482, "ronment the": 0.0012263127867333846, "g sonar is": 0.001412997877799242, "to recognize landmarks": 0.001412997877799242, "thrun": 0.001039526833456673, "robot maintains at": 0.001412997877799242, "three successive runs": 0.0012953547128852297, "200 mobile robot": 0.001412997877799242, "the yellow": 0.0010397031738864368, "from supervised learning": 0.001412997877799242, "or far": 0.0011086075099259812, "based methods in": 0.0011087956007827721, "the possibility exists": 0.0012265208479459286, "from the": 1.1800789777850942e-05, "to employ a": 0.0010057508064281846, "it requires": 0.00046523782410889047, "every step": 0.0007437201166480605, "the colored": 0.0011086075099259812, "layer behavior": 0.0013439565011394887, "in every state": 0.0011397700534482, "percept": 0.0009906108645477269, "a computational": 0.0005258336588949284, "in either a": 0.0011397700534482, "as follows we": 0.0005943328552515203, "objects for recycling": 0.001412997877799242, "uneven floors": 0.0013439565011394887, "work as well": 0.0009773255297405913, "intensity which": 0.0013439565011394887, "using batch": 0.0010706929277613088, "here is to": 0.00203920083185483, "outputs": 0.0005494943053939604, "learn have": 0.0013439565011394887, "here we focus": 0.0010057508064281846, "is colored": 0.0009217509760058083, "to predict a": 0.0009647109541934066, "robotics in": 0.0011086075099259812, "this paper assumes": 0.0011397700534482, "the grdt algorithm": 0.001412997877799242, "we present": 0.00016045798764915064, "cases": -0.000455089610638424, "b in": 0.00036337447101637035, "9 f are": 0.001412997877799242, "feature detectors are": 0.001412997877799242, "in domains": 0.0008346023623118109, "to explaining the": 0.001412997877799242, "geometrical aligment": 0.0013439565011394887, "in section": 6.291087004761473e-05, "its environment": 0.0007541286032508272, "approach we": 0.00046523782410889047, "from the current": 0.0007074960937271329, "examples both": 0.0012263127867333846, "a coarsely subsampled": 0.001412997877799242, "machine learning": 0.0026907610584900217, "labeled": 0.0026157359109535722, "to robot": 0.0020794063477728737, "can": -0.05272250623221031, "11 a": 0.0005273294080774565, "navigation the neural": 0.001412997877799242, "probabilistic model of": 0.001039879574153469, "below 4": 0.0008346023623118109, "lab18": 0.0012261047960979141, "the ability to": 0.00048226304753991637, "near and very": 0.001412997877799242, "each local occupancy": 0.001412997877799242, "figure": -0.011831905387646615, "net trained": 0.0013439565011394887, "forms of bias": 0.0012953547128852297, "behaviors to learning": 0.001412997877799242, "corresponding features": 0.0010706929277613088, "g even": 0.001157470080128191, "topic": 0.0007266256806789359, "semi markov": 0.0018435019520116167, "into hsi": 0.0013439565011394887, "hybrid two layered": 0.001412997877799242, "performed": -5.706788273765483e-05, "e g on": 0.0009909470066802508, "find trash receptacles": 0.001412997877799242, "autonomous vehicle for": 0.001412997877799242, "into four": 0.0006372791512719589, "some recent neural": 0.001412997877799242, "occur": -1.1311291468567212e-05, "e g sonar": 0.001412997877799242, "a good": 0.00026091609397589394, "approach the results": 0.001412997877799242, "to learn one": 0.001412997877799242, "from a": 8.09086844431638e-05, "discussion": 3.441409631908712e-06, "recycling domain for": 0.001412997877799242, "relies on": 0.000451668842582774, "results not only": 0.0012265208479459286, "2 ff": 0.0007595764743381157, "abstract observation ff": 0.001412997877799242, "1": 0, "virtual sensors by": 0.001412997877799242, "approach which extends": 0.0012953547128852297, "criterion": 0.000227544805319212, "data a robot": 0.001412997877799242, "for solving the": 0.001244834792203361, "values we": 0.0005731297104135156, "action is defined": 0.001412997877799242, "3 25": 0.0007387405675331519, "spatial decomposition": 0.008584189507133692, "litter and": 0.0013439565011394887, "grid or a": 0.001412997877799242, "right and 3": 0.001412997877799242, "top bottom": 0.001157470080128191, "necessary to learn": 0.001412997877799242, "paramount": 0.0007768969997482151, "information": -0.0004476566674903216, "the decision": 0.0009459178655727723, "took various": 0.0013439565011394887, "used in": 0.00041576116639428036, "these examples": 0.0005892470628878294, "near the figure": 0.0012953547128852297, "hundred input units": 0.001412997877799242, "which was used": 0.0009909470066802508, "predicted by": 0.0006372791512719589, "produce": 0.00011514733588434935, "decision tree": 0.0034039461843834084, "it helps to": 0.001039879574153469, "used is": 0.000577026606170962, "this paper were": 0.0008405371151868688, "representations": 0.00022979775485617242, "as avoiding": 0.0013439565011394887, "improvement in current": 0.001412997877799242, "400 pixels": 0.0012263127867333846, "input e": 0.0010706929277613088, "cited the": 0.0013439565011394887, "of examples encountered": 0.001412997877799242, "paper is organized": 0.00036873091130827526, "succeeded": 0.0006638810654963465, "clear that": 0.0003363626966119245, "the sensory concepts": 0.001412997877799242, "explicit": 8.585322612989181e-05, "net architecture": 0.0013439565011394887, "robotics tasks": 0.0012263127867333846, "numerous specular": 0.0013439565011394887, "are all that": 0.001412997877799242, "that were close": 0.001412997877799242, "mobile robot base": 0.001412997877799242, "representation": 3.09733806970972e-05, "measured until it": 0.001412997877799242, "g the": 0.0005363909163481421, "research was supported": 0.0006797336106182766, "action the": 0.0007246032270542877, "feedforward neural net": 0.002825995755598484, "a fairly easy": 0.0012953547128852297, "the net can": 0.0012953547128852297, "starting position 5": 0.001412997877799242, "suggest that the": 0.0007340240462866124, "level observations": 0.0013439565011394887, "probability that a": 0.0006310701423978614, "done by": 0.00033752132031601365, "far near very": 0.002825995755598484, "learning introduction to": 0.0012265208479459286, "for her": 0.0007964395063592673, "mainly": 0.0002382140096694762, "other litter": 0.0013439565011394887, "to represent concepts": 0.001412997877799242, "pursuit model of": 0.001412997877799242, "planning and execution": 0.0011397700534482, "not only": 0.0002677615550320837, "trash can six": 0.001412997877799242, "be able": 0.0002801988594165668, "still": -0.00030635661569539623, "mitchell 27 propose": 0.001412997877799242, "can be easily": 0.0008566526358307968, "ular": 0.0007337750557688759, "as noted earlier": 0.0008956300062288188, "examples it": 0.0008623569375540945, "or far on": 0.001412997877799242, "acknowledge": 0.00045361872814018024, "direction each": 0.0012263127867333846, "simplifying the": 0.0007157773884946746, "hypotheses bias": 0.0013439565011394887, "information is un": 0.001412997877799242, "learning alvinn differs": 0.001412997877799242, "forms": 0.00010933177402735496, "platform": 0.0007976171157270955, "paramount importance to": 0.0012265208479459286, "up objects based": 0.001412997877799242, "and state estimator": 0.001412997877799242, "a front near": 0.001412997877799242, "approximate location of": 0.0011087956007827721, "event markov decision": 0.001412997877799242, "for her detailed": 0.001412997877799242, "particular in our": 0.0012265208479459286, "n khaleeli": 0.012095608510255398, "possibilities door": 0.0013439565011394887, "non": -0.0005251322552678392, "a high": 0.0006081781629314328, "gray": 0.0004556665315238027, "net using": 0.0013439565011394887, "below figure": 0.001013492172364257, "powerful than traditional": 0.0012953547128852297, "khaleeli20601001401800 20": 0.0013439565011394887, "position c note": 0.001412997877799242, "extended the decision": 0.001412997877799242, "training the": 0.0007964395063592673, "scaling": 0.0005002316383457338, "multi task": 0.0012263127867333846, "observation will": 0.0009528025610969587, "able to correctly": 0.0022175912015655443, "dozen or": 0.001157470080128191, "in the nominal": 0.0012265208479459286, "slippage": 0.0009906108645477269, "not": 0, "10 the 3rd": 0.001412997877799242, "now": -0.0005883992725197104, "discuss": 3.441409631908712e-06, "grids generated": 0.0013439565011394887, "undergo multiple": 0.0013439565011394887, "or soda": 0.0013439565011394887, "term": -6.391726407460982e-06, "navigation we": 0.0012263127867333846, "base which was": 0.001412997877799242, "is color coded": 0.0012953547128852297, "well studied form": 0.0012953547128852297, "in machine learning": 0.0017054873098833036, "drop": 0.0003421589404744671, "of multiple": 0.0004043680498426622, "the training": 0.001187022804027878, "possibilities": 0.00028106345688975554, "realistic": 0.000227544805319212, "into several": 0.0006189654335108611, "abstract observation this": 0.001412997877799242, "by an": 0.00018310109020190367, "such as reinforcement": 0.001412997877799242, "4 s mahadevan": 0.001412997877799242, "training examples and": 0.0010057508064281846, "in that it": 0.001248229380925861, "domain": 0.00016514169072016484, "also limited": 0.0011086075099259812, "most successful": 0.0008623569375540945, "ee": 0.0005870525139763916, "distribution ff": 0.0013439565011394887, "combines a high": 0.001412997877799242, "concept4 figure": 0.0013439565011394887, "first idea": 0.0010397031738864368, "snapshots": 0.0006239029826303446, "00000000000000000000000000000011111111111111111111111110000000000000000000000000111111111111111111111111100000000000000000000000001111111111111111111111111000000111111000000111111000000111111": 0.0012261047960979141, "use of": 0.00020948158715923277, "tasks navigation and": 0.001412997877799242, "are labeled": 0.0005871520987964046, "ex": 0.0002747471526969802, "updated state": 0.0012263127867333846, "difficult to use": 0.0009316462484985891, "et": 5.617190060673039e-05, "another other than": 0.001412997877799242, "learning task": 0.0009081111668589885, "quite limited": 0.0009707370964526472, "bias is of": 0.001412997877799242, "steering to": 0.0013439565011394887, "neural net trained": 0.001412997877799242, "shown": -0.00040036242246495763, "learning fundamentals": 0.0013439565011394887, "approach is based": 0.0007277706970731944, "commands neural net": 0.001412997877799242, "space": -0.001752657215330546, "of two disjoint": 0.0009773255297405913, "the sensory representation": 0.001412997877799242, "the net for": 0.0012953547128852297, "state which": 0.0007291894113705743, "ffl filling in": 0.001412997877799242, "bias to make": 0.001412997877799242, "out certain hypotheses": 0.001412997877799242, "nsf career": 0.0008346023623118109, "representations incur a": 0.001412997877799242, "conducted over": 0.001157470080128191, "navigating": 0.0028290244073458076, "same camera": 0.001157470080128191, "slower to": 0.0011086075099259812, "the real": 0.0003627218358225084, "tasks learning feature": 0.001412997877799242, "used to test": 0.002504231893024156, "shows": -0.004186953754298606, "is to improve": 0.000887696035668378, "fundamentals of digital": 0.0011397700534482, "robots a comparison": 0.001412997877799242, "be partitioned": 0.0006046361590848585, "alvinn differs from": 0.001412997877799242, "designer specifies most": 0.001412997877799242, "objects using the": 0.0011087956007827721, "in every five": 0.0012953547128852297, "architecture for": 0.0013989661967022118, "the presentation here": 0.001177670521728601, "criterion for selecting": 0.001177670521728601, "advantages": 0.00017855478021912944, "to other": 0.0009478005520195289, "used on": 0.0006092863925155239, "the navigation and": 0.0012265208479459286, "control architecture for": 0.001177670521728601, "corridor or": 0.0013439565011394887, "than traditional state": 0.001412997877799242, "2 4 recycling": 0.001412997877799242, "these occupancy": 0.0013439565011394887, "way either": 0.001157470080128191, "are noticeable in": 0.001412997877799242, "in neural nets": 0.0012953547128852297, "neural net despite": 0.001412997877799242, "layer the planning": 0.001412997877799242, "well studied": 0.0022623858097524817, "inductive bias": 0.0009217509760058083, "380 test examples": 0.001412997877799242, "sensor values into": 0.0012953547128852297, "being filled": 0.0010397031738864368, "avenue towards": 0.0012263127867333846, "turn": 0.00022220809986033717, "place": 7.442188392481762e-05, "the presentation rapid": 0.001412997877799242, "trash can but": 0.002825995755598484, "ture": 0.0005128000387594285, "512": 0.0004050960623474284, "incur a": 0.0007595764743381157, "necessary for": 0.0004083832322832275, "guided mobile": 0.0013439565011394887, "predicts the high": 0.001412997877799242, "which was": 0.00043803992979003455, "alvinn differs": 0.0013439565011394887, "begin by": 0.00046961187631144803, "scaling rotation and": 0.001412997877799242, "c1 pose c2": 0.001412997877799242, "variables": -1.6224606246214684e-05, "from the robot": 0.0012953547128852297, "symbolic": 0.0012364525969435606, "approach could": 0.0016068527390651385, "use a": 0.0007705999149006846, "it had found": 0.001412997877799242, "situation this": 0.001157470080128191, "concept2 concept3": 0.0013439565011394887, "directly": -0.00035811878536013726, "space in": 0.0004707210961828941, "control architecture": 0.0010706929277613088, "impossible": 0.000227544805319212, "ring": 0.0004556665315238027, "first idea is": 0.001177670521728601, "millions": 0.000571115303593364, "as illustrated in": 0.0006190704497024985, "given": -0.0025825390025578827, "approximately oriented": 0.0013439565011394887, "the original": 0.00045602443997793166, "the distance far": 0.001412997877799242, "is often high": 0.0012953547128852297, "input size is": 0.0011087956007827721, "overall learning task": 0.001412997877799242, "can and": 0.0007595764743381157, "recognize and": 0.0009528025610969587, "framework to handle": 0.0012953547128852297, "the latter work": 0.0012265208479459286, "13 electrical": 0.0013439565011394887, "multiple reflections before": 0.001412997877799242, "compares the training": 0.001412997877799242, "some details": 0.0008837126637559662, "studies in the": 0.0010826007236946758, "is used": 0.00011592543141140471, "to speed convergence": 0.0012265208479459286, "white": 0.0007854158010254773, "a low occupancy": 0.0012953547128852297, "yellow avoid motors": 0.001412997877799242, "color coded to": 0.002825995755598484, "states where the": 0.001021962604845781, "hue": 0.0009906108645477269, "figure 15": 0.001106142977434748, "to learn": 0.006786936274807947, "our system the": 0.0009039491294179812, "that": 0, "quadrants left right": 0.001412997877799242, "actual range": 0.0012263127867333846, "pavlov either": 0.0013439565011394887, "had found the": 0.0012953547128852297, "the figures": 0.0005850811540016608, "over another": 0.0019414741929052945, "the bias strategies": 0.001412997877799242, "robots 900000000000000000000000000000000011111111111111111111111111111111111111111111000000000000000000000000000000000000111111111111111111111111111111111111": 0.0013439565011394887, "off with": 0.0008954780757782285, "layer behavior based": 0.001412997877799242, "abilities such as": 0.0012953547128852297, "than": -0.0054174774877145185, "containers could be": 0.001412997877799242, "a weakness of": 0.0010057508064281846, "inductive learning": 0.0008623569375540945, "that high": 0.0007964395063592673, "post scale o": 0.001412997877799242, "noisy due": 0.002314940160256382, "desired target concept": 0.001412997877799242, "require": -0.00011480438597153408, "markov models": 0.0007652009340995504, "trash can finder": 0.001412997877799242, "studied work by": 0.001412997877799242, "0 3 0": 0.0007615602934733865, "black represents occupied": 0.001412997877799242, "r": 0, "opening wall or": 0.001412997877799242, "training set it": 0.0011397700534482, "pair of": 0.00026863009361224443, "compares the": 0.0005199682495302577, "the user in": 0.0007653307612006872, "orientation of": 0.0006807892368766817, "representation the": 0.0012429386416046297, "describes the experimental": 0.001177670521728601, "decompose": 0.00042877863325190105, "and": 0, "onboard pavlov": 0.0013439565011394887, "electrical engineering department": 0.002453041695891857, "can the other": 0.0012953547128852297, "acknowledge the": 0.0006738777284751093, "4 only": 0.0009217509760058083, "robots 5 ff": 0.001412997877799242, "generalization": 0.0002129511826859615, "which extends": 0.0008107079716898269, "order of a": 0.0008527436549416518, "khaleeli generally": 0.0013439565011394887, "navigation architecture": 0.0026879130022789775, "the same": 1.696509937282021e-05, "designer provides": 0.0011086075099259812, "be using a": 0.0012265208479459286, "the robot employs": 0.0012953547128852297, "likelihood of each": 0.001177670521728601, "pavlov see": 0.0013439565011394887, "any": -0.0014313119759756128, "decompose the overall": 0.001412997877799242, "a trash can": 0.0038860641386556888, "left or": 0.0006879834963441684, "rapid learning we": 0.001412997877799242, "free space": 0.0008346023623118109, "task in order": 0.0011397700534482, "navigation system 11": 0.001412997877799242, "achieve rapid": 0.0013439565011394887, "are two": 0.00023516443784900602, "learning from labeled": 0.0012953547128852297, "learning problem tractable": 0.001412997877799242, "and s 2": 0.0007507167322393574, "subsampled image can": 0.001412997877799242, "space could be": 0.0011087956007827721, "have the": 0.00012342429553360992, "khaleeli generally less": 0.001412997877799242, "grids this results": 0.001412997877799242, "theocharous": 0.012261047960979142, "by scaling": 0.0008262639069617736, "strengths": 0.000527239969575408, "now present": 0.0005871520987964046, "successful run": 0.001157470080128191, "0000000000000000000000000000000000000000000000000000000000000000111111111111111111111111111111111111111111111111111111111111111111111111": 0.0012261047960979141, "notes 1 pavlov": 0.001412997877799242, "begin": 0.00018539474435823265, "sensor i": 0.0036789383602001536, "multiple": -0.001008037269273317, "main categories": 0.0010706929277613088, "c and d": 0.0006207360845490545, "on the task": 0.0009419732139289226, "navigation is challenging": 0.001412997877799242, "declarative reactive architecture": 0.001412997877799242, "it requires dealing": 0.001412997877799242, "network approach": 0.0009528025610969587, "multiple output units": 0.0012953547128852297, "i2i given the": 0.001412997877799242, "learning from preclassified": 0.001412997877799242, "this programming": 0.0010706929277613088, "key limitations": 0.0012263127867333846, "successive": 0.0002335924145220866, "of the experiments": 0.0007340240462866124, "execution layer": 0.0013439565011394887, "percepts in each": 0.001412997877799242, "the 100x100": 0.0013439565011394887, "was studied": 0.0007157773884946746, "layer output layer": 0.0012953547128852297, "with a set": 0.0006706348685868236, "must map": 0.0010706929277613088, "adopt": 0.0003294778878222104, "patterns the": 0.0007201345364976421, "an event": 0.0005228778271257987, "learn useful concepts": 0.001412997877799242, "al 15": 0.0007488464497674484, "nominal directions front": 0.001412997877799242, "for these reasons": 0.0008035626821164737, "al 12": 0.0007437201166480605, "learning learning sensory": 0.001412997877799242, "experimental studies on": 0.0012265208479459286, "2 i": 0.0008135352918739171, "learning is beyond": 0.001412997877799242, "typically": 3.950670924022602e-05, "at the same": 0.00036739487540605374, "intensity can be": 0.001412997877799242, "if a": 0.00012174809691969625, "robust robot navigation": 0.001412997877799242, "interesting concepts": 0.0026879130022789775, "can placed": 0.0013439565011394887, "however for": 0.0008087360996853245, "weakness of this": 0.0010826007236946758, "9 c shows": 0.001177670521728601, "net this would": 0.001412997877799242, "programming burden seems": 0.001412997877799242, "or on": 0.0005655780229006622, "and based on": 0.0008956300062288188, "pavlov has": 0.0013439565011394887, "output net to": 0.0012953547128852297, "grdt algorithm": 0.0013439565011394887, "navigation system based": 0.001412997877799242, "recy cling both": 0.001412997877799242, "concept4 figure 6": 0.001412997877799242, "tree based algorithm": 0.001177670521728601, "studies on": 0.000634544764829945, "dealing with": 0.00043156351621725415, "those using decision": 0.001412997877799242, "the overall planner": 0.001412997877799242, "of a feedforward": 0.002825995755598484, "even sometimes": 0.001157470080128191, "a neural net": 0.0034193101603446, "accomplished by": 0.0005619164728262171, "to node": 0.0005830336660574013, "complex since": 0.0010397031738864368, "some key limitations": 0.001412997877799242, "only": -0.006237161000740039, "explicitly": 6.723461204006894e-05, "behavior based layer": 0.002825995755598484, "a particular": 0.0004455206433557007, "the sensor model": 0.001412997877799242, "developed": -4.900785336495523e-05, "1 in": 0.00017730541639972633, "the specularities become": 0.001412997877799242, "weakness of": 0.0007246032270542877, "a discrete": 0.0014756175129776534, "output labels": 0.0013439565011394887, "observation this": 0.001157470080128191, "in state s": 0.0008527436549416518, "can finder": 0.0013439565011394887, "fairly smooth we": 0.001412997877799242, "we adopt": 0.0005565583063253017, "reactive behaviors and": 0.001412997877799242, "the missing": 0.0006428774807200497, "leading to an": 0.0009126929338602609, "and rotating the": 0.0012953547128852297, "learning autonomous": 0.0012263127867333846, "the use": 0.00017254731884060195, "illustrates the navigation": 0.001412997877799242, "blanco l moreno": 0.001412997877799242, "are difficult to": 0.000730869328480087, "this solution": 0.0005583269585823748, "and deposit it": 0.001412997877799242, "with the virtual": 0.0010826007236946758, "input to a": 0.00080838360373212, "to new circumstances": 0.001412997877799242, "estimating the": 0.0005243498648614615, "opening undefined": 0.0013439565011394887, "learning robots": 0.0013439565011394887, "estimation and refer": 0.001412997877799242, "unobservable to": 0.0013439565011394887, "a color": 0.0007541286032508272, "classes using": 0.0009217509760058083, "used in state": 0.0012953547128852297, "height and shape": 0.001412997877799242, "comparing multi output": 0.001412997877799242, "robot s": 0.0019414741929052945, "robots 15 inputs": 0.001412997877799242, "of the 380": 0.001412997877799242, "correctly predicts the": 0.0012953547128852297, "1 doing the": 0.001412997877799242, "images and the": 0.0009419732139289226, "representation can": 0.0008433654142724929, "predicted": 0.0002903741227944372, "by selecting": 0.000595682008283464, "sonar": 0.004737541871705305, "trajectories of": 0.0008183105262917859, "programming burden": 0.0012263127867333846, "robot called": 0.0026879130022789775, "for solving": 0.0007565237996256105, "n khaleeli 2": 0.002825995755598484, "maps by using": 0.001412997877799242, "reveals": 0.0003713023833232557, "fairly reliable observations": 0.001412997877799242, "a sonar": 0.0013439565011394887, "physically": 0.00042346355282140487, "well studied topic": 0.001177670521728601, "succeeded despite significant": 0.001412997877799242, "the object such": 0.001412997877799242, "here is": 0.0009703498493418982, "recycling task the": 0.001412997877799242, "itself acquire new": 0.001412997877799242, "here in": 0.0006023554586211942, "a run on": 0.001177670521728601, "can represent": 0.0006457442730738455, "decision processes pomdp": 0.001412997877799242, "also show that": 0.0005943328552515203, "g on": 0.000631851774969883, "framework of": 0.0005349948063638271, "features in the": 0.0008347439643413854, "navigating mobile robots": 0.001412997877799242, "pavlov a nomad": 0.001412997877799242, "all training": 0.0009528025610969587, "distribution now serves": 0.001412997877799242, "helps speed": 0.0012263127867333846, "detect": 0.0006345903453140295, "occupancy grid and": 0.001412997877799242, "inputs to": 0.0005913666291750407, "ways": 3.950670924022602e-05, "subsequent": 0.0002921095358884243, "learn multiple categories": 0.001412997877799242, "definite": 0.000354352372432295, "trained on": 0.002454931578875358, "of different paradigms": 0.001412997877799242, "instances of": 0.0004200683230017812, "the sonars": 0.0013439565011394887, "3": 0, "it difficult": 0.0014402690729952842, "between": -0.0006000015666811451, "on those": 0.000631851774969883, "artificial neural network": 0.001177670521728601, "corridors": 0.001039526833456673, "9 c": 0.0015420279190796371, "9 a": 0.00048696509187993325, "9 f": 0.0010397031738864368, "of the different": 0.0006439371750110811, "9 e": 0.0009528025610969587, "on partially": 0.0012263127867333846, "task we study": 0.001412997877799242, "uses a discrete": 0.001177670521728601, "that we are": 0.0005264202030821872, "trash can left": 0.001412997877799242, "5 this idea": 0.001412997877799242, "b introduction programming": 0.001412997877799242, "is located": 0.0006116575347696522, "undefined these observations": 0.001412997877799242, "accelerating sensory": 0.0026879130022789775, "finding trash cans": 0.001412997877799242, "it could be": 0.0006868803310078682, "infra red": 0.0010397031738864368, "noisy sensing": 0.0013439565011394887, "pixels": 0.0012809734741195233, "not directly": 0.0005693146787156503, "21 this": 0.0007964395063592673, "as a result": 0.00038985609335619073, "information is": 0.00034945266426170216, "strategies for speeding": 0.001412997877799242, "approaches on": 0.001013492172364257, "a somewhat": 0.0006546338046551141, "region": 0.0003269862291458115, "long training": 0.0012263127867333846, "of using": 0.00035757073401193715, "10 by contrast": 0.001412997877799242, "voronoi": 0.000724480329627718, "although somewhat tedious": 0.0012953547128852297, "sensor is": 0.0009707370964526472, "physically occupied": 0.0013439565011394887, "strategies provide": 0.0024526255734667692, "can net figure": 0.001412997877799242, "low occupancy": 0.0012263127867333846, "the case": 7.340368966166919e-05, "noticeably longer when": 0.001412997877799242, "near figure": 0.0013439565011394887, "camera sensors avoid": 0.001412997877799242, "doing the loop": 0.001412997877799242, "robot generates 4": 0.001412997877799242, "however a weakness": 0.001412997877799242, "training examples reinforcement": 0.001412997877799242, "updates scale": 0.0013439565011394887, "learning an office": 0.001412997877799242, "color": 0.002687169379051111, "robotics": 0.003743417895782067, "an introduction": 0.0005101280194599199, "period": 0.0004565876736709466, "sampling": 0.0003122119325467533, "or the output": 0.0011087956007827721, "data the paper": 0.001177670521728601, "knowledge based": 0.0007291894113705743, "dimensional sensor represen": 0.001412997877799242, "learning": 0.02800687922935171, "running the": 0.001526290840472636, "uncertainty to determine": 0.0012953547128852297, "are being investigated": 0.0012953547128852297, "are used": 0.00015741929968402822, "nets vs": 0.0013439565011394887, "sensors that can": 0.001412997877799242, "different paradigms mobile": 0.001412997877799242, "receptacles are": 0.0013439565011394887, "spatial regularity of": 0.001412997877799242, "execution system used": 0.001412997877799242, "in each": 0.00048595904266948524, "four separate": 0.0010397031738864368, "the front": 0.00066081832163666, "navigation is": 0.0021413858555226176, "knowledge or": 0.0009528025610969587, "a common": 0.0003191248780767641, "to sufficiently constrain": 0.001412997877799242, "declarative structure logical": 0.001412997877799242, "openings these observations": 0.001412997877799242, "generalization over": 0.0012263127867333846, "12 sample": 0.001157470080128191, "direction": 0.0002356746627304324, "forward is": 0.0011086075099259812, "be trained": 0.0037462915795534353, "despite noisy": 0.0013439565011394887, "has clearly demonstrated": 0.0012953547128852297, "we identified": 0.0008107079716898269, "b2 pose": 0.0013439565011394887, "commands": 0.0009689519017030133, "data a few": 0.001412997877799242, "despite noisy sensing": 0.001412997877799242, "the second task": 0.002079759148306938, "js for": 0.0012263127867333846, "16 show several": 0.001412997877799242, "relatively rapid": 0.0012263127867333846, "two example": 0.0010397031738864368, "sonars in both": 0.001412997877799242, "12 sample images": 0.001412997877799242, "flexible navigation": 0.0013439565011394887, "0 of": 0.0008505833977144572, "case": -0.001936904251918412, "hidden layer output": 0.0012953547128852297, "thus if": 0.00044183835550954694, "to induce features": 0.001412997877799242, "human teacher for": 0.001412997877799242, "use of hypotheses": 0.001412997877799242, "these": -0.00932276399697858, "transformed into": 0.0005074090681964598, "inside the laboratory": 0.001412997877799242, "acquire useful sensory": 0.001412997877799242, "on by q": 0.001412997877799242, "an event based": 0.001177670521728601, "cans could be": 0.001412997877799242, "the robot was": 0.001412997877799242, "4 experimental": 0.0006457442730738455, "14 shows": 0.0007488464497674484, "navigation system": 0.006719782505697444, "a comparison of": 0.0005274188769285046, "combined with": 0.000394283096389793, "few hundred at": 0.001412997877799242, "theocharous n khaleeli20601001401800": 0.001412997877799242, "model however": 0.0007338995299089556, "orientation": 0.0003957356500215619, "errors the": 0.0006807892368766817, "south florida": 0.0012263127867333846, "valued inputs the": 0.001412997877799242, "south corridor": 0.0013439565011394887, "we use two": 0.0008291394238884059, "fact in a": 0.001177670521728601, "l boada d": 0.001412997877799242, "to light": 0.0009528025610969587, "label estimating the": 0.001412997877799242, "distance and": 0.0006807892368766817, "bias": 0.007378960059185613, "smarter and": 0.0013439565011394887, "features effects": 0.0013439565011394887, "training instances of": 0.001412997877799242, "planning layer": 0.0013439565011394887, "which is decomposed": 0.001412997877799242, "net based approaches": 0.0012953547128852297, "et al 12": 0.0008133430731188866, "observations output by": 0.001412997877799242, "the results presented": 0.000684465666466304, "examples through exploration": 0.001412997877799242, "shows that even": 0.0010057508064281846, "coarsely": 0.0008181717354969602, "the supervised neural": 0.001412997877799242, "figure 16 show": 0.001412997877799242, "probability with": 0.0008837126637559662, "in service robot": 0.001412997877799242, "fast vision": 0.0013439565011394887, "f in": 0.0004486675246498633, "images the": 0.0006576990239911289, "hidden units right": 0.001412997877799242, "or on the": 0.0008184493641822325, "g on the": 0.0008956300062288188, "or because they": 0.0011397700534482, "or bias": 0.0011086075099259812, "n khaleeli generally": 0.001412997877799242, "is improved by": 0.0009126929338602609, "on perceived": 0.0013439565011394887, "investigated": 0.0009435749771270569, "and shape": 0.0007246032270542877, "from a local": 0.0012265208479459286, "it performed better": 0.001412997877799242, "that in the": 0.0004139335641321289, "our case the": 0.0008184493641822325, "several months on": 0.001412997877799242, "input size": 0.0007832601051609397, "track the": 0.0006807892368766817, "c2 trace": 0.0013439565011394887, "sensor model": 0.0012263127867333846, "is one": 0.000487491045939948, "investigates": 0.0005789087042364873, "further processing": 0.000872702844207972, "range 1": 0.0007832601051609397, "as alvinn 22": 0.001412997877799242, "occur when": 0.0005850811540016608, "approximately the": 0.0006092863925155239, "feedforward neural": 0.0029723367213096174, "navigation induction": 0.0013439565011394887, "relies": 0.0002903741227944372, "navigation to lab": 0.005651991511196968, "approach described": 0.0006993597717998856, "we show": 0.0003288890779264134, "we begin by": 0.0005675330367269512, "structures the": 0.0006576990239911289, "hypothesis space": 0.0029723367213096174, "months on": 0.0010706929277613088, "observable from": 0.0021413858555226176, "preclassified": 0.0012261047960979141, "to acknowledge the": 0.0008527436549416518, "trash can from": 0.002825995755598484, "features figure 7": 0.0012953547128852297, "accuracy of 85": 0.0012953547128852297, "time model": 0.0008107079716898269, "nomad 200 real": 0.001412997877799242, "filled in": 0.0007710139595398186, "components": -5.899951846237371e-06, "more readily": 0.0009365728948883588, "well as some": 0.0008658836593557804, "q i and": 0.0008728509105201892, "model": -0.001948798728728516, "area of": 0.00042441161427938937, "researchers": 0.0002659880794681955, "overall control architec": 0.001412997877799242, "in addition": 0.00029865934641717365, "the controller 2": 0.001412997877799242, "data reveals": 0.0013439565011394887, "it feasible": 0.0009365728948883588, "on the left": 0.0010691289231866217, "approach taken in": 0.0009316462484985891, "using hidden": 0.0009707370964526472, "guided": 0.00042699115803984113, "front and": 0.0009365728948883588, "actions": 0.0005268348134180892, "pomdp s the": 0.001412997877799242, "the two general": 0.001412997877799242, "trash cans a": 0.001412997877799242, "issue on learning": 0.0012953547128852297, "the local": 0.0003239963638342778, "observation door opening": 0.001412997877799242, "by the sensory": 0.001412997877799242, "of digital image": 0.0010599041887614004, "is necessary": 0.0005705165174893305, "i and s": 0.000794306715118076, "in the case": 0.0002820746076939343, "speed": 0.0007767737026984677, "g near": 0.0011086075099259812, "engineering department": 0.0031191095216593105, "feedforward": 0.002454515206490881, "sampled": 0.0004165894486024949, "how to detect": 0.0022175912015655443, "of the": 0.0, "to wheel": 0.0013439565011394887, "out on": 0.0006879834963441684, "is a multi": 0.0009316462484985891, "such a decomposition": 0.0010057508064281846, "seems": 0.00022412208439850454, "except": -2.709620411921097e-05, "substantially larger than": 0.0011087956007827721, "improvement": 0.00010715818524379625, "invariances": 0.0019052819191541965, "robot eventually": 0.0013439565011394887, "e g prefer": 0.001412997877799242, "very high dimensional": 0.003533011565185803, "demonstrated that": 0.000600103348117393, "we believe many": 0.0012953547128852297, "2 1 pavlov": 0.001412997877799242, "actions we": 0.0008262639069617736, "3 the": 0.00010528111952220413, "real": -0.0009534918531212892, "learning curve": 0.0025870708126622833, "directly observable": 0.0020794063477728737, "framework to": 0.0006372791512719589, "rules": 0.0002956482010662856, "robot must": 0.0010706929277613088, "given the": 0.0005269241831913578, "trash cans or": 0.001412997877799242, "camera invariances": 0.0013439565011394887, "reasons we adopt": 0.001412997877799242, "concepts although": 0.0013439565011394887, "patterns was": 0.0011086075099259812, "using": -0.02503382424946468, "in the": 0.0, "execution": 0.00015607035316611708, "pavlov a real": 0.001412997877799242, "create hard coded": 0.001412997877799242, "their work is": 0.0010826007236946758, "far fewer": 0.0009365728948883588, "symbolic place": 0.0013439565011394887, "v i f": 0.001412997877799242, "of weights": 0.0007201345364976421, "network based": 0.0007770287888915143, "such cases": 0.0005446340152121855, "is recycling where": 0.001412997877799242, "net produces a": 0.001412997877799242, "of such": 0.000201109018260828, "started at": 0.0007770287888915143, "of a particular": 0.00057516526655311, "setup used": 0.0010706929277613088, "patterns the neural": 0.001412997877799242, "a pose a1": 0.001412997877799242, "moreno": 0.0009526409595770983, "t": 0, "right front far": 0.001412997877799242, "representation and simultaneous": 0.001412997877799242, "output": 0.000621162439508049, "general in fact": 0.0012953547128852297, "a similar": 0.00020629377478409945, "a robust layered": 0.001412997877799242, "feature based": 0.0007770287888915143, "not explicitly represented": 0.0012265208479459286, "over the entire": 0.0007102523865098931, "this paper": 0.0002141720091113219, "how to": 0.00040841927264837754, "f are": 0.0005101280194599199, "abstract observation is": 0.001412997877799242, "of its": 0.00028221125533479366, "robot platform section": 0.001412997877799242, "till it": 0.0011086075099259812, "domain the number": 0.001412997877799242, "salganicoff": 0.0009906108645477269, "can is not": 0.001412997877799242, "on a probabilistic": 0.001177670521728601, "many different approaches": 0.0012953547128852297, "our approach and": 0.0008801129633255439, "functions for": 0.000451668842582774, "original function front": 0.001412997877799242, "provided": -0.00030801786534949465, "that sensor i": 0.001412997877799242, "a standardized": 0.0010397031738864368, "a distinguished": 0.0006993597717998856, "as any": 0.000634544764829945, "features for": 0.0006516207816749321, "high dimensional in": 0.001412997877799242, "algorithm local": 0.0011086075099259812, "it is easy": 0.00034626618112701066, "10 feature": 0.0013439565011394887, "more thing": 0.0013439565011394887, "south corridor or": 0.001412997877799242, "4 training patterns": 0.001412997877799242, "processes learning concepts": 0.001412997877799242, "provides": -0.00015400893267474732, "and learning": 0.0014976928995348968, "cases the camera": 0.001412997877799242, "focus of this": 0.0007855213434982123, "solving the task": 0.0012953547128852297, "ryan for her": 0.001412997877799242, "detectors and recognizers": 0.001412997877799242, "support of the": 0.000757870016081158, "right simultaneously": 0.0013439565011394887, "sensory state helps": 0.001412997877799242, "net can generate": 0.001412997877799242, "sources for details": 0.001412997877799242, "because the": 0.00016352084877385115, "3 4 5": 0.001303462676611376, "curve for the": 0.0009219073640234544, "processing phase to": 0.0012953547128852297, "discusses some related": 0.0012953547128852297, "office navigating": 0.0013439565011394887, "robots 3": 0.0012263127867333846, "we adopt the": 0.000777160622754577, "instructed more": 0.0013439565011394887, "a policy": 0.0007595764743381157, "of data with": 0.0011397700534482, "images were labeled": 0.001412997877799242, "quadrants of": 0.0010397031738864368, "is in position": 0.0012265208479459286, "comparison": -3.937319241952307e-05, "ring two sets": 0.001412997877799242, "engineering building was": 0.001412997877799242, "this updated": 0.0013439565011394887, "make recognition": 0.0013439565011394887, "country experiment the": 0.001412997877799242, "of": 0, "majority of the": 0.0006728658761679748, "the other behaviors": 0.001412997877799242, "attributes of the": 0.0008184493641822325, "aggregate of the": 0.0012953547128852297, "as reinforcement learning": 0.0012953547128852297, "estimator": 0.0004993960276740909, "supervised": 0.002698299315797025, "robots 5": 0.0013439565011394887, "on scaling rotation": 0.001412997877799242, "intensity which are": 0.001412997877799242, "a set of": 0.00042557211638123916, "bias to": 0.003212078783283926, "discusses": 0.0005217436818140755, "coded to facilitate": 0.001412997877799242, "or": -0.02329599112586037, "details here the": 0.0012265208479459286, "realistic tasks": 0.0012263127867333846, "khaleeli to": 0.0013439565011394887, "where examples": 0.0013439565011394887, "communication": 8.115506158803497e-05, "some recent": 0.0007832601051609397, "18 the robot": 0.001412997877799242, "g in our": 0.0012265208479459286, "use an": 0.0004427995236991089, "a mobile": 0.0006807892368766817, "learning with": 0.0006843495569384895, "architecture for recycling": 0.001412997877799242, "optimal values 2": 0.001412997877799242, "determine": -9.588090384159774e-05, "approximator in the": 0.0012953547128852297, "below two ways": 0.001412997877799242, "reactive behaviors": 0.0012263127867333846, "and recy cling": 0.001412997877799242, "a recycling": 0.0013439565011394887, "florida computer": 0.0013439565011394887, "hue saturation": 0.0013439565011394887, "six boolean variables": 0.002825995755598484, "occupancy information is": 0.001412997877799242, "more invariant": 0.0013439565011394887, "an image": 0.0005185303358808077, "area": 9.058386803430425e-05, "distance and orientation": 0.001412997877799242, "have spatial regularity": 0.001412997877799242, "there": -0.0027369339471861568, "it easy": 0.0007033220515237973, "primarily on the": 0.001039879574153469, "previous work on": 0.0006918115785384662, "learning vs": 0.0013439565011394887, "strict": 0.0002980865210682648, "out of the": 0.0005093037082612842, "apparent that": 0.0007115262727613508, "typically data collection": 0.001412997877799242, "low": 4.424768671013886e-06, "image of": 0.0005060642343450019, "reflections occur": 0.0013439565011394887, "turn behavior": 0.0026879130022789775, "actuator": 0.0026176644843653295, "learning 6 related": 0.001412997877799242, "many circumstances": 0.0009907789071032058, "assumes": 0.00036225547930639803, "sensor representation": 0.0026879130022789775, "machine learning are": 0.001412997877799242, "sensor and undergo": 0.001412997877799242, "large burden": 0.0013439565011394887, "occupancy information": 0.0012263127867333846, "is located adjacent": 0.0012953547128852297, "39 n 2": 0.0010057508064281846, "but it is": 0.0005039295150658069, "fundamentals": 0.0005564639104117459, "and recognizers": 0.0013439565011394887, "from limited": 0.0022172150198519623, "starting position": 0.0018435019520116167, "or undefined the": 0.001412997877799242, "procedure is": 0.0008233069596953609, "to find and": 0.001021962604845781, "shared structure this": 0.001412997877799242, "normalization constant": 0.0009707370964526472, "we study is": 0.001177670521728601, "situations for these": 0.001412997877799242, "2 by describing": 0.0012953547128852297, "region the idea": 0.001412997877799242, "the sensor": 0.004738345525966832, "comparing multi": 0.0013439565011394887, "1024": 0.0004820994576323383, "top bottom each": 0.001412997877799242, "err very": 0.0013439565011394887, "speed up": 0.0010342068612970861, "7 shows the": 0.0006662557885853236, "human provided": 0.0013439565011394887, "not defined": 0.0007488464497674484, "finder a single": 0.001412997877799242, "illustrates the": 0.0012251496968496824, "going to be": 0.0008801129633255439, "far on": 0.0011086075099259812, "the sonars in": 0.001412997877799242, "camera sensors": 0.0013439565011394887, "paper see 17": 0.001412997877799242, "shows the neural": 0.002825995755598484, "each case the": 0.0007438462992263857, "new circumstances": 0.0013439565011394887, "turret turn": 0.0013439565011394887, "that it had": 0.0010826007236946758, "concept1 concept2": 0.0013439565011394887, "space gray": 0.0013439565011394887, "sensor data a": 0.001412997877799242, "dangerous": 0.0006842334867965392, "before it": 0.0005171034306485431, "to move to": 0.0009219073640234544, "robot testbed followed": 0.001412997877799242, "describe": -0.00023181153940645544, "to be able": 0.0004987046829938479, "1200": 0.0006515102625464255, "and infra red": 0.0012265208479459286, "features in": 0.0018568963005325832, "where much": 0.0013439565011394887, "the robot over": 0.001412997877799242, "part by": 0.00038684771632577214, "teacher to find": 0.001412997877799242, "necessary to realize": 0.0012953547128852297, "of this approach": 0.0011276674042051049, "image generates": 0.0013439565011394887, "in our": 0.000735076244078637, "learning with trash": 0.001412997877799242, "symbolic place recognition": 0.001412997877799242, "were prone": 0.0013439565011394887, "and execution": 0.0012531699655371105, "vs one multi": 0.001412997877799242, "converge it performed": 0.001412997877799242, "and find trash": 0.001412997877799242, "a percept": 0.0013439565011394887, "c shows some": 0.001412997877799242, "an entire": 0.0011701623080033216, "4 1 learning": 0.0012953547128852297, "5": -0.011034943164881227, "v 39 n": 0.0006439371750110811, "it stopped": 0.0013439565011394887, "has already": 0.000458857097148134, "wheel slippage uneven": 0.001412997877799242, "task 4 2": 0.001412997877799242, "task 4 1": 0.001412997877799242, "trash": 0.03238979262562134, "post scale": 0.0026879130022789775, "of labeled data": 0.001412997877799242, "many interesting concepts": 0.001412997877799242, "lab at four": 0.001412997877799242, "the two strategies": 0.0011087956007827721, "c note that": 0.0007988727145907639, "separate": 0.00019176180768319554, "speed up learning": 0.002825995755598484, "to numerous specular": 0.001412997877799242, "robot this": 0.0012263127867333846, "intersec tions": 0.0012263127867333846, "subsequently describe": 0.0013439565011394887, "this is facilitated": 0.0012953547128852297, "into 400": 0.0013439565011394887, "of the sonars": 0.001412997877799242, "different approaches to": 0.0017912600124576376, "and succeeded despite": 0.001412997877799242, "for example new": 0.001177670521728601, "board camera of": 0.001412997877799242, "18 the": 0.0005429920482072152, "2 learning to": 0.001412997877799242, "observations output": 0.0013439565011394887, "were 1": 0.0009217509760058083, "real robot": 0.007357876720400307, "often also": 0.001013492172364257, "building": 0.0004685517779329479, "learning depends on": 0.001412997877799242, "85 of the": 0.0010826007236946758, "front far very": 0.001412997877799242, "ditions": 0.000852454393186244, "given by": 0.00019065193695482562, "each state and": 0.0010826007236946758, "the experiments were": 0.0008184493641822325, "as doors": 0.0026879130022789775, "curve": 0.0010401151420425887, "virtual sensors that": 0.001412997877799242, "many of": 0.0003416245722115272, "grasping to": 0.0013439565011394887, "generates 4": 0.0013439565011394887, "directions for": 0.0005637380560122889, "six boolean": 0.0026879130022789775, "be easily combined": 0.0012953547128852297, "alvinn": 0.005529567846222089, "most well studied": 0.001412997877799242, "c left": 0.0012263127867333846, "is organized": 0.0002695015745406249, "all": -0.006130523980489571, "above is huge": 0.001412997877799242, "173 197 february": 0.001412997877799242, "output layer input": 0.0012953547128852297, "are examples": 0.0006807892368766817, "is provided": 0.00047983361412572704, "use a multi": 0.001177670521728601, "navigation task and": 0.001412997877799242, "speed convergence here": 0.001412997877799242, "sensory learning": 0.0013439565011394887, "2 1": 0.00011785887343127918, "2 0": 0.00034044447360242054, "scalar": 0.00028015133586510534, "2 2": 0.00014110562766739683, "valued inputs": 0.0013439565011394887, "2 4": 0.00023516443784900602, "or right": 0.0007157773884946746, "or right and": 0.001412997877799242, "i and": 0.0003425780983811395, "both updates": 0.0012263127867333846, "our case": 0.0004894029300213453, "detectors one": 0.0013439565011394887, "approach similar": 0.0008525989995294478, "synthetic": 0.00042346355282140487, "far on the": 0.0012953547128852297, "decomposing the sensory": 0.001412997877799242, "involves several": 0.0011086075099259812, "occupied region": 0.0012263127867333846, "of the features": 0.0007731269361814234, "defined as": 0.0002059454548455772, "back quadrants": 0.0013439565011394887, "importance to": 0.0007897242543278053, "the robot till": 0.001412997877799242, "then y": 0.0006843495569384895, "program": 2.0654128112283713e-05, "need to learn": 0.0012265208479459286, "322 leading to": 0.001412997877799242, "autonomous driving is": 0.001412997877799242, "ability to": 0.00034520304794030795, "two tasks": 0.002187568234111723, "nodes": 7.133392804356537e-05, "provides the": 0.0007900830778589017, "presentation": 0.0004611053429889289, "see 5 6": 0.0011397700534482, "network were pre": 0.001412997877799242, "2 a": 0.00018440228435403458, "studied here": 0.0008433654142724929, "is complementary": 0.001013492172364257, "uncer tainty which": 0.001412997877799242, "locating and": 0.0010706929277613088, "among the main": 0.0012953547128852297, "carried out on": 0.0008291394238884059, "very": -0.0036726563670396568, "yellow color": 0.001157470080128191, "useful sensory concepts": 0.001412997877799242, "map the": 0.0005810090920244843, "pragmatic approach": 0.0010706929277613088, "induce": 0.00044958658351803546, "and s": 0.00029376796618315205, "2 q": 0.0005978790985189038, "2 p": 0.00017444297474042872, "our environment": 0.0019815578142064116, "using batch update": 0.001412997877799242, "processed selected pixels": 0.001412997877799242, "a successful": 0.0006400562598342001, "camera invariances based": 0.001412997877799242, "results for the": 0.0009906004054300456, "or wall": 0.0012263127867333846, "attributes of": 0.000631851774969883, "advantages of": 0.0004496628492658757, "operate in unstructured": 0.001412997877799242, "over the": 0.0001535038862848227, "net symbolic": 0.0013439565011394887, "every human": 0.0013439565011394887, "action a is": 0.0010826007236946758, "smooth flat surface": 0.001412997877799242, "work in that": 0.0010826007236946758, "partitioned we believe": 0.001412997877799242, "high dimensional e": 0.0012953547128852297, "features that": 0.0006214693208023149, "the image": 0.00045471705861272453, "neural net architecture": 0.001412997877799242, "to realize": 0.000634544764829945, "neural net the": 0.001412997877799242, "idea is simple": 0.0011397700534482, "this research": 0.0012653830748193594, "is facing": 0.001157470080128191, "4 behavior": 0.001157470080128191, "based studies": 0.0011086075099259812, "that the strategies": 0.0012953547128852297, "learns only": 0.0013439565011394887, "of some sort": 0.0011397700534482, "the experimental findings": 0.001412997877799242, "make an": 0.0006772995603809331, "whereas in our": 0.001039879574153469, "of the control": 0.0006968853899317012, "placed in": 0.0010399364990605153, "discusses the": 0.0005712121849001653, "their effectiveness in": 0.0010826007236946758, "award grant no": 0.001412997877799242, "problem where the": 0.00080838360373212, "sensors predict the": 0.001412997877799242, "sub": 0.0002362312843265813, "and preference bias": 0.001412997877799242, "and b": 0.00040084815893939857, "can report on": 0.001412997877799242, "output net is": 0.001412997877799242, "explaining the use": 0.001412997877799242, "and very": 0.0007033220515237973, "set of data": 0.0007372369477455303, "observation data generated": 0.001412997877799242, "computed using a": 0.0008658836593557804, "scale this updated": 0.001412997877799242, "an approximator we": 0.001412997877799242, "coded to make": 0.001412997877799242, "learned": 0.002171197805090014, "specifies most": 0.0013439565011394887, "loop 3 4": 0.0012953547128852297, "less than": 0.00017698622647816762, "which combines": 0.0008346023623118109, "alvinn system 22": 0.001412997877799242, "decision process models": 0.002825995755598484, "irregularities in this": 0.001412997877799242, "acceptable range 1": 0.001412997877799242, "region the": 0.0006457442730738455, "recognize landmarks": 0.0013439565011394887, "can but": 0.0026879130022789775, "a more": 0.0001601530439294987, "that it can": 0.0005463834612792816, "object is": 0.0005334361147210187, "l moreno": 0.0013439565011394887, "current sensor values": 0.001412997877799242, "directions": 0.0005053353831791451, "aligment": 0.0011084194828720588, "representation original function": 0.001412997877799242, "pixels from": 0.001013492172364257, "observation ff": 0.0013439565011394887, "learn subfunctions for": 0.001412997877799242, "robot starting": 0.0026879130022789775, "despite the high": 0.001412997877799242, "robotics is an": 0.002825995755598484, "colored": 0.002133382561927005, "steering to synthesize": 0.001412997877799242, "into black and": 0.0012953547128852297, "on learning autonomous": 0.001412997877799242, "allows": -9.322684143186135e-05, "run with observations": 0.001412997877799242, "running the robot": 0.004238993633397726, "the task of": 0.001130116976060881, "problems we": 0.0004994807428611434, "amount": 2.9497528344418652e-06, "recy": 0.0012261047960979141, "illustrated in figure": 0.001020429139706898, "detect trash cans": 0.001412997877799242, "sequence of sensor": 0.001412997877799242, "state s": 0.0005830336660574013, "the robot as": 0.002825995755598484, "sensors are independent": 0.0012953547128852297, "learning multiple": 0.0020794063477728737, "trainer": 0.0011084194828720588, "towards trash cans": 0.001412997877799242, "6 9 16": 0.0012953547128852297, "and based": 0.0008107079716898269, "form of bias": 0.0012953547128852297, "exists that the": 0.001412997877799242, "from limited training": 0.002825995755598484, "to be dependent": 0.0009909470066802508, "data with": 0.0006092863925155239, "these tasks are": 0.001039879574153469, "the occupancy": 0.002026984344728514, "architecture combining a": 0.001412997877799242, "millions of": 0.0007595764743381157, "thru door by": 0.001412997877799242, "of the order": 0.0006537346506207054, "use and their": 0.0012265208479459286, "for much": 0.0007710139595398186, "trained": 0.006853383643120367, "bias studied in": 0.001412997877799242, "robot lab18 y": 0.001412997877799242, "of sensor values": 0.0012953547128852297, "places a": 0.0008346023623118109, "features from the": 0.0009909470066802508, "cans learning": 0.0013439565011394887, "n khaleeli20601001401800": 0.0013439565011394887, "robot figure": 0.0013439565011394887, "takes": -9.901981294481073e-05, "robotics the": 0.0012263127867333846, "probabilities": 0.000300053763988856, "percepts in": 0.0013439565011394887, "is simple partition": 0.001412997877799242, "easy although somewhat": 0.001412997877799242, "the figure": 0.0007373367230707292, "images front": 0.0013439565011394887, "are two advantages": 0.0012265208479459286, "topic 1 however": 0.001412997877799242, "a relational learning": 0.001412997877799242, "will mainly": 0.0009707370964526472, "net trained to": 0.001412997877799242, "taken": -4.100241816959356e-05, "arguable that in": 0.001412997877799242, "studied form of": 0.0012265208479459286, "to lab position": 0.007064989388996209, "more readily than": 0.0012953547128852297, "earlier alvinn": 0.0013439565011394887, "100x100 color images": 0.001412997877799242, "four possibilities door": 0.001412997877799242, "flat": 0.00042877863325190105, "recognition easier here": 0.001412997877799242, "they require": 0.0006400562598342001, "grids generated over": 0.001412997877799242, "geometric attributes of": 0.0012953547128852297, "the six boolean": 0.001412997877799242, "is much more": 0.0006207360845490545, "computed by integrating": 0.0012265208479459286, "move to": 0.0006240088185900783, "be an active": 0.0012265208479459286, "updates scale is": 0.001412997877799242, "process that": 0.0005318904522356488, "by q i": 0.0010826007236946758, "known": -0.0006848815105064199, "and execution system": 0.001412997877799242, "paper assumes that": 0.0012265208479459286, "real valued input": 0.001412997877799242, "net can robustly": 0.001412997877799242, "the first": 8.751228358246633e-05, "undefined an abstract": 0.001412997877799242, "a somewhat large": 0.001412997877799242, "can opening in": 0.001412997877799242, "huge of": 0.0013439565011394887, "are decision": 0.001013492172364257, "multi class label": 0.001412997877799242, "summary this paper": 0.001039879574153469, "r navigating mobile": 0.001412997877799242, "a c b": 0.0009039491294179812, "navigation despite": 0.0013439565011394887, "grids free": 0.0013439565011394887, "b c": 0.000346408871480994, "neural net feature": 0.005651991511196968, "b d": 0.0005601128957225589, "v": -0.0014052886618045022, "also subservient behaviors": 0.001412997877799242, "learn new concepts": 0.001412997877799242, "testing the neural": 0.001412997877799242, "b l": 0.0006879834963441684, "history": 0.00028015133586510534, "here the original": 0.0011397700534482, "called partially observable": 0.001412997877799242, "challenging": 0.0011872069500646857, "be programmed": 0.0008525989995294478, "commands action": 0.0013439565011394887, "interesting concepts that": 0.001412997877799242, "can which is": 0.0012265208479459286, "instance based methods": 0.0012265208479459286, "ultrasound sonar and": 0.001412997877799242, "figure 7 shows": 0.0006241146904629305, "been encouraging 7": 0.001412997877799242, "symbolic learning": 0.0012263127867333846, "similarly a": 0.0006546338046551141, "to map sensory": 0.001412997877799242, "underlying state": 0.001157470080128191, "of learning": 0.0019919810494485797, "again spatial decomposition": 0.001412997877799242, "control structure": 0.0008433654142724929, "be exploited to": 0.0016694879286827708, "that high dimensional": 0.001412997877799242, "term robots": 0.0013439565011394887, "extremely challenging problem": 0.002825995755598484, "into a few": 0.0011397700534482, "goal": 1.919336665537463e-05, "that robots need": 0.001412997877799242, "a run": 0.0005830336660574013, "rather": -0.00016126991069032387, "errors 14": 0.0012263127867333846, "both sensor": 0.0013439565011394887, "perceive features in": 0.001412997877799242, "pavlov a": 0.0026879130022789775, "in robotics is": 0.002825995755598484, "as opposed": 0.0004506632696548802, "the original sensory": 0.002825995755598484, "some key": 0.0008954780757782285, "speeding": 0.0006091830535751379, "trees for": 0.0006457442730738455, "a pre specified": 0.0010599041887614004, "onboard the": 0.0012263127867333846, "if it is": 0.00035531047509135066, "lab position": 0.006719782505697444, "training robot learning": 0.001412997877799242, "tried": 0.00035310202227246875, "from the 100x100": 0.001412997877799242, "in position c": 0.0012953547128852297, "have attempted a": 0.001412997877799242, "multi category learning": 0.001412997877799242, "was only": 0.0006954851132481282, "and right": 0.0010342068612970861, "to represent temporally": 0.001412997877799242, "of sensory": 0.0022172150198519623, "in position d": 0.0012953547128852297, "reflect": 0.0002783370076962827, "as follows": 6.647945358814172e-05, "called grdt": 0.0013439565011394887, "ff": 0.0008183863320581576, "features as": 0.0007246032270542877, "camera image": 0.001157470080128191, "by additional": 0.001816222333717977, "second form": 0.0010397031738864368, "a": 0, "reasoning and prediction": 0.001412997877799242, "discrete bayesian": 0.0013439565011394887, "short": 9.375675421726982e-05, "learning we": 0.0008525989995294478, "weights figure": 0.0010397031738864368, "further work section": 0.001412997877799242, "good example of": 0.0010057508064281846, "a priori knowledge": 0.0008184493641822325, "be exploited": 0.0011166539171647495, "2 illustrates": 0.0006879834963441684, "vs training": 0.0011086075099259812, "for picking": 0.0009707370964526472, "net specular reflections": 0.001412997877799242, "hundred at": 0.0013439565011394887, "and proposes": 0.0009907789071032058, "by integrating": 0.0007488464497674484, "22 has": 0.0010706929277613088, "pavlov 1": 0.0013439565011394887, "under these": 0.0013153980479822579, "processed selected": 0.0013439565011394887, "output is": 0.0005413646011976051, "investigated ranging from": 0.001412997877799242, "using a wireless": 0.001412997877799242, "front left right": 0.001412997877799242, "pavlov the": 0.0026879130022789775, "taxonomy": 0.0005128000387594285, "rather than 1024": 0.001412997877799242, "with so little": 0.001412997877799242, "result the": 0.0004371016452995968, "simple partition the": 0.001412997877799242, "clearly has some": 0.001412997877799242, "ffl": 0.00015909132926037446, "reports from each": 0.001412997877799242, "facilitate recognition this": 0.001412997877799242, "range in the": 0.0009773255297405913, "the paper proposes": 0.0012953547128852297, "counterparts for": 0.0011086075099259812, "avenue": 0.0006000015666811451, "for sensory concept": 0.001412997877799242, "net a front": 0.001412997877799242, "items of trash": 0.001412997877799242, "labeled examples using": 0.0012265208479459286, "in voronoi based": 0.001412997877799242, "from the original": 0.0006364709769073721, "shown in": 0.00010016845233246175, "approach clearly has": 0.001412997877799242, "an nsf": 0.0008034263695325692, "for the purposes": 0.0013156212237623705, "training neural": 0.0012263127867333846, "robots a": 0.0034724102403845734, "solving": 0.00012834571856525545, "a weakness": 0.0008525989995294478, "and moving": 0.0009081111668589885, "of this solution": 0.0009419732139289226, "and mitchell": 0.0011086075099259812, "a door": 0.0011086075099259812, "the purposes": 0.0011580138151580422, "highly specular": 0.0013439565011394887, "systems": -0.0007775652722296478, "learning problem": 0.0016867308285449859, "dimensions is": 0.0008034263695325692, "the number of": 0.0007831976928344829, "cost in": 0.0005349948063638271, "tree based studies": 0.001412997877799242, "is a good": 0.0005872517174083484, "occupancy grids where": 0.001412997877799242, "concepts from": 0.0032732421051671436, "findings from the": 0.001412997877799242, "images were": 0.0015665202103218793, "100x100 images and": 0.001412997877799242, "theocharous n": 0.013439565011394887, "of trash e": 0.001412997877799242, "a few": 0.0006929101497429618, "for improvement": 0.0007897242543278053, "objects such": 0.0015304018681991007, "able to sufficiently": 0.001412997877799242, "framework": 6.100108736936347e-05, "from our": 0.0004466919402916898, "and recognizers we": 0.001412997877799242, "as kalman filters": 0.001412997877799242, "using model": 0.0008433654142724929, "robot temporarily loses": 0.001412997877799242, "robots to successfully": 0.001412997877799242, "purposes of this": 0.0015625810158805668, "results in": 0.0003058098441005076, "noisy the number": 0.001412997877799242, "trash can net": 0.001412997877799242, "and openings these": 0.001412997877799242, "25 mm faculty": 0.001412997877799242, "much of the": 0.0005662915604782974, "paper assumes": 0.0010706929277613088, "single yellow": 0.0013439565011394887, "the robot temporarily": 0.001412997877799242, "than 2 dimensional": 0.001412997877799242, "level": -0.0005195294194029286, "control architec ture": 0.001412997877799242, "into four overlapping": 0.001412997877799242, "capability": 0.000321763905170604, "the robot through": 0.001412997877799242, "recent neural net": 0.001412997877799242, "the approach": 0.0006681265576352905, "stopped": 0.0004893199240969862, "control strategy": 0.0009528025610969587, "s 2 s": 0.0007438462992263857, "examples the": 0.0011501353964593825, "accommodated": 0.0006575874739531386, "15 extended the": 0.001412997877799242, "were collected": 0.000872702844207972, "be learned from": 0.0010826007236946758, "of this": 0.00015058107395668306, "black and": 0.0007541286032508272, "state distribution": 0.0037462915795534353, "despite significant sensor": 0.001412997877799242, "simultaneously using": 0.0021413858555226176, "system the input": 0.001177670521728601, "improvement in": 0.00045990605238462056, "we thank lynn": 0.001412997877799242, "our work thrun": 0.001412997877799242, "either the input": 0.0012265208479459286, "nsf career award": 0.0009773255297405913, "for sensory": 0.0012263127867333846, "dimensions is s": 0.001412997877799242, "multi output err": 0.001412997877799242, "goal is": 0.00032509312695519076, "pavlov in": 0.0013439565011394887, "of the object": 0.0006328522719948063, "run which": 0.0010397031738864368, "navigation run which": 0.001412997877799242, "beyond": 0.00015799833853543817, "studied topic": 0.0011086075099259812, "event": 0.0005788542906583335, "a further": 0.0005047289660579865, "some directions": 0.0009528025610969587, "net the neural": 0.001412997877799242, "output nets": 0.0013439565011394887, "percepts": 0.0011084194828720588, "multi output learning": 0.001412997877799242, "we do": 0.00018701963790433078, "discrete": 0.0006044581382334053, "d the": 0.00036337447101637035, "navigational": 0.0008725548281217766, "since": -0.0030935993643335293, "problem the purpose": 0.0012953547128852297, "find a sufficiently": 0.001412997877799242, "based on perceived": 0.001412997877799242, "figure 15 and": 0.0011087956007827721, "dimensional in both": 0.0012953547128852297, "state distribution ff": 0.001412997877799242, "the two": 0.00029258477615987414, "7": -0.0039455248437188315, "3 image": 0.0009365728948883588, "walls in": 0.0010706929277613088, "this programming burden": 0.001412997877799242, "issue": 8.585322612989181e-05, "specifically a": 0.0007770287888915143, "reflections occur when": 0.001412997877799242, "thresholded the": 0.0013439565011394887, "lying on the": 0.0010826007236946758, "function approximator in": 0.0025907094257704593, "processing a": 0.0006843495569384895, "etc we will": 0.001177670521728601, "to other approximators": 0.001412997877799242, "from sensor": 0.0010706929277613088, "similarly a recycling": 0.001412997877799242, "machine learning for": 0.0011087956007827721, "these observations": 0.0012583978337383829, "form of learning": 0.0012953547128852297, "s 8s": 0.0013439565011394887, "than the actual": 0.0009419732139289226, "left near very": 0.001412997877799242, "it directly learns": 0.001412997877799242, "base": 0.00012931542172832567, "used on pavlov": 0.001412997877799242, "building see": 0.0013439565011394887, "from scalar": 0.0012263127867333846, "probabilistic model unlike": 0.001412997877799242, "predicted by the": 0.0008347439643413854, "cans or soda": 0.001412997877799242, "e g decision": 0.0011397700534482, "generate": 3.105812197540244e-05, "collected from actual": 0.001412997877799242, "it difficult to": 0.0016266861462377732, "with those using": 0.001412997877799242, "figure 8": 0.0005286326100242748, "for robot": 0.001013492172364257, "dimensional sensory": 0.0013439565011394887, "category learning provide": 0.001412997877799242, "a hypothesis": 0.0007832601051609397, "will be using": 0.001021962604845781, "set it is": 0.0008658836593557804, "figure shows an": 0.0012265208479459286, "it uses a": 0.000730869328480087, "time model however": 0.001412997877799242, "using decision": 0.0020794063477728737, "specular": 0.003947951559754421, "using the on": 0.0012265208479459286, "sensor data the": 0.001412997877799242, "results obtained on": 0.001039879574153469, "undergo": 0.0006771846859643148, "of bias is": 0.0012953547128852297, "dimensional sensor": 0.0026879130022789775, "with decision": 0.0009707370964526472, "concepts under these": 0.001412997877799242, "make recognition easier": 0.001412997877799242, "concepts is": 0.0009907789071032058, "thing tr ctr": 0.001412997877799242, "probability": 0.0005822867194188872, "encoding": 0.0003010434787842052, "order of": 0.0004642157270965945, "data has several": 0.001412997877799242, "is difficult because": 0.0011087956007827721, "since the": 7.701752901190078e-05, "occupancy grids generated": 0.001412997877799242, "reactive layer": 0.0013439565011394887, "robot multitask learning": 0.001412997877799242, "sonar is prone": 0.001412997877799242, "work by": 0.0005548065944701884, "and subsequently describe": 0.001412997877799242, "epochs curve": 0.0013439565011394887, "entire floor of": 0.002825995755598484, "was only necessary": 0.001412997877799242, "figure 2": 0.00020894164758551272, "concepts in": 0.0006843495569384895, "and returning": 0.0009528025610969587, "net vs": 0.0013439565011394887, "tree based": 0.0014774811350663037, "enable a": 0.0007652009340995504, "16 results": 0.0013439565011394887, "learning 5 9": 0.001412997877799242, "time for a": 0.0006684317399421915, "task the focus": 0.001412997877799242, "leading": 0.0001983443590971374, "collection of": 0.000620388284527278, "concepts figure 6": 0.001412997877799242, "to speed up": 0.0014317976603922997, "program robots": 0.0013439565011394887, "in our system": 0.0007542565517753014, "the observation": 0.0008855990473982178, "acquire new": 0.0010397031738864368, "learn one": 0.0013439565011394887, "hundred": 0.0019283978305293533, "extended actions however": 0.001412997877799242, "top figure": 0.0011086075099259812, "actual mobile robot": 0.001412997877799242, "sets of bumper": 0.001412997877799242, "by describing": 0.0013759669926883369, "labels generated": 0.001157470080128191, "on track": 0.001157470080128191, "robot that": 0.0011086075099259812, "sensors by i": 0.001412997877799242, "which are not": 0.0005486163518549943, "investigate two general": 0.002825995755598484, "8 shows the": 0.0006619827406042598, "or even sometimes": 0.001412997877799242, "reflections the occupancy": 0.001412997877799242, "it is undefined": 0.0012265208479459286, "decomposition the sensory": 0.001412997877799242, "figure shows": 0.0028445262730060253, "authors": 8.637720970220658e-05, "n khaleeli figure": 0.001412997877799242, "estimating the likelihood": 0.001412997877799242, "encoding the": 0.0006879834963441684, "cases the": 0.0006081781629314328, "observation probability": 0.0012263127867333846, "and would": 0.000600103348117393, "task of detecting": 0.0012953547128852297, "information yet": 0.0011086075099259812, "see 17 it": 0.0012953547128852297, "as opening or": 0.001412997877799242, "feature detection the": 0.001412997877799242, "a top decision": 0.001412997877799242, "receptacle see": 0.0013439565011394887, "to fill in": 0.0009419732139289226, "and difficult easing": 0.001412997877799242, "images 100x100 color": 0.001412997877799242, "black represents": 0.0013439565011394887, "subservient behaviors such": 0.001412997877799242, "mitchell 27": 0.0013439565011394887, "a steering behavior": 0.001412997877799242, "task is accomplished": 0.0012265208479459286, "occupancy grid 32x32": 0.001412997877799242, "function learning problem": 0.0012953547128852297, "2 multi": 0.0009528025610969587, "in general": 0.0002998467387978728, "lifelong learning approach": 0.001412997877799242, "test the": 0.001334208241947663, "in order to": 0.0005938759934225441, "procedural": 0.0005128000387594285, "multi class": 0.0025577969985883437, "on pavlov showing": 0.001412997877799242, "do not": 5.303943892107254e-05, "have not been": 0.0005957830741145268, "architec ture": 0.0009907789071032058, "concepts that robots": 0.001412997877799242, "shown in the": 0.0004517454745547087, "several sample trajectories": 0.001412997877799242, "term robots are": 0.001412997877799242, "some related": 0.0007291894113705743, "solving the": 0.0007189760374315013, "with observations output": 0.001412997877799242, "on learning": 0.0014147521548524922, "trained using spatial": 0.001412997877799242, "estimation procedure": 0.002651137991267899, "by such": 0.00066081832163666, "trained using": 0.002026984344728514, "navigating to the": 0.001412997877799242, "is necessary for": 0.0007047825434311068, "improved by": 0.0005101280194599199, "target concept previous": 0.001412997877799242, "engineering building over": 0.001412997877799242, "occupancy grid in": 0.001412997877799242, "the neural": 0.014529778669743816, "returning to": 0.0007073760774262461, "a highly specular": 0.001412997877799242, "navigation is a": 0.001412997877799242, "topic for": 0.0009081111668589885, "robustly": 0.0006771846859643148, "learning and some": 0.001412997877799242, "to the robot": 0.0012953547128852297, "features in a": 0.0009126929338602609, "learn a steering": 0.001412997877799242, "learning to": 0.0013833884457695401, "a pre": 0.000553071488717374, "computer science and": 0.0006893286454678117, "label estimating": 0.0013439565011394887, "figure 14 environmental": 0.001412997877799242, "opening undefined figure": 0.001412997877799242, "approaches which use": 0.0012953547128852297, "second task we": 0.0012953547128852297, "the camera": 0.0006916942228847701, "this paper investigates": 0.0010057508064281846, "training epochs": 0.0013439565011394887, "finding": 0.00011919874044704497, "state space in": 0.0009219073640234544, "task we": 0.0014402690729952842, "shallower decision trees": 0.001412997877799242, "ways of accelerating": 0.001412997877799242, "possible generalizations a": 0.001412997877799242, "and other litter": 0.001412997877799242, "towards": 0.00036267488294004313, "note that": 0.00011921896075924973, "pair of two": 0.001177670521728601, "and typically data": 0.001412997877799242, "strength of": 0.0006400562598342001, "vs training a": 0.001412997877799242, "were decomposable in": 0.001412997877799242, "takes noticeably longer": 0.001412997877799242, "adopt the": 0.0006046361590848585, "very near s": 0.001412997877799242, "observation will be": 0.0010826007236946758, "a concept learning": 0.0012953547128852297, "yellow colored": 0.0013439565011394887, "see figure": 0.0012679696851011348, "a detailed": 0.0007916055615019947, "scale o ojs": 0.001412997877799242, "the overall": 0.0016949150058007793, "to new": 0.000631851774969883, "batch update": 0.001157470080128191, "measured": 0.00012931542172832567, "detailed comparison": 0.0009907789071032058, "starting at node": 0.0012953547128852297, "impossible and would": 0.001412997877799242, "human trainers": 0.0013439565011394887, "plot of": 0.0006516207816749321, "mobile": 0.0074413998210781955, "into several distinct": 0.0012953547128852297, "clear": 1.0327064056141857e-05, "mm faculty office": 0.001412997877799242, "generated from a": 0.00080838360373212, "learning 6": 0.0021413858555226176, "wall an": 0.0013439565011394887, "templates were 1": 0.001412997877799242, "traditional": 0.0001734644738625163, "is defined in": 0.000585868219173452, "is it possible": 0.0008035626821164737, "highly specular environment": 0.001412997877799242, "effectiveness in actual": 0.001412997877799242, "because they require": 0.0010826007236946758, "demonstrated that there": 0.0012953547128852297, "although it has": 0.001039879574153469, "uncertainty v": 0.0013439565011394887, "behaviors from": 0.0013439565011394887, "lying": 0.0004942908563209946, "on rapid": 0.0013439565011394887, "over another other": 0.001412997877799242, "note that the": 0.00025210028275353364, "in its envi": 0.001412997877799242, "work as": 0.0006372791512719589, "to test the": 0.0018234779687190492, "times or because": 0.001412997877799242, "towards trash": 0.0013439565011394887, "speed rapid": 0.0013439565011394887, "512 rather": 0.0013439565011394887, "labeled as": 0.0007897242543278053, "of the backpropagation": 0.0012953547128852297, "which infers": 0.0012263127867333846, "registers": 0.0003581471879645512, "with significant": 0.0008346023623118109, "etc however for": 0.0012953547128852297, "correctly predicts features": 0.001412997877799242, "interesting way": 0.0010706929277613088, "towards smarter and": 0.001412997877799242, "learning in": 0.0013615784737533634, "is simple": 0.0004956383297929675, "accurate job": 0.0013439565011394887, "bias sensory": 0.0013439565011394887, "for the left": 0.0009529642174527608, "the support": 0.0005214173517462262, "g soda": 0.0026879130022789775, "trash cans": 0.006719782505697444, "not just": 0.0005171034306485431, "been almost": 0.001157470080128191, "a complex": 0.0004956383297929675, "322 leading": 0.0013439565011394887, "autonomous navigation": 0.001157470080128191, "frame grabber communication": 0.001412997877799242, "domain to": 0.0007246032270542877, "contain millions": 0.0013439565011394887, "that we could": 0.0008347439643413854, "00110011001101010011 001100000000000000000000000001111111111111111111111111000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111111110000011111000000000000000000000000011111111111111111111111110000011111 00000000000000000000000000000011111111111111111111111110000000000000000000000000111111111111111111111111100000000000000000000000001111111111111111111111111000000111111000000111111000000111111": 0.001412997877799242, "prone to numerous": 0.001412997877799242, "account both sensor": 0.001412997877799242, "shaded box": 0.0012263127867333846, "state estimation to": 0.001412997877799242, "categories of bias": 0.001412997877799242, "different angles": 0.0010706929277613088, "the environment this": 0.0010599041887614004, "hallway navigation problem": 0.001412997877799242, "different locations": 0.0008837126637559662, "and multi category": 0.001412997877799242, "bottom each": 0.0013439565011394887, "neural networks 19": 0.001412997877799242, "sensor is capable": 0.001412997877799242, "sensory input space": 0.001412997877799242, "trees": 0.001239644612603011, "regularity of some": 0.001412997877799242, "is challenging": 0.0009528025610969587, "using discrete": 0.0010706929277613088, "over an": 0.0005619164728262171, "relational": 0.00040350596803811654, "categories using": 0.0011086075099259812, "during": -9.534918531212891e-05, "walls in our": 0.001412997877799242, "angled obliquely": 0.0013439565011394887, "the image input": 0.001412997877799242, "recognize objects": 0.0011086075099259812, "robot learns not": 0.001412997877799242, "selecting one": 0.0021413858555226176, "sample trajectories": 0.001157470080128191, "are constructed by": 0.0008956300062288188, "far very": 0.0013439565011394887, "grid was": 0.001157470080128191, "specular errors and": 0.001412997877799242, "on systems such": 0.001412997877799242, "labeled training examples": 0.001412997877799242, "structure logical representations": 0.001412997877799242, "involving considerable": 0.0013439565011394887, "investigate": 0.0005688756993852838, "requires using some": 0.001412997877799242, "navigation to": 0.004434430039703925, "between using multiple": 0.001412997877799242, "described here in": 0.0012953547128852297, "this places a": 0.0011397700534482, "underlying function": 0.001157470080128191, "training patterns the": 0.0012953547128852297, "level observations in": 0.001412997877799242, "machine learning 20": 0.001412997877799242, "in robot": 0.001157470080128191, "and its route": 0.001412997877799242, "steering behavior": 0.0013439565011394887, "and behaviors": 0.002026984344728514, "robots is": 0.001157470080128191, "testbed": 0.0011129278208234917, "the experiments reported": 0.0008801129633255439, "often high dimensional": 0.001412997877799242, "3 shows that": 0.0007542565517753014, "by using": 0.0003584532908388202, "wall right": 0.006719782505697444, "learned from limited": 0.001412997877799242, "carefully structures": 0.0013439565011394887, "unlike previous": 0.0009528025610969587, "figure 6 illustrates": 0.0009529642174527608, "three successful traces": 0.002825995755598484, "the state this": 0.0012953547128852297, "are": 0, "mobile robot": 0.007277922217205058, "be applicable": 0.0006639936831495265, "note that in": 0.00045377265373507006, "close": 1.6235617990867413e-05, "a particular navigation": 0.001412997877799242, "judicious use of": 0.001177670521728601, "place recognition": 0.0013439565011394887, "from color": 0.0012263127867333846, "the colored images": 0.001412997877799242, "use two general": 0.001412997877799242, "of recognizing many": 0.001412997877799242, "mobile robots can": 0.001412997877799242, "learns": 0.0016094272620904703, "produces a six": 0.001412997877799242, "multiple quadrants": 0.0013439565011394887, "concept learning problem": 0.0012265208479459286, "c left front": 0.001412997877799242, "the learning curve": 0.0021198083775228007, "the variation": 0.0006372791512719589, "encouraging 7": 0.0013439565011394887, "inside it": 0.0009907789071032058, "whereas in": 0.000595682008283464, "lab position a": 0.001412997877799242, "lab position b": 0.001412997877799242, "lab position c": 0.002825995755598484, "various": -7.648725635905543e-05, "sensor represen": 0.0013439565011394887, "probably": 0.000300053763988856, "conditions": -6.468242139231747e-05, "testbed followed by": 0.001412997877799242, "and move": 0.0014677990598179111, "as we": 0.00018310109020190367, "the yellow color": 0.0012953547128852297, "begin in": 0.0008954780757782285, "of these two": 0.000561408532790537, "undefined an": 0.0013439565011394887, "missing": 0.0006020869575684104, "initially": 0.0001298823548507322, "3 is very": 0.0012953547128852297, "in part": 0.0003410337391315971, "the same set": 0.0006002051640909454, "at four": 0.0009365728948883588, "lab18 y meters": 0.001412997877799242, "requires the": 0.0007781009701207034, "robots are": 0.0010706929277613088, "of concepts and": 0.0012953547128852297, "are going": 0.00066081832163666, "is apparent that": 0.0008591880780779472, "the concept of": 0.0004708009606376249, "both positions a": 0.001412997877799242, "run when": 0.0009365728948883588, "shared representation": 0.0034724102403845734, "user in the": 0.0009647109541934066, "fewer inputs": 0.0012263127867333846, "floor e g": 0.001412997877799242, "both": -0.0060000156668114524, "c": -0.0039543268505679565, "paradigms": 0.0005213289159674361, "of the allowed": 0.0012265208479459286, "robot navigation architecture": 0.002825995755598484, "0 4 0": 0.000757870016081158, "sensors that": 0.001013492172364257, "oriented along": 0.0010706929277613088, "3rd floor of": 0.001412997877799242, "would be the": 0.0006797336106182766, "ours in": 0.0007897242543278053, "generates four": 0.0013439565011394887, "sensory representation and": 0.001412997877799242, "these features": 0.000600103348117393, "larger than the": 0.0005139029917271836, "attempted a taxonomy": 0.001412997877799242, "for learning strategies": 0.001412997877799242, "of which": 0.00022349717979373282, "context": -2.6560668390012828e-05, "ability to learn": 0.001177670521728601, "backpropagation algorithm local": 0.001412997877799242, "more powerful than": 0.0008347439643413854, "decomposition and": 0.00264327328654664, "finds": 0.00025918842407654925, "experimental": 0.0006041246007999158, "better performance as": 0.0012265208479459286, "tree approach": 0.0009528025610969587, "a pursuit": 0.0011086075099259812, "an entire policy": 0.001412997877799242, "gray areas indicate": 0.001412997877799242, "separate feature detectors": 0.001412997877799242, "reasons": 0.00023401902284906324, "bias which": 0.0020794063477728737, "robot learning 5": 0.001412997877799242, "f front": 0.0012263127867333846, "results in a": 0.00046495663302069287, "as the": 1.1313210262709438e-05, "space with": 0.0006069462075329354, "four different locations": 0.0012953547128852297, "probabilities v": 0.0013439565011394887, "architecture combining": 0.0013439565011394887, "conditions requires using": 0.001412997877799242, "some interesting": 0.0006843495569384895, "step a belief": 0.001412997877799242, "by i": 0.0005185303358808077, "can which": 0.0010706929277613088, "the support of": 0.0006537346506207054, "neural net on": 0.001412997877799242, "grdt": 0.0024522095921958283, "described": -0.00128757845369585, "department main": 0.0013439565011394887, "decomposition the": 0.0007488464497674484, "gets back": 0.0011086075099259812, "of pixels": 0.0006993597717998856, "due": -0.0005828740099508615, "strategy": 0.0001602304419736074, "describes": 0.00016231012317606994, "learning concepts": 0.0022172150198519623, "shows three": 0.0008433654142724929, "high dimensional but": 0.001412997877799242, "learn high dimensional": 0.001412997877799242, "collected": 0.000900161291966568, "i f": 0.0012185727850310478, "robot repeated": 0.0013439565011394887, "selected pixels from": 0.001412997877799242, "presentation here to": 0.001412997877799242, "estimation using pomdp": 0.001412997877799242, "feedback while": 0.0012263127867333846, "recognize features": 0.0013439565011394887, "for navigation": 0.003040476517092771, "related work this": 0.0010826007236946758, "data reveals that": 0.001412997877799242, "directions front left": 0.001412997877799242, "robots 13 electrical": 0.001412997877799242, "high dimensional sensory": 0.001412997877799242, "here such studies": 0.001412997877799242, "learning in robotics": 0.002825995755598484, "robot through the": 0.001412997877799242, "again spatial": 0.0013439565011394887, "as opening": 0.0012263127867333846, "recycling task": 0.00940769550797642, "a sufficiently diverse": 0.001412997877799242, "net to recognize": 0.001412997877799242, "as ff": 0.0008107079716898269, "unlike previous approaches": 0.001177670521728601, "decision trees": 0.004003363232633261, "each case": 0.0004857578053865428, "robots a concept": 0.001412997877799242, "position 5 limitations": 0.001412997877799242, "based architecture for": 0.0010826007236946758, "s pentium": 0.0013439565011394887, "batch": 0.0004917890795456392, "results for learning": 0.0012953547128852297, "near in such": 0.001412997877799242, "while": -0.0007162943759291024, "location of": 0.00043803992979003455, "and figure 9": 0.002079759148306938, "behavior": -4.474208485222688e-05, "or soda cans": 0.001412997877799242, "recognize visual objects": 0.001412997877799242, "invariant rapid": 0.0013439565011394887, "in the occupancy": 0.001412997877799242, "mitchell": 0.0006188604529420837, "below the sensors": 0.001412997877799242, "loop": 0.0002769441019018576, "pose c1 pose": 0.001412997877799242, "below were conducted": 0.001412997877799242, "layer the route": 0.001412997877799242, "examples using": 0.0008954780757782285, "mahadevan g": 0.013439565011394887, "learned knowledge": 0.0011086075099259812, "history of": 0.0005548065944701884, "with the output": 0.0019294219083868132, "quite difficult": 0.0008954780757782285, "any useful": 0.001013492172364257, "to recognize and": 0.0010826007236946758, "obstacle": 0.0005870525139763916, "as well as": 0.00047710785200172785, "using a shared": 0.005698850267241, "collecting and": 0.0009707370964526472, "tried to": 0.0006092863925155239, "kalman filters 14": 0.001412997877799242, "graph compares the": 0.0012953547128852297, "south florida computer": 0.001412997877799242, "some sample images": 0.001412997877799242, "autonomous driving": 0.0013439565011394887, "contrast in our": 0.001177670521728601, "neural network approach": 0.0010826007236946758, "grant": 0.00014605476794421216, "set it": 0.0006400562598342001, "platform section 5": 0.001412997877799242, "several reasons": 0.0006993597717998856, "criterion for": 0.0005496498068625872, "vector as": 0.0007832601051609397, "of instances": 0.0006372791512719589, "map sensory values": 0.001412997877799242, "a wall an": 0.001412997877799242, "run onboard the": 0.001412997877799242, "made denote": 0.0013439565011394887, "cases the robot": 0.001412997877799242, "of hypotheses": 0.0018435019520116167, "concept of trash": 0.001412997877799242, "9": -0.006121103014529204, "top decision": 0.0013439565011394887, "had found": 0.0011086075099259812, "c in": 0.0003875793839458082, "as when the": 0.001021962604845781, "hallway": 0.001039526833456673, "less than 10": 0.000757870016081158, "used": -0.011682451316416851, "learning strategies": 0.001013492172364257, "in each state": 0.0009529642174527608, "robot navigation robot": 0.001412997877799242, "loses the": 0.001013492172364257, "observable markov decision": 0.0025907094257704593, "bumper switches": 0.0013439565011394887, "but also whether": 0.001412997877799242, "to make it": 0.0006751254918513721, "uses": -0.0007097754324960348, "user": 0.00011615941368901264, "nets where the": 0.001412997877799242, "real data 20060010000": 0.001412997877799242, "robust": 0.0004202312177668792, "learning approach which": 0.001412997877799242, "and behaviors in": 0.001412997877799242, "and openings": 0.0013439565011394887, "vehicle for learning": 0.001412997877799242, "number of examples": 0.0008291394238884059, "units despite": 0.0012263127867333846, "figure shows a": 0.0008801129633255439, "for finding trash": 0.001412997877799242, "an opening a": 0.001412997877799242, "accurate job of": 0.001412997877799242, "image processing program": 0.001412997877799242, "symbolic rules": 0.0012263127867333846, "of the possible": 0.0006774144737776724, "obviously": 0.0001715741030662279, "south east": 0.003490811376831888, "i can report": 0.0012953547128852297, "learning are": 0.0021413858555226176, "successfully learn interesting": 0.001412997877799242, "the data rapid": 0.001412997877799242, "consistency": 0.0002747471526969802, "sometimes a": 0.0008034263695325692, "sensors are": 0.0009707370964526472, "found that collecting": 0.001412997877799242, "scaling rotation": 0.0013439565011394887, "months on our": 0.001412997877799242, "learned 3": 0.0013439565011394887, "distances": 0.00033979912393180357, "the recycling": 0.007357876720400307, "abilities": 0.0006139563403370056, "exploits": 0.00037680054790711974, "unseen": 0.000724480329627718, "subsampled": 0.0009526409595770983, "learning methods have": 0.001177670521728601, "values motor commands": 0.001412997877799242, "on pavlov a": 0.001412997877799242, "concept supervised concept": 0.001412997877799242, "being learned": 0.001013492172364257, "make the": 0.00026906546463226737, "semi markov decision": 0.0012953547128852297, "pose c2 pose": 0.001412997877799242, "values motor": 0.0013439565011394887, "with 3 bits": 0.001412997877799242, "discrete event probabilistic": 0.001412997877799242, "ample given the": 0.001412997877799242, "shows that": 0.00016567965911647918, "focus on the": 0.000505703874405148, "with a": 4.723674685369417e-05, "learning and": 0.0012480176371801566, "khaleeli front": 0.0013439565011394887, "robots can acquire": 0.001412997877799242, "also": -0.012192614311592647, "reflections before it": 0.001412997877799242, "that sensor": 0.0011086075099259812, "output values": 0.0009081111668589885, "shared representation we": 0.001412997877799242, "mobile robots 5": 0.001412997877799242, "must map the": 0.0012953547128852297, "and learn independently": 0.001412997877799242, "approach similar to": 0.0009219073640234544, "a reactive behavior": 0.001412997877799242, "over multiple sonar": 0.001412997877799242, "extract the": 0.0006639936831495265, "building over": 0.0013439565011394887, "finder": 0.0008344608083154893, "trainers for much": 0.001412997877799242, "pixels from the": 0.0012953547128852297, "is huge of": 0.001412997877799242, "is decomposed": 0.0013615784737533634, "critical to successful": 0.001412997877799242, "this solution in": 0.0012953547128852297, "it can learn": 0.0012953547128852297, "the output with": 0.0012265208479459286, "is that": 0.0002730766368117771, "showing": 0.00014079095811535868, "feedforward neural network": 0.0011087956007827721, "with 3": 0.000577026606170962, "c b d": 0.001039879574153469, "we will be": 0.0006774144737776724, "with observations": 0.0010706929277613088, "approach the advantage": 0.0012265208479459286, "robot and": 0.0009528025610969587, "noise the": 0.0007652009340995504, "surface angled obliquely": 0.001412997877799242, "temporally extended": 0.001157470080128191, "one set of": 0.0007812905079402834, "supported in part": 0.0004846403471700854, "these two": 0.0002176530548585982, "a six element": 0.001412997877799242, "paper 2 two": 0.0012265208479459286, "a taxonomy of": 0.0009529642174527608, "every five": 0.001157470080128191, "approaches with": 0.0009707370964526472, "tasks their approach": 0.0012953547128852297, "from each sensor": 0.001412997877799242, "units and": 0.0006265849827685552, "applications has not": 0.001412997877799242, "second task": 0.0018435019520116167, "would amount to": 0.0012265208479459286, "that spatial": 0.0010706929277613088, "ones in": 0.0005830336660574013, "also approaches involving": 0.001412997877799242, "to detect": 0.0011805822905422978, "of the local": 0.000603214805139025, "their approach is": 0.0009773255297405913, "able to successfully": 0.0011087956007827721, "each state the": 0.0010599041887614004, "total error over": 0.0012953547128852297, "longer when": 0.0011086075099259812, "we use": 0.0003740304067394354, "for a": 3.1474216509540375e-05, "to find the": 0.0004510744034307452, "representation original": 0.0013439565011394887, "some": -0.009945924963486948, "rapid learning": 0.0013439565011394887, "of freedom": 0.0005655780229006622, "litter": 0.0024522095921958283, "noise the net": 0.001412997877799242, "for the front": 0.001177670521728601, "direction of": 0.0004466919402916898, "a sequence": 0.00023134881850209936, "in these": 0.0005329284136704542, "can also be": 0.0003414853810420278, "the execution of": 0.00046785663572827943, "navigation run": 0.0013439565011394887, "be adapted to": 0.0006918115785384662, "trained to find": 0.001412997877799242, "this assumes": 0.0009081111668589885, "describing": 0.00042732841382440686, "architecture the approach": 0.0012953547128852297, "s 4 13": 0.001412997877799242, "id3": 0.000754000698128159, "continues to": 0.0005565583063253017, "behaviors and": 0.0008954780757782285, "to an": 0.00044532221070778754, "node 1 the": 0.0012265208479459286, "on human trainers": 0.001412997877799242, "process models": 0.0016867308285449859, "this approach clearly": 0.001412997877799242, "openings these": 0.0013439565011394887, "effectiveness of these": 0.0019546510594811825, "both updates scale": 0.001412997877799242, "a dozen": 0.0009081111668589885, "simultaneous learning": 0.0012263127867333846, "models machine": 0.001157470080128191, "run": -7.37742558054479e-05, "a b c": 0.0004870477123570083, "quadrant the second": 0.001412997877799242, "east west": 0.0009528025610969587, "moreno symbolic place": 0.001412997877799242, "processing": 4.57508155270226e-05, "the other": 4.275667549637923e-05, "not approximately oriented": 0.001412997877799242, "infra": 0.0008953261968644262, "step": -0.0001628786749838685, "are trained using": 0.0012953547128852297, "using some": 0.0006291989168691914, "we first took": 0.001412997877799242, "predict features even": 0.001412997877799242, "the two tasks": 0.0010826007236946758, "of feature detectors": 0.001412997877799242, "are focusing": 0.0011086075099259812, "equip them with": 0.001412997877799242, "on pavlov in": 0.001412997877799242, "c and": 0.000244141944457037, "capturing subsequent images": 0.001412997877799242, "occupied space": 0.0012263127867333846, "procedural reactive": 0.0013439565011394887, "from the starting": 0.001021962604845781, "learning is to": 0.0034193101603446, "figure 9 c": 0.0018839464278578451, "figure 9 b": 0.0016694879286827708, "figure 9 a": 0.000730869328480087, "space in both": 0.0012265208479459286, "a3 0": 0.0012263127867333846, "readily than": 0.0012263127867333846, "location and": 0.000634544764829945, "for mobile robot": 0.001412997877799242, "and multiple output": 0.001412997877799242, "a 1200 dimensional": 0.001412997877799242, "range": -8.277305585135765e-05, "tedious and": 0.0008346023623118109, "during an actual": 0.0012265208479459286, "learning concepts could": 0.001412997877799242, "work and contrast": 0.001412997877799242, "few high level": 0.001412997877799242, "we use an": 0.0006968853899317012, "of the controller": 0.0009773255297405913, "and proposes some": 0.0012953547128852297, "training a set": 0.001412997877799242, "sensory concepts here": 0.001412997877799242, "different angles and": 0.001412997877799242, "the output values": 0.0011397700534482, "one where": 0.0013909702264962565, "model of": 0.000553165207055389, "paper we will": 0.0005928942145642387, "net on an": 0.001412997877799242, "country experiment": 0.0013439565011394887, "net is a": 0.0010826007236946758, "within": -0.00029683112077367785, "finding trash": 0.0013439565011394887, "constructed by scaling": 0.001412997877799242, "the occupancy grids": 0.001412997877799242, "figure 15 three": 0.001412997877799242, "train four": 0.0013439565011394887, "y i2i": 0.0012263127867333846, "3 bits": 0.001790956151556457, "unseen set of": 0.001412997877799242, "determining if": 0.0008107079716898269, "which use a": 0.0010826007236946758, "to yield fast": 0.001412997877799242, "active topic for": 0.001412997877799242, "in service": 0.0008837126637559662, "output neural net": 0.001412997877799242, "approach uses": 0.0007897242543278053, "it continues to": 0.0009647109541934066, "every step a": 0.0012953547128852297, "a discrete event": 0.0009647109541934066, "trees 23": 0.0013439565011394887, "probabilistic": 0.0013170870335452232, "earlier alvinn exploits": 0.001412997877799242, "15 inputs 6": 0.001412997877799242, "where the specularities": 0.001412997877799242, "long": -4.549931930031876e-05, "to robot learning": 0.002825995755598484, "the sensors used": 0.0012953547128852297, "adopted in this": 0.0010599041887614004, "complementary to ours": 0.001412997877799242, "research builds": 0.0013439565011394887, "logical representations": 0.001157470080128191, "colored images were": 0.001412997877799242, "paper notes": 0.0013439565011394887, "a front": 0.0009217509760058083, "on learning the": 0.001412997877799242, "trace the robot": 0.001412997877799242, "and actions": 0.0007595764743381157, "so little data": 0.001412997877799242, "pavlov which combines": 0.001412997877799242, "into a pair": 0.0010826007236946758, "far very near": 0.001412997877799242, "and actions we": 0.0012953547128852297, "this idea is": 0.0017317673187115608, "the loop in": 0.00084653211689172, "halved from": 0.0013439565011394887, "sensors predict": 0.0013439565011394887, "using partially": 0.0012263127867333846, "a policy whereas": 0.001412997877799242, "is to complete": 0.0012265208479459286, "observation probability thus": 0.001412997877799242, "seems clear": 0.0009528025610969587, "difficult in general": 0.001412997877799242, "user in": 0.0006486581696160977, "work section": 0.0007291894113705743, "announced that it": 0.001412997877799242, "infers": 0.0008032901031876688, "represents occupied": 0.0013439565011394887, "examples available is": 0.001412997877799242, "pre specified much": 0.001412997877799242, "limited since": 0.001157470080128191, "un known the": 0.001412997877799242, "odometric plot of": 0.001412997877799242, "representatives of true": 0.001412997877799242, "of hypotheses bias": 0.001412997877799242, "using a behavior": 0.001412997877799242, "that the net": 0.0009647109541934066, "trained on manually": 0.001412997877799242, "and error": 0.0005810090920244843, "slippage uneven": 0.0013439565011394887, "to the distance": 0.0008591880780779472, "difficult easing": 0.0013439565011394887, "belief state which": 0.001412997877799242, "run on": 0.00047636541130555675, "is illustrated in": 0.0005543204292900327, "infers a": 0.0012263127867333846, "the navigation": 0.008736633868073825, "similar": -0.0007480672203807957, "called": -0.0011339885281690279, "pomdp approach": 0.0013439565011394887, "that rapid concept": 0.001412997877799242, "20 to constrain": 0.001412997877799242, "task in": 0.0005810090920244843, "a trash": 0.0036789383602001536, "motors turret turn": 0.001412997877799242, "example new": 0.0011086075099259812, "service robot": 0.0013439565011394887, "the test": 0.0003920243363346696, "and undergo multiple": 0.001412997877799242, "our neural network": 0.001412997877799242, "through the": 0.0004231319961517126, "below that using": 0.0012953547128852297, "rather than": 0.00040290407962157956, "4 0 20": 0.0011397700534482, "yield fast": 0.0013439565011394887, "and proceeds with": 0.0012953547128852297, "forms of": 0.0004630874411601419, "the supervised": 0.0010397031738864368, "unreliable due to": 0.0012953547128852297, "of learning is": 0.0012953547128852297, "of research e": 0.001412997877799242, "is the": 3.441904850503996e-06, "a collection of": 0.0004510744034307452, "turn behavior simply": 0.001412997877799242, "avoid motors": 0.0013439565011394887, "or containers": 0.0013439565011394887, "and the": 0.0, "which demonstrates": 0.001013492172364257, "we begin": 0.0007635933021550497, "200 real robot": 0.001412997877799242, "extends the": 0.0005288373163369861, "the possible applications": 0.0012265208479459286, "rules a": 0.0007073760774262461, "electrical": 0.001099113165351069, "hidden markov": 0.0007832601051609397, "12 describe": 0.001157470080128191, "department": 0.0011007918314751793, "or if it": 0.0008801129633255439, "network based autonomous": 0.001412997877799242, "university of south": 0.0012265208479459286, "markov models journal": 0.001412997877799242, "calculate only the": 0.001412997877799242, "true color": 0.0011086075099259812, "of robotics": 0.001013492172364257, "not explicitly": 0.0005712121849001653, "visual objects for": 0.001412997877799242, "generates": 0.00029093330983532276, "actual use and": 0.0012953547128852297, "inputs concept1": 0.0013439565011394887, "this idea": 0.0010399364990605153, "similarly for": 0.0005273294080774565, "the walls in": 0.001412997877799242, "problems": -0.00017536482111341536, "the tradeoff between": 0.0008184493641822325, "p 173 197": 0.0012953547128852297, "the concept learning": 0.001177670521728601, "generated": -0.00039279110455072076, "in better": 0.0007201345364976421, "color value": 0.001157470080128191, "based layer the": 0.001412997877799242, "six element": 0.0013439565011394887, "net is trained": 0.002825995755598484, "can generate a": 0.0009529642174527608, "categories of": 0.0007541286032508272, "this graph compares": 0.001412997877799242, "g soda cans": 0.002825995755598484, "structure": -0.000528628246235735, "both in": 0.0004894029300213453, "that takes": 0.0005429920482072152, "independently": 0.0001253659237124794, "color and": 0.0007437201166480605, "e": -0.010520627700015424, "a symbolic": 0.0006879834963441684, "an nsf career": 0.0011397700534482, "west corridor for": 0.001412997877799242, "paper were run": 0.001412997877799242, "both these": 0.000600103348117393, "required": -0.0003481936093967729, "task and the": 0.0009039491294179812, "engineering computing": 0.001157470080128191, "four separate feature": 0.001412997877799242, "decomposition of the": 0.002053396999398912, "weights": 0.0005530713866335682, "believe the bias": 0.001412997877799242, "to successfully": 0.0014774811350663037, "can be one": 0.001021962604845781, "pose d1": 0.0013439565011394887, "requires": -0.000789991692677191, "concepts results in": 0.001412997877799242, "once": -0.00010176084430053206, "multiple classes": 0.0009217509760058083, "the multi output": 0.0012265208479459286, "bits indicating": 0.0026879130022789775, "described below the": 0.0008956300062288188, "15 three": 0.0012263127867333846, "map which is": 0.001177670521728601, "other behaviors": 0.001157470080128191, "sensory concept learning": 0.011303983022393936, "robot is facing": 0.001412997877799242, "a single concept": 0.0011087956007827721, "salganicoff et": 0.0013439565011394887, "summarizes the paper": 0.0010599041887614004, "go": 0.00015558097783322617, "very high": 0.0015181927030350057, "one multi": 0.0012263127867333846, "circumstances much": 0.0012263127867333846, "e left near": 0.001412997877799242, "that can": 0.000301631070878981, "no iri 9501852": 0.001412997877799242, "of the paper": 0.0003769284069325379, "when the state": 0.0009909470066802508, "dangerous situations for": 0.001412997877799242, "to drop items": 0.001412997877799242, "be easily used": 0.001177670521728601, "second task is": 0.0011397700534482, "feature detection": 0.0009365728948883588, "multiple categories using": 0.001412997877799242, "tree type": 0.001157470080128191, "studies in": 0.0007115262727613508, "ing klingspor": 0.0013439565011394887, "regularity of": 0.0006954851132481282, "study how pavlov": 0.002825995755598484, "and announced that": 0.001412997877799242, "dimensional sensor data": 0.001412997877799242, "easily accommodated": 0.0010706929277613088, "neural nets": 0.0019815578142064116, "is used in": 0.00046932316724806957, "into account": 0.0003212772357093832, "tr ctr b": 0.001177670521728601, "sensory concepts being": 0.001412997877799242, "include": -6.774594416107432e-05, "grids where": 0.0010397031738864368, "is that it": 0.0008687738214326924, "and multiple": 0.0011957581970378076, "not learned 3": 0.001412997877799242, "learning are hypothesis": 0.001412997877799242, "the recycling task": 0.007064989388996209, "in both the": 0.0006224173961016805, "systems navigation": 0.0013439565011394887, "distinct training examples": 0.001412997877799242, "context of": 0.0002904233804912641, "unstructured": 0.0005128000387594285, "complex function": 0.001013492172364257, "hypotheses 3": 0.0013439565011394887, "the advantage however": 0.001412997877799242, "4 although": 0.0008262639069617736, "in observation": 0.0010706929277613088, "d1 figure": 0.0012263127867333846, "original input": 0.0008954780757782285, "it is located": 0.0012265208479459286, "most how is": 0.001412997877799242, "to 1": 0.000258394558846485, "for robot navigation": 0.0012953547128852297, "processes pomdp s": 0.001412997877799242, "performance as we": 0.0010826007236946758, "an image processing": 0.0012953547128852297, "about training epochs": 0.001412997877799242, "described above": 0.00032841545005472464, "positions": 0.00045959550971234485, "notes": 0.000300053763988856, "two sets of": 0.0005872517174083484, "to achieve rapid": 0.001412997877799242, "dimensional concepts": 0.0013439565011394887, "ryan": 0.0006992411558277349, "occupancy grids": 0.006131563933666923, "an odometric trace": 0.002825995755598484, "that in pose": 0.001412997877799242, "paper 2": 0.0006672272054388769, "approach for": 0.0003531619208343471, "recycling robot which": 0.001412997877799242, "is slower to": 0.001412997877799242, "on an unseen": 0.001412997877799242, "noted": 0.00017409680469838642, "policy whereas in": 0.001412997877799242, "floors etc we": 0.001412997877799242, "in state": 0.001659214466152122, "smaller": -6.112140532904656e-05, "smooth flat": 0.0013439565011394887, "number of inputs": 0.0009039491294179812, "however it": 0.0002947320785224751, "this results": 0.0004969104621112533, "nets where": 0.001157470080128191, "seem more applicable": 0.001412997877799242, "solution e": 0.0009707370964526472, "work on": 0.000665844682456497, "in section 2": 0.0002860824483043657, "we use a": 0.0008126017561714406, "dimensional e g": 0.0012953547128852297, "4 experimental results": 0.0007691850242282122, "have a smaller": 0.0009647109541934066, "is received": 0.000577026606170962, "learning multiple concepts": 0.002453041695891857, "decomposition of": 0.0013672314859360514, "class learning the": 0.001412997877799242, "concepts that": 0.0007770287888915143, "then sub sampled": 0.001412997877799242, "figure shows only": 0.0012265208479459286, "to illustrate the": 0.0005387751331447606, "here in particular": 0.0012953547128852297, "hidden markov models": 0.0009126929338602609, "q i the": 0.0009909470066802508, "find": -0.00078825999011122, "two strategies for": 0.0010599041887614004, "detection the net": 0.001412997877799242, "of some": 0.00026049415651071867, "experiment": 0.00018048271923285961, "science and": 0.0005115024387919628, "each observation": 0.0010397031738864368, "for each": 0.00012003567727910045, "problem are": 0.0006400562598342001, "the transducer the": 0.001412997877799242, "of recognizing": 0.0009217509760058083, "recognizing many": 0.0013439565011394887, "also be viewed": 0.0008658836593557804, "i the": 0.000229836736663612, "used to make": 0.0008591880780779472, "some definite": 0.0013439565011394887, "than their": 0.0006807892368766817, "examples have": 0.0008262639069617736, "neural net based": 0.0012265208479459286, "degree": 8.37612711215836e-05, "some researchers have": 0.0009909470066802508, "reliable observations s": 0.001412997877799242, "training data the": 0.0009647109541934066, "noticeably longer": 0.0013439565011394887, "chosen for": 0.0005462907753655785, "show below 4": 0.001412997877799242, "desired": 0.0002419048660354858, "problems we use": 0.0011397700534482, "robot navigation": 0.0070944452065497985, "disjoint quadrants": 0.0013439565011394887, "eventually gets back": 0.001412997877799242, "figure also": 0.0007897242543278053, "i is": 0.0001586319237848247, "we also show": 0.000603214805139025, "location in": 0.0005871520987964046, "observations are": 0.0014677990598179111, "3 0 2": 0.0008728509105201892, "during an": 0.0006705211052503373, "below the": 0.0003846680015569265, "is also": 0.00017751045963937162, "larger": -8.585322612989181e-05, "behaviors to": 0.001013492172364257, "through of the": 0.0012953547128852297, "ffl filling": 0.0013439565011394887, "when a": 0.0001970211399680372, "and in robot": 0.001412997877799242, "subfunctions for": 0.0012263127867333846, "to specular reflections": 0.001412997877799242, "trash can in": 0.0025907094257704593, "neural net was": 0.001412997877799242, "to accurately predict": 0.0010057508064281846, "approximator": 0.0031185805003700194, "shaded": 0.00042172281920285635, "can figure": 0.0010706929277613088, "hundred real valued": 0.002825995755598484, "navigation task for": 0.001412997877799242, "describes the two": 0.0012953547128852297, "almost totally": 0.0026879130022789775, "special issue on": 0.0009126929338602609, "based semi": 0.0012263127867333846, "navigation and recy": 0.001412997877799242, "declarative reactive": 0.0013439565011394887, "neural net specular": 0.001412997877799242, "robotic systems": 0.0009907789071032058, "in these examples": 0.001021962604845781, "up learning their": 0.001412997877799242, "yet the": 0.00066081832163666, "to bias": 0.0008837126637559662, "boolean": 0.0004359559851589287, "show several sample": 0.001412997877799242, "motor": 0.0008344608083154893, "net learning": 0.001157470080128191, "although we do": 0.0009039491294179812, "developed an id3": 0.001412997877799242, "facing a": 0.001157470080128191, "locations in each": 0.0012953547128852297, "use": -0.007156559879878065, "repeated this": 0.0009528025610969587, "from": 0, "was carried out": 0.0008133430731188866, "bias is": 0.003490811376831888, "one each": 0.0017051979990588956, "noted earlier": 0.0007770287888915143, "range that is": 0.0012953547128852297, "high level observations": 0.001412997877799242, "concept3 concept4 figure": 0.001412997877799242, "much more easily": 0.0012953547128852297, "b front": 0.0013439565011394887, "few": -0.00010657637291161236, "navigation domain the": 0.001412997877799242, "camera": 0.0038950599954304024, "quadrants 00110011001101010011 001100000000000000000000000001111111111111111111111111000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111111110000011111000000000000000000000000011111111111111111111111110000011111": 0.001412997877799242, "vehicle": 0.0005673405221283328, "the right": 0.00020317272117257687, "simpler": 0.00012089162764668104, "we investigate the": 0.0006439371750110811, "the 380 test": 0.001412997877799242, "an approximator": 0.0013439565011394887, "we focus primarily": 0.001177670521728601, "sort": 0.00029227936086039793, "used in feature": 0.001412997877799242, "and one each": 0.001412997877799242, "on spatial decomposition": 0.002825995755598484, "formally": 0.00015982122981943533, "using quickprop": 0.0013439565011394887, "but it": 0.000270376024353464, "the trained": 0.0020794063477728737, "started": 0.000300053763988856, "class label": 0.0009365728948883588, "to do in": 0.0009909470066802508, "complete rapid": 0.0013439565011394887, "nets although": 0.0013439565011394887, "digital image": 0.0008183105262917859, "the problem the": 0.0008133430731188866, "a known pursuit": 0.001412997877799242, "subsequent images which": 0.0012953547128852297, "scope of": 0.0004399299902938202, "set of virtual": 0.001021962604845781, "probabilistic framework formally": 0.001412997877799242, "have the capability": 0.001021962604845781, "or in the": 0.000684465666466304, "level features such": 0.0012953547128852297, "need to": 0.00011180645274516415, "time for": 0.00027974396681155117, "receptacles from": 0.0013439565011394887, "logical description": 0.0012263127867333846, "some details of": 0.0011087956007827721, "is tedious and": 0.001177670521728601, "8 an optimized": 0.001412997877799242, "of four virtual": 0.001412997877799242, "net figure": 0.0011086075099259812, "either the": 0.0003640290954836604, "of a pre": 0.0010057508064281846, "while black represents": 0.001412997877799242, "yellow colored trash": 0.001412997877799242, "of random weights": 0.0012953547128852297, "to acknowledge": 0.0007291894113705743, "state estimation using": 0.001412997877799242, "once again": 0.0005446340152121855, "geometrical aligment of": 0.001412997877799242, "this is": 0.00011731512273973072, "to specularities": 0.0024526255734667692, "navigation we first": 0.001412997877799242, "control": -0.00012806221151847913, "the engineering": 0.0024102791085977076, "figure 1 the": 0.0004524188617196826, "is not": 4.9183424639821305e-05, "corridors for": 0.0013439565011394887, "robot navigating to": 0.002825995755598484, "our approach": 0.00029185115310751027, "tradeoff between using": 0.001412997877799242, "scalar feedback": 0.0013439565011394887, "from preclassified training": 0.001412997877799242, "recognition this": 0.0009707370964526472, "a hallway": 0.0013439565011394887, "on a real": 0.0018078982588359625, "planner and execution": 0.001412997877799242, "tan": 0.000524260931709348, "are pre programmed": 0.001412997877799242, "original input e": 0.001412997877799242, "partition a high": 0.001412997877799242, "the route": 0.0007291894113705743, "radially in": 0.0013439565011394887, "observations s mahadevan": 0.001412997877799242, "neural net used": 0.001412997877799242, "case the": 0.0002962897017215909, "on decomposing the": 0.001412997877799242, "right far": 0.0026879130022789775, "a physically": 0.0008525989995294478, "s pentium processor": 0.001412997877799242, "six": 0.0006648626525552234, "coarsely subsampled image": 0.001412997877799242, "in the corridors": 0.001412997877799242, "templates were": 0.0012263127867333846, "100x100": 0.0019052819191541965, "located": 0.0002765356933167841, "shared representation can": 0.001412997877799242, "to predict": 0.0004894029300213453, "by white": 0.001013492172364257, "neural net is": 0.004238993633397726, "novel in": 0.0010397031738864368, "updated state distribution": 0.001412997877799242, "can in all": 0.0012953547128852297, "on perceived geometric": 0.001412997877799242, "concept learn ing": 0.001412997877799242, "tried to find": 0.0012953547128852297, "be contrasted with": 0.0010057508064281846, "the experimental": 0.0014188767983591584, "and image": 0.0005655780229006622, "constrain the": 0.0013032415633498643, "localize the robot": 0.0012953547128852297, "a shared structure": 0.002825995755598484, "given that": 0.00042092948418490783, "hypothesis space to": 0.0012265208479459286, "difficult for": 0.0006516207816749321, "the same location": 0.0008405371151868688, "is accomplished by": 0.0007372369477455303, "filling in": 0.0009707370964526472, "learn to": 0.0008346023623118109, "for recognizing": 0.0008183105262917859, "color images were": 0.001412997877799242, "constant that ensures": 0.001412997877799242, "the same camera": 0.0012265208479459286, "often very": 0.0017674253275119325, "values we thresholded": 0.001412997877799242, "n khaleeli 3": 0.001412997877799242, "light": 0.0002838200262250284, "although it": 0.0009240423130257241, "scalar feedback while": 0.001412997877799242, "actions however": 0.0010706929277613088, "possible applications of": 0.0011397700534482, "not high dimensional": 0.001412997877799242, "robot around in": 0.001412997877799242, "strategies studied here": 0.001412997877799242, "is undefined an": 0.001412997877799242, "robot navigation is": 0.001412997877799242, "to equip": 0.001157470080128191, "combination of two": 0.0009316462484985891, "thing tr": 0.0013439565011394887, "see 24 among": 0.001412997877799242, "c2 pose c3": 0.001412997877799242, "1 in both": 0.0009647109541934066, "of two": 0.00042506336990892065, "we show the": 0.0005626170878486259, "this can": 0.0002359337601841021, "20 and in": 0.001177670521728601, "move towards the": 0.0011397700534482, "features such": 0.0013987195435997712, "pavlov can be": 0.002825995755598484, "paper investigates": 0.0009217509760058083, "nomad 200 mobile": 0.0012953547128852297, "facilitated": 0.0006638810654963465, "the virtual sensors": 0.001412997877799242, "two concept learning": 0.001412997877799242, "experimental study was": 0.001412997877799242, "however it continues": 0.001412997877799242, "including": -4.200043611304368e-05, "robot was": 0.0013439565011394887, "as a trash": 0.001412997877799242, "from each quadrant": 0.001412997877799242, "the designer": 0.0006164961457553095, "distributions such as": 0.0012953547128852297, "algorithm is that": 0.0007542565517753014, "advantages of such": 0.0011087956007827721, "cans and other": 0.002825995755598484, "although the": 0.00025383321843281065, "in order": 0.0002552472960650791, "sort that": 0.0011086075099259812, "estimates of its": 0.0012265208479459286, "we first": 0.00044921189219429, "transfer across related": 0.001412997877799242, "thus there": 0.0005288373163369861, "were conducted over": 0.001412997877799242, "a wall": 0.003040476517092771, "estimating": 0.0003174698400443676, "of prior work": 0.0012265208479459286, "learns only feature": 0.001412997877799242, "173 197": 0.0012263127867333846, "single concept": 0.0010397031738864368, "two realistic tasks": 0.001412997877799242, "receptacles": 0.0024522095921958283, "sensor uncer": 0.0013439565011394887, "introduction to the": 0.0007405102499664257, "pixel": 0.00041158366073644443, "it is apparent": 0.0008347439643413854, "predicts features for": 0.001412997877799242, "accurate and consistent": 0.0012953547128852297, "port it": 0.0011086075099259812, "strength of the": 0.0008347439643413854, "task pavlov is": 0.002825995755598484, "the task 4": 0.001412997877799242, "robot platform": 0.0013439565011394887, "raw sensor values": 0.001412997877799242, "our work": 0.0018366627613598649, "red ir sensors": 0.001412997877799242, "opening wall right": 0.007064989388996209, "khaleeli20601001401800": 0.0012261047960979141, "is still able": 0.002355341043457202, "has not been": 0.0005356081635914791, "neural network produced": 0.001412997877799242, "more easily": 0.0006954851132481282, "front": 0.0038568488919022027, "estimation procedure is": 0.002355341043457202, "are hypothesis": 0.0013439565011394887, "7 the recycling": 0.001412997877799242, "environment the": 0.0005303575928524533, "desired output is": 0.0012953547128852297, "the presentation": 0.0010015582880538588, "only the output": 0.001412997877799242, "also possible": 0.0005619164728262171, "7 shows": 0.0004894029300213453, "features figure 9": 0.0012265208479459286, "to the": 0.0, "university": 0.00011151407736788688, "which extends the": 0.001021962604845781, "they are more": 0.0008956300062288188, "supported in": 0.00039127686416685035, "a nomad 200": 0.0038860641386556888, "training times or": 0.001412997877799242, "approach uses a": 0.001039879574153469, "concepts from high": 0.002825995755598484, "two layered architecture": 0.001412997877799242, "based maps": 0.0013439565011394887, "chooses one": 0.0008954780757782285, "system used is": 0.001412997877799242, "serves as ff": 0.001412997877799242, "explicit probabilistic model": 0.0012953547128852297, "it could": 0.00048818009817504264, "learning is currently": 0.001412997877799242, "where examples can": 0.001412997877799242, "map": 0.0004941749868891421, "study two": 0.0010397031738864368, "space is": 0.000833320233743956, "of the environment": 0.0007855213434982123, "caruana 3 shows": 0.001412997877799242, "we do not": 0.00029655996518674466, "related": -0.0008940472224131356, "several months": 0.0026879130022789775, "a robot to": 0.0012265208479459286, "findings from": 0.0012263127867333846, "space is decomposed": 0.001412997877799242, "colored trash": 0.0026879130022789775, "be in either": 0.0010826007236946758, "units and multiple": 0.001412997877799242, "our": -0.0072340308353526965, "neural net symbolic": 0.001412997877799242, "learning of concepts": 0.0012953547128852297, "grid map": 0.0013439565011394887, "special": -5.8586001889636625e-05, "85": 0.0005584850596111118, "category": 0.0006703063728717777, "four distinct": 0.0009528025610969587, "bleed through of": 0.001412997877799242, "case the robot": 0.0025907094257704593, "easier here": 0.0013439565011394887, "this paper notes": 0.001412997877799242, "and orientation of": 0.0009529642174527608, "arranged radially in": 0.001412997877799242, "to partition": 0.0005830336660574013, "finally section 7": 0.0008658836593557804, "since data collection": 0.001412997877799242, "reports action commands": 0.001412997877799242, "are better": 0.0005871520987964046, "made denote the": 0.001412997877799242, "observations the": 0.0008954780757782285, "the robot learns": 0.0025907094257704593, "multiple categories": 0.001157470080128191, "g far near": 0.001412997877799242, "in partic": 0.000872702844207972, "study two concept": 0.001412997877799242, "until it stopped": 0.001412997877799242, "intelligent and robotic": 0.0011397700534482, "induction": 0.00019563674237096915, "labeling examples": 0.0013439565011394887, "real time": 0.00037272681549384556, "robot is able": 0.001412997877799242, "that using an": 0.0011087956007827721, "that bias free": 0.001412997877799242, "tedious and difficult": 0.001177670521728601, "the reader": 0.00036534436840742916, "is tedious": 0.0010397031738864368, "structure this idea": 0.001412997877799242, "learn related concepts": 0.001412997877799242, "present the experimental": 0.0012265208479459286, "maintains": 0.0002659880794681955, "estimators such": 0.001157470080128191, "to a": 9.098565422806242e-06, "decision tree approach": 0.0012265208479459286, "more easily than": 0.001177670521728601, "be one": 0.0005619164728262171, "used to produce": 0.0007731269361814234, "and noisy": 0.002651137991267899, "8s": 0.0007435939768725096, "two layered": 0.0012263127867333846, "different type of": 0.0009529642174527608, "of several months": 0.002825995755598484, "robots that have": 0.0012953547128852297, "in all": 0.00022683617852704282, "n khaleeli20601001401800 20": 0.001412997877799242, "strategies for": 0.0009715156107730856, "of input dimensions": 0.001412997877799242, "g": -0.009490106926129081, "g in": 0.0007664548001737944, "determining": 0.00011260857001588855, "route": 0.0008198844510206236, "florida": 0.00044369014968242206, "used in our": 0.0005886458922766477, "an unseen set": 0.001412997877799242, "times": -0.00025185625750422206, "not discuss the": 0.0010057508064281846, "bayesian models": 0.001157470080128191, "sensory state space": 0.001412997877799242, "soda cans and": 0.002825995755598484, "we have": 2.784319206413085e-05, "carried out using": 0.0008591880780779472, "based layer planning": 0.001412997877799242, "specularities become": 0.0013439565011394887, "to make an": 0.0008591880780779472, "and thus": 0.00021441527384486988, "the desired output": 0.001021962604845781, "into symbolic": 0.0011086075099259812, "figure 7 a": 0.0007047825434311068, "train but": 0.0013439565011394887, "this framework uses": 0.001412997877799242, "11 shows": 0.0006240088185900783, "and execution layer": 0.001412997877799242, "powerful": 0.0002003900862404812, "fairly well known": 0.001412997877799242, "bump figure": 0.0013439565011394887, "over deeper ones": 0.001412997877799242, "examples the neural": 0.002825995755598484, "of the feature": 0.0008527436549416518, "position d pose": 0.001412997877799242, "for training the": 0.001039879574153469, "time robotics applications": 0.001412997877799242, "3 0": 0.00047636541130555675, "3 1": 9.856316920088874e-05, "3 2": 0.00010826226675634337, "we believe": 0.0010160579551521975, "3 4": 0.0003610266709404378, "department nodes": 0.0013439565011394887, "making it difficult": 0.001039879574153469, "present below": 0.0009707370964526472, "net based": 0.0009707370964526472, "13 21": 0.0009217509760058083, "other irregularities in": 0.001412997877799242, "trash cans we": 0.001412997877799242, "in general the": 0.0004944585831130955, "1 within about": 0.001412997877799242, "size is halved": 0.001412997877799242, "the quickprop method": 0.001412997877799242, "acronym for programmable": 0.001412997877799242, "a type": 0.0005185303358808077, "adopted": 0.00033173088434737666, "from high": 0.0015665202103218793, "provided example a": 0.001412997877799242, "their": -0.0024344124971440017, "very near err": 0.001412997877799242, "with 380": 0.0013439565011394887, "south east navigation": 0.005651991511196968, "possible hypotheses": 0.001157470080128191, "long training times": 0.0012953547128852297, "as it navigated": 0.001412997877799242, "in voronoi": 0.0012263127867333846, "reasoning and": 0.0007710139595398186, "a visual": 0.0007157773884946746, "11 opening right": 0.001412997877799242, "prone": 0.0009412825176384535, "of each": 0.00012063379446921434, "the on": 0.0005913666291750407, "rapid concept learning": 0.014129978777992418, "figure 13 shows": 0.0007855213434982123, "we study": 0.0016768433593601086, "modeling of four": 0.001412997877799242, "ctr b": 0.0010397031738864368, "distribution now": 0.0012263127867333846, "figure 5 this": 0.001039879574153469, "learning context where": 0.0012953547128852297, "sonar pulse hits": 0.001412997877799242, "using a nomad": 0.0012953547128852297, "2 navigation": 0.0013439565011394887, "a high level": 0.0006062757282217702, "implement and train": 0.001412997877799242, "comparison of": 0.000621420232460138, "this approach": 0.0008939887191749313, "shows an odometric": 0.002825995755598484, "multiple single output": 0.001412997877799242, "a high dimensional": 0.0010826007236946758, "investigated sensory concept": 0.001412997877799242, "the trash and": 0.001412997877799242, "inputs the number": 0.0012265208479459286, "2 q i": 0.001177670521728601, "navigation given": 0.0013439565011394887, "8 learning": 0.0013439565011394887, "were decomposable": 0.0013439565011394887, "intensity can": 0.0013439565011394887, "2 0 4": 0.0009126929338602609, "because it can": 0.000777160622754577, "easy to show": 0.0006641063390170443, "an odometric": 0.0026879130022789775, "providing": 0.00013044998092568983, "distinguished": 0.00033979912393180357, "that is learned": 0.001412997877799242, "descriptions": 0.00029613525227948625, "behaviors": 0.0028134971048928864, "and easier": 0.0008262639069617736, "fill in some": 0.0012953547128852297, "a range that": 0.0012953547128852297, "net to represent": 0.0012265208479459286, "the scope": 0.00043803992979003455, "to produce 4": 0.001412997877799242, "hypotheses space": 0.0012263127867333846, "input or the": 0.0012265208479459286, "can speed sensory": 0.001412997877799242, "21 this framework": 0.001412997877799242, "well known in": 0.0008956300062288188, "based on": 0.0003242580265329301, "space to": 0.0005258336588949284, "of using decision": 0.001412997877799242, "coarsely subsampled": 0.0013439565011394887, "disjoint": 0.0002101156088834396, "grids were collected": 0.001412997877799242, "having a": 0.0004371016452995968, "errors 14 s": 0.001412997877799242, "to our": 0.0005312058204042253, "as in": 0.00021870064110781506, "quadrant": 0.0006638810654963465, "is difficult": 0.0008505833977144572, "an id3 decision": 0.001412997877799242, "estimation to": 0.0009217509760058083, "describe the": 0.0002469330451211589, "easily used in": 0.0012953547128852297, "dimensional vector if": 0.001412997877799242, "able": -0.0005409580359399148, "and image intensity": 0.001412997877799242, "for every human": 0.001412997877799242, "instance": 3.441409631908712e-06, "that it relies": 0.001412997877799242, "programmed obviously": 0.0013439565011394887, "sources for": 0.0007710139595398186, "which": -0.026974305514154112, "estimation and": 0.0006576990239911289, "this work is": 0.0005531653250744689, "detector": 0.0011272848847328504, "each possible observation": 0.001412997877799242, "paper we are": 0.0007653307612006872, "c shows": 0.0007201345364976421, "observation is a": 0.001412997877799242, "studied work": 0.0013439565011394887, "20 2": 0.0008262639069617736, "serves as": 0.0005513526645513448, "box are trained": 0.001412997877799242, "main office engineering": 0.001412997877799242, "run onboard": 0.0013439565011394887, "tainty": 0.0009906108645477269, "local occupancy": 0.012095608510255398, "vector if the": 0.0012265208479459286, "recycling a detailed": 0.001412997877799242, "examples and": 0.0006265849827685552, "which is input": 0.0012953547128852297, "ff post after": 0.002825995755598484, "features it was": 0.001412997877799242, "overlapping": 0.00029906812530704327, "studies can": 0.0010397031738864368, "algorithm local occupancy": 0.001412997877799242, "acting under": 0.0012263127867333846, "represen": 0.000754000698128159, "class": -0.00018641233824343034, "values of": 0.0003400702266384226, "2 dimensional as": 0.001412997877799242, "one for each": 0.0005578301321858288, "with capturing": 0.0013439565011394887, "building was used": 0.001412997877799242, "converged to": 0.0008954780757782285, "amount to": 0.0007832601051609397, "assumes that the": 0.000627558497619122, "use two": 0.0006486581696160977, "a logical": 0.0005619164728262171, "event probabilistic": 0.0013439565011394887, "new examples": 0.001816222333717977, "noticeable in": 0.0019815578142064116, "b in both": 0.0012265208479459286, "and figure 16": 0.0012953547128852297, "which could be": 0.000730869328480087, "trained neural": 0.002314940160256382, "environments and": 0.0008262639069617736, "the basic": 0.00043458315367669696, "we will": 0.00033870508521131854, "of sensor": 0.0009217509760058083, "concept thru": 0.0013439565011394887, "concept it helps": 0.001412997877799242, "constrain": 0.0008759312707300724, "are not learned": 0.001412997877799242, "is decomposed into": 0.0016071253642329475, "d right": 0.0012263127867333846, "noisy training": 0.0012263127867333846, "other sources": 0.0009081111668589885, "one each for": 0.0022795401068964, "s the robot": 0.001412997877799242, "detailed experimental studies": 0.001412997877799242, "regions and": 0.0006576990239911289, "hypotheses 3 the": 0.001412997877799242, "gray areas": 0.0013439565011394887, "intelligent and": 0.0010397031738864368, "prior the state": 0.001412997877799242, "how pavlov can": 0.002825995755598484, "months see": 0.0013439565011394887, "of accelerating sensory": 0.001412997877799242, "judicious use": 0.0011086075099259812, "this paper we": 0.0008360507906793916, "output is computed": 0.001412997877799242, "around in": 0.0009528025610969587, "planning": 0.0013547767098162071, "litter and deposit": 0.001412997877799242, "pragmatic approach to": 0.0012265208479459286, "with far fewer": 0.0012953547128852297, "for selecting one": 0.001412997877799242, "near figure 11": 0.001412997877799242, "using hidden markov": 0.001039879574153469, "of the solution": 0.0005777823180207654, "alvinn exploits a": 0.001412997877799242, "based": -0.011088287525543783, "hand labeled examples": 0.002825995755598484, "speed convergence": 0.0011086075099259812, "a wall 2": 0.001412997877799242, "were pre processed": 0.0012265208479459286, "the country experiment": 0.001412997877799242, "domain the": 0.0005913666291750407, "high degree": 0.0006372791512719589, "reactive": 0.002410497288161692, "envi": 0.0006771846859643148, "robotic system": 0.0013439565011394887, "go forward is": 0.001412997877799242, "an extremely": 0.001327987366299053, "9 b and": 0.001177670521728601, "description of": 0.00025383321843281065, "local": -0.00032420303025977327, "pavlov in the": 0.001412997877799242, "achieve": 4.349882613120259e-05, "b c figure": 0.000757870016081158, "hallways each": 0.0013439565011394887, "facilitate learning": 0.0013439565011394887, "sensory concept learn": 0.001412997877799242, "detectors shaded box": 0.001412997877799242, "quadrants there": 0.0013439565011394887, "more flexible": 0.0006240088185900783, "framework uses an": 0.0012953547128852297, "as its output": 0.0012265208479459286, "section 2 by": 0.0009529642174527608, "learning of multiple": 0.0012265208479459286, "overall": 0.0002940471201897313, "ff post this": 0.001412997877799242, "concept supervised": 0.0013439565011394887, "training examples available": 0.0012953547128852297, "ones": 6.162928897546766e-05, "actual real time": 0.001412997877799242, "observations in": 0.0016867308285449859, "fairly reliable": 0.0010397031738864368, "although examples have": 0.001412997877799242, "3 this": 0.0004158170065315799, "around in order": 0.001412997877799242, "of training": 0.0006807892368766817, "believe many": 0.0012263127867333846, "f then": 0.000593511402013939, "partic": 0.0007156559879878064, "processes": 0.0002688862876210917, "is an acronym": 0.0011397700534482, "some sort that": 0.001412997877799242, "results presented": 0.0005258336588949284, "paper is on": 0.0009909470066802508, "klingspor et al": 0.001412997877799242, "the net was": 0.001412997877799242, "numerous": 0.0003469554115849005, "neural network were": 0.001412997877799242, "examples since all": 0.001412997877799242, "two general approaches": 0.002453041695891857, "processor figure 1": 0.0011397700534482, "to implement": 0.0005914000916582454, "specified much of": 0.001412997877799242, "the input": 0.0007878320043407583, "processed": 0.00026771614092844864, "contain": -1.5250271842340877e-05, "signatures we show": 0.001412997877799242, "c b": 0.0005637380560122889, "of three successive": 0.0012953547128852297, "or an": 0.00042092948418490783, "and infra": 0.001157470080128191, "to extract": 0.0005479626095875345, "finally section": 0.0005637380560122889, "computed": -0.0001467824798356648, "geometric attributes": 0.001157470080128191, "recognition this can": 0.001412997877799242, "a period": 0.001209272318169717, "smooth": 0.0005285429504906886, "systems such as": 0.0006578106118811853, "possible to learn": 0.0012953547128852297, "across an": 0.0009528025610969587, "computer": -0.00028858578781962735, "correctly predict 85": 0.001412997877799242, "tested by": 0.0007832601051609397, "directly learning": 0.0013439565011394887, "are studied on": 0.0012953547128852297, "set of possible": 0.0007074960937271329, "20 among the": 0.001412997877799242, "theocharous n khaleeli": 0.012716980900193176, "discrete time": 0.0006372791512719589, "policy learning": 0.0013439565011394887, "19 concept learning": 0.001412997877799242, "can perceive features": 0.001412997877799242, "and neural networks": 0.0009529642174527608, "specularities and": 0.002314940160256382, "several sample": 0.0012263127867333846, "networks 19 concept": 0.001412997877799242, "where we": 0.00033349208643894965, "errors and": 0.0006046361590848585, "favor": 0.00044563597599098887, "state": -0.0021740128328233024, "previous work": 0.00038179665107752485, "sensors arranged radially": 0.001412997877799242, "arguable": 0.001039526833456673, "correctly": 0.0006837846505969771, "as locating and": 0.001412997877799242, "symbolic concept": 0.0012263127867333846, "with trash can": 0.001412997877799242, "local occupancy grid": 0.009890985144594694, "investigated ranging": 0.0013439565011394887, "ability": 0.00014664370967580105, "opening": 0.009358544739455169, "importance": 0.00019228351568510512, "sampling was done": 0.0012953547128852297, "e g even": 0.001412997877799242, "the nominal directions": 0.001412997877799242, "acknowledgements this": 0.0007157773884946746, "these conditions": 0.0005185303358808077, "6 discusses": 0.0008262639069617736, "specified by": 0.0008200235323524339, "job": 0.0003972663650691326, "8 learning curve": 0.001412997877799242, "hypothesis": 0.0006517641683151615, "those values we": 0.001412997877799242, "key": 4.950990647240536e-05, "a hypothesis space": 0.0011397700534482, "a robot navigation": 0.001412997877799242, "distribution": 0.00026515221543395746, "black and white": 0.0009647109541934066, "network approach we": 0.001412997877799242, "autonomous robots robotics": 0.001412997877799242, "hits": 0.0004942908563209946, "wall opening or": 0.001412997877799242, "presentation rapid": 0.0013439565011394887, "concepts being learned": 0.0012953547128852297, "related concepts results": 0.001412997877799242, "through exploration": 0.0013439565011394887, "career": 0.0006515102625464255, "integrating over": 0.0009528025610969587, "where the tradeoff": 0.001412997877799242, "ours in that": 0.0011087956007827721, "trash can we": 0.0012953547128852297, "known pursuit": 0.0013439565011394887, "could be trained": 0.002825995755598484, "sensory concepts can": 0.001412997877799242, "belief estimates of": 0.001412997877799242, "tasks are": 0.0006046361590848585, "learn ing": 0.0009907789071032058, "successful approaches are": 0.0012953547128852297, "estimation": 0.001365268831915272, "programmable autonomous": 0.0013439565011394887, "example the robot": 0.0012953547128852297, "filled in by": 0.0010826007236946758, "received by": 0.0005496498068625872, "data rapid": 0.0013439565011394887, "training examples provided": 0.001412997877799242, "wall": 0.009018279077862804, "rules out": 0.0008107079716898269, "problem tractable section": 0.001412997877799242, "simpler feature": 0.0013439565011394887, "environments": 0.0005034853356445367, "rote learning 4": 0.001412997877799242, "the authors": 0.0003122648947066425, "however of": 0.0009217509760058083, "values a hypothesis": 0.001412997877799242, "5 6 9": 0.001039879574153469, "near the": 0.0009938209242225065, "the idea is": 0.0005928942145642387, "is near or": 0.001412997877799242, "9 illustrates": 0.0008954780757782285, "to produce": 0.0006361123799334361, "general forms": 0.001013492172364257, "section 3 describes": 0.0006797336106182766, "department 3 25": 0.001412997877799242, "addition": -0.00024401273845114292, "majority of": 0.00047295893278638616, "a concept": 0.0006705211052503373, "system for a": 0.0008728509105201892, "going to": 0.0005258336588949284, "declarative structure": 0.0013439565011394887, "concept learning methods": 0.0012953547128852297, "and distances using": 0.001412997877799242, "a majority of": 0.000823711514802973, "navigation the": 0.002026984344728514, "in particular": 0.00026950514690557214, "sampled the images": 0.001412997877799242, "trees for example": 0.0010826007236946758, "thank lynn": 0.0013439565011394887, "that the learned": 0.001177670521728601, "corresponding": -0.0002694558653183486, "experiments described below": 0.0022175912015655443, "circumstances much more": 0.001412997877799242, "particular by": 0.0009528025610969587, "trash and also": 0.001412997877799242, "sufficient": 0.00010102932290223842, "were 1 dimensional": 0.001412997877799242, "0 0": 0.0007635933021550497, "using decision trees": 0.002355341043457202, "bias studied": 0.0013439565011394887, "computing computer science": 0.001412997877799242, "controller": 0.00043058230745210023, "robot to": 0.004158812695545747, "across related": 0.0026879130022789775, "the situation this": 0.001412997877799242, "in a highly": 0.0009219073640234544, "g the overall": 0.0012953547128852297, "the robot with": 0.0012953547128852297, "s 2": 0.0007495710427882765, "specular reflections occur": 0.001412997877799242, "s 4": 0.0006046361590848585, "present": -0.0007775652722296478, "to train": 0.0007770287888915143, "in actuality the": 0.001412997877799242, "novel": 0.0002525597933651796, "6 and returning": 0.001412997877799242, "unlike": 0.00016906879144473665, "training epochs a": 0.001412997877799242, "position b pose": 0.001412997877799242, "symbolic concept description": 0.001412997877799242, "speed sensory": 0.0026879130022789775, "allowed compass": 0.0013439565011394887, "will": -0.0036000094000868707, "exists that": 0.0008262639069617736, "discrete event markov": 0.001412997877799242, "architecture using": 0.0009081111668589885, "much of this": 0.0009219073640234544, "some form of": 0.0007074960937271329, "even a": 0.0005731297104135156, "tasks where": 0.0019414741929052945, "many of the": 0.0004961455863729884, "problem the first": 0.0009126929338602609, "philosophy adopted in": 0.001412997877799242, "the experiments below": 0.0011087956007827721, "generally defined": 0.0012263127867333846, "can learn": 0.0008262639069617736, "layer": 0.0026827786896143836, "categories using a": 0.001412997877799242, "that we": 0.00020732336394143995, "grid data": 0.001157470080128191, "was done": 0.00048336597935908464, "robots a robust": 0.001412997877799242, "instructed more readily": 0.001412997877799242, "thus": -0.0007536010958142397, "surface": 0.00031960686763883974, "of obstacle": 0.001157470080128191, "sensor reports grids": 0.001412997877799242, "s an observation": 0.001412997877799242, "each observation can": 0.001412997877799242, "able to": 0.0014113295541334431, "trial and": 0.0007964395063592673, "uses a feedforward": 0.001412997877799242, "is generally": 0.00047636541130555675, "been encouraging": 0.001157470080128191, "recognizers we": 0.0013439565011394887, "their approach": 0.00066081832163666, "our environment the": 0.001412997877799242, "and train": 0.0011086075099259812, "this made": 0.0009365728948883588, "layer with": 0.001013492172364257, "number of instances": 0.0007988727145907639, "among the most": 0.000887696035668378, "parts": 6.621284951658511e-05, "from examples both": 0.001412997877799242, "diverse collection of": 0.001412997877799242, "these reasons": 0.0006843495569384895, "units": 0.0006219177164946759, "for which the": 0.0004425536846910808, "gets": 0.0002335924145220866, "example tasks we": 0.001412997877799242, "tasks are studied": 0.001412997877799242, "difficult": 0.00013776990396122498, "in unstructured": 0.0012263127867333846, "huge of the": 0.001412997877799242, "the state estimation": 0.001412997877799242, "to ff": 0.0007246032270542877, "task the": 0.0006428774807200497, "odometric trace of": 0.002825995755598484, "objects based": 0.0009907789071032058, "far e left": 0.001412997877799242, "approach we first": 0.0010826007236946758, "strategy as": 0.0008346023623118109, "approach to robot": 0.0012265208479459286, "we identified the": 0.0011087956007827721, "significant odometric": 0.0026879130022789775, "figure 9": 0.00267443379330436, "is capable": 0.0006046361590848585, "priori knowledge or": 0.001412997877799242, "complementary to": 0.0008183105262917859, "model based reasoning": 0.0012953547128852297, "figure 1": 0.00018225410018727058, "representation and": 0.0005303575928524533, "figure 3": 0.00025189898121202604, "figure 4": 0.00028922110911932186, "figure 5": 0.00035397245295633523, "trash receptacles": 0.0026879130022789775, "figure 7": 0.00046726408007539364, "formally called partially": 0.001412997877799242, "into 400 pixels": 0.001412997877799242, "to be": 1.376797366563784e-05, "case of": 0.0001262308890178431, "navigation task": 0.0033258225297779433, "6 in": 0.0004108309607838615, "i": -0.007374481185542422, "trash receptacle the": 0.001412997877799242, "obstacles": 0.0006091830535751379, "well": -0.0025944150314710698, "a large": 0.0001824523345832373, "we present below": 0.0010599041887614004, "route planner": 0.0013439565011394887, "and learn": 0.0019056051221939174, "induction of": 0.0007710139595398186, "more complex": 0.0003482300814824197, "images 100x100": 0.0013439565011394887, "boada": 0.0012261047960979141, "which could": 0.0005513526645513448, "sensing": 0.0006188604529420837, "of the reports": 0.001412997877799242, "the alvinn system": 0.002825995755598484, "repeated this task": 0.001412997877799242, "probabilistic planning": 0.0013439565011394887, "its envi ronment": 0.001412997877799242, "accurate": 0.00022741065906583147, "its output": 0.0006807892368766817, "initially unobservable to": 0.001412997877799242, "pose c2 trace": 0.001412997877799242, "200 real": 0.0013439565011394887, "better representatives of": 0.001412997877799242, "sources": 0.00026512835785796554, "any criterion": 0.0013439565011394887, "near or even": 0.001412997877799242, "particular navigation": 0.0013439565011394887, "40": 9.854645224546117e-05, "and b in": 0.0007898582421551431, "error over all": 0.0012953547128852297, "provide sufficient bias": 0.002825995755598484, "functions the sensory": 0.001412997877799242, "2 multi class": 0.001412997877799242, "camera turn behavior": 0.002825995755598484, "this is necessary": 0.0008801129633255439, "robots 7": 0.0013439565011394887, "rapid": 0.004639373135263347, "will eventually resolve": 0.001412997877799242, "viewed as a": 0.00048226304753991637, "instance based": 0.0008954780757782285, "work to speed": 0.001412997877799242, "obliquely to the": 0.001412997877799242, "ryan for": 0.0013439565011394887, "examples can be": 0.0008658836593557804, "high level features": 0.0022175912015655443, "find the": 0.00030763113883053127, "is slower": 0.0008034263695325692, "extends": 0.00022530924316835796, "new concepts and": 0.0012953547128852297, "results suggest that": 0.000757870016081158, "i f 2": 0.0012265208479459286, "situations for": 0.0007897242543278053, "shows the": 0.0009220114217701729, "left front far": 0.001412997877799242, "odometric errors": 0.0013439565011394887, "to successful": 0.001157470080128191, "specularities become very": 0.001412997877799242, "the figure shows": 0.0007653307612006872, "saturation": 0.0006842334867965392, "form of": 0.0012398549000691018, "ample": 0.0004556665315238027, "target concept": 0.000872702844207972, "combining a": 0.0007832601051609397, "arguable that": 0.0012263127867333846, "element vector as": 0.001412997877799242, "sensory space is": 0.001412997877799242, "concepts and": 0.0011580138151580422, "and announced": 0.0012263127867333846, "location of the": 0.0005914669628413412, "from scalar feedback": 0.001412997877799242, "pavlov is required": 0.002825995755598484, "restrict possible generalizations": 0.001412997877799242, "concepts and behaviors": 0.002825995755598484, "burden": 0.0010426578319348721, "labeled with": 0.0005978790985189038, "sensors and corresponding": 0.001412997877799242, "the direct policy": 0.001412997877799242, "i 2": 0.000652390375175781, "on board": 0.0009707370964526472, "trash can placed": 0.001412997877799242, "necessary": -0.0005104749436421483, "uncertainty discrete bayesian": 0.001412997877799242, "sensing and": 0.0009907789071032058, "layer input layer": 0.0012265208479459286, "a human teacher": 0.0025907094257704593, "4 2 learning": 0.0012265208479459286, "a human": 0.003172723824149725, "concepts here the": 0.001412997877799242, "loses": 0.000571115303593364, "its envi": 0.0013439565011394887, "output learning vs": 0.001412997877799242, "the high": 0.0007359988233574629, "robot was started": 0.001412997877799242, "figure 1 in": 0.00080838360373212, "by running": 0.0011620181840489687, "sensors used on": 0.001412997877799242, "approaches are decision": 0.001412997877799242, "rote": 0.001039526833456673, "action reports action": 0.001412997877799242, "boolean variables": 0.0014583788227411486, "prior s": 0.0012263127867333846, "net on": 0.0012263127867333846, "because": -0.0021336597076843052, "in this": 9.834039678472628e-06, "be made": 0.00030916558573279194, "would be": 0.0002992528272949762, "sequence": -0.00010176084430053206, "pomdp": 0.003678314388293742, "e g near": 0.0012265208479459286, "policy learning approach": 0.001412997877799242, "examples encountered": 0.0013439565011394887, "f in state": 0.0012953547128852297, "can robustly": 0.0012263127867333846, "type approach": 0.001157470080128191, "7 a local": 0.0012953547128852297, "from such": 0.0006672272054388769, "framework formally called": 0.001412997877799242, "procedure that takes": 0.0012265208479459286, "obscured by specular": 0.001412997877799242, "floor of": 0.003212078783283926, "investigate the": 0.0004352383371715153, "learning framework": 0.001013492172364257, "net for which": 0.001412997877799242, "left near": 0.0013439565011394887, "them with": 0.0005513526645513448, "sonars in": 0.0013439565011394887, "use and": 0.0005892470628878294, "the learned knowledge": 0.001177670521728601, "robot base": 0.0013439565011394887, "can report": 0.0009907789071032058, "spatial decomposition of": 0.0038860641386556888, "demonstrates": 0.0003030353065250183, "learning problem the": 0.001412997877799242, "with trash": 0.0013439565011394887, "has to": 0.0008177259449193552, "all i 2": 0.0008801129633255439, "period of several": 0.002453041695891857, "and moving the": 0.001177670521728601, "grid map which": 0.001412997877799242, "a comparison": 0.00038684771632577214, "features the net": 0.001412997877799242, "to different": 0.00043803992979003455, "model unlike previous": 0.001412997877799242, "these occupancy grids": 0.001412997877799242, "in states where": 0.0012265208479459286, "demonstrated": 0.00020591052515513526, "limitations": 0.0007876983829017588, "for a teacher": 0.0012953547128852297, "angles and distances": 0.001177670521728601, "opening or wall": 0.001412997877799242, "pose b2 pose": 0.001412997877799242, "acronym": 0.0008344608083154893, "left and right": 0.0006310701423978614, "journal": -1.3280334195006414e-05, "architec": 0.0006992411558277349, "voronoi based": 0.001157470080128191, "approaches involving considerable": 0.001412997877799242, "missing pieces of": 0.001412997877799242, "learning feature": 0.002314940160256382, "mahadevan g theocharous": 0.014129978777992418, "grid representation": 0.0012263127867333846, "that there are": 0.0004041717243965071, "for probabilistic navigation": 0.001412997877799242, "shows the learning": 0.002825995755598484, "for the navigation": 0.002825995755598484, "sensor as": 0.001157470080128191, "maximum value": 0.0005913666291750407, "one pixel": 0.0008525989995294478, "irregularities in": 0.0011086075099259812, "such as opening": 0.0012953547128852297, "observation this is": 0.0012953547128852297, "recent neural": 0.0013439565011394887, "strategy as opposed": 0.001412997877799242, "carried": 0.000372663598598409, "are focusing on": 0.0012265208479459286, "freedom": 0.0003261398627596022, "navigational system uses": 0.001412997877799242, "move to different": 0.001412997877799242, "and succeeded": 0.0013439565011394887, "occupancy probability in": 0.001412997877799242, "the current sensor": 0.001412997877799242, "2 illustrates the": 0.000887696035668378, "is to equip": 0.001412997877799242, "burden seems": 0.0013439565011394887, "useful sensory": 0.0013439565011394887, "of south": 0.0011086075099259812, "grammar which restrict": 0.001412997877799242, "is updated": 0.0004894029300213453, "system 11 18": 0.001412997877799242, "common underlying function": 0.001412997877799242, "we investigate": 0.0014645402945251279, "to partition a": 0.0009647109541934066, "in the experiments": 0.0012729419538147443, "ultrasound": 0.0008725548281217766, "light variations 10": 0.001412997877799242, "research since": 0.0010397031738864368, "concepts can": 0.0009217509760058083, "estimators": 0.0005829347797504038, "caruana 3": 0.0013439565011394887, "27 propose a": 0.001412997877799242, "reflect away from": 0.001412997877799242, "for programmable": 0.0010706929277613088, "designer has": 0.0008837126637559662, "to test": 0.0011874083422529918, "additional": -0.00020998616296004867, "an optimized": 0.0007541286032508272, "and the purpose": 0.0012265208479459286, "since the overall": 0.0011397700534482, "transfer": 0.00022679770563380553, "on track the": 0.001412997877799242, "task this": 0.0007897242543278053, "based layer": 0.0024526255734667692, "1 pavlov is": 0.001412997877799242, "reported in": 0.00039965180241839, "a detailed experimental": 0.001412997877799242, "1 however it": 0.0011087956007827721, "drivers as noted": 0.001412997877799242, "figure 4 behavior": 0.001412997877799242, "every action is": 0.001412997877799242, "investigated here is": 0.001412997877799242, "wall 2": 0.0012263127867333846, "and back": 0.0007115262727613508, "discrete probability": 0.0011086075099259812, "input to": 0.0008760798595800691, "bottom each of": 0.001412997877799242, "in the ee": 0.0012953547128852297, "limitations of our": 0.0010599041887614004, "north": 0.0004379656353650362, "raw sensor": 0.0012263127867333846, "of pavlov the": 0.001412997877799242, "turn is": 0.0006807892368766817, "two concept": 0.0013439565011394887, "estimates of": 0.0005101280194599199, "such studies": 0.0009217509760058083, "collected similarly for": 0.001412997877799242, "can is in": 0.0012953547128852297, "hierarchical": 0.0002382140096694762, "contradictory": 0.0007072561018364519, "learn multiple concepts": 0.0012953547128852297, "and are": 0.00020282783737873264, "ample given": 0.0013439565011394887, "several component": 0.0012263127867333846, "distribution on": 0.0006428774807200497, "available is quite": 0.001412997877799242, "the state distribution": 0.002825995755598484, "can represent discontinuous": 0.001412997877799242, "uneven floors etc": 0.001412997877799242, "collected similarly": 0.0012263127867333846, "values that": 0.0005228778271257987, "made": -0.0002473664822031251, "provided that": 0.0003768644665751278, "whether": -9.961597833563253e-05, "wall a": 0.0012263127867333846, "neural net has": 0.001412997877799242, "of true color": 0.001412997877799242, "approaches to decompose": 0.001412997877799242, "the partioning": 0.001157470080128191, "below": -0.0006658060308844007, "converted": 0.00035310202227246875, "of four": 0.0008953544799373226, "to explaining": 0.0013439565011394887, "focus primarily": 0.0009907789071032058, "are used in": 0.0004953002027150228, "concept description e": 0.001412997877799242, "15 three successful": 0.001412997877799242, "was used in": 0.0006797336106182766, "is specified by": 0.001336863479884383, "wall an opening": 0.001412997877799242, "to facilitate learning": 0.001412997877799242, "designer carefully": 0.0013439565011394887, "feature detectors one": 0.001412997877799242, "on board camera": 0.001412997877799242, "processes pomdp": 0.0013439565011394887, "using a navigation": 0.0012953547128852297, "particular in": 0.0007246032270542877, "has some definite": 0.001412997877799242, "adopted in": 0.0007338995299089556, "doing the": 0.0007246032270542877, "872 hand": 0.0026879130022789775, "probability in": 0.0006576990239911289, "grdt algorithm is": 0.001412997877799242, "three times": 0.0006639936831495265, "the floor e": 0.001412997877799242, "learning these related": 0.001412997877799242, "model to represent": 0.001177670521728601, "robots 21 3": 0.001412997877799242, "domain for example": 0.0011087956007827721, "sensory representation": 0.0013439565011394887, "c3 south east": 0.001412997877799242, "functions": -0.00015090776426864003, "scaling and": 0.0008262639069617736, "solution in the": 0.0007653307612006872, "the control": 0.00040919586641565266, "decomposition each image": 0.001412997877799242, "ingredients": 0.0006290922006349871, "fast learning the": 0.001412997877799242, "a strength of": 0.0012265208479459286, "the virtual": 0.0005790069075790211, "features figure": 0.0019414741929052945, "using the same": 0.0005264202030821872, "and contrast some": 0.001412997877799242, "mobile robots to": 0.001412997877799242, "900000000000000000000000000000000011111111111111111111111111111111111111111111000000000000000000000000000000000000111111111111111111111111111111111111 sensor": 0.0013439565011394887, "other": -0.0076720895386761965, "towards smarter": 0.0013439565011394887, "door by": 0.0013439565011394887, "navigational system": 0.0013439565011394887, "to show that": 0.000354891141104935, "epochs a separate": 0.001412997877799242, "junk": 0.0009215946410370149, "the two robotics": 0.001412997877799242, "6 outputs": 0.0012263127867333846, "training phase in": 0.0012953547128852297, "office robot lab18": 0.001412997877799242, "function from": 0.0005731297104135156, "radially": 0.0008181717354969602, "neural net": 0.025308382482031187, "multi task learning": 0.001412997877799242, "more complex since": 0.001177670521728601, "was then": 0.0006672272054388769, "areas indicate that": 0.001412997877799242, "in a physically": 0.001177670521728601, "this is not": 0.00039791412219811396, "1 pavlov a": 0.001412997877799242, "also shows": 0.0005171034306485431, "coded to": 0.0024526255734667692, "and white we": 0.001412997877799242, "prefer shallower": 0.0013439565011394887, "already pre": 0.0013439565011394887, "graph compares": 0.001157470080128191, "program we": 0.0005731297104135156, "net correctly": 0.0026879130022789775, "ranks": 0.0005428999532193917, "which sensor i": 0.001412997877799242, "selecting one pixel": 0.001412997877799242, "believe that directly": 0.001412997877799242, "allows a robot": 0.001412997877799242, "knowledge can": 0.0008623569375540945, "approaches on two": 0.001412997877799242, "idea is fairly": 0.001412997877799242, "examples reinforcement": 0.0013439565011394887, "for programmable autonomous": 0.001412997877799242, "avenue towards smarter": 0.001412997877799242, "inductive bias acting": 0.001412997877799242, "s the": 0.000306613696767932}