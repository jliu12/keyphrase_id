{"systems this hybrid": 0.0008091139115659897, "fact that accuracy": 0.0008091139115659897, "possible reason": 0.001269718529437276, "example of self": 0.0007417488271393706, "goal or": 0.0005363412876789271, "is trying to": 0.0005456884385180774, "genetic algorithms a": 0.0006349209434580451, "still worked": 0.000702264802583379, "be solved": 0.00038590804657978584, "probability following": 0.000702264802583379, "four": -3.4713834039876305e-05, "approach the": 0.0002311124137898519, "markov games littman": 0.0008091139115659897, "the surface for": 0.0006526576017704936, "of actions through": 0.0008091139115659897, "value of the": 0.0004207569019029011, "training consists": 0.000702264802583379, "booker goldberg": 0.0007696350858963753, "of learning to": 0.0007023330300003208, "by a roll": 0.0007417488271393706, "point k": 0.000567383102523159, "payoff": 0.005817407831635164, "with corresponding": 0.00044153169724958527, "may contain": 0.0002953154240675878, "or something close": 0.0007417488271393706, "power of combining": 0.0008091139115659897, "experiments demonstrate significant": 0.0008091139115659897, "high level greater": 0.0008091139115659897, "termination at": 0.0006131469602829721, "addition the": 0.0004743273518917672, "performed even": 0.0005954002535516364, "improvement over k": 0.0008091139115659897, "rithms lamarkian learning": 0.0008091139115659897, "one pursuer problem": 0.0016182278231319793, "to prevent": 0.0002603999475929679, "of fuel": 0.0006628410843555166, "rule of": 0.00036183856746138145, "lazy algorithm": 0.000702264802583379, "topics programming": 0.0007696350858963753, "example this": 0.0003859053049699601, "in terms": 8.264531790288143e-05, "q function": 0.0006131469602829721, "players to make": 0.0008091139115659897, "and grefenstette 1994": 0.0008091139115659897, "stored examples must": 0.0008091139115659897, "the storage of": 0.0005334812968668691, "for learning": 0.001188324493075302, "both directions": 0.00042590150453082544, "in using": 0.0003449470981709676, "several algorithms to": 0.0007417488271393706, "learn plans or": 0.0008091139115659897, "not require quantization": 0.0007417488271393706, "of rl": 0.000634859264718638, "arise in robotics": 0.0008091139115659897, "expect the": 0.00032821057342992757, "particular game": 0.0007696350858963753, "using wilson": 0.0007696350858963753, "e succeeded": 0.0007696350858963753, "are shown": 0.0001508751729120388, "of temporal difference": 0.0007417488271393706, "ga right away": 0.0008091139115659897, "own teacher": 0.000702264802583379, "the network millan": 0.0008091139115659897, "indicates that": 0.00019262270220781963, "action pair s": 0.0008091139115659897, "to find the": 0.0002582952039075888, "naturally causes problems": 0.0008091139115659897, "figure 2 reaching": 0.0008091139115659897, "k nn still": 0.0008091139115659897, "learning process and": 0.0007023330300003208, "their two": 0.0005456354281782176, "the turns": 0.000634859264718638, "state we": 0.0007176449336352503, "escaping from": 0.0006628410843555166, "and lazy q": 0.0016182278231319793, "methods 4 1": 0.0007417488271393706, "particular differential": 0.000702264802583379, "evader a one": 0.0008091139115659897, "one possible": 0.0006127441973022656, "grefenstette simon kasif": 0.0008091139115659897, "definition of": 0.0001282001025608576, "td gammon": 0.0013256821687110331, "second": -0.002385829421039641, "1983 demonstrated": 0.0007696350858963753, "of actions before": 0.0008091139115659897, "several different": 0.0003462531725087664, "the editing procedure": 0.0008091139115659897, "and the anonymous": 0.0004240325865444586, "and actions i": 0.0008091139115659897, "by appending": 0.0005200422895505865, "permit the": 0.00044497617160632185, "on performance": 0.0003449470981709676, "and scale up": 0.0007023330300003208, "of control": 0.0002627707973273995, "from the pursuers": 0.0008091139115659897, "k 0 is": 0.0004882999224935485, "classes and": 0.00032495042922757434, "and crossover rules": 0.0008091139115659897, "to work effectively": 0.0006743602501766612, "superb exceeding": 0.0007696350858963753, "a system of": 0.001006443393706886, "ran ten experiments": 0.0008091139115659897, "typically gas": 0.0007696350858963753, "nn 96 9": 0.0008091139115659897, "perform well": 0.001744580961666511, "niches in": 0.0007696350858963753, "increasing": 1.863924310928657e-05, "learner ramsey": 0.0007696350858963753, "reward or penalty": 0.0008091139115659897, "players positions": 0.0007696350858963753, "an exact": 0.0002945105957876159, "example sets": 0.0006628410843555166, "game in terms": 0.0008091139115659897, "7 next": 0.0005456354281782176, "will for a": 0.0008091139115659897, "nn one possible": 0.0008091139115659897, "here": -0.0005600998697600543, "e evades p": 0.0008091139115659897, "reported": 7.503486379761692e-05, "better solutions than": 0.0007417488271393706, "parking lot": 0.001404529605166758, "three algorithms on": 0.0007023330300003208, "methods for decision": 0.0013487205003533224, "in the ga": 0.002225246481418112, "we halt learning": 0.0008091139115659897, "mccallum": 0.0010255159313671991, "be successful a": 0.0007417488271393706, "a random factor": 0.0008091139115659897, "both lazy": 0.0015392701717927505, "then uses": 0.0008197994375706445, "only controls its": 0.0008091139115659897, "a teaching": 0.0012262939205659443, "k": -0.011453064048579677, "whenever a": 0.00028239161378183786, "gen eral": 0.00045224640365867626, "after each pass": 0.0006743602501766612, "planning for": 0.0010726825753578542, "then used": 0.0002953154240675878, "drops below a": 0.0006199211760863129, "military": 0.0004258601347877918, "sample with the": 0.0008091139115659897, "take turns learning": 0.0008091139115659897, "ga began": 0.0007696350858963753, "accuracy outperforming": 0.0007696350858963753, "classification": 0.0005600998697600544, "attempts to achieve": 0.0006199211760863129, "single pursuer": 0.0038481754294818755, "parameters the speed": 0.0008091139115659897, "surprising result was": 0.0007023330300003208, "as chess and": 0.0008091139115659897, "capabilities of e": 0.0008091139115659897, "function defined below": 0.0008091139115659897, "evasion rate of": 0.0008091139115659897, "50 plans during": 0.0008091139115659897, "in each example": 0.0006526576017704936, "based on genetic": 0.0013487205003533224, "more space and": 0.0007417488271393706, "to transmit": 0.00037664034839981597, "it collected many": 0.0008091139115659897, "learning problems the": 0.0007417488271393706, "in training": 0.0004997652289300559, "opponents": 0.0010911648562732532, "at most 20": 0.0008091139115659897, "problems one": 0.0009121839693001518, "an environment for": 0.0011348764514472745, "nn for evasive": 0.0008091139115659897, "select best": 0.000702264802583379, "a simple task": 0.0006349209434580451, "but little has": 0.0008091139115659897, "started slowly being": 0.0008091139115659897, "therefore": -0.0008239106373820331, "of whether": 0.0003072722989859923, "applies a": 0.0004560919846500759, "those encountered in": 0.0007417488271393706, "5 degrees right": 0.0008091139115659897, "until": -0.00037484249534041264, "this demonstrates that": 0.0005954580987137418, "the mean": 0.0005071504162048275, "examples illustrate": 0.00048296474811893784, "e both p1": 0.0008091139115659897, "above 95": 0.000702264802583379, "complex many": 0.0007696350858963753, "successful": 0.0010288894043653577, "brings": 0.000280236063377934, "learning algorithms": 0.005042243230016787, "to prevent the": 0.00045745222770795314, "of the population": 0.0005759152096655707, "99": 0.00015431877434841996, "98": 0.00036241780267844316, "to vary continuously": 0.0007417488271393706, "same reactive control": 0.0008091139115659897, "91": 0.00016848966055251153, "90": 0.0012282217441097123, "midst": 0.0005953424196270563, "do our experiments": 0.0008091139115659897, "95": 0.0004797225833300869, "94": 0.00017412385966395318, "97": 0.0003188101014817451, "96": 0.00015888831673156617, "k 1 tended": 0.0008091139115659897, "escape depends on": 0.0008091139115659897, "ahead but": 0.0007696350858963753, "pursue": 0.0006498377306398543, "rules using edited": 0.0008091139115659897, "e it is": 0.00038402039400084893, "the example": 0.0007249060187632742, "tac toe and": 0.0007417488271393706, "90 to limit": 0.0008091139115659897, "they showed no": 0.0008091139115659897, "entertainment industries": 0.0007696350858963753, "demonstrate that": 0.0005303867234581381, "binary emitting": 0.0007696350858963753, "example": -0.0049392908955131825, "nn finally the": 0.0008091139115659897, "turn increases so": 0.0008091139115659897, "reward so": 0.0007696350858963753, "this difficult task": 0.0008091139115659897, "slow to": 0.0005060701527920558, "local models to": 0.0016182278231319793, "on four": 0.0004149539560409001, "can be": 3.378922969509918e-06, "those directly using": 0.0008091139115659897, "national science foundation": 0.00031609743499068404, "way that": 0.00019837578175446472, "q learning solves": 0.0008091139115659897, "to cause problems": 0.0008091139115659897, "behavior robot": 0.0007696350858963753, "to start": 0.0002875267402688875, "see in the": 0.0004339731734948358, "these results led": 0.0008091139115659897, "ship routing are": 0.0008091139115659897, "analysis of": 8.670781185388977e-05, "quite small only": 0.0008091139115659897, "were the correct": 0.0008091139115659897, "to learn to": 0.0012138492739842013, "gle ga": 0.0007696350858963753, "feature": 0.00022412814595566802, "machine": 6.485254619937958e-05, "how": -0.0028990114374884413, "is the learning": 0.0006349209434580451, "97 success": 0.0007696350858963753, "algorithm the": 0.0003359100233991918, "this means": 0.0001660434384585759, "been applied": 0.0006275965773301955, "population of solutions": 0.0008091139115659897, "primary cause of": 0.0008091139115659897, "are less than": 0.0004221582211223312, "to be included": 0.00046866225128631864, "label each": 0.0005803901647646488, "8instance": 0.0007021965884209132, "minimized": 0.00017586045852300558, "some individual": 0.000702264802583379, "rule strength and": 0.0008091139115659897, "speed as they": 0.0007417488271393706, "namely evades": 0.0007696350858963753, "state y state": 0.0008091139115659897, "the solution to": 0.00033950437196557105, "the ga provided": 0.0008091139115659897, "in complex domains": 0.0008091139115659897, "types": -1.126200618616019e-06, "consider two": 0.0002658073710966492, "in memory requirements": 0.0007417488271393706, "sequence of state": 0.0006526576017704936, "that points that": 0.0007417488271393706, "learning rather than": 0.0007417488271393706, "sets of 100": 0.0007417488271393706, "wins": 0.0012447409490485748, "determine the winners": 0.0008091139115659897, "requires several": 0.0005456354281782176, "used for simple": 0.0008091139115659897, "e the distance": 0.0006199211760863129, "keeps turning sharply": 0.0008091139115659897, "k nn and": 0.005192241789975595, "keeps": 0.0003748322237982013, "only achieving 2": 0.0008091139115659897, "guarantees that escape": 0.0008091139115659897, "after 20": 0.000634859264718638, "perform the": 0.00022535886933316643, "we first trained": 0.0008091139115659897, "neuronlike adaptive elements": 0.0007417488271393706, "hart s": 0.0007696350858963753, "plans during each": 0.0008091139115659897, "evasion occurred the": 0.0008091139115659897, "feedback": 0.0003470997896593508, "search credit": 0.0007696350858963753, "state hidden": 0.0007696350858963753, "an agent": 0.002339179649147876, "vary": 0.00012400968436223982, "system centered on": 0.0008091139115659897, "possibility of": 0.0002311124137898519, "learning after about": 0.0008091139115659897, "behind our success": 0.0008091139115659897, "is the state": 0.00046866225128631864, "was about 90": 0.0008091139115659897, "is more": 0.0001080420598703441, "database of": 0.00039610816435843403, "the evader from": 0.0008091139115659897, "as many": 0.00023202315752870006, "matcher which": 0.0007696350858963753, "achieving 91": 0.0007696350858963753, "poor examples were": 0.0008091139115659897, "examples required for": 0.0007417488271393706, "of 100": 0.00034112545549164767, "maneuvering game by": 0.0008091139115659897, "the first step": 0.00030087107663277584, "as with k": 0.0007023330300003208, "decision problem since": 0.0008091139115659897, "was quite": 0.00048825248710181613, "training but": 0.000702264802583379, "method alone and": 0.0008091139115659897, "to control tasks": 0.0008091139115659897, "have limited": 0.0004560919846500759, "known optimal": 0.0006628410843555166, "niches in the": 0.0008091139115659897, "hidden": 0.0005565687901320256, "pursuer will grab": 0.0008091139115659897, "upper an example": 0.0008091139115659897, "state variable": 0.0009558929329372694, "artifact of perceptual": 0.0008091139115659897, "without explicitly generating": 0.0008091139115659897, "nn all": 0.0007696350858963753, "to be poor": 0.0008091139115659897, "one algorithm train": 0.0008091139115659897, "distance to": 0.0003462531725087664, "the direction": 0.0002558042537419382, "strength and": 0.0011607803295292977, "attributes however determining": 0.0008091139115659897, "effects": 0.00023000506318781357, "pursue a": 0.0005954002535516364, "learning techniques": 0.0005060701527920558, "9 theta": 0.0006131469602829721, "is a discount": 0.0008091139115659897, "be too strict": 0.0007417488271393706, "represents": -1.5801519744199603e-05, "improves decision": 0.0007696350858963753, "success was the": 0.0007417488271393706, "examples stored": 0.0023089052576891257, "suitable for": 0.00024405533553294298, "complex sequential": 0.0006628410843555166, "samuel with": 0.0007696350858963753, "until reaching": 0.000567383102523159, "of reinforcement learning": 0.0006526576017704936, "games achieving": 0.0007696350858963753, "human teacher": 0.000702264802583379, "games but": 0.0015392701717927505, "examples stores": 0.0007696350858963753, "noise tomek": 0.0007696350858963753, "search space is": 0.0005524148804057065, "plateau between 5": 0.0008091139115659897, "is to": 0.00011269891282785285, "ga evades if": 0.0008091139115659897, "the payoff the": 0.0008091139115659897, "reinforcement learning with": 0.0007417488271393706, "hypothesis was": 0.0005456354281782176, "of solutions dependent": 0.0008091139115659897, "as learning": 0.0005559058853301298, "also generate random": 0.0008091139115659897, "series": 0.0002766875384761948, "predict both future": 0.0008091139115659897, "begins by": 0.00041758029726340933, "ga based": 0.0005954002535516364, "paths of": 0.0003489161923333023, "the network": 0.00021502160361016836, "to use genetic": 0.0016182278231319793, "train a lazy": 0.0008091139115659897, "x reward is": 0.0008091139115659897, "selected action": 0.000702264802583379, "problems widrow": 0.0015392701717927505, "substantially": 0.0004988963073324921, "alone with": 0.000634859264718638, "have converged": 0.0005954002535516364, "backgammon": 0.0023813696785082252, "been done": 0.0008717242443223618, "simulator passes the": 0.0008091139115659897, "highest fitness": 0.000702264802583379, "some task": 0.0005803901647646488, "probability 0": 0.0014488942443568135, "within 5 000": 0.0008091139115659897, "outperforms its": 0.0007696350858963753, "stores up": 0.0007696350858963753, "performing some task": 0.0008091139115659897, "these games": 0.0018394408808489165, "learning method k": 0.0008091139115659897, "time steps since": 0.0007417488271393706, "adapt": 0.00038520798378383585, "level equal": 0.0007696350858963753, "rl": 0.0007837281472855552, "delayed rewards": 0.0006628410843555166, "a reward": 0.000634859264718638, "introduction when": 0.00052785331295456, "of solving this": 0.0007023330300003208, "approaches such as": 0.0005393947462253054, "foundation": 0.00013074506672966981, "that gll performed": 0.0008091139115659897, "evade a": 0.0007696350858963753, "sharpness of the": 0.0006199211760863129, "just keeps turning": 0.0008091139115659897, "systems for": 0.0002754534187430607, "it still worked": 0.0008091139115659897, "colearning in differential": 0.0007417488271393706, "pursuers p1": 0.0015392701717927505, "evade p": 0.0007696350858963753, "then compared": 0.0004731713358791195, "nearer bound is": 0.0008091139115659897, "were able": 0.0009947286924941704, "estimate": 0.00011043254593193994, "learning in the": 0.0005393947462253054, "erratically but": 0.0007696350858963753, "had no way": 0.0006743602501766612, "enormous": 0.00034888230052248793, "communication or": 0.0005128077770266814, "speed and one": 0.0008091139115659897, "might be percent": 0.0008091139115659897, "set consisted of": 0.0005851984448616567, "the population are": 0.0007417488271393706, "to find": 0.00045988642825535507, "9223591 r": 0.0007696350858963753, "of the task": 0.00042987704457580605, "to solve the": 0.0007842211907587189, "can be applied": 0.00023927628110257646, "speeds": 0.0012381958090944979, "games do not": 0.0007417488271393706, "to design a": 0.0004240325865444586, "was having": 0.0006628410843555166, "fast 6 discussion": 0.0008091139115659897, "metrics for instance": 0.0016182278231319793, "of competitive games": 0.0008091139115659897, "experiments were encouraging": 0.0008091139115659897, "examples include such": 0.0008091139115659897, "k nn all": 0.0008091139115659897, "being that such": 0.0008091139115659897, "controls its": 0.0006628410843555166, "capture e": 0.001404529605166758, "differential games to": 0.0008091139115659897, "1992 mccallum": 0.0007696350858963753, "respectively for some": 0.0007417488271393706, "instance attrib then": 0.0008091139115659897, "such an": 0.00033371896193400683, "e to escape": 0.0008091139115659897, "similarly": -3.0370810338972582e-05, "engagement": 0.000567327990031413, "averaging the associated": 0.0008091139115659897, "needed": -5.858676315948151e-05, "master": 0.00029210341667957533, "obstacles considerable research": 0.0008091139115659897, "it might": 0.0005577344504822629, "which will": 0.0002174224613812204, "such as": 0.0003201666875272627, "high 1 low": 0.0008091139115659897, "a known": 0.00032932038867923357, "task is the": 0.0005851984448616567, "more complicated": 0.0005082566781673908, "finally the threshold": 0.0008091139115659897, "rewards": 0.0013566074247486392, "in terms of": 0.00013541822969687968, "approach similar to": 0.0005279045957013737, "to determine optimal": 0.0006069246369921007, "is the history": 0.0007417488271393706, "what they call": 0.0006743602501766612, "the midst of": 0.0007023330300003208, "1992 mccallum showed": 0.0008091139115659897, "control tasks in": 0.0007417488271393706, "although all": 0.0004997652289300559, "are within": 0.0003714629793944916, "degrees is close": 0.0008091139115659897, "for one": 0.0002126674618296013, "reasonably expect the": 0.0008091139115659897, "learning algorithms to": 0.0012398423521726258, "states and": 0.0018067550529544997, "action asymptotic properties": 0.0008091139115659897, "then communicate what": 0.0008091139115659897, "showed": 0.00044378624393927486, "military and entertainment": 0.0008091139115659897, "action a": 0.0008637241337018897, "tree": 0.00011532843277695657, "until it": 0.0005858377456146533, "the task requires": 0.0007023330300003208, "to learn": 0.002591087969690619, "85 after twice": 0.0008091139115659897, "action with the": 0.0006743602501766612, "method could": 0.000946342671758239, "distance bearing": 0.0007696350858963753, "are discarded": 0.00042304989757217126, "to grefenstette et": 0.0008091139115659897, "a one pursuer": 0.0008091139115659897, "suggests that a": 0.0005226282087022614, "games one": 0.0038481754294818755, "used for markov": 0.0008091139115659897, "action prioritized sweeping": 0.0008091139115659897, "1 high 1": 0.0008091139115659897, "the pedestrian can": 0.0008091139115659897, "contains up to": 0.0007417488271393706, "difficulty of": 0.0006654456183183088, "1 low": 0.0006628410843555166, "since training consists": 0.0008091139115659897, "using 1": 0.0004382027886649359, "responsible": 0.00018933724154262334, "reduce the size": 0.0008809047960363514, "by the players": 0.0016182278231319793, "the sample": 0.0003054794925471542, "and time": 0.0002541283390836954, "an earlier draft": 0.0005524148804057065, "these examples can": 0.0008091139115659897, "at a very": 0.0005393947462253054, "such simple": 0.0005559058853301298, "e evades two": 0.0008091139115659897, "information about": 0.00017852531974008515, "pursuers k nn": 0.0008091139115659897, "it did": 0.0004382027886649359, "x axis to": 0.0007023330300003208, "motivated by the": 0.00035738190863582157, "which is described": 0.0004779929005953682, "on difficult delayed": 0.0008091139115659897, "time step": 0.001243807314622706, "object": 6.859827704004837e-05, "in addition the": 0.0005653163042484318, "interest probability": 0.0007696350858963753, "metrics": 0.000416142303378631, "continues until": 0.0012083009987563975, "prob lem": 0.0003714629793944916, "contain up": 0.0005954002535516364, "opponent in": 0.000634859264718638, "likewise machine learning": 0.0008091139115659897, "the x axis": 0.00038275883369467365, "find any nearby": 0.0008091139115659897, "and target": 0.00042590150453082544, "neural networks barto": 0.0008091139115659897, "s samuel system": 0.0008091139115659897, "course we": 0.0004004979458675273, "to approximate": 0.0002831104418951413, "the same task": 0.0004882999224935485, "strategy imado ishihara": 0.0008091139115659897, "a bootstrapping": 0.0006628410843555166, "testing the": 0.0006847672985756632, "1971 3": 0.0007696350858963753, "using k": 0.0009876810077484722, "system begins an": 0.0008091139115659897, "temporal difference algorithms": 0.0008091139115659897, "likewise machine": 0.0007696350858963753, "curvature our extended": 0.0008091139115659897, "by encoding": 0.00048825248710181613, "using a": 0.0004144955615286683, "though much": 0.0007696350858963753, "the ga started": 0.0008091139115659897, "editing algorithm for": 0.0008091139115659897, "relative to": 0.0004066375688773674, "incorporate": 0.0001614907953130693, "result of": 0.00011379864819581871, "bomb": 0.0007021965884209132, "the fact that": 0.0002732025337314858, "complete game at": 0.0008091139115659897, "payoff and determining": 0.0008091139115659897, "and all": 0.00015063118441919246, "within the": 0.00024928400201893077, "reinforcement problems is": 0.0008091139115659897, "then stored at": 0.0008091139115659897, "called a pursuit": 0.0008091139115659897, "in training we": 0.0008091139115659897, "stored in the": 0.0003135086419505659, "solutions than either": 0.0008091139115659897, "lethal": 0.0007021965884209132, "lem and": 0.0006628410843555166, "90 success rate": 0.0008091139115659897, "pair that is": 0.0006349209434580451, "that operationalizes": 0.0007696350858963753, "is required": 0.0001655020401378066, "lazy q": 0.0038481754294818755, "general as a": 0.0006526576017704936, "some asymptotic": 0.0006628410843555166, "to adapt": 0.00032821057342992757, "the ability": 0.0012440700890365244, "switched to": 0.00052785331295456, "p will be": 0.0005759152096655707, "difficulty here then": 0.0008091139115659897, "gll performs quite": 0.0008091139115659897, "50 80 success": 0.0008091139115659897, "and genetic algorithms": 0.0012698418869160901, "to chess": 0.000634859264718638, "1 bootstrapping nearest": 0.0008091139115659897, "payoff received from": 0.0008091139115659897, "and strategies are": 0.0007417488271393706, "the corresponding": 0.00021396714993289116, "this permits": 0.00046861672357587705, "decision making in": 0.0006349209434580451, "the direction that": 0.0007023330300003208, "in nearest neighbor": 0.0007023330300003208, "7 5 theta": 0.0007417488271393706, "focus of updating": 0.0008091139115659897, "for example 359": 0.0008091139115659897, "phase of gll": 0.0008091139115659897, "so that p": 0.0004958241803403253, "to label": 0.00045224640365867626, "of computing": 0.00021502160361016836, "problem of teaching": 0.0008091139115659897, "passed to k": 0.0007417488271393706, "at every": 0.0002961263574580495, "exceeding the": 0.0009995304578601118, "through a genetic": 0.0008091139115659897, "complex domains and": 0.0008091139115659897, "at least": 0.00023313850320417226, "45 this demonstrates": 0.0008091139115659897, "occurs in a": 0.0005083144306061808, "discarded the": 0.0004779464664686347, "where lb i": 0.0008091139115659897, "tests for each": 0.0007023330300003208, "is zero basar": 0.0008091139115659897, "our strategy for": 0.0005954580987137418, "we limit feedback": 0.0008091139115659897, "hidden state": 0.0017862007606549094, "release": 0.00023477604289546367, "additional information": 0.00033865419457809065, "at 90 for": 0.0008091139115659897, "system reaches some": 0.0008091139115659897, "single plan": 0.0006628410843555166, "problem since the": 0.0004958241803403253, "50 80": 0.0007696350858963753, "a three dimensional": 0.0004319040237213277, "goldberg 1989 namely": 0.0008091139115659897, "of those": 0.00020623389645783668, "of p1": 0.0010121403055841115, "are using": 0.00034112545549164767, "to the homicidal": 0.0008091139115659897, "the amount of": 0.00022380728235843543, "radius": 0.0014885276313275774, "result": -0.0016176297535569833, "is not one": 0.0005759152096655707, "metagamer has": 0.0007696350858963753, "randomly if lined": 0.0008091139115659897, "differential games is": 0.0008091139115659897, "was superior to": 0.0007023330300003208, "learner and the": 0.0007023330300003208, "best": -0.0002733372930507533, "monitor the": 0.00039610816435843403, "training is": 0.0005128077770266814, "smoke bombs which": 0.0008091139115659897, "by clouse and": 0.0008091139115659897, "points the one": 0.0008091139115659897, "solution to": 0.0005022185093159821, "state information": 0.0007532806967996319, "iri": 0.0006676995553974513, "algorithm classifies each": 0.0008091139115659897, "changes of": 0.00040989971878532225, "pursuers for 20": 0.0008091139115659897, "use of a": 0.00027525632410922143, "ga based teacher": 0.0008091139115659897, "using lazy learning": 0.0008091139115659897, "the evasion task": 0.0008091139115659897, "well even": 0.00052785331295456, "nature": 6.828031506640578e-05, "to a particular": 0.0003655094953325257, "for markov": 0.0005803901647646488, "proceeds as": 0.0003530449562101758, "any nearby": 0.0007696350858963753, "teach a": 0.0015392701717927505, "through 5 000": 0.0008091139115659897, "8s2rules": 0.0007021965884209132, "resembles complicated planning": 0.0008091139115659897, "the pursuer and": 0.0008091139115659897, "task acknowledgments": 0.000702264802583379, "games will be": 0.0008091139115659897, "based on our": 0.00041499427023074183, "one and two": 0.0019992551312954412, "nearest neighbors and": 0.0014834976542787413, "delay between": 0.0004382027886649359, "hypothesized k": 0.0007696350858963753, "10 000 random": 0.0006743602501766612, "demonstrate that the": 0.00041851198115822714, "then updates the": 0.0007023330300003208, "methods apply reinforcement": 0.0008091139115659897, "initial database of": 0.0007417488271393706, "we describe": 0.00013445030160621737, "single pursuer game": 0.0008091139115659897, "learning methods": 0.0019117858658745388, "decision making problems": 0.0007417488271393706, "change direction": 0.0006628410843555166, "of the genetic": 0.0007023330300003208, "took advantage of": 0.0006069246369921007, "problems the more": 0.0008091139115659897, "pursuer one evader": 0.0008091139115659897, "end results": 0.0007696350858963753, "of both": 0.0003256516974806242, "find the k": 0.0006743602501766612, "therefore modified a": 0.0008091139115659897, "original work": 0.0005456354281782176, "must be appended": 0.0007023330300003208, "figure 2 performance": 0.0006743602501766612, "procedure of": 0.00037664034839981597, "algo rithms lamarkian": 0.0008091139115659897, "3 the problem": 0.0006199211760863129, "decide which": 0.0004004979458675273, "turning sharply so": 0.0008091139115659897, "the sensor readings": 0.0008091139115659897, "of their": 0.00013291974505704414, "the game including": 0.0008091139115659897, "practical issues in": 0.0013487205003533224, "this hybrid": 0.000567383102523159, "salzberg et": 0.0007696350858963753, "to encapsulate some": 0.0008091139115659897, "and crossover": 0.0006628410843555166, "clouse and utgoff": 0.0016182278231319793, "both the ga": 0.0008091139115659897, "different types": 0.0005720689681691161, "this paper also": 0.0005083144306061808, "with the initial": 0.000449806936615026, "one must": 0.00033865419457809065, "grefenstette et": 0.005387445601274626, "much": -0.000899429073290757, "state y is": 0.0008091139115659897, "e evades a": 0.0008091139115659897, "as those encountered": 0.0008091139115659897, "wall socket": 0.0007696350858963753, "this work": 0.00010956007804161377, "those bad": 0.0007696350858963753, "own starts performing": 0.0008091139115659897, "experiments applying three": 0.0008091139115659897, "good examples to": 0.0008091139115659897, "this range": 0.0003982790696131452, "this class of": 0.0003802820132290351, "1991 that": 0.0006131469602829721, "salzberg 1993 used": 0.0008091139115659897, "dt where": 0.0005559058853301298, "table that": 0.0004074652591731264, "used the genetic": 0.0008091139115659897, "used it to": 0.0005759152096655707, "environments specifically we": 0.0008091139115659897, "updating mccallum 1995": 0.0008091139115659897, "a necessary component": 0.0007417488271393706, "reaches a": 0.0006951521067430843, "worked": 0.00027342865430586913, "and the ga": 0.0006743602501766612, "examples from": 0.00042590150453082544, "of the mean": 0.00046289837369057756, "assuming that": 0.0001836745797320467, "pursuer p": 0.0007696350858963753, "pursuer s": 0.000702264802583379, "we extended it": 0.0008091139115659897, "with state": 0.0008460997951443425, "nn is still": 0.0008091139115659897, "nn the": 0.000634859264718638, "game extremely well": 0.0008091139115659897, "not better": 0.000567383102523159, "they use": 0.0003197335749799009, "euclidean": 0.0004102255114597366, "prior state information": 0.0008091139115659897, "where e successfully": 0.0008091139115659897, "pursuer e": 0.0007696350858963753, "n each": 0.00039610816435843403, "architecture in": 0.0003839830887362287, "reinforcement learning called": 0.0008091139115659897, "whitehead 1992": 0.0007696350858963753, "algorithms on the": 0.00044270962419637705, "it was clear": 0.0006349209434580451, "improving the": 0.00025357520810241374, "improves somewhat": 0.000634859264718638, "changing strategy of": 0.0008091139115659897, "coordinate system": 0.0003714629793944916, "98 100": 0.0007696350858963753, "thus basically": 0.0007696350858963753, "agent takes a": 0.0008091139115659897, "player": 0.0028584998430993777, "rare in": 0.00048825248710181613, "somewhat inflated": 0.0007696350858963753, "wilson s algorithm": 0.0008091139115659897, "a minimum threshold": 0.0008091139115659897, "take bad": 0.0007696350858963753, "we extended": 0.0004779464664686347, "systems and genetic": 0.0016182278231319793, "achieve an": 0.00041758029726340933, "severity": 0.000452202474916213, "some of the": 0.00017903882420248617, "also capable of": 0.0006349209434580451, "fill in": 0.0003681525887744991, "know the correct": 0.0007023330300003208, "formulation similar to": 0.0006743602501766612, "worked quite": 0.000702264802583379, "goals training": 0.0007696350858963753, "at each": 0.0003942101548543238, "to use until": 0.0008091139115659897, "we observed after": 0.0008091139115659897, "action at random": 0.0008091139115659897, "peak performance": 0.0004997652289300559, "step thus basically": 0.0008091139115659897, "immediately and": 0.0005803901647646488, "learning process": 0.00045224640365867626, "by a margin": 0.0016182278231319793, "a single constant": 0.0006743602501766612, "and beyond what": 0.0007417488271393706, "stored since": 0.000702264802583379, "000 games in": 0.0008091139115659897, "10 success further": 0.0008091139115659897, "out that": 0.00020404116742445282, "the nearer bound": 0.0007417488271393706, "converge and": 0.0005363412876789271, "substantially harder": 0.000702264802583379, "nn on 10": 0.0008091139115659897, "dorigo and colombetti": 0.0008091139115659897, "with probability 0": 0.0011703968897233135, "salzberg et al": 0.0008091139115659897, "of actions taken": 0.0008091139115659897, "to train the": 0.0005334812968668691, "examples ga": 0.0007696350858963753, "benefit from": 0.0003037165348615905, "ctr john": 0.0005363412876789271, "required for": 0.00037486863648751535, "simulated": 0.0002818751141241277, "using local models": 0.0016182278231319793, "generation the fact": 0.0007417488271393706, "0 01": 0.0003530449562101758, "with strategic": 0.000702264802583379, "the frequency": 0.0002831104418951413, "4 4": 0.0009674644230476117, "using genetic": 0.0004997652289300559, "4 2": 0.00015302395159346927, "4 1": 0.0001455437171543203, "single pursuer problems": 0.0008091139115659897, "in comparison": 0.0002953154240675878, "above 90 after": 0.0008091139115659897, "think of": 0.0002921317927643509, "rule of interest": 0.0008091139115659897, "n 2": 7.084091602242208e-05, "more difficult for": 0.0006069246369921007, "chess checkers": 0.0007696350858963753, "arena while": 0.0007696350858963753, "wal 1981 markov": 0.0008091139115659897, "previous": -0.0004878329958684523, "then performance flattened": 0.0008091139115659897, "replayed": 0.00046004841655118944, "for the adaptive": 0.0011909161974274836, "sequence memory algorithm": 0.0008091139115659897, "implementation takes only": 0.0008091139115659897, "how actions": 0.000702264802583379, "to one of": 0.00032427110244429073, "then proceeds": 0.0004997652289300559, "had": 0.0004677600766880202, "hybrid system that": 0.0007417488271393706, "genetic operators mutation": 0.0008091139115659897, "heading is": 0.000634859264718638, "in dasarathy": 0.0007696350858963753, "initial training is": 0.0008091139115659897, "are maximally": 0.000702264802583379, "easy": -3.0370810338972582e-05, "2 reducing memory": 0.0008091139115659897, "an architecture": 0.00033988242810104627, "good actions": 0.0015392701717927505, "east": 0.00032928840029762313, "payoff the": 0.000702264802583379, "of three different": 0.0005954580987137418, "of selection": 0.0009285260332449058, "applicable to": 0.0002513894493847149, "taken by": 0.0008493313256854239, "clouse": 0.0019043927938845048, "evasion performance": 0.0007696350858963753, "possible": -0.0018707482500706174, "possibly": 4.618005796163912e-05, "issues in": 0.0005340914273401683, "the stored instances": 0.0008091139115659897, "that k": 0.0010782595150566005, "p2 run": 0.0007696350858963753, "that e": 0.0005127369981766579, "that a": 6.219093280280993e-05, "number of training": 0.0004958241803403253, "learner that the": 0.0008091139115659897, "population for the": 0.0007417488271393706, "a set used": 0.0008091139115659897, "as grefenstette": 0.0007696350858963753, "applied in": 0.00028167752214893036, "series of actions": 0.0008091139115659897, "7 next steps": 0.0008091139115659897, "to permit": 0.00040276699958546587, "base guarantees that": 0.0008091139115659897, "approximately 95 4": 0.0008091139115659897, "are the focus": 0.0006743602501766612, "might be possible": 0.0005524148804057065, "includes 13": 0.000702264802583379, "conjunctive goals credit": 0.0008091139115659897, "steps": -0.00016437608574021035, "evasive maneuvering game": 0.0008091139115659897, "his metagamer focused": 0.0008091139115659897, "ability of p": 0.0007417488271393706, "of curvature intuitively": 0.0008091139115659897, "and forth or": 0.0008091139115659897, "agent trying": 0.0007696350858963753, "right": -0.00016694681543613757, "those results": 0.0005200422895505865, "people": 0.0002150007175874767, "very difficult for": 0.0006743602501766612, "using the complete": 0.0008091139115659897, "for only": 0.00035882246681762515, "solve complex sequential": 0.0008091139115659897, "embedded in a": 0.00048474305809383046, "rate 0": 0.0006131469602829721, "assuming optimal": 0.0007696350858963753, "dimensional vector": 0.00041758029726340933, "the maximum q": 0.0008091139115659897, "transmit information": 0.0007696350858963753, "algorithms most": 0.0005803901647646488, "modeled by": 0.0003037165348615905, "games in which": 0.0013487205003533224, "number of examples": 0.003323485315339342, "nn by a": 0.0008091139115659897, "traveling at fixed": 0.0008091139115659897, "of the state": 0.0013781954806852076, "using this method": 0.0005674382257236372, "the learning rate": 0.0012398423521726258, "cancel out values": 0.0008091139115659897, "for": 0, "as the number": 0.000540887682015339, "with performance": 0.0005060701527920558, "information with state": 0.0008091139115659897, "is exploring": 0.000702264802583379, "data set with": 0.0005596382660342995, "actions randomly": 0.001404529605166758, "consists of": 0.00016361515796585991, "requires that": 0.00024006682541839522, "focus on": 0.00017734209036133165, "good examples is": 0.0008091139115659897, "its own thus": 0.0007417488271393706, "in the lazy": 0.0007023330300003208, "ga provided examples": 0.0008091139115659897, "algorithm further to": 0.0007417488271393706, "being an": 0.00042590150453082544, "benefits above and": 0.0008091139115659897, "particular problem in": 0.0007023330300003208, "behavior for the": 0.0005176213124249083, "to robot path": 0.0016182278231319793, "of genetic algorithms": 0.0006199211760863129, "from a single": 0.00037786441809092093, "hard to": 0.00022753861360478008, "k nn based": 0.0008091139115659897, "shifting": 0.0002708200979869593, "in a simplified": 0.0006526576017704936, "mingers 1989 wilson": 0.0008091139115659897, "ga surpassing both": 0.0008091139115659897, "5 4 theta": 0.0008091139115659897, "zero basar": 0.0007696350858963753, "3 of generating": 0.0008091139115659897, "responsible for the": 0.0004339731734948358, "stores examples": 0.0015392701717927505, "work in": 0.000173566754154994, "train the network": 0.0007417488271393706, "in section": 3.602677083064784e-05, "k a vector": 0.0008091139115659897, "elements that": 0.0003462531725087664, "o": -5.674418974426016e-05, "of curvature of": 0.0007417488271393706, "level 3 the": 0.0006199211760863129, "later we": 0.0007117858259431993, "using differential": 0.000634859264718638, "a form of": 0.0007418794663306229, "wins or": 0.0007696350858963753, "transmit examples": 0.0007696350858963753, "some task and": 0.0008091139115659897, "of combining different": 0.0008091139115659897, "radius of curvature": 0.0039159456106229625, "k nn almost": 0.0008091139115659897, "markovian": 0.0014176983897218167, "tasks the": 0.00038024507112555464, "space and": 0.00044899620413694916, "other in learning": 0.0008091139115659897, "awarded immediately delayed": 0.0008091139115659897, "tic tac": 0.0006628410843555166, "know which attributes": 0.0008091139115659897, "agent is using": 0.0008091139115659897, "the stored": 0.0012608328333436837, "d 2": 0.0002513894493847149, "d 1": 0.0007623850172510863, "play backgammon classifier": 0.0008091139115659897, "editing methods specifically": 0.0008091139115659897, "to developing": 0.0005200422895505865, "games one complication": 0.0008091139115659897, "reducing": 0.00011226442659790499, "a probability": 0.00030459434776852046, "similar distributions of": 0.0008091139115659897, "effectively at any": 0.0008091139115659897, "learning algorithms working": 0.0008091139115659897, "1988 as follows": 0.0008091139115659897, "1991 algorithms for": 0.0008091139115659897, "but not": 0.0001398112262069393, "1992 tesauro 1992": 0.0008091139115659897, "al 1990 studied": 0.0008091139115659897, "the three": 0.0005351703423439763, "to hart": 0.0007696350858963753, "our bootstrapping idea": 0.0008091139115659897, "for the jth": 0.0006743602501766612, "expected payoff to": 0.0008091139115659897, "plan and the": 0.0006743602501766612, "of expected payoff": 0.0008091139115659897, "algorithms to determine": 0.0006526576017704936, "resulted": 0.00044981171081556233, "though is": 0.0005456354281782176, "to show how": 0.0003975888325128001, "halls": 0.0007021965884209132, "pursuer pursuer": 0.0015392701717927505, "areas and": 0.0004560919846500759, "these problems one": 0.0008091139115659897, "namely evades the": 0.0008091139115659897, "game as the": 0.0008091139115659897, "e is facing": 0.0016182278231319793, "dice distinguishes": 0.0007696350858963753, "denoting": 0.00021821229979048103, "genetic algorithm to": 0.0014834976542787413, "interpret differential games": 0.0008091139115659897, "othello pell": 0.0007696350858963753, "are important for": 0.00046289837369057756, "differential game called": 0.0008091139115659897, "nn is probably": 0.0008091139115659897, "barto et al": 0.002427341734697969, "for each rule": 0.0006199211760863129, "ase with a": 0.0008091139115659897, "which meant that": 0.0007417488271393706, "end results show": 0.0008091139115659897, "source of difficulty": 0.0006743602501766612, "a particular": 0.0003827002417789765, "as described above": 0.00034985342360325584, "by p 1": 0.0005176213124249083, "system reaches": 0.0006131469602829721, "the driver of": 0.0007417488271393706, "inside": 0.00010784267378953168, "achieved better": 0.000702264802583379, "not able": 0.0003489161923333023, "or two particularly": 0.0008091139115659897, "phase we used": 0.0008091139115659897, "algorithm to a": 0.0010558091914027474, "neighbors those points": 0.0008091139115659897, "to fill": 0.0003898632748579793, "averaging cyclic values": 0.0008091139115659897, "examples": -0.0018762017059888716, "ga plus": 0.0007696350858963753, "as few": 0.00042590150453082544, "performance remained in": 0.0008091139115659897, "likely to": 0.00019229223543292377, "homogenous": 0.00046004841655118944, "random games will": 0.0008091139115659897, "of randomly": 0.0008699637295945586, "approach ritter et": 0.0008091139115659897, "problem the state": 0.0007417488271393706, "significantly affecting": 0.000634859264718638, "perform a task": 0.0006743602501766612, "though the": 0.00022753861360478008, "is given the": 0.0004601378070916638, "learns the task": 0.0008091139115659897, "result was a": 0.0006349209434580451, "games are difficult": 0.0008091139115659897, "eventual": 0.00038020813619878184, "lazy approach must": 0.0008091139115659897, "for each state": 0.0009096752703596502, "action associated with": 0.0008091139115659897, "selection is determined": 0.0008091139115659897, "state depends": 0.0005954002535516364, "in neural": 0.0005456354281782176, "schultz 1990 can": 0.0008091139115659897, "steps i": 0.0004938405038742361, "until termination": 0.001269718529437276, "roll": 0.0003665013746209431, "idea requires": 0.0007696350858963753, "a similar": 0.00023627390758738419, "radius circle centered": 0.0008091139115659897, "is grefenstette s": 0.0008091139115659897, "models": -5.980627067337377e-05, "the set": 0.00041878653038741903, "solution strategies": 0.0006628410843555166, "particularly good": 0.0005803901647646488, "ga and it": 0.0008091139115659897, "of reinforcement": 0.0006131469602829721, "a plan for": 0.0014046660600006416, "research has": 0.0003374403959319754, "variable": -6.274526244769328e-05, "theory to assist": 0.0008091139115659897, "experiment q": 0.0007696350858963753, "store almost immediately": 0.0008091139115659897, "obtained a success": 0.0008091139115659897, "similar fashion to": 0.0006526576017704936, "values that were": 0.0006526576017704936, "has two players": 0.0008091139115659897, "this approach is": 0.00027706015240296664, "thus making": 0.0004349818647972793, "and capture": 0.0005803901647646488, "is even": 0.00024977745859821677, "n high n": 0.0008091139115659897, "its speed": 0.0011118117706602597, "fixed playing arena": 0.0008091139115659897, "payoff or": 0.0007696350858963753, "1 and": 7.351140049162098e-05, "fact we": 0.00029694349427019246, "time": -0.004626983655221359, "the popular video": 0.0008091139115659897, "dimension of": 0.00029135044701075676, "a vector": 0.00020260056961542738, "limit because the": 0.0008091139115659897, "learn a": 0.00045224640365867626, "to cancel": 0.0005363412876789271, "too have": 0.000702264802583379, "reviewers": 0.0002329184334918281, "are encoded": 0.000391902140873557, "stored since our": 0.0008091139115659897, "modified a known": 0.0008091139115659897, "is the more": 0.00048474305809383046, "all of which": 0.00042031844251562157, "strategies for learning": 0.0008091139115659897, "to examine the": 0.00038529791840416234, "explore the": 0.0003147644852783128, "classic pursuit game": 0.0008091139115659897, "in size": 0.00030909603197861395, "93": 0.0003229815906261386, "of e but": 0.0007023330300003208, "only 66": 0.0006628410843555166, "early 1960s isaacs": 0.0008091139115659897, "can be seeded": 0.0008091139115659897, "checked for": 0.00040989971878532225, "two particularly good": 0.0008091139115659897, "basically keeps only": 0.0008091139115659897, "3 2 the": 0.0003122377618813423, "and its": 0.00013848397835726278, "there was an": 0.0005954580987137418, "nn alone if": 0.0008091139115659897, "the field": 0.0002875267402688875, "e succeeds": 0.0007696350858963753, "perceptions is": 0.0007696350858963753, "into the path": 0.0007023330300003208, "the different": 0.0001963154002722508, "well k nn": 0.0008091139115659897, "similar to the": 0.00037448154248799454, "clouse utgoff 1992": 0.0008091139115659897, "this material is": 0.0004919901420568756, "the pursuit games": 0.0008091139115659897, "feedback on performance": 0.0008091139115659897, "editing methods however": 0.0008091139115659897, "until inside": 0.0007696350858963753, "begin by considering": 0.0005759152096655707, "multi agent tasks": 0.0008091139115659897, "choice": -1.7219465280591964e-05, "difficulty solving": 0.0007696350858963753, "these algorithms to": 0.0006349209434580451, "ga system strength": 0.0008091139115659897, "classification accuracy in": 0.0006743602501766612, "to date little": 0.0007417488271393706, "second pursuer adversely": 0.0008091139115659897, "actions if k": 0.0008091139115659897, "p to escape": 0.0008091139115659897, "exact": 3.90914709569069e-05, "isaacs 1963 as": 0.0008091139115659897, "perfect accuracy": 0.0006628410843555166, "prespecified": 0.00047790004136261533, "solves": 0.00015683967024455008, "game by initializing": 0.0008091139115659897, "required during": 0.0005363412876789271, "ga each": 0.000702264802583379, "solved": 0.00011104263797613179, "probably a": 0.0005456354281782176, "players to": 0.001134766205046318, "of trials 5": 0.0008091139115659897, "ran for": 0.0005803901647646488, "crossover rules within": 0.0008091139115659897, "is new": 0.00044497617160632185, "ga eventually": 0.0007696350858963753, "sharply so": 0.0007696350858963753, "objective frequently": 0.0007696350858963753, "determined as": 0.0003859053049699601, "prevent": 0.00013598223773906526, "mapping from a": 0.0005524148804057065, "striking observation": 0.0006628410843555166, "algorithm gll init": 0.0008091139115659897, "in a form": 0.0005039721952628732, "comparing the three": 0.0007417488271393706, "method our experiments": 0.0007417488271393706, "evading the": 0.0007696350858963753, "learning for evasive": 0.0008091139115659897, "assume that both": 0.0005039721952628732, "5 did not": 0.0008091139115659897, "set at 90": 0.0008091139115659897, "e or conversely": 0.0008091139115659897, "he calls": 0.0006131469602829721, "used ace ase": 0.0008091139115659897, "applied a modified": 0.0008091139115659897, "learning it": 0.0011908005071032729, "is required during": 0.0007023330300003208, "learning is": 0.001345633860479038, "current": -0.0003022220143379174, "building an environment": 0.0008091139115659897, "goals of": 0.00036338074496527356, "pairs our": 0.000634859264718638, "an architecture should": 0.0008091139115659897, "high n each": 0.0008091139115659897, "of course be": 0.0005759152096655707, "updated using": 0.0005128077770266814, "complete sequences we": 0.0008091139115659897, "averaging process": 0.0007696350858963753, "opponents finally": 0.0007696350858963753, "nearer bound": 0.000702264802583379, "simple multi step": 0.0008091139115659897, "has applied samuel": 0.0008091139115659897, "pursue a target": 0.0008091139115659897, "to diana": 0.0007696350858963753, "into the population": 0.0007417488271393706, "pairs are": 0.00039610816435843403, "one rule will": 0.0008091139115659897, "alone": 0.001019077844762124, "which explicitly": 0.00052785331295456, "along": -1.7219465280591964e-05, "through learning": 0.0005954002535516364, "a plan are": 0.0007023330300003208, "dogfighting and": 0.0007696350858963753, "to store games": 0.0008091139115659897, "robot path finding": 0.0016182278231319793, "obstacles considerable": 0.0007696350858963753, "developed the nearest": 0.0008091139115659897, "studied": 0.00018049433881466102, "determined by their": 0.0005851984448616567, "commonly": 0.00013509757321858006, "experiment with the": 0.0005759152096655707, "learning strategies": 0.0005803901647646488, "its batteries": 0.0007696350858963753, "for the two": 0.0015335055456174964, "system begins": 0.000634859264718638, "studies": 0.00010225925052666218, "defense mechanisms and": 0.0008091139115659897, "the parking": 0.0007696350858963753, "tasks": 0.001547060015156273, "permits it": 0.0006628410843555166, "been generated": 0.00042590150453082544, "e has additional": 0.0008091139115659897, "implementation see": 0.0006628410843555166, "further this question": 0.0008091139115659897, "that resulted": 0.000567383102523159, "is facing north": 0.0008091139115659897, "we hypothesize": 0.0005803901647646488, "of the expected": 0.000449806936615026, "a set": 0.0005066151581958594, "and the pursuer": 0.0008091139115659897, "oe is an": 0.0005176213124249083, "that fired": 0.003078540343585501, "the database any": 0.0008091139115659897, "the classifiers with": 0.0007023330300003208, "run out": 0.000567383102523159, "one pursuer one": 0.0008091139115659897, "set the": 0.0001852280409905605, "degree improving": 0.0007696350858963753, "the other": 4.897039091726357e-05, "working": 0.00011165652219179202, "bearing heading and": 0.0008091139115659897, "of the study": 0.0005279045957013737, "be modeled with": 0.0005954580987137418, "predictions": 0.00022928963990805147, "angle and": 0.0004779464664686347, "can produce": 0.0003374403959319754, "distinguishes it from": 0.0008091139115659897, "researchers atkeson 1990": 0.0008091139115659897, "a state": 0.00023764249209833115, "training on": 0.0005060701527920558, "theoretical": 5.705058846691494e-05, "simulation a": 0.0004149539560409001, "initially we were": 0.0008091139115659897, "used for planning": 0.0008091139115659897, "play backgammon an": 0.0008091139115659897, "ga we": 0.002539437058874552, "pursuer task we": 0.0008091139115659897, "apparent": 0.0001718423499250408, "to the simulator": 0.0011909161974274836, "guidance from": 0.0006628410843555166, "second algorithm at": 0.0008091139115659897, "he calls symmetric": 0.0008091139115659897, "multidit algorithm planning": 0.0008091139115659897, "therefore modified": 0.0015392701717927505, "samuel system which": 0.0008091139115659897, "result though": 0.0006628410843555166, "takes over later": 0.0008091139115659897, "valued": 0.000170715699681252, "the resulting set": 0.0005128575980484463, "tends to": 0.00023479884997171157, "a very": 0.00013248506752184532, "with 21": 0.0005803901647646488, "20 time steps": 0.002427341734697969, "10 trials the": 0.0007417488271393706, "surface characterizing": 0.0007696350858963753, "evader additional": 0.0007696350858963753, "point was": 0.0005456354281782176, "used by clouse": 0.0008091139115659897, "the fitness of": 0.0005851984448616567, "values": -0.0013316292685381507, "ga teaching": 0.0007696350858963753, "following": -0.0012996754612797086, "them the resulting": 0.0006743602501766612, "were responsible for": 0.0006743602501766612, "bootstrapping method for": 0.0008091139115659897, "the expected": 0.0006403413378675597, "lazy algorithm for": 0.0008091139115659897, "learning to counter": 0.0008091139115659897, "we began": 0.0009659294962378757, "e only controls": 0.0008091139115659897, "still an": 0.0004288371693587632, "allowed to transmit": 0.0007417488271393706, "the next step": 0.0003634160486420408, "the games": 0.0013256821687110331, "outperformed both of": 0.0008091139115659897, "are determined": 0.0005455943461523718, "allowed": 0.00010013909729431625, "to markov decision": 0.0008091139115659897, "learning is notoriously": 0.0008091139115659897, "acknowledgments thanks to": 0.0005851984448616567, "233": 0.00033384977769872567, "or the": 0.00010485534551585605, "first minimal computational": 0.0008091139115659897, "monitoring": 0.0002366638432639197, "is possible": 0.00011051502162170635, "bound is adjusted": 0.0008091139115659897, "problem and": 0.0006198094763121065, "classes to be": 0.0011909161974274836, "sample 1 of": 0.0008091139115659897, "lazy methods have": 0.0008091139115659897, "the advantages to": 0.0008091139115659897, "to construct": 0.0003375647178725453, "the terms": 0.0002627707973273995, "noisy using local": 0.0008091139115659897, "to be successful": 0.0005334812968668691, "examination of the": 0.0004548376351798251, "performance will": 0.0005060701527920558, "large continuous state": 0.0016182278231319793, "planning game playing": 0.0008091139115659897, "optimal": -0.0001318848590363056, "comparing two": 0.0004779464664686347, "include a": 0.0002905747481074539, "shown in figure": 0.0001720644544263975, "capabilities in the": 0.0006526576017704936, "by storing": 0.00042304989757217126, "the popular": 0.00042304989757217126, "domain of control": 0.0008091139115659897, "results for": 0.0002702213942656464, "they showed": 0.00042304989757217126, "each example using": 0.0008091139115659897, "an agent takes": 0.0008091139115659897, "halls of a": 0.0008091139115659897, "applications": -0.00021568534757906337, "explored": 0.00017880539624047184, "one pursuer e": 0.0008091139115659897, "1993b": 0.0005127579656835996, "1993a": 0.0005278020401703972, "problem while": 0.0009659294962378757, "improving": 0.00010262662212213915, "such": -0.009077247840502609, "these states and": 0.0006743602501766612, "the key": 0.0001782285325378948, "data": -0.000734199609881118, "averaging control values": 0.0008091139115659897, "pursuer evasion figure": 0.0008091139115659897, "that the": 4.223653711887397e-06, "natural": 1.410218648319552e-05, "x with": 0.0002741172369601924, "initial speeds of": 0.0008091139115659897, "if lined up": 0.0008091139115659897, "how accuracy": 0.0006628410843555166, "it also has": 0.0010352426248498167, "a ga to": 0.0016182278231319793, "for the k": 0.0004747836164770488, "were surprised with": 0.0008091139115659897, "the experiences": 0.000634859264718638, "play by both": 0.0008091139115659897, "inflated for the": 0.0008091139115659897, "truck": 0.0004997166844687707, "around 85": 0.0007696350858963753, "the nearest": 0.0006748807918639508, "one pursuer the": 0.0008091139115659897, "accelerate it one": 0.0008091139115659897, "all 20 state": 0.0008091139115659897, "algorithm can": 0.0006078017088462822, "plagued by hidden": 0.0008091139115659897, "sharply so that": 0.0008091139115659897, "is reduced": 0.00023340273528180345, "the pursuers": 0.003078540343585501, "grefenstette ramsey": 0.0007696350858963753, "proceeds using": 0.0007696350858963753, "lazy methods can": 0.0016182278231319793, "ran for only": 0.0008091139115659897, "course": 0.00011376132901887884, "the highest": 0.00044899620413694916, "experiments": 0.0002107696236732203, "it provides the": 0.0005083144306061808, "originated in the": 0.0008091139115659897, "for state i": 0.0007023330300003208, "begun to deal": 0.0008091139115659897, "the learning algorithm": 0.0005039721952628732, "passing k nn": 0.0008091139115659897, "been performed using": 0.0006349209434580451, "it as": 0.0002466206804679992, "of good": 0.0003839830887362287, "propagation algorithm": 0.00052785331295456, "tasks are": 0.0006925063450175328, "successfully evade": 0.0007696350858963753, "1989 namely probability": 0.0008091139115659897, "troubles": 0.0006347975979615015, "decreases": 0.0002264079232469182, "actual payoff values": 0.0008091139115659897, "control theory": 0.00048825248710181613, "variations of the": 0.0004473842663752093, "players in a": 0.0006743602501766612, "decreased": 0.00023018634469504555, "performance above": 0.001269718529437276, "11 and": 0.00022449810206847458, "matcher": 0.0009994333689375414, "a second pursuer": 0.0016182278231319793, "our earlier hypothesis": 0.0008091139115659897, "solutions than": 0.000634859264718638, "we were": 0.0015730399806395613, "more formal analysis": 0.0008091139115659897, "we gave the": 0.0006743602501766612, "if the current": 0.0004473842663752093, "in their study": 0.0005851984448616567, "target tracking": 0.0006628410843555166, "a probability 0": 0.0007417488271393706, "of a difficult": 0.0008091139115659897, "the development of": 0.0002717355336162034, "one generation as": 0.0008091139115659897, "demonstrate significant improvement": 0.0008091139115659897, "utgoff 1992 later": 0.0008091139115659897, "will see this": 0.0006199211760863129, "classifier systems": 0.0019885232530665498, "of success": 0.0004149539560409001, "performance changed": 0.0007696350858963753, "methods on": 0.00035445902764197844, "capture in the": 0.0007023330300003208, "exact match": 0.00052785331295456, "ga nor": 0.0007696350858963753, "500 games and": 0.0008091139115659897, "methods of": 0.000524346660213187, "bearing would be": 0.0008091139115659897, "study aha and": 0.0008091139115659897, "are ace": 0.0007696350858963753, "approach uses a": 0.0005954580987137418, "the surface": 0.0003304421841245212, "near the boundaries": 0.0006069246369921007, "performance above 45": 0.0008091139115659897, "having difficulty": 0.0007696350858963753, "e can": 0.00037664034839981597, "sufficient to construct": 0.0008091139115659897, "two lazy": 0.001404529605166758, "accuracy decreased very": 0.0008091139115659897, "of having a": 0.0004919901420568756, "all actions": 0.0004997652289300559, "can both": 0.0004938405038742361, "it is hard": 0.00042031844251562157, "initializing samuel with": 0.0008091139115659897, "we concluded was": 0.0008091139115659897, "by the national": 0.00037786441809092093, "which we applied": 0.0007417488271393706, "three dimensional": 0.00027956301522652775, "aha and": 0.0013256821687110331, "both benefit from": 0.0008091139115659897, "and p1 is": 0.0007417488271393706, "game was replayed": 0.0008091139115659897, "was that gll": 0.0008091139115659897, "searched the": 0.0006628410843555166, "plan for": 0.0009876810077484722, "and approaches such": 0.0008091139115659897, "the decisions about": 0.0007417488271393706, "the pattern recognition": 0.0007417488271393706, "used by though": 0.0008091139115659897, "intermediate states": 0.0005200422895505865, "the actions are": 0.0005954580987137418, "and strategies": 0.0005200422895505865, "was stored": 0.0005954002535516364, "the same payoff": 0.0008091139115659897, "successful evasion instead": 0.0008091139115659897, "an agent that": 0.0005674382257236372, "most likely reason": 0.0008091139115659897, "with the best": 0.000449806936615026, "one for": 0.0003926308005445016, "loses i e": 0.0008091139115659897, "and turn": 0.0005456354281782176, "in fact it": 0.0003655094953325257, "possibility": 8.230188056213731e-05, "quite": 6.320607897679841e-05, "1960s isaacs": 0.0007696350858963753, "turn with": 0.0006628410843555166, "each state and": 0.0006199211760863129, "complicated": 0.000308984002553791, "facing north": 0.0007696350858963753, "determining optimal strategies": 0.0008091139115659897, "remainder": 0.00021342637953727242, "limit examples for": 0.0008091139115659897, "objective examples include": 0.0008091139115659897, "1989 td methods": 0.0008091139115659897, "training": 0.0034273758767286422, "problems for nearest": 0.0008091139115659897, "recently michael littman": 0.0008091139115659897, "which was": 0.0002508495615030361, "for extensions to": 0.0007417488271393706, "wish to": 0.00020188646752198293, "programming": 2.4509232987671794e-05, "generate good": 0.0005954002535516364, "wait until": 0.00040989971878532225, "left with": 0.00040276699958546587, "in which e": 0.001119276532068599, "robotics planning game": 0.0008091139115659897, "gordon": 0.0007462466261240844, "the following sections": 0.0003507647800338115, "need for": 0.0001980300438984334, "t where rules": 0.0008091139115659897, "to navigate around": 0.0008091139115659897, "intuition": 0.0001806039456279112, "game is to": 0.0008091139115659897, "in escaping however": 0.0008091139115659897, "clause": 0.00024869125320661913, "long series of": 0.0007417488271393706, "a framework for": 0.0006098363920317323, "on the": 9.714412039088666e-06, "treated in a": 0.0005226282087022614, "one": -0.03581202600946658, "removed from": 0.00026767013033800354, "learn rapidly": 0.0007696350858963753, "on control": 0.0004938405038742361, "we combined": 0.000634859264718638, "chauffeur is": 0.0007696350858963753, "probability 0 3": 0.0008091139115659897, "open": 6.199184677305917e-05, "study on": 0.0004004979458675273, "decision rules using": 0.0016182278231319793, "ace ase barto": 0.0008091139115659897, "function the strength": 0.0008091139115659897, "learning ctr": 0.0006131469602829721, "strategy where": 0.0005803901647646488, "to provide": 0.00045043319616696166, "indicate": 2.4339807892025612e-05, "2": 0, "draft": 0.00030724245223524084, "by both players": 0.0008091139115659897, "structures": 3.967803263549106e-05, "be sure": 0.0004149539560409001, "pursuer e controls": 0.0008091139115659897, "learning sutton 1988": 0.0008091139115659897, "limited time help": 0.0008091139115659897, "such a high": 0.0007023330300003208, "multi step": 0.0005559058853301298, "evasion figure 5a": 0.0008091139115659897, "comparing one": 0.0007696350858963753, "each step": 0.0002430451200871382, "be used for": 0.00023927628110257646, "artifact": 0.0003602843725054768, "grefenstette 1988": 0.0007696350858963753, "to follow a": 0.0005334812968668691, "and computing the": 0.0004813101872060044, "is a plan": 0.0006526576017704936, "a is": 0.0003646879721323591, "and teaching": 0.000702264802583379, "optimization and machine": 0.0006526576017704936, "degrees left 5": 0.0008091139115659897, "research showed": 0.000702264802583379, "earlier k nn": 0.0008091139115659897, "1975 described another": 0.0008091139115659897, "this system": 0.00027612768624444016, "areas and solutions": 0.0008091139115659897, "similar distributions": 0.000702264802583379, "lamarkian learning": 0.0007696350858963753, "result though is": 0.0008091139115659897, "future": -1.351573233041886e-05, "selected it": 0.000567383102523159, "method i": 0.0004642630166224529, "since it": 0.00014654283989160092, "no known optimal": 0.0008091139115659897, "using its": 0.00040989971878532225, "examples the result": 0.0007417488271393706, "in which we": 0.0010997177650022179, "is highly nonlinear": 0.0008091139115659897, "a lazy method": 0.0008091139115659897, "results of training": 0.0016182278231319793, "strength r t": 0.0008091139115659897, "locations": 0.00014093755706206385, "upon work": 0.0005559058853301298, "sensing abilities one": 0.0008091139115659897, "were correct": 0.0006131469602829721, "are discarded the": 0.0006526576017704936, "stopped was about": 0.0008091139115659897, "represents a problem": 0.0007417488271393706, "ratio of": 0.00021462605873503448, "for decision tree": 0.0012138492739842013, "throughout a sequence": 0.0008091139115659897, "checkers noughts": 0.0007696350858963753, "millan torras 1992": 0.0008091139115659897, "but then its": 0.0008091139115659897, "delayed reinformement": 0.0007696350858963753, "study on the": 0.0005456884385180774, "evades at": 0.0007696350858963753, "take": -0.00028090006902045244, "are provided by": 0.0004998137828238603, "suppose we": 0.0002921317927643509, "tesauro used temporal": 0.0008091139115659897, "by all": 0.00026157905702535613, "how well": 0.0006631524616627802, "ga recognizing": 0.0007696350858963753, "maneuvering": 0.001134655980062826, "formative stages of": 0.0008091139115659897, "samuel for the": 0.0008091139115659897, "games smith and": 0.0008091139115659897, "a different": 0.00014348896706960944, "in fact": 0.0004726238984983337, "knew": 0.0003918640736427776, "nearest neighbor k": 0.0016182278231319793, "of niches": 0.0007696350858963753, "devijver": 0.0014043931768418264, "deriving strategies": 0.0007696350858963753, "has variable": 0.0007696350858963753, "by differential": 0.000634859264718638, "better examples": 0.0007696350858963753, "233 nov dec": 0.0007417488271393706, "example set to": 0.0008091139115659897, "45 from there": 0.0008091139115659897, "itself to": 0.00036183856746138145, "determining good examples": 0.0008091139115659897, "recently been studied": 0.0006526576017704936, "by though small": 0.0008091139115659897, "2 k nn": 0.0008091139115659897, "namely probability of": 0.0008091139115659897, "the problem reinforcement": 0.0008091139115659897, "as well or": 0.0006526576017704936, "359 degrees": 0.0007696350858963753, "employed a": 0.00052785331295456, "new state is": 0.0006743602501766612, "on the fitness": 0.0008091139115659897, "best performance this": 0.0008091139115659897, "curvature intuitively optimal": 0.0008091139115659897, "problems studied": 0.0005559058853301298, "the distance metrics": 0.0007417488271393706, "laws": 0.0005873664941283323, "be possible with": 0.0006349209434580451, "well again this": 0.0008091139115659897, "based method of": 0.0007023330300003208, "we used the": 0.000625742566944542, "constructing a complete": 0.0007417488271393706, "game then the": 0.0008091139115659897, "examples for": 0.0007060899124203516, "evasion while the": 0.0008091139115659897, "next set out": 0.0008091139115659897, "describe a": 0.0002270994318821418, "decision problems so": 0.0008091139115659897, "classified we": 0.000702264802583379, "reason for": 0.0007158183569925133, "algorithm further": 0.0006131469602829721, "these techniques": 0.0002546842039466833, "degrees right and": 0.0008091139115659897, "for two": 0.0001913059091344491, "1990 watkins 1989": 0.0008091139115659897, "each player": 0.0017021493075694769, "slow": 0.00014417433409228696, "size our bootstrapping": 0.0008091139115659897, "plan for the": 0.0012398423521726258, "sets with": 0.000391902140873557, "this type this": 0.0007417488271393706, "ga 50 ga": 0.0008091139115659897, "simulated aircraft": 0.0007696350858963753, "play the evasive": 0.0008091139115659897, "towards p until": 0.0008091139115659897, "goldberg holland": 0.0007696350858963753, "at the start": 0.00037786441809092093, "agent must perform": 0.0007417488271393706, "teacher for": 0.0006628410843555166, "labeled examples": 0.0005456354281782176, "neighbors we": 0.0005363412876789271, "a fixed minimum": 0.0007417488271393706, "jumped to another": 0.0008091139115659897, "recharge its batteries": 0.0008091139115659897, "satisfy several goals": 0.0008091139115659897, "states and one": 0.0014834976542787413, "and less time": 0.0007417488271393706, "pairs initially": 0.000702264802583379, "the evasion": 0.0007696350858963753, "figure 6 using": 0.0006743602501766612, "are non": 0.0002768061441929089, "well in": 0.00026767013033800354, "is used to": 0.0001739660651457752, "exceeds 90 success": 0.0008091139115659897, "that achieved": 0.0005060701527920558, "employed a lazy": 0.0008091139115659897, "differential games": 0.010533972038750682, "we also generate": 0.0007417488271393706, "for evasive maneuvers": 0.002427341734697969, "have used": 0.00022975945283717957, "boundaries between": 0.0004997652289300559, "the state variables": 0.0005393947462253054, "games differential games": 0.0008091139115659897, "the associated actions": 0.0008091139115659897, "a point was": 0.0007023330300003208, "evaluate lazy": 0.0007696350858963753, "space as it": 0.0006743602501766612, "learn evasion": 0.0007696350858963753, "national science": 0.0002721430567364954, "differences distance metrics": 0.0008091139115659897, "this was": 0.0008125392195771556, "using the payoff": 0.0008091139115659897, "they provided": 0.0005803901647646488, "system would": 0.00042027761111456123, "complete simulation": 0.0005803901647646488, "task one such": 0.0007417488271393706, "random factor up": 0.0008091139115659897, "bombs": 0.0007021965884209132, "we describe a": 0.0003249819992683037, "showed no improvement": 0.0008091139115659897, "3 shows": 0.00022153363976495309, "can both benefit": 0.0008091139115659897, "where": -0.009742401347988391, "extremely well": 0.0010256155540533628, "that sequence of": 0.0007023330300003208, "faster than the": 0.0003526121597601731, "of discrete classes": 0.0008091139115659897, "the same time": 0.00023296369112973578, "q learning rather": 0.0008091139115659897, "is as": 0.00015014439872232055, "of dice distinguishes": 0.0008091139115659897, "had no": 0.0008518030090616509, "use interpolation so": 0.0008091139115659897, "speed of both": 0.0008091139115659897, "1963 as a": 0.0008091139115659897, "correct action": 0.0021067944077501365, "of initializing samuel": 0.0008091139115659897, "close to": 0.0002893127145290653, "the class": 0.0007665353761275167, "1992 later used": 0.0008091139115659897, "over time in": 0.0005334812968668691, "state space or": 0.0008091139115659897, "to near": 0.0005803901647646488, "jumped": 0.0005278020401703972, "game by": 0.0006628410843555166, "in robotics": 0.000567383102523159, "grefenstette": 0.007389228562385562, "continue to be": 0.0005176213124249083, "ended in successful": 0.0008091139115659897, "affecting": 0.00025300020453897806, "rule strength for": 0.0008091139115659897, "should be correct": 0.0007417488271393706, "problems when": 0.0004560919846500759, "k nn for": 0.0032364556462639586, "the two evasion": 0.0008091139115659897, "able to make": 0.0005226282087022614, "tasks we were": 0.0008091139115659897, "of lazy learning": 0.002809332120001283, "around 85 after": 0.0008091139115659897, "be selected": 0.0003118921235356357, "ga provided": 0.0007696350858963753, "also encouraging": 0.000634859264718638, "imado ishihara": 0.0007696350858963753, "and sequential": 0.0004123948992280552, "statistical approach robot": 0.0008091139115659897, "must perform": 0.00044497617160632185, "algorithms the following": 0.0006526576017704936, "and q learning": 0.002225246481418112, "many": -0.0017200057406998137, "500 generations": 0.0007696350858963753, "performing the task": 0.0007023330300003208, "ga s ability": 0.0008091139115659897, "s": -0.01405713614130183, "the actual": 0.0005430952157097604, "such as k": 0.0012398423521726258, "database later we": 0.0008091139115659897, "the condensed": 0.000702264802583379, "salzberg": 0.0026390102008519863, "deleted it": 0.0006131469602829721, "the arithmetic mean": 0.0005759152096655707, "terms of expected": 0.0007417488271393706, "plan from ga": 0.0008091139115659897, "feature of pursuit": 0.0008091139115659897, "that generation the": 0.0008091139115659897, "induction learning sequential": 0.0008091139115659897, "this confirms in": 0.0008091139115659897, "perfect accuracy with": 0.0008091139115659897, "s algorithm classifies": 0.0008091139115659897, "the averaging process": 0.0008091139115659897, "adding a": 0.00029371177661993307, "learning to navigating": 0.0008091139115659897, "of direction": 0.0004997652289300559, "algorithm adds additional": 0.0008091139115659897, "q learning for": 0.0007023330300003208, "it is also": 0.00023053156232084892, "the second phase": 0.00039332290595165396, "hide e": 0.0007696350858963753, "minimal computational time": 0.0008091139115659897, "exception to": 0.0004382027886649359, "to identify the": 0.00033009897175506186, "1 500": 0.0005803901647646488, "is close": 0.0002658073710966492, "ga was performing": 0.0008091139115659897, "have on": 0.0004074652591731264, "go and": 0.0005363412876789271, "and needed": 0.000634859264718638, "notoriously slow to": 0.0008091139115659897, "the tests": 0.0003681525887744991, "combined": 0.00034628073810873925, "also capable": 0.0005954002535516364, "alone demonstrating": 0.0007696350858963753, "prototype": 0.00019393432558271667, "is probably a": 0.0006199211760863129, "shows a sample": 0.0005674382257236372, "addition the learning": 0.0007417488271393706, "enable": 0.00013821549240404768, "tomek": 0.001269595195923003, "to use the": 0.0002323508949521072, "readings": 0.00038394579071886724, "level with": 0.00046861672357587705, "better these": 0.0006628410843555166, "when used": 0.00036494662878843966, "tasks tolerating": 0.0007696350858963753, "no idea which": 0.0007417488271393706, "than the best": 0.0004813101872060044, "game because": 0.0007696350858963753, "optimal play for": 0.0007417488271393706, "backer upper an": 0.0008091139115659897, "idea of tomek": 0.0008091139115659897, "see figure 5b": 0.0007417488271393706, "tasks such a": 0.0007417488271393706, "learning we then": 0.0008091139115659897, "be the": 4.3512867114876856e-05, "papers from the": 0.0006743602501766612, "approach is typical": 0.0007417488271393706, "b introduction when": 0.0005759152096655707, "approach had": 0.0015392701717927505, "control movement neuronlike": 0.0008091139115659897, "its learning slowed": 0.0008091139115659897, "used on the": 0.0004919901420568756, "pursuer the": 0.0007696350858963753, "reactive control": 0.0006628410843555166, "tracking ramsey": 0.0007696350858963753, "added to": 0.0001782285325378948, "maneuvers problem": 0.0007696350858963753, "experiments using": 0.0003878648638474452, "ten example": 0.0007696350858963753, "be 3": 0.0005200422895505865, "a differential game": 0.0029669953085574826, "value differential games": 0.0008091139115659897, "methods k": 0.000702264802583379, "implemented the same": 0.0007417488271393706, "e the behaviors": 0.0008091139115659897, "we store": 0.00042590150453082544, "algorithms working together": 0.0008091139115659897, "trained ga made": 0.0008091139115659897, "be removed": 0.00029371177661993307, "crossing the parking": 0.0008091139115659897, "kittler 1982 to": 0.0008091139115659897, "models and competition": 0.0016182278231319793, "catch a ball": 0.0008091139115659897, "90 success": 0.003078540343585501, "binary": 0.00013719655408009674, "is possible to": 0.00021268812319769897, "recharge its": 0.0007696350858963753, "that examples": 0.0006628410843555166, "between k nn": 0.0008091139115659897, "in escaping": 0.0007696350858963753, "demonstrated that genetic": 0.0008091139115659897, "whether a": 0.00022535886933316643, "its own starts": 0.0008091139115659897, "set to 0": 0.0004221582211223312, "known as": 0.0004146900296788414, "neighbor techniques": 0.000702264802583379, "for reducing memory": 0.0007023330300003208, "an initial": 0.00020188646752198293, "though small": 0.0006628410843555166, "the stored examples": 0.0008091139115659897, "would like": 0.00015063118441919246, "k 1 to": 0.0004882999224935485, "traveling straight ahead": 0.0008091139115659897, "actions distance is": 0.0008091139115659897, "millan and torras": 0.0008091139115659897, "are learning at": 0.0008091139115659897, "lazy methods 4": 0.0008091139115659897, "selection for": 0.0003665369780185166, "methods 4": 0.0004938405038742361, "control tasks such": 0.0008091139115659897, "chromosome for the": 0.0008091139115659897, "neither the ga": 0.0008091139115659897, "classifiers with": 0.00052785331295456, "algorithms in conjunction": 0.0008091139115659897, "strategy for collecting": 0.0008091139115659897, "one implementation of": 0.0007023330300003208, "be a": 9.624950363340372e-05, "q learning or": 0.0008091139115659897, "k nn was": 0.0016182278231319793, "tracking": 0.00020438408492182684, "minimal number of": 0.0004522903409367932, "however our": 0.00030818023003300325, "selects an action": 0.0007417488271393706, "suggest solution strategies": 0.0008091139115659897, "these experiments": 0.0009033775264772498, "second threshold was": 0.0008091139115659897, "1993 but little": 0.0008091139115659897, "when only": 0.00034757605337154215, "have been no": 0.0006526576017704936, "direction that e": 0.0008091139115659897, "320 generations": 0.0007696350858963753, "dimension": 0.00011012176867211072, "to be the": 0.00018808987448485395, "was still only": 0.0016182278231319793, "shows how accuracy": 0.0007417488271393706, "ga throughout training": 0.0008091139115659897, "of its training": 0.0007417488271393706, "being": -0.0005660198081172955, "hypothesize this was": 0.0008091139115659897, "1990 millan torras": 0.0008091139115659897, "extended it to": 0.0008091139115659897, "as 8instance": 0.0007696350858963753, "on the editing": 0.0014046660600006416, "is learning it": 0.0008091139115659897, "that point the": 0.0005039721952628732, "accumulate as": 0.0007696350858963753, "results show": 0.00023248120615389274, "of pairs learning": 0.0008091139115659897, "angle of": 0.0007965581392262904, "are deleted": 0.00044153169724958527, "to play backgammon": 0.0016182278231319793, "pursuer which makes": 0.0008091139115659897, "a j is": 0.0004958241803403253, "solved by a": 0.0004958241803403253, "strength and associated": 0.0008091139115659897, "generator": 0.00018933724154262334, "will focus on": 0.0004319040237213277, "direction much more": 0.0008091139115659897, "this class the": 0.0006069246369921007, "the military and": 0.0008091139115659897, "its very": 0.0005803901647646488, "teaching phase are": 0.0008091139115659897, "has both the": 0.0006743602501766612, "efficiency provided": 0.0007696350858963753, "formative": 0.0005455824281366266, "by letting": 0.0003878648638474452, "the broader": 0.0005060701527920558, "examples such": 0.0005456354281782176, "source of good": 0.0008091139115659897, "jump start a": 0.0016182278231319793, "barto sutton": 0.001269718529437276, "around": 0.0003963857090516998, "better these results": 0.0007417488271393706, "illustrated the": 0.00046861672357587705, "the examples are": 0.0005851984448616567, "we are averaging": 0.0008091139115659897, "rules is": 0.00041758029726340933, "genetic algorithm using": 0.0008091139115659897, "rules in": 0.0009501718746810529, "equal to": 0.00022179670713972564, "traffic": 0.00017527911559062502, "following sections": 0.0003072722989859923, "after each": 0.00030027612719626154, "q learning in": 0.0008091139115659897, "own teacher the": 0.0008091139115659897, "algorithm which is": 0.00039614664761543957, "step control problems": 0.0008091139115659897, "we see in": 0.00048474305809383046, "attempt to": 0.0003981402298588186, "k nn k": 0.0008091139115659897, "minimized the effects": 0.0008091139115659897, "heart of": 0.000391902140873557, "discarded": 0.00020957743974090145, "angle of the": 0.0005226282087022614, "in kd trees": 0.0008091139115659897, "acknowledgments thanks": 0.0005456354281782176, "5 and determined": 0.0008091139115659897, "otherwise the action": 0.0008091139115659897, "harder unlike the": 0.0008091139115659897, "the maximum": 0.0003303973990128366, "he embedded linear": 0.0008091139115659897, "to teach a": 0.0016182278231319793, "foundation under": 0.0003436573962650119, "immediately and catching": 0.0008091139115659897, "improve this": 0.00046861672357587705, "addition dorigo and": 0.0008091139115659897, "perhaps it could": 0.0008091139115659897, "database i e": 0.0013487205003533224, "simulation run": 0.00048296474811893784, "conducted a": 0.0004560919846500759, "path finding in": 0.0016182278231319793, "earlier draft of": 0.0005851984448616567, "ten experiments by": 0.0008091139115659897, "actions before storing": 0.0008091139115659897, "was rare": 0.000702264802583379, "probability following each": 0.0008091139115659897, "cyclic values": 0.0007696350858963753, "the cart and": 0.0016182278231319793, "the five": 0.0003118921235356357, "learning for the": 0.0019047628303741355, "a low": 0.0002487154120616033, "strategies with": 0.0005456354281782176, "moves where the": 0.0008091139115659897, "4 theta 10": 0.0007417488271393706, "1988 tesauro": 0.0007696350858963753, "nn based": 0.0007696350858963753, "second we": 0.0002921317927643509, "power": 8.288410494174091e-05, "different sensing": 0.0007696350858963753, "the focus of": 0.00038790254623973576, "until many": 0.000702264802583379, "experiments with": 0.0002747832868924773, "more interesting": 0.00035589291297159965, "lower limits of": 0.0007417488271393706, "counted one generation": 0.0008091139115659897, "set to": 0.00048768298269558026, "they begin": 0.000567383102523159, "eventually achieved near": 0.0008091139115659897, "q learning algorithm": 0.0007417488271393706, "sample game": 0.0015392701717927505, "we were surprised": 0.0006349209434580451, "this information": 0.0002134471126225199, "known as evasive": 0.0008091139115659897, "state action pair": 0.002427341734697969, "each plan": 0.0018394408808489165, "ace": 0.0011906848392541126, "and high level": 0.0005279045957013737, "s performance at": 0.0007417488271393706, "ga this suggests": 0.0008091139115659897, "pursuer is": 0.0015392701717927505, "particularly good actions": 0.0008091139115659897, "learning because of": 0.0008091139115659897, "the plan with": 0.0007417488271393706, "rule and": 0.0004004979458675273, "with k 1": 0.0005851984448616567, "neighbor": 0.0032489372016461684, "pursuer in": 0.000702264802583379, "also interpret": 0.000702264802583379, "of reference": 0.0003839830887362287, "we combined the": 0.0007023330300003208, "experiences of the": 0.0007417488271393706, "state and": 0.0007143699009627929, "task the evasive": 0.0008091139115659897, "fails to": 0.0002768061441929089, "using knowledge of": 0.0006526576017704936, "speed the": 0.0004288371693587632, "sets with where": 0.0008091139115659897, "enormous improvement over": 0.0008091139115659897, "algorithm to start": 0.0008091139115659897, "an agent must": 0.0007417488271393706, "results reveals": 0.0007696350858963753, "a vector in": 0.0005083144306061808, "rules to generate": 0.0007023330300003208, "one striking observation": 0.0008091139115659897, "provide these": 0.0005456354281782176, "to the changing": 0.0006069246369921007, "studied tends to": 0.0008091139115659897, "where a is": 0.0003731958134629092, "and artificial systems": 0.0006526576017704936, "then we made": 0.0008091139115659897, "initially figure 2": 0.0008091139115659897, "problems by letting": 0.0008091139115659897, "3 ga for": 0.0008091139115659897, "player some other": 0.0008091139115659897, "which the": 0.00035340341429604194, "the effects": 0.0007015987432415852, "is added to": 0.0003249819992683037, "remainder of": 0.00040235284760644404, "consequent are represented": 0.0008091139115659897, "reduction is 70": 0.0008091139115659897, "nn will be": 0.0008091139115659897, "strategies are modeled": 0.0008091139115659897, "one evader figure": 0.0008091139115659897, "complete": -0.000473518094547191, "most popular approaches": 0.0007023330300003208, "therefore we": 0.00036427846121115276, "s stochastic component": 0.0008091139115659897, "a problem using": 0.0007023330300003208, "above a": 0.0003489161923333023, "which an": 0.0009813374285952423, "the competition": 0.0006628410843555166, "certain performance threshold": 0.0008091139115659897, "three approaches see": 0.0008091139115659897, "phase are": 0.0004779464664686347, "the homicidal chauffeur": 0.0032364556462639586, "remained ahead of": 0.0008091139115659897, "curvature of the": 0.0005393947462253054, "with": 0, "the algorithms to": 0.0005279045957013737, "figure shows performance": 0.0007417488271393706, "very good performance": 0.0006349209434580451, "its training experiences": 0.0008091139115659897, "strength for each": 0.0008091139115659897, "direction that": 0.0005200422895505865, "right to left": 0.0004657382758148953, "strategies with the": 0.0008091139115659897, "variable speed and": 0.0008091139115659897, "a stored": 0.0016090238630367814, "difficult in": 0.0004731713358791195, "variant of": 0.00048013365083679043, "state and the": 0.000449806936615026, "with fitness determined": 0.0008091139115659897, "tesauro sejnowski 1989": 0.0008091139115659897, "an approach": 0.0006760766079994993, "is typical": 0.0004074652591731264, "methods specifically tied": 0.0008091139115659897, "the player": 0.00052785331295456, "the car the": 0.002225246481418112, "not know which": 0.0005524148804057065, "pursuer problems the": 0.0008091139115659897, "ae": 0.00017203498593416217, "what either": 0.0007696350858963753, "antecedant compares": 0.0007696350858963753, "the national science": 0.00035168430803720827, "certain": -5.127412235268017e-05, "performance of the": 0.0008839948888299323, "learning slowed consider": 0.0008091139115659897, "al": 9.887431329566306e-05, "recognition most": 0.000702264802583379, "an": 0, "pursuers as before": 0.0008091139115659897, "differential strategies": 0.0007696350858963753, "as": 0, "performance would be": 0.0006349209434580451, "at": -0.029492256713678357, "same time we": 0.0004657382758148953, "formulation": 0.0003419476486841962, "training the second": 0.0007417488271393706, "by though": 0.0007696350858963753, "performance after 5": 0.0008091139115659897, "pruning improves decision": 0.0008091139115659897, "the condensed nearest": 0.0008091139115659897, "the context": 0.00015014439872232055, "by both k": 0.0008091139115659897, "was tested using": 0.0007023330300003208, "concluded was": 0.0007696350858963753, "20 examples evaluate": 0.0008091139115659897, "stored instances": 0.000702264802583379, "used the five": 0.0008091139115659897, "remained at": 0.000702264802583379, "games genetic algorithms": 0.0008091139115659897, "range 80": 0.0007696350858963753, "completely surprising in": 0.0008091139115659897, "process and hands": 0.0008091139115659897, "graph are the": 0.0005954580987137418, "spatial": 0.00015940505074087255, "moderately well": 0.0007696350858963753, "studies the question": 0.0008091139115659897, "and apply the": 0.0004601378070916638, "s approach ritter": 0.0008091139115659897, "memory based learning": 0.0007023330300003208, "since the lazy": 0.0008091139115659897, "fixed radius circle": 0.0008091139115659897, "training experiences for": 0.0008091139115659897, "modified a": 0.0005363412876789271, "genetic algorithm": 0.008073803162874229, "adaptive elements": 0.000702264802583379, "of difficulty": 0.0004731713358791195, "accuracy of": 0.00022279508543139435, "of examples used": 0.0007023330300003208, "prior state": 0.0006628410843555166, "the two phase": 0.0005596382660342995, "a superficial": 0.0006131469602829721, "al and": 0.0009765049742036323, "algorithm performed": 0.0005803901647646488, "initially implemented the": 0.0008091139115659897, "where rules is": 0.0008091139115659897, "result in successful": 0.0008091139115659897, "experiences of": 0.0005803901647646488, "q learning watkins": 0.0008091139115659897, "its class": 0.00048296474811893784, "while nearest": 0.000702264802583379, "135 they": 0.0007696350858963753, "a database": 0.0006415126326567875, "strategy is the": 0.0006199211760863129, "approximately equal": 0.00044153169724958527, "theoretical work": 0.0005456354281782176, "in which the": 0.0007129833921869576, "to predict by": 0.0014046660600006416, "smoke is": 0.000702264802583379, "by sampling": 0.0004349818647972793, "bad examples": 0.0031742963235931896, "games as the": 0.0016182278231319793, "examples can": 0.0008764055773298718, "e s direction": 0.0008091139115659897, "original": -5.2785289193629815e-05, "meta game": 0.000702264802583379, "consider": -0.0004044467262396262, "variables being predicted": 0.0008091139115659897, "to have": 0.00021045513149689778, "higher than": 0.0002541283390836954, "to learn essentially": 0.0008091139115659897, "10 22": 0.0005456354281782176, "t where": 0.0002945105957876159, "1995 developed": 0.0006628410843555166, "they would have": 0.0005524148804057065, "reinforcement and appropriate": 0.0008091139115659897, "time t": 0.0004860902401742764, "learning the": 0.0008055339991709317, "reasoning": 0.00015431877434841996, "causes": 0.00010596383576229036, "the table": 0.00041919559784973394, "stored for": 0.00046861672357587705, "also gave bag": 0.0008091139115659897, "discovery systems": 0.001404529605166758, "non markovian e": 0.0008091139115659897, "e might": 0.0006131469602829721, "tr": 0, "three different actions": 0.0008091139115659897, "complete game": 0.0023089052576891257, "to": 0, "could get": 0.0005200422895505865, "many bad examples": 0.0016182278231319793, "the learning curve": 0.0006069246369921007, "td": 0.0012775804043633756, "has also been": 0.00034628681218354623, "the database using": 0.0006349209434580451, "i following": 0.000567383102523159, "catch a": 0.0006628410843555166, "game the same": 0.0008091139115659897, "y state y": 0.0008091139115659897, "in the beginning": 0.00046289837369057756, "of problems the": 0.0005456884385180774, "at intermediate": 0.0005128077770266814, "angle as the": 0.0008091139115659897, "rate continued": 0.0007696350858963753, "has a probability": 0.0005954580987137418, "actions do": 0.0006131469602829721, "attempts to": 0.0006947006956933633, "generated another possible": 0.0008091139115659897, "highways": 0.000567327990031413, "these games the": 0.0008091139115659897, "than d": 0.00044153169724958527, "be more difficult": 0.0006349209434580451, "than a": 0.00016496272185669375, "database if": 0.0005559058853301298, "pursuer task q": 0.0008091139115659897, "are complex": 0.0004382027886649359, "contain up to": 0.0006349209434580451, "than k": 0.0003462531725087664, "closed form solutions": 0.0005954580987137418, "large": -0.00031777663346313235, "form dt": 0.0007696350858963753, "database is": 0.0003714629793944916, "adjust": 0.00022839973357585987, "people learn a": 0.0008091139115659897, "the mean payoff": 0.0008091139115659897, "small": -0.001192249787822135, "i e both": 0.0006199211760863129, "the game at": 0.0008091139115659897, "on line": 0.0002747832868924773, "variables correspond to": 0.0007417488271393706, "car and": 0.0017862007606549094, "experiments demonstrated the": 0.0007417488271393706, "for a lazy": 0.0007023330300003208, "feature space": 0.00046009310747955083, "then to": 0.0005827008940215135, "own starts": 0.0007696350858963753, "the results were": 0.00045745222770795314, "initial experiments using": 0.0007023330300003208, "clause in": 0.0004560919846500759, "of differential equations": 0.001552863937274725, "in these games": 0.0008091139115659897, "could achieve alone": 0.0008091139115659897, "which players positions": 0.0008091139115659897, "similarly using plan": 0.0008091139115659897, "figure 7 results": 0.0006743602501766612, "algorithm i e": 0.0005176213124249083, "pass": 0.00024719489734707583, "simply editing": 0.0007696350858963753, "that are": 0.00018176292476871123, "some interesting differences": 0.0008091139115659897, "in nature": 0.00036338074496527356, "pursuer will": 0.0007696350858963753, "each training": 0.0004997652289300559, "e is random": 0.0008091139115659897, "clock": 0.0003697958263699327, "used to": 0.0001874394545137725, "section": -0.0010995041238628293, "observations suggested the": 0.0008091139115659897, "determined simply as": 0.0008091139115659897, "can be produced": 0.0005176213124249083, "pursuer task the": 0.0008091139115659897, "took combined": 0.0007696350858963753, "and scale": 0.0004288371693587632, "is higher than": 0.0004319040237213277, "training k": 0.0007696350858963753, "method": -0.002158264058620468, "contrast": 3.675212999809355e-05, "this was superior": 0.0008091139115659897, "performance on the": 0.001799227746460104, "full": -4.787308038061675e-06, "escaping": 0.0009371424094201219, "apply one approach": 0.0008091139115659897, "s troubles": 0.0007696350858963753, "test on": 0.00046009310747955083, "expanded watkins q": 0.0008091139115659897, "approach k": 0.0015392701717927505, "operators for": 0.00040276699958546587, "made a": 0.0004123948992280552, "the purpose": 0.0002126674618296013, "learning both": 0.000702264802583379, "be labeled": 0.00044497617160632185, "differential games genetic": 0.0008091139115659897, "study in which": 0.0011518304193311414, "examplars": 0.0007021965884209132, "classifying each example": 0.0008091139115659897, "the current environment": 0.0006526576017704936, "analyzing a differential": 0.0008091139115659897, "learned to solve": 0.0008091139115659897, "reinforcement program to": 0.0008091139115659897, "prior": 0.0002862044167639961, "to permit the": 0.0006199211760863129, "in such": 0.00014026624279180064, "by the methods": 0.0005759152096655707, "action": 0.0043904969628160715, "the more": 0.0006407968464558362, "from achieving": 0.000634859264718638, "learning system in": 0.0007417488271393706, "othello pell 1993": 0.0008091139115659897, "followed": 7.503486379761692e-05, "used temporal": 0.0007696350858963753, "class of problems": 0.0009045806818735864, "a mathematical": 0.0003573471911393542, "5 4": 0.0001949601876710967, "if lined": 0.0007696350858963753, "to markov": 0.0005559058853301298, "a state variable": 0.0005954580987137418, "5 1": 0.0001101324663376122, "explicitly provides very": 0.0008091139115659897, "approach uses one": 0.0008091139115659897, "select": 0.00015399257424127797, "was used": 0.000418438906501223, "has only recently": 0.0007417488271393706, "diana gordon john": 0.0008091139115659897, "an estimate of": 0.0007310189906650513, "the early stages": 0.0009694861161876609, "v 33": 0.000310019848849804, "only 20": 0.00052785331295456, "when used alone": 0.0007023330300003208, "success games one": 0.0008091139115659897, "initially all rules": 0.0008091139115659897, "change its speed": 0.0008091139115659897, "relatively simple and": 0.0006199211760863129, "or makes": 0.000702264802583379, "6": -0.0014991500534063125, "is a lazy": 0.0006743602501766612, "the winners": 0.0006628410843555166, "the bearing would": 0.0008091139115659897, "modified this": 0.0005954002535516364, "more": -0.01076791727935559, "generate random": 0.0005363412876789271, "performance and k": 0.0008091139115659897, "rules to": 0.00036338074496527356, "the behaviors": 0.0009285260332449058, "escape second": 0.0007696350858963753, "difficult control problems": 0.0008091139115659897, "corrected": 0.0002747565959466888, "mccallum 1995 developed": 0.0008091139115659897, "function then": 0.00039398316601407357, "tested": 0.00010336339121874117, "pursuers": 0.009830752237892785, "if it": 0.00019117674626982706, "quality of": 0.00021701898437179995, "alone previous work": 0.0008091139115659897, "after 50 000": 0.0016182278231319793, "dynamic control tasks": 0.0008091139115659897, "a lazy learner": 0.004045569557829949, "to it stored": 0.0008091139115659897, "space which": 0.00037664034839981597, "science": 1.4951567668343448e-05, "considerable difficulty": 0.0007696350858963753, "a parallel network": 0.0014834976542787413, "selection devijver": 0.0007696350858963753, "1987 nguyen widrow": 0.0008091139115659897, "if the": 8.882273916062264e-05, "to the set": 0.00031098203868469185, "method when": 0.0004560919846500759, "learn": 0.002704924971961102, "follows first": 0.00031379828866509775, "in that": 0.00022449241887875397, "and the genetic": 0.0013487205003533224, "draft of this": 0.0005083144306061808, "equal to the": 0.0004436687178457831, "called classifiers": 0.0007696350858963753, "problems by": 0.0008009958917350546, "strategy for memory": 0.0007417488271393706, "which attributes": 0.0005803901647646488, "stated": 7.601373144085365e-05, "between the results": 0.0006199211760863129, "success the figure": 0.0008091139115659897, "store with each": 0.0014046660600006416, "mapping between states": 0.0008091139115659897, "for extensions": 0.0005456354281782176, "states": -0.00017597103174712462, "movement adaptation in": 0.0008091139115659897, "angle of its": 0.0008091139115659897, "sense": 3.0973054371922355e-06, "good actions before": 0.0008091139115659897, "shaping developing": 0.0007696350858963753, "provide good examples": 0.0008091139115659897, "et al demonstrated": 0.0008091139115659897, "pole problem could": 0.0008091139115659897, "axis": 0.00014748057431744982, "pursuer task both": 0.0008091139115659897, "information": -0.0008973135493278559, "training game": 0.0007696350858963753, "start a lazy": 0.0008091139115659897, "which we used": 0.0005759152096655707, "about 90": 0.0005363412876789271, "gll outperformed ga": 0.0008091139115659897, "lazy learning": 0.017896709277598944, "both p1 and": 0.0016182278231319793, "evasion task at": 0.0008091139115659897, "made the task": 0.0007417488271393706, "same payoff used": 0.0008091139115659897, "it from": 0.00032821057342992757, "sampling idea": 0.0007696350858963753, "greater than 90": 0.0005954580987137418, "could be removed": 0.0007417488271393706, "whereas for": 0.0004382027886649359, "assignment problem": 0.00045224640365867626, "the training": 0.00033988242810104627, "ga plus lazy": 0.0008091139115659897, "programming to": 0.00042027761111456123, "however many of": 0.0005674382257236372, "excellent performance on": 0.0007417488271393706, "evader have": 0.0007696350858963753, "plans": 0.0015272490996990798, "is given": 8.24775387783796e-05, "performance is the": 0.0005674382257236372, "plateau at 80": 0.0008091139115659897, "variant": 0.000259776449231067, "mapping": 0.00013275967327250717, "still inferior to": 0.0008091139115659897, "in speed to": 0.0007023330300003208, "system also performed": 0.0008091139115659897, "the three learning": 0.0008091139115659897, "the game change": 0.0008091139115659897, "algorithm by": 0.00029943314463829254, "caught a smoke": 0.0008091139115659897, "care conditions can": 0.0008091139115659897, "no possibility of": 0.0005954580987137418, "e s own": 0.0008091139115659897, "neighbor k nn": 0.0016182278231319793, "not supported as": 0.0007417488271393706, "current state": 0.0009245406900990098, "escape from a": 0.0008091139115659897, "the two": 0.0008796515534464644, "it can also": 0.00038659182444107513, "resulting joint": 0.0007696350858963753, "1994 observed that": 0.0008091139115659897, "for a learning": 0.0006743602501766612, "ideas during the": 0.0008091139115659897, "fundamental": 0.00010079641329673081, "regardless of": 0.00046041741181960253, "comparing learning for": 0.0008091139115659897, "a teacher": 0.0018394408808489165, "s ability through": 0.0008091139115659897, "requires significantly more": 0.0006526576017704936, "to fifty": 0.0007696350858963753, "action and": 0.00042590150453082544, "learning learning": 0.0004938405038742361, "only the nearer": 0.0008091139115659897, "is notoriously": 0.0005954002535516364, "hands off": 0.0007696350858963753, "payoff both": 0.0007696350858963753, "paper": -0.0013544851982464747, "could assume that": 0.0007417488271393706, "termination it": 0.0006131469602829721, "its": -0.010722992928930478, "later we found": 0.0008091139115659897, "kittler 1982": 0.0007696350858963753, "perceptual aliasing in": 0.0008091139115659897, "rapidly": 0.0005546937395548991, "is probably not": 0.0006349209434580451, "kasif and": 0.0006628410843555166, "but then": 0.0007206387439175994, "1989 barto sutton": 0.0008091139115659897, "programming learning with": 0.0008091139115659897, "stored at that": 0.0007417488271393706, "on determining good": 0.0008091139115659897, "dependent on": 0.0007043965499151347, "into a strategy": 0.0008091139115659897, "evasion neither": 0.0007696350858963753, "both pursuers p1": 0.0008091139115659897, "teacher which explicitly": 0.0008091139115659897, "with its genetic": 0.0008091139115659897, "initially it": 0.0005803901647646488, "agent tasks": 0.0007696350858963753, "analyzing learning": 0.000702264802583379, "but they": 0.0004974308241232066, "is based": 9.417141608588533e-05, "next step": 0.0003063720986511328, "to provide examplars": 0.0008091139115659897, "agents to": 0.000946342671758239, "are in": 0.00012547253107547703, "both pursuers": 0.0007696350858963753, "4 as": 0.0003109518286556765, "e g": 0.0002067698616363342, "for samuel to": 0.0008091139115659897, "associated actions if": 0.0008091139115659897, "e a": 0.00018122650469081856, "optimization and": 0.0003197335749799009, "range 80 85": 0.0008091139115659897, "that yield": 0.00045224640365867626, "own training the": 0.0008091139115659897, "e y": 0.00039398316601407357, "but the amount": 0.0006349209434580451, "applications that rely": 0.0008091139115659897, "q learning is": 0.0007023330300003208, "e s": 0.0015318604932556639, "e p": 0.0003327228091591544, "ga so": 0.0007696350858963753, "are updated": 0.0003304421841245212, "more details see": 0.0005279045957013737, "the value of": 0.00033889148421695334, "always": -0.00018515875764873652, "accuracy outperforming either": 0.0008091139115659897, "speed bearing heading": 0.0008091139115659897, "learned rules to": 0.0008091139115659897, "often the error": 0.0008091139115659897, "found": -0.0005021617218478374, "to hide e": 0.0008091139115659897, "envision a": 0.0005456354281782176, "the maximum speed": 0.0006743602501766612, "the chromosome": 0.0006628410843555166, "the ga began": 0.0008091139115659897, "angle as": 0.000702264802583379, "angle at": 0.001134766205046318, "1 e p": 0.0008091139115659897, "actions correspond": 0.0006628410843555166, "reduce": -8.593967618978099e-05, "numeric": 0.00028165016153483134, "8s2rules strength s": 0.0008091139115659897, "classifies each example": 0.0008091139115659897, "one such": 0.0002586543449607007, "of these": 9.242004926064153e-05, "even possible": 0.0005363412876789271, "measurement": 0.00019194397156153478, "examples ga 0": 0.0008091139115659897, "time steps they": 0.0008091139115659897, "was actually a": 0.0008091139115659897, "with bad actions": 0.0008091139115659897, "searches a": 0.0005456354281782176, "a plan in": 0.0007023330300003208, "of temporal differences": 0.0014046660600006416, "ga learned much": 0.0008091139115659897, "using neural": 0.000567383102523159, "the use": 0.00019762316778032808, "facing e": 0.0007696350858963753, "study one": 0.0006131469602829721, "research": -0.0001878446254488446, "the implementation see": 0.0007417488271393706, "ga with": 0.000634859264718638, "for samuel": 0.0007696350858963753, "only 10 000": 0.0014834976542787413, "pairs initially it": 0.0008091139115659897, "occurs": 1.577542751067818e-05, "and less": 0.00035027405940034004, "of interest": 0.00020117642380322202, "the corresponding sequence": 0.0006069246369921007, "was quite small": 0.0007417488271393706, "or control laws": 0.0008091139115659897, "demonstrated the": 0.0003982790696131452, "the position of": 0.0003331401991494251, "an apparent": 0.0005363412876789271, "right away indicates": 0.0008091139115659897, "approach to determine": 0.0005851984448616567, "up to the": 0.0003419957654508641, "examples that still": 0.0008091139115659897, "we experimented with": 0.0009559858011907364, "with issues": 0.0006131469602829721, "of 52 the": 0.0008091139115659897, "definition": -3.967803263549105e-05, "pairs": 0.0005606988293062162, "that were extreme": 0.0008091139115659897, "the consequent": 0.00046861672357587705, "outperform either method": 0.0008091139115659897, "2 to": 0.00015710943354638437, "co adaptive": 0.0013256821687110331, "two learners would": 0.0008091139115659897, "to monitor the": 0.0004919901420568756, "must be": 5.3093423972029333e-05, "yield this": 0.000634859264718638, "w": -4.085331129139013e-05, "editing methods": 0.0015392701717927505, "performance learning occurs": 0.0008091139115659897, "is new along": 0.0008091139115659897, "reaching a certain": 0.0008091139115659897, "differential equations finding": 0.0008091139115659897, "steps later when": 0.0008091139115659897, "of the predicate": 0.0005176213124249083, "than constructing": 0.0006628410843555166, "we had": 0.000851502220943135, "vector within which": 0.0008091139115659897, "the limitations of": 0.00041328080567602945, "study these problems": 0.0008091139115659897, "number": -0.004154634472429616, "feature space and": 0.0006069246369921007, "examples gll obtained": 0.0008091139115659897, "lem and applied": 0.0008091139115659897, "state i and": 0.0006069246369921007, "on four parameters": 0.0008091139115659897, "namely probability": 0.000702264802583379, "in the field": 0.00041851198115822714, "strategy using": 0.0005803901647646488, "encapsulate some": 0.0007696350858963753, "for the actions": 0.0007417488271393706, "even when": 0.0004439052784846589, "pursuer game we": 0.002427341734697969, "the game": 0.013121268260124556, "introduction": -0.0006347975979615015, "direction although": 0.000702264802583379, "might escape": 0.0007696350858963753, "moderately": 0.0003573124803874222, "action pairs are": 0.0007417488271393706, "from deterministic games": 0.0008091139115659897, "we also gave": 0.0007023330300003208, "learning plus": 0.0007696350858963753, "nearest neighbor to": 0.0007023330300003208, "train on": 0.0005456354281782176, "improvement over": 0.0003238859962113274, "idea behind": 0.0003338822091906335, "states which": 0.00042027761111456123, "25 000 games": 0.0008091139115659897, "and we": 0.00017891207063614153, "showed that": 0.00040377293504396586, "goals simultaneously": 0.000702264802583379, "by testing": 0.00044497617160632185, "actions two of": 0.0008091139115659897, "expanded watkins": 0.0007696350858963753, "to catch applying": 0.0008091139115659897, "task with": 0.00044153169724958527, "p2 drops below": 0.0008091139115659897, "and sequential decision": 0.0007023330300003208, "which searched": 0.0007696350858963753, "grefenstette s samuel": 0.0008091139115659897, "it begins": 0.00048825248710181613, "by adding": 0.0002069735289986681, "determines": 6.764544207817014e-05, "performing nearly": 0.0007696350858963753, "p uses": 0.0005559058853301298, "next step in": 0.0005334812968668691, "a separate": 0.0004714779995535412, "in grefenstette": 0.0007696350858963753, "gas use": 0.0007696350858963753, "to 50": 0.0008149305183462528, "payoff values": 0.0007696350858963753, "called tag": 0.0006628410843555166, "determined": -0.00029217911783074456, "performs well when": 0.0007023330300003208, "depends only": 0.0003063720986511328, "car the speed": 0.0008091139115659897, "first used a": 0.0007023330300003208, "game theory": 0.0036949731906819193, "studied in differential": 0.0007417488271393706, "full of correctly": 0.0008091139115659897, "results in a": 0.0002662444763454739, "follows when action": 0.0008091139115659897, "a constraint therefore": 0.0008091139115659897, "to teach": 0.0016369062845346528, "for the": 0.0, "of e": 0.0010517900697703908, "recently michael": 0.000702264802583379, "sequences non markovian": 0.0008091139115659897, "pedestrian": 0.004393845548327815, "recently moore": 0.0007696350858963753, "that sequence": 0.00048825248710181613, "curvature and": 0.0010256155540533628, "nn all points": 0.0008091139115659897, "uses a": 0.0010243937020896579, "are selected": 0.0003327228091591544, "play ended": 0.000702264802583379, "neighbors those": 0.0007696350858963753, "intervals we": 0.00046861672357587705, "class name": 0.000567383102523159, "of what": 0.0002953154240675878, "at a master": 0.0008091139115659897, "self": 9.46924804298419e-05, "difficult problems": 0.0005128077770266814, "8 results of": 0.0006743602501766612, "another agent is": 0.0008091139115659897, "complex control tasks": 0.0016182278231319793, "also": -0.010156761567384024, "recognizing": 0.0002574805727462202, "our experiments demonstrate": 0.0019047628303741355, "generalized": 6.859827704004837e-05, "nearest neighbor rules": 0.0008091139115659897, "poor quality": 0.0005559058853301298, "actions randomly until": 0.0008091139115659897, "had no idea": 0.0008091139115659897, "the class of": 0.0008062345519557336, "play": 0.0024691003895747194, "as those": 0.000498490382286008, "found in the": 0.00031479506571990205, "s game": 0.000702264802583379, "approaches to": 0.0009262675942578178, "sense since": 0.0005954002535516364, "selected an": 0.0005559058853301298, "1990 employed a": 0.0008091139115659897, "the players friedman": 0.0008091139115659897, "than all of": 0.0006526576017704936, "we use the": 0.00015943602422785222, "plan": 0.0034908178604889004, "communicate what": 0.0007696350858963753, "hide e from": 0.0008091139115659897, "the control variables": 0.0007023330300003208, "tesauro 1992 q": 0.0008091139115659897, "which attributes to": 0.0008091139115659897, "on their": 0.0004891276214888098, "ga alone demonstrating": 0.0008091139115659897, "to multi agent": 0.0006743602501766612, "fact the": 0.00044140005947255475, "mutation and crossover": 0.0008091139115659897, "to optimize competing": 0.0008091139115659897, "an evasive maneuvering": 0.0008091139115659897, "task in": 0.0006654456183183088, "cover": 0.00015532192377010215, "difficult learning control": 0.0007417488271393706, "of initializing": 0.0006628410843555166, "the nearer": 0.000702264802583379, "game at the": 0.0008091139115659897, "and colombetti": 0.0015392701717927505, "speed bearing": 0.0007696350858963753, "pell 1993 developed": 0.0008091139115659897, "algorithms and": 0.00042455900560917727, "difficult we": 0.0004997652289300559, "improvement through 500": 0.0008091139115659897, "population may contain": 0.0008091139115659897, "action space but": 0.0008091139115659897, "problem while nearest": 0.0008091139115659897, "position of the": 0.00034283978877556906, "and capture another": 0.0008091139115659897, "of q": 0.0019363499288129389, "that measure": 0.0004938405038742361, "of other members": 0.0008091139115659897, "for delayed reinforcement": 0.0008091139115659897, "k nn eventually": 0.0008091139115659897, "to improve its": 0.0005851984448616567, "before the reward": 0.0008091139115659897, "lin 1991 used": 0.0008091139115659897, "left the graph": 0.0008091139115659897, "described above": 0.00018807160268822633, "5 theta 10": 0.0006349209434580451, "because only the": 0.0006349209434580451, "algorithms in": 0.001101426981337712, "known editing": 0.0007696350858963753, "navigating a race": 0.0008091139115659897, "implementation takes": 0.0006131469602829721, "approximators": 0.0005278020401703972, "similar actions": 0.0006628410843555166, "stepwise": 0.00038020813619878184, "players follow": 0.0007696350858963753, "turns i e": 0.0008091139115659897, "1994 observed": 0.0007696350858963753, "method of initializing": 0.0008091139115659897, "out values that": 0.0008091139115659897, "teacher the ga": 0.0008091139115659897, "with almost": 0.0005128077770266814, "state space to": 0.0006199211760863129, "e controls": 0.0007696350858963753, "failed": 0.00039879870429118295, "store with": 0.0010726825753578542, "of experiments applying": 0.0008091139115659897, "factor": 1.2956070810815374e-05, "frequency with which": 0.0005334812968668691, "make arbitrarily sharp": 0.0008091139115659897, "we therefore modified": 0.0016182278231319793, "map this rule": 0.0008091139115659897, "difficult to solve": 0.0005759152096655707, "45 this": 0.000634859264718638, "turns into": 0.0004997652289300559, "state space has": 0.0006199211760863129, "learners would": 0.0007696350858963753, "dependent": 0.00012786539901526705, "running each": 0.0006131469602829721, "can regain speed": 0.0008091139115659897, "method similar": 0.0004731713358791195, "game it stores": 0.0008091139115659897, "formal analysis of": 0.0005176213124249083, "methods can": 0.0005938869885403849, "bad examples it": 0.0008091139115659897, "plans all of": 0.0008091139115659897, "and plug": 0.000702264802583379, "k nn using": 0.0008091139115659897, "a wall": 0.0005803901647646488, "i e tic": 0.0008091139115659897, "until e succeeds": 0.0008091139115659897, "the rules in": 0.0004779929005953682, "they would": 0.0003681525887744991, "which compete against": 0.0008091139115659897, "combining eager learning": 0.0008091139115659897, "mathematical theory with": 0.0008091139115659897, "players are modeled": 0.0008091139115659897, "approach by": 0.00040989971878532225, "nn almost": 0.0007696350858963753, "1982 to": 0.000702264802583379, "rate ae": 0.0005803901647646488, "using simulation": 0.0009558929329372694, "some payoff": 0.000702264802583379, "reinforcement program more": 0.0008091139115659897, "advice with its": 0.0008091139115659897, "state action pairs": 0.005192241789975595, "different actions two": 0.0008091139115659897, "ga achieved": 0.0007696350858963753, "examples were good": 0.0008091139115659897, "noise into": 0.0007696350858963753, "set": -0.013059315957171478, "learning a reinforcement": 0.0016182278231319793, "players at time": 0.0008091139115659897, "provide good": 0.00046861672357587705, "reset the game": 0.0008091139115659897, "each player assuming": 0.0008091139115659897, "good and": 0.00044497617160632185, "see": -0.0017482723760728805, "two of": 0.0005328496159164386, "with two pursuers": 0.0008091139115659897, "3 000": 0.0010726825753578542, "goals training agents": 0.0008091139115659897, "000 test games": 0.0008091139115659897, "p is": 0.0001460690329335417, "x with corresponding": 0.0008091139115659897, "players in the": 0.0007417488271393706, "instead of the": 0.0003055091709200821, "at regular intervals": 0.0005279045957013737, "only a small": 0.0003436907837512904, "pass within a": 0.0008091139115659897, "currently": 4.677600766880202e-05, "how well the": 0.0004522903409367932, "similar to": 0.00048581031991369367, "to classes": 0.0005060701527920558, "action by": 0.0005128077770266814, "linear programming to": 0.0006069246369921007, "be good function": 0.0008091139115659897, "nearest neighbor is": 0.0007023330300003208, "the sampling": 0.0003898632748579793, "david aha and": 0.0008091139115659897, "from no turn": 0.0008091139115659897, "but steadily until": 0.0008091139115659897, "improve until it": 0.0008091139115659897, "to modify the": 0.0003526121597601731, "to produce a": 0.000312871283472271, "they can both": 0.0007023330300003208, "9 42": 0.0005803901647646488, "determine the": 0.0012021654324728514, "our bootstrapping algorithm": 0.0008091139115659897, "problem and scale": 0.0008091139115659897, "and p2 drops": 0.0008091139115659897, "an objective frequently": 0.0008091139115659897, "of two genetic": 0.0008091139115659897, "of the": 0.0, "maneuvers lazy learning": 0.0008091139115659897, "is a genetic": 0.0008091139115659897, "4 results for": 0.0005851984448616567, "accounted for": 0.00038024507112555464, "that the players": 0.0007417488271393706, "special issue": 0.0004560919846500759, "lazy version": 0.0015392701717927505, "improved": 3.646046495474075e-05, "sequence one class": 0.0008091139115659897, "goldberg holland 1989": 0.0008091139115659897, "degree improving the": 0.0008091139115659897, "in robotics planning": 0.0008091139115659897, "games increased": 0.0007696350858963753, "comments on": 0.00028383407364771163, "generating a set": 0.0006349209434580451, "improves": 0.00024884581747684585, "for markov decision": 0.0008091139115659897, "figure 5b": 0.00052785331295456, "outperformed ga": 0.0007696350858963753, "performs well even": 0.0007023330300003208, "algorithm applies a": 0.0007417488271393706, "and ideas during": 0.0008091139115659897, "of states and": 0.0004998137828238603, "applied a traditional": 0.0008091139115659897, "7 ga 99": 0.0008091139115659897, "algorithm as a": 0.0004657382758148953, "contrast a": 0.00046009310747955083, "find the": 0.00017616918237866545, "predator prey": 0.0006628410843555166, "has no": 0.00017912087523321658, "equations learning solutions": 0.0008091139115659897, "served to": 0.0005559058853301298, "dimensional": 9.176480678741031e-05, "paper to": 0.00033865419457809065, "with only 66": 0.0008091139115659897, "agents": 0.0017944051779802631, "adaptation": 0.0004191548794818029, "a classical approach": 0.0007023330300003208, "either wins or": 0.0008091139115659897, "the car is": 0.0008091139115659897, "to evade": 0.002809059210333516, "by generating a": 0.0005334812968668691, "arbitrarily and was": 0.0008091139115659897, "with relatively small": 0.0006199211760863129, "and speed and": 0.0007417488271393706, "to improve rapidly": 0.0008091139115659897, "which one is": 0.0005674382257236372, "only the first": 0.0004221582211223312, "no way": 0.0003449470981709676, "solution is": 0.00039744494010191835, "how to find": 0.0005039721952628732, "space contains 7": 0.0008091139115659897, "would have on": 0.0006743602501766612, "gle on the": 0.0008091139115659897, "introduces noise": 0.0007696350858963753, "algorithm to continue": 0.0008091139115659897, "not q learning": 0.0008091139115659897, "correct behavior": 0.000634859264718638, "proportion to the": 0.0005226282087022614, "wall socket to": 0.0008091139115659897, "efficient memory based": 0.0007417488271393706, "intuitively optimal play": 0.0008091139115659897, "problems are those": 0.0006349209434580451, "accomplish we limit": 0.0008091139115659897, "reason that": 0.00035882246681762515, "the correct behavior": 0.0007023330300003208, "the predicted": 0.0006724813721400439, "cannot be": 9.31147751600377e-05, "set of instances": 0.0006199211760863129, "use samuel then": 0.0008091139115659897, "this alternation continues": 0.0008091139115659897, "ga 50": 0.0007696350858963753, "turn a game": 0.0008091139115659897, "other members in": 0.0007417488271393706, "the beginning exceeding": 0.0008091139115659897, "produced for": 0.0005128077770266814, "strategies in": 0.0011819494980422206, "advantages to a": 0.0008091139115659897, "straight": 0.00017880539624047184, "expanded": 0.00021110247608071628, "determine performance": 0.0006628410843555166, "empirical": 0.00031777663346313235, "is significantly more": 0.0005128575980484463, "but little": 0.0006131469602829721, "random actions": 0.0007696350858963753, "optimization": 3.587762054065548e-05, "error": 1.9207702078989046e-05, "on a particular": 0.0004404523980181757, "averages of 10": 0.0007417488271393706, "complication in classifying": 0.0008091139115659897, "which meant": 0.000702264802583379, "very difficult": 0.00034112545549164767, "into a wall": 0.0008091139115659897, "games involves": 0.0015392701717927505, "of 10 trials": 0.0007417488271393706, "still performing": 0.000702264802583379, "shifted by": 0.00048825248710181613, "hoping": 0.00044493294905444163, "k nn by": 0.0008091139115659897, "averaging": 0.0012650010226948904, "we would": 0.00014536106689930242, "somewhat inflated for": 0.0008091139115659897, "above 90": 0.001269718529437276, "genetic algorithms that": 0.0008091139115659897, "zero payoff at": 0.0008091139115659897, "games the initial": 0.0008091139115659897, "in comparison with": 0.00044270962419637705, "that each": 0.00012422823936075384, "literature e": 0.0005060701527920558, "of correctly": 0.00048296474811893784, "reinforcement learning task": 0.0008091139115659897, "we were left": 0.0008091139115659897, "payoff both lazy": 0.0008091139115659897, "are represented as": 0.0004319040237213277, "once evasion": 0.0007696350858963753, "the ga using": 0.0008091139115659897, "algorithms reinforcement": 0.0007696350858963753, "o clock": 0.000702264802583379, "continuous state and": 0.0008091139115659897, "the experiments where": 0.0006743602501766612, "particular differential game": 0.0008091139115659897, "games smith": 0.0007696350858963753, "to stepwise": 0.0007696350858963753, "rules": 0.0017778522420215262, "with the three": 0.0005039721952628732, "it reached 60": 0.0008091139115659897, "space which resulted": 0.0008091139115659897, "we focused": 0.0004779464664686347, "guarantees that the": 0.00038529791840416234, "penalty typically": 0.0007696350858963753, "operators for this": 0.0008091139115659897, "solve our": 0.00052785331295456, "select the most": 0.0005759152096655707, "values with": 0.0007757297276948904, "is complex solving": 0.0008091139115659897, "system of": 0.0005982561677692435, "littman expanded watkins": 0.0008091139115659897, "are known as": 0.0005176213124249083, "deleted from the": 0.0004919901420568756, "success after 16": 0.0008091139115659897, "discrete sutton": 0.0007696350858963753, "a payoff function": 0.0008091139115659897, "on the task": 0.0005393947462253054, "design a more": 0.0006526576017704936, "then tried a": 0.0008091139115659897, "results of running": 0.0005954580987137418, "lazy learner ramsey": 0.0008091139115659897, "recent": 3.123687461170105e-05, "that perhaps": 0.0006131469602829721, "nn finally": 0.0007696350858963753, "samuel to aerial": 0.0008091139115659897, "learning evasion": 0.0007696350858963753, "e also": 0.0005200422895505865, "few as 11": 0.0008091139115659897, "rarely used for": 0.0007417488271393706, "task thus we": 0.0007023330300003208, "algorithm pattern recognition": 0.0007023330300003208, "learned much better": 0.0008091139115659897, "air traffic control": 0.0005954580987137418, "every state in": 0.0005954580987137418, "it begins by": 0.0006526576017704936, "studied the evasive": 0.0008091139115659897, "learning tesauro": 0.0007696350858963753, "did not have": 0.00048474305809383046, "the game are": 0.0007417488271393706, "1993 used nearest": 0.0008091139115659897, "classifiers with fitness": 0.0008091139115659897, "demonstrate clearly": 0.000702264802583379, "data and": 0.0003912719745846033, "bag of": 0.0005363412876789271, "hypothesized": 0.0004004590436872584, "rare in the": 0.0006199211760863129, "extensions to": 0.000310019848849804, "demonstrated the ability": 0.0006743602501766612, "learning on neural": 0.0008091139115659897, "of the opponent": 0.0007417488271393706, "behind our": 0.0004642630166224529, "plagued": 0.0005127579656835996, "follows when": 0.0004642630166224529, "trees in": 0.0003449470981709676, "to this rule": 0.0006069246369921007, "like to reduce": 0.0008091139115659897, "level of success": 0.0008091139115659897, "editing the": 0.00052785331295456, "examples were edited": 0.0008091139115659897, "to perform sequential": 0.0016182278231319793, "to compare with": 0.0005674382257236372, "learning for": 0.002555409027184953, "analyzed to determine": 0.0005954580987137418, "probably not": 0.00048825248710181613, "conclusions": 5.914363251579639e-06, "next steps our": 0.0008091139115659897, "we initially": 0.0004560919846500759, "it can": 7.341855486316466e-05, "corresponding to": 0.00010616121629025307, "eager": 0.0023269631326540657, "location": 0.00015072149517339654, "regular intervals we": 0.0008091139115659897, "decision tree induction": 0.0011518304193311414, "long series": 0.000702264802583379, "player must adapt": 0.0008091139115659897, "1994 have": 0.000634859264718638, "robot made a": 0.0008091139115659897, "surprised": 0.0004258601347877918, "continuously they": 0.0007696350858963753, "time steps later": 0.0008091139115659897, "the combined": 0.0009272880959358418, "format": 0.0001952786684974031, "in what he": 0.0007417488271393706, "pursuit games 2060100": 0.0008091139115659897, "space to achieve": 0.0007023330300003208, "nearest sequence memory": 0.0008091139115659897, "algorithms are ace": 0.0008091139115659897, "nn experiments": 0.0007696350858963753, "agents thus making": 0.0008091139115659897, "that the two": 0.00033009897175506186, "performing to": 0.000702264802583379, "three values": 0.0004642630166224529, "on sequential": 0.0005363412876789271, "apply the": 0.00019361924942928985, "can be solved": 0.00027797337528372303, "formal": 8.772601292569482e-05, "only around 85": 0.0008091139115659897, "was still performing": 0.0008091139115659897, "d": -0.0007321620559877995, "to grefenstette": 0.0007696350858963753, "problem reinforcement learning": 0.0007417488271393706, "control of perception": 0.0016182278231319793, "learns to": 0.0010912708563564353, "identical maneuvering": 0.0007696350858963753, "achieving that": 0.000702264802583379, "continue": 0.0003537780834331261, "interpret differential": 0.0007696350858963753, "which we": 0.0003437393620975998, "when achieved 98": 0.0008091139115659897, "focus of": 0.0003118921235356357, "an action at": 0.0007023330300003208, "competing goals more": 0.0008091139115659897, "on translating the": 0.0008091139115659897, "would be in": 0.0005083144306061808, "in evasion": 0.0007696350858963753, "eager learning as": 0.0008091139115659897, "with one pursuer": 0.0016182278231319793, "methods": -0.0013397574613186775, "and p2 in": 0.0007023330300003208, "learner ramsey and": 0.0008091139115659897, "its own training": 0.0008091139115659897, "mechanisms and": 0.00045224640365867626, "reward fl": 0.0007696350858963753, "a minimal": 0.00028529602391613707, "mutation hill climbing": 0.0007417488271393706, "meta game playing": 0.0008091139115659897, "determined using": 0.0004382027886649359, "kasif": 0.000567327990031413, "when playing": 0.0005954002535516364, "1 low n": 0.0008091139115659897, "between states and": 0.0007023330300003208, "95 successful after": 0.0008091139115659897, "it will": 0.00014118025038131017, "pursuers speeds dropped": 0.0008091139115659897, "performing at a": 0.0008091139115659897, "one of which": 0.0004319040237213277, "reason for k": 0.0016182278231319793, "such as ours": 0.0006069246369921007, "and pole prob": 0.0008091139115659897, "memory requirements as": 0.0008091139115659897, "the pursuer is": 0.0008091139115659897, "no idea": 0.0006131469602829721, "strongest examples": 0.0007696350858963753, "the variables being": 0.0008091139115659897, "for mutation using": 0.0008091139115659897, "7 5": 0.00030818023003300325, "payoff for the": 0.0008091139115659897, "example generator": 0.0007696350858963753, "includes 13 features": 0.0008091139115659897, "averaging the algorithm": 0.0008091139115659897, "apply zero": 0.0007696350858963753, "be": 0, "method for predicting": 0.0007417488271393706, "substantially better": 0.0005363412876789271, "was that the": 0.0010913768770361549, "released the": 0.00052785331295456, "one exception": 0.0004731713358791195, "85 range": 0.0007696350858963753, "k between 1": 0.0008091139115659897, "to evaluate the": 0.00026665729318471246, "to this": 0.00035920763860789015, "by": 0, "prob lem and": 0.0007023330300003208, "run genetic": 0.0007696350858963753, "play by": 0.0015392701717927505, "the lethal envelope": 0.0008091139115659897, "also interpret differential": 0.0008091139115659897, "operationalizes the": 0.0007696350858963753, "limitations of": 0.0003128408899145216, "develop multiple": 0.0007696350858963753, "taking a sample": 0.0007023330300003208, "difficult for k": 0.0008091139115659897, "of the multiedit": 0.0008091139115659897, "fashion to markovian": 0.0008091139115659897, "clear that an": 0.0006526576017704936, "they can capture": 0.0007417488271393706, "computational": -1.6893387772578165e-06, "into": -0.0025824076465798492, "by methods": 0.0005363412876789271, "appropriate": -5.0396524785923386e-05, "strategy where the": 0.0007023330300003208, "calls symmetric": 0.0007696350858963753, "primarily": 0.00016254520394587348, "fewest time steps": 0.0008091139115659897, "ever pass within": 0.0008091139115659897, "have a database": 0.0007417488271393706, "called a": 0.00019163384403187916, "learning how to": 0.0006743602501766612, "evade store examples": 0.0008091139115659897, "21 examples": 0.0007696350858963753, "al 1975": 0.0006628410843555166, "encountered in differential": 0.0008091139115659897, "skalak 1994 in": 0.0008091139115659897, "to use samuel": 0.0008091139115659897, "their often": 0.0007696350858963753, "to know the": 0.00039614664761543957, "the players in": 0.0007023330300003208, "rarely used": 0.0005559058853301298, "with a helpful": 0.0007023330300003208, "specifically": 0.00023000506318781357, "games and very": 0.0008091139115659897, "table this": 0.0004731713358791195, "with the edited": 0.0008091139115659897, "pairs these": 0.000702264802583379, "were extreme for": 0.0008091139115659897, "ga indeed": 0.0007696350858963753, "considerably": 0.00016738990885215214, "state space": 0.002510386309320782, "hill climbing": 0.0009765049742036323, "every action": 0.0005803901647646488, "to 0 which": 0.0006199211760863129, "action is awarded": 0.0008091139115659897, "a modified": 0.00027748884847682954, "markovian problems": 0.0015392701717927505, "enough to": 0.0001782285325378948, "have the following": 0.0002658331951878856, "formative stages": 0.0007696350858963753, "in more": 0.0002134471126225199, "with an eager": 0.0008091139115659897, "and it even": 0.0008091139115659897, "to outperform": 0.00045224640365867626, "direct proportion": 0.0006131469602829721, "level strategic": 0.0007696350858963753, "predicted reward is": 0.0008091139115659897, "line": -2.6918145919065427e-05, "considerable": 0.0004908225023624726, "toward the": 0.00037315955974098747, "in instance": 0.001904577794155914, "an intermediate level": 0.0006743602501766612, "players speeds": 0.0007696350858963753, "small memory": 0.0011607803295292977, "broader domain of": 0.0008091139115659897, "learning performed moderately": 0.0008091139115659897, "the difficulty by": 0.0008091139115659897, "7 results": 0.0005128077770266814, "up": -0.0009273053905283272, "us": -0.00010189254826254972, "is an": 8.480806917428326e-05, "translating the rules": 0.0008091139115659897, "the rule that": 0.0006349209434580451, "down the": 0.000271492817488675, "making the": 0.0002546842039466833, "continuously": 0.00039879870429118295, "behavior robot shaping": 0.0008091139115659897, "ub": 0.0004098599033682474, "storing": 0.0009000086475198297, "was to play": 0.0008091139115659897, "aerial": 0.00046857120471006095, "exceeding the ga": 0.0016182278231319793, "defined": -0.00023505558124617138, "likewise": 0.00023018634469504555, "solved using": 0.0003748850085915968, "games assuming similar": 0.0008091139115659897, "surpassing": 0.000567327990031413, "games do": 0.000702264802583379, "on difficult": 0.000634859264718638, "the range": 0.00036611659055733425, "it stores the": 0.0005851984448616567, "activities in the": 0.0006349209434580451, "both the": 0.0002948127778351894, "to jump": 0.00105570662590912, "neighbor k": 0.0011908005071032729, "markovian e g": 0.0008091139115659897, "three instances": 0.000567383102523159, "the playing": 0.000702264802583379, "database any": 0.000702264802583379, "training game the": 0.0008091139115659897, "a strategy using": 0.0008091139115659897, "poor whenever a": 0.0008091139115659897, "extremely well initially": 0.0008091139115659897, "adapt its": 0.0005803901647646488, "which the examples": 0.0006743602501766612, "component of any": 0.0007023330300003208, "for state": 0.0008299079120818002, "performance against": 0.0005128077770266814, "some state action": 0.0016182278231319793, "trajectory moore 1990": 0.0008091139115659897, "of examples gll": 0.0008091139115659897, "hand if": 0.0002689296688222252, "task substantially": 0.0007696350858963753, "game 4 4": 0.0008091139115659897, "by k nn": 0.0008091139115659897, "solve the task": 0.0008091139115659897, "are those in": 0.0005674382257236372, "elements": -4.787308038061675e-06, "our study in": 0.0006743602501766612, "discounted reward for": 0.0008091139115659897, "best examples": 0.000702264802583379, "robots": 0.00036975837685967165, "and ub": 0.0006628410843555166, "we considered": 0.0009622689489851813, "editing approach": 0.0007696350858963753, "the task substantially": 0.0008091139115659897, "level for each": 0.0006199211760863129, "in the game": 0.0030996058804315645, "second details": 0.000702264802583379, "an eager learning": 0.0016182278231319793, "a new state": 0.0005128575980484463, "bootstrapping algorithm": 0.0007696350858963753, "examples evaluate": 0.0007696350858963753, "s radius of": 0.0016182278231319793, "fuel if the": 0.0016182278231319793, "and games": 0.0009995304578601118, "nn s troubles": 0.0008091139115659897, "can adjust": 0.0005803901647646488, "algorithm": -0.007208716704614348, "regular intervals": 0.00048825248710181613, "instead use": 0.0005060701527920558, "and eager approaches": 0.0008091139115659897, "a solution": 0.00019262270220781963, "correct ones": 0.0006628410843555166, "cause of its": 0.0007417488271393706, "of the improved": 0.0006069246369921007, "examples of": 0.0003673491594640934, "four parameters": 0.00052785331295456, "oracle": 0.00030024696001537796, "smoke it": 0.0007696350858963753, "when the robot": 0.0007023330300003208, "reached 93": 0.0007696350858963753, "having": -0.00010882077632503605, "to one whitehead": 0.0008091139115659897, "a continuous state": 0.0007023330300003208, "is the maximum": 0.0003174161673210388, "e had": 0.0007696350858963753, "evader caught1": 0.0007696350858963753, "symmetric chess": 0.0007696350858963753, "the improved": 0.0003714629793944916, "similar to one": 0.0005456884385180774, "time than the": 0.0005083144306061808, "neighbors and selected": 0.0008091139115659897, "results": -0.005378575899806033, "in a neural": 0.0006743602501766612, "is updated 4": 0.0008091139115659897, "illustrated": 7.601373144085365e-05, "broader": 0.00030024696001537796, "grefenstette simon": 0.0007696350858963753, "2060100 percent success": 0.0008091139115659897, "the action": 0.0015363614949299614, "each example to": 0.0008091139115659897, "differential games suggest": 0.0008091139115659897, "and call": 0.0003714629793944916, "then the": 0.0001261068828119895, "state 1 high": 0.0008091139115659897, "action a j": 0.0007417488271393706, "control the development": 0.0008091139115659897, "the algorithm applies": 0.0007023330300003208, "pursuit games": 0.005387445601274626, "learning to catch": 0.0008091139115659897, "first algorithm": 0.0007757297276948904, "other recent": 0.0004779464664686347, "well as described": 0.0008091139115659897, "a minimal size": 0.0008091139115659897, "maneuvers task to": 0.0008091139115659897, "methods however because": 0.0008091139115659897, "isaacs 1963 shows": 0.0008091139115659897, "no possibility": 0.0005128077770266814, "maximum speed reduction": 0.0008091139115659897, "by their starting": 0.0007417488271393706, "reinforcement problems widrow": 0.0008091139115659897, "indicating": 0.00014511170716971887, "a sample 1": 0.0008091139115659897, "traditional lazy": 0.003078540343585501, "successful evasion rate": 0.0008091139115659897, "basically zigzags": 0.0007696350858963753, "the learning algorithms": 0.0006199211760863129, "games and it": 0.0008091139115659897, "algorithms can work": 0.0008091139115659897, "of a game": 0.0019047628303741355, "continues": 0.00046295632304525997, "chauffeur is trying": 0.0008091139115659897, "shaping genetic algorithms": 0.0008091139115659897, "as those discussed": 0.0007023330300003208, "is considered to": 0.00041159621990674106, "examine the": 0.0002306596879313485, "gave the": 0.00042304989757217126, "were not able": 0.0005456884385180774, "continued": 0.0004973825064132383, "reached 93 evasion": 0.0008091139115659897, "1990 studied": 0.0007696350858963753, "an objective": 0.0004288371693587632, "between a stored": 0.0008091139115659897, "evader attempts to": 0.0008091139115659897, "classifier systems to": 0.0008091139115659897, "have converged when": 0.0007417488271393706, "applications to warfare": 0.0008091139115659897, "is challenging in": 0.0008091139115659897, "race": 0.00036334544814691844, "information since": 0.0005200422895505865, "1992 the": 0.00044854462015967935, "and for both": 0.0006526576017704936, "to achieve": 0.0006233648989030357, "new set": 0.0003603193719587997, "the result": 0.00017546906995726213, "using genetic operators": 0.0008091139115659897, "memory our": 0.0005559058853301298, "state based": 0.00048296474811893784, "we developed a": 0.00044270962419637705, "starts performing at": 0.0008091139115659897, "process and": 0.00025750558543057484, "difficult we do": 0.0008091139115659897, "examples which": 0.0004731713358791195, "outperforming either method": 0.0008091139115659897, "thus we could": 0.0006199211760863129, "consists primarily of": 0.0007023330300003208, "task grefenstette 1991": 0.0008091139115659897, "2 performance of": 0.0010787894924506108, "example standard q": 0.0008091139115659897, "learning approach": 0.0025303507639602785, "video": 0.0002073248744785815, "do not know": 0.00036035437821275464, "the q function": 0.0007023330300003208, "q learning": 0.022073290570186997, "clearly the": 0.0002487154120616033, "dynamics": 0.00019870316723696684, "of solutions and": 0.0007023330300003208, "which differs": 0.0005200422895505865, "permitted to vary": 0.0008091139115659897, "the multidit": 0.0007696350858963753, "of q learning": 0.005618664240002566, "applied to this": 0.0004882999224935485, "because the pursuer": 0.0008091139115659897, "game even": 0.0007696350858963753, "nn table": 0.0007696350858963753, "games the pursuer": 0.0008091139115659897, "better than": 0.001864842025305785, "editing rate": 0.0015392701717927505, "similar coverage": 0.0006628410843555166, "edited nearest neighbor": 0.0008091139115659897, "given the payoff": 0.0008091139115659897, "tackle increasingly": 0.0007696350858963753, "change the state": 0.0005674382257236372, "more space": 0.00046009310747955083, "such a": 0.00022577419173858138, "against itself and": 0.0008091139115659897, "led": 0.000341431399362504, "observed that": 0.00025981503993729386, "respectively": -0.00030457953268860224, "all other examples": 0.0008091139115659897, "outside the": 0.0002627707973273995, "in optimizing their": 0.0008091139115659897, "lem": 0.0002830829420950543, "agent activities": 0.000702264802583379, "nguyen widrow 1989": 0.0008091139115659897, "network that learns": 0.0014834976542787413, "evasive maneuvers q": 0.0008091139115659897, "games his": 0.0007696350858963753, "take bad actions": 0.0008091139115659897, "which is a": 0.00021744358471371638, "figure 5a": 0.00052785331295456, "this question is": 0.0004998137828238603, "produced for a": 0.0007417488271393706, "it could have": 0.0006349209434580451, "see profound differences": 0.0008091139115659897, "work together to": 0.0018207739109763023, "continue learning the": 0.0008091139115659897, "at first": 0.0009748512876827231, "great": 0.0001400249674400136, "resulted in success": 0.0008091139115659897, "ctr": -0.00017527911559062502, "done applying": 0.0007696350858963753, "success stored": 0.0015392701717927505, "involved": 5.7971449404712314e-05, "early stages": 0.0008149305183462528, "theta 10 15": 0.0008091139115659897, "we gave e": 0.0008091139115659897, "rules is the": 0.0006199211760863129, "is reduced and": 0.0005851984448616567, "learning approaches lazy": 0.0008091139115659897, "rate on": 0.0009876810077484722, "resulting": -0.00042959034690451275, "rl is challenging": 0.0008091139115659897, "nov dec 1998": 0.0006743602501766612, "rate of": 0.0006121235022733584, "directions could be": 0.0008091139115659897, "makes": -8.247708093822566e-05, "involves": 0.00012647830240373066, "where e": 0.0012475684941425428, "where c": 0.00025807848985967736, "shown to": 0.00019229223543292377, "where a": 0.0002800771400417603, "surface characterizing the": 0.0008091139115659897, "ga 90 figure": 0.0008091139115659897, "to match": 0.0002953154240675878, "conducted a series": 0.0006199211760863129, "the robot": 0.0014647574613054484, "games to achieve": 0.0008091139115659897, "multiedit algorithm": 0.0007696350858963753, "needs to have": 0.0006069246369921007, "9116843 and": 0.0007696350858963753, "complex task": 0.00052785331295456, "this credit": 0.000702264802583379, "its memory": 0.00048825248710181613, "region the editing": 0.0008091139115659897, "rapidly in the": 0.0013487205003533224, "have numeric values": 0.0008091139115659897, "careful editing to": 0.0008091139115659897, "if perf": 0.0007696350858963753, "ramsey and": 0.001404529605166758, "discrete classes to": 0.0008091139115659897, "editing and": 0.0005559058853301298, "asymptotic": 0.0005584528363479892, "rule form into": 0.0008091139115659897, "barto et": 0.0023089052576891257, "spaces atkeson 1992": 0.0008091139115659897, "did not": 0.0005464176918167291, "difficulty for": 0.0005128077770266814, "next": -0.0010447431579837193, "eager learning method": 0.0008091139115659897, "appropriate actions": 0.001269718529437276, "beginning with": 0.0004050885930083273, "such as chess": 0.0014834976542787413, "it stored with": 0.0008091139115659897, "a game into": 0.0008091139115659897, "confirms in part": 0.0008091139115659897, "sufficient to play": 0.0008091139115659897, "should reasonably": 0.0007696350858963753, "induction learning": 0.000702264802583379, "by generating": 0.0007532806967996319, "training k nn": 0.0008091139115659897, "three algorithms ga": 0.0008091139115659897, "which terms in": 0.0008091139115659897, "this material": 0.0004123948992280552, "intermediate states and": 0.0008091139115659897, "occurred": 0.0005528275818025881, "discount factor and": 0.0008091139115659897, "those bad examples": 0.0008091139115659897, "that it is": 0.00034946840691993267, "typical instances": 0.0015392701717927505, "sharply": 0.0011092751305790151, "payoff used": 0.0007696350858963753, "provided an agent": 0.0008091139115659897, "develop pursuit strategies": 0.0008091139115659897, "analyzing a": 0.0004731713358791195, "here show": 0.0006131469602829721, "achieved 98 100": 0.0008091139115659897, "performing to the": 0.0007417488271393706, "quality of its": 0.0006743602501766612, "task when we": 0.0007417488271393706, "method i e": 0.0005456884385180774, "asymptotic limit": 0.000634859264718638, "of curvature and": 0.0016182278231319793, "this": 0, "assuming similar distributions": 0.0008091139115659897, "study in": 0.0006314793000835784, "the game guarantees": 0.0008091139115659897, "determined the": 0.00036494662878843966, "using plan": 0.0007696350858963753, "designed initial": 0.0007696350858963753, "15 000 games": 0.0008091139115659897, "games and 30": 0.0008091139115659897, "used for": 0.00043867267489315534, "algorithms k": 0.0007696350858963753, "three fold first": 0.0008091139115659897, "be treated in": 0.0005226282087022614, "values of members": 0.0008091139115659897, "after twice as": 0.0008091139115659897, "trees mingers 1989": 0.0008091139115659897, "a backgammon program": 0.0008091139115659897, "process": -0.0003178915072868711, "more striking result": 0.0008091139115659897, "problems can be": 0.00040993954193880374, "action spaces atkeson": 0.0008091139115659897, "with relatively": 0.0004004979458675273, "this choice": 0.0002985967834217994, "given the object": 0.0007417488271393706, "high": -0.0006370801079629714, "we also": 0.00013752813952344406, "90 the chromosome": 0.0008091139115659897, "the actual payoff": 0.0008091139115659897, "on this range": 0.0008091139115659897, "random the database": 0.0008091139115659897, "gordon john": 0.0007696350858963753, "the resulting": 0.000690418456708645, "of co": 0.00046861672357587705, "match all": 0.000634859264718638, "the initial experiments": 0.0008091139115659897, "the complexity of": 0.00021477862791978585, "delay": 0.00011832515194928532, "the states and": 0.0005524148804057065, "low 1": 0.0005803901647646488, "striking observation was": 0.0008091139115659897, "intelligent": 0.00041316618093940904, "by initializing": 0.0005954002535516364, "well or": 0.0005559058853301298, "01 regardless of": 0.0008091139115659897, "show we were": 0.0008091139115659897, "1 of the": 0.0006415749577935461, "game as stated": 0.0008091139115659897, "as k nearest": 0.0008091139115659897, "could perform": 0.000634859264718638, "tied": 0.0003186897732673777, "are averaging cyclic": 0.0008091139115659897, "store each of": 0.0008091139115659897, "they maneuver in": 0.0008091139115659897, "to attempt": 0.00044153169724958527, "first 5 000": 0.0007023330300003208, "the examples and": 0.0006526576017704936, "demonstrating": 0.0002860067002590034, "well on": 0.0017056272774582382, "can produce benefits": 0.0008091139115659897, "reward the": 0.000702264802583379, "or performing": 0.000634859264718638, "has a non": 0.00046866225128631864, "so that": 0.0001804077739672305, "used a case": 0.0008091139115659897, "approach stores complete": 0.0016182278231319793, "that perform": 0.0003878648638474452, "used a reinforcement": 0.0008091139115659897, "counter": 0.0001614907953130693, "robot": 0.0043269241131257815, "range about": 0.0007696350858963753, "relatively small memory": 0.0007417488271393706, "applications that": 0.0003374403959319754, "they lose": 0.0006628410843555166, "for reinforcement learning": 0.0007023330300003208, "counted": 0.0002445400551532689, "suggested that simply": 0.0008091139115659897, "plus editing": 0.0007696350858963753, "assuming similar": 0.0007696350858963753, "game e": 0.0023089052576891257, "in figure 6": 0.00024223356267214416, "and lower limits": 0.0006526576017704936, "game i": 0.001404529605166758, "by shifting": 0.0004642630166224529, "move": 0.00010079641329673081, "on our hypothesis": 0.0008091139115659897, "produced": 0.00021346466700454766, "game s": 0.000702264802583379, "poorer than": 0.0006131469602829721, "50 to permit": 0.0008091139115659897, "approximate a markov": 0.0008091139115659897, "52 the more": 0.0008091139115659897, "pairs these experiments": 0.0008091139115659897, "perfect": 0.0008793022926150279, "for future": 0.00025524283217824665, "been studied by": 0.00045745222770795314, "severity of": 0.0005363412876789271, "0 ga 50": 0.0008091139115659897, "5b for": 0.000702264802583379, "gle ga plus": 0.0008091139115659897, "chosen": -4.916858875782827e-05, "pairs without explicitly": 0.0008091139115659897, "hypothesize": 0.0004098599033682474, "percent success games": 0.0008091139115659897, "about 90 there": 0.0008091139115659897, "degrees": 0.0006501808157834939, "states the": 0.00029943314463829254, "that assuming": 0.0005128077770266814, "and call the": 0.0006069246369921007, "learning differential games": 0.0008091139115659897, "games a": 0.0005456354281782176, "this family of": 0.0006743602501766612, "own for": 0.000702264802583379, "the ga indeed": 0.0008091139115659897, "strategy they anticipate": 0.0008091139115659897, "used by grefenstette": 0.0007417488271393706, "watkins 1989 td": 0.0008091139115659897, "compares a state": 0.0008091139115659897, "a more traditional": 0.0006069246369921007, "converged when they": 0.0008091139115659897, "strategies for the": 0.0016789147981028988, "nn experiments performance": 0.0008091139115659897, "game 3": 0.000702264802583379, "game 4": 0.0007696350858963753, "achieve alone this": 0.0008091139115659897, "tended to cancel": 0.0008091139115659897, "these pairs after": 0.0008091139115659897, "threshold our": 0.000702264802583379, "the truck": 0.0006628410843555166, "are analyzed": 0.0004288371693587632, "hands off the": 0.0008091139115659897, "sequence of actions": 0.0012398423521726258, "a format amenable": 0.0008091139115659897, "with large continuous": 0.0008091139115659897, "for 20": 0.001040084579101173, "the radius of": 0.000943350950791552, "algorithm and": 0.00017734209036133165, "evasive maneuvering": 0.0007696350858963753, "1993 developed an": 0.0008091139115659897, "values we": 0.00032821057342992757, "addition we": 0.0002747832868924773, "pursuer which": 0.0015392701717927505, "performance remained at": 0.0008091139115659897, "determined in": 0.00035882246681762515, "to explanation": 0.000702264802583379, "pursuer problem has": 0.0008091139115659897, "function approximators in": 0.0008091139115659897, "left 5": 0.0007696350858963753, "five nearest neighbors": 0.0008091139115659897, "game of soccer": 0.0008091139115659897, "start a ga": 0.0008091139115659897, "learning an": 0.0005060701527920558, "tasks we": 0.0008830633944991705, "be correct or": 0.0008091139115659897, "learning at": 0.001134766205046318, "frequency": 0.0001355392982704429, "to reduce its": 0.0005759152096655707, "evasion usually": 0.0007696350858963753, "method genetic algorithms": 0.0008091139115659897, "that e is": 0.0004779929005953682, "to explore the": 0.0004020439867656976, "to bootstrap k": 0.0008091139115659897, "to generate good": 0.0006526576017704936, "any action can": 0.0008091139115659897, "an estimate": 0.0005676681472954233, "used q": 0.0007696350858963753, "plans that": 0.0005954002535516364, "known closed": 0.0007696350858963753, "perceptual aliasing": 0.0015392701717927505, "curves we": 0.0005060701527920558, "develop a": 0.00024254333664610486, "to the starting": 0.0005851984448616567, "used a": 0.0008861345590598123, "a teacher and": 0.0008091139115659897, "adaptive": 0.0005679642259527548, "initial database": 0.0006628410843555166, "in successful": 0.0015392701717927505, "start of": 0.0002961263574580495, "in nature these": 0.0008091139115659897, "programming robots": 0.0007696350858963753, "for solving control": 0.0008091139115659897, "interactions": 0.00017412385966395318, "general architecture in": 0.0008091139115659897, "was the combined": 0.0008091139115659897, "experiments with the": 0.0004601378070916638, "generation and evaluation": 0.0007417488271393706, "bearing measures the": 0.0008091139115659897, "considerable research": 0.0005803901647646488, "and feature selection": 0.0006526576017704936, "known to cause": 0.0007417488271393706, "al against": 0.0007696350858963753, "1 for this": 0.0004813101872060044, "its training": 0.0005954002535516364, "order to": 0.00010983365242861094, "is shifted": 0.0004938405038742361, "jth dimension": 0.0007696350858963753, "algorithms k nn": 0.0008091139115659897, "reduce the": 0.00036897863987901637, "could": -0.0009898250128700943, "introduces noise into": 0.0008091139115659897, "between classes and": 0.0006349209434580451, "and 30": 0.00042027761111456123, "david": 0.00010784267378953168, "be removed from": 0.0004319040237213277, "work well we": 0.0008091139115659897, "the antecedent and": 0.0006743602501766612, "the relative frame": 0.0008091139115659897, "for this": 0.0002154081959209917, "pursuer is relatively": 0.0008091139115659897, "and lower": 0.00027020377595269354, "of examples decreases": 0.0008091139115659897, "surprised with": 0.0007696350858963753, "the halls": 0.0007696350858963753, "nearest neighbors we": 0.0007417488271393706, "outperformed ga right": 0.0008091139115659897, "determining good": 0.0015392701717927505, "turns they make": 0.0008091139115659897, "in pursuit": 0.000702264802583379, "is always": 0.0001578757045645674, "olsder 1982": 0.0007696350858963753, "somewhat erratically": 0.0007696350858963753, "direction is to": 0.0005954580987137418, "popular approaches": 0.0006131469602829721, "state is outside": 0.0008091139115659897, "of editing examples": 0.0008091139115659897, "combined the editing": 0.0008091139115659897, "or something": 0.000634859264718638, "and iri": 0.000567383102523159, "for decision": 0.0008764055773298718, "after generating": 0.000567383102523159, "on its own": 0.001886701901583104, "system": -0.002906834315635248, "future games": 0.000702264802583379, "not require": 0.0002174224613812204, "sheppard salzberg": 0.0015392701717927505, "s k murthy": 0.0007417488271393706, "shifting it toward": 0.0008091139115659897, "the example set": 0.0021069990900009624, "can be treated": 0.00042987704457580605, "depends only on": 0.00035168430803720827, "pedestrian crossing the": 0.0008091139115659897, "was because": 0.0005803901647646488, "techniques to train": 0.0008091139115659897, "the reinforcement program": 0.0008091139115659897, "alone and": 0.0005060701527920558, "learned to": 0.0010726825753578542, "a time": 0.00017271023122164848, "play by the": 0.0008091139115659897, "competitive goals of": 0.0008091139115659897, "plan grefenstette 1988": 0.0008091139115659897, "source of": 0.0005027788987694298, "of 11 and": 0.0006199211760863129, "the experiments also": 0.0006526576017704936, "actions before the": 0.0008091139115659897, "eral to": 0.0007696350858963753, "where they can": 0.0006526576017704936, "updated 4 2": 0.0008091139115659897, "has been applied": 0.00042031844251562157, "trials on": 0.000702264802583379, "before storing examples": 0.0008091139115659897, "or penalty for": 0.0008091139115659897, "differential equations of": 0.0005759152096655707, "warfare": 0.000567327990031413, "gll init population": 0.0008091139115659897, "don t care": 0.000471675475395776, "placements of": 0.000567383102523159, "we illustrated the": 0.0006199211760863129, "data set": 0.0003072722989859923, "the threshold was": 0.0008091139115659897, "call a": 0.0005509068374861213, "state variable to": 0.0008091139115659897, "by classifying": 0.0005559058853301298, "variables being": 0.000634859264718638, "shift closer": 0.0007696350858963753, "e and": 0.00042147980024210646, "collecting": 0.00025300020453897806, "than producing": 0.000702264802583379, "we adopted in": 0.0007023330300003208, "on the other": 0.00013929556083065029, "e are identical": 0.0007417488271393706, "each state variable": 0.0007417488271393706, "one way": 0.00024204374110161736, "low n": 0.0006628410843555166, "its genetic": 0.0007696350858963753, "reduced and games": 0.0008091139115659897, "classifiers which": 0.000702264802583379, "performance with": 0.0003238859962113274, "variant of q": 0.0008091139115659897, "and crosses": 0.000702264802583379, "clearly": -1.9492053954555717e-05, "not checked": 0.0005803901647646488, "run down": 0.0006628410843555166, "obtained a": 0.00040989971878532225, "follow a prespecified": 0.0008091139115659897, "the two problems": 0.0005083144306061808, "provides very good": 0.0008091139115659897, "of examples and": 0.0005524148804057065, "one generation select": 0.0008091139115659897, "1993 and": 0.0004004979458675273, "al 1991": 0.00042027761111456123, "al 1990": 0.001892685343516478, "s strategy": 0.0004997652289300559, "a sequence of": 0.0003933511638000211, "be incorrect": 0.0004938405038742361, "is similar": 0.00041468675761599115, "1988 temporal difference": 0.0008091139115659897, "the players we": 0.0007417488271393706, "accuracy": 0.0005808121578911465, "after reaching a": 0.0007023330300003208, "less than d": 0.0006069246369921007, "the algorithms k": 0.0008091139115659897, "to satisfy several": 0.0007417488271393706, "experiment since our": 0.0008091139115659897, "3 81": 0.0005559058853301298, "counted one": 0.0007696350858963753, "for the game": 0.0007417488271393706, "faster than": 0.0002410510306265817, "only points": 0.0005200422895505865, "autonomous agents": 0.0004560919846500759, "building and plug": 0.0008091139115659897, "mapping between": 0.00040276699958546587, "the resulting joint": 0.0008091139115659897, "features that measure": 0.0008091139115659897, "encoding them": 0.000634859264718638, "an experiment with": 0.0005954580987137418, "prior to": 0.0005173086899214014, "care conditions": 0.000702264802583379, "game is more": 0.0008091139115659897, "structures in": 0.0003177175902857743, "special type": 0.00046861672357587705, "implementation uses": 0.00042590150453082544, "its own": 0.0013789893069362086, "approach robot shaping": 0.0008091139115659897, "for a complete": 0.0004522903409367932, "trials the": 0.0005128077770266814, "the same control": 0.0005759152096655707, "fact": -0.0009333983957561145, "figure 8 results": 0.0006743602501766612, "to deal": 0.00023433161380612713, "s path": 0.0004938405038742361, "for instance based": 0.0007417488271393706, "artifact of": 0.0004731713358791195, "the game continues": 0.0014834976542787413, "a wall socket": 0.0008091139115659897, "p is to": 0.0005954580987137418, "heart of the": 0.00048474305809383046, "and fi is": 0.0005851984448616567, "of pruning methods": 0.0014046660600006416, "this was because": 0.0006743602501766612, "of a helpful": 0.0008091139115659897, "devijver kittler": 0.0007696350858963753, "two problems with": 0.0005851984448616567, "robot and provide": 0.0008091139115659897, "results motivated the": 0.0006743602501766612, "it is": 9.855357598403708e-06, "2 if smoke": 0.0008091139115659897, "p s": 0.00027886722524113144, "the states in": 0.0004882999224935485, "successfully evading": 0.0007696350858963753, "the earlier": 0.0003147644852783128, "of all of": 0.0003975888325128001, "car is": 0.0006628410843555166, "learning in neural": 0.0007023330300003208, "should": -0.000593754229569824, "experiments best": 0.0007696350858963753, "widrow 1989": 0.0007696350858963753, "widrow 1987": 0.0015392701717927505, "develops a mapping": 0.0008091139115659897, "meant": 0.0002476391618188996, "examples in": 0.00265783881660829, "playing arena": 0.0007696350858963753, "game k": 0.0007696350858963753, "handle": 6.701195525585609e-05, "there it improves": 0.0008091139115659897, "means": -8.73832970058766e-05, "examples if": 0.001134766205046318, "learning represents a": 0.0008091139115659897, "natural and artificial": 0.0006526576017704936, "that fired are": 0.0016182278231319793, "gave e": 0.000702264802583379, "stored game typically": 0.0008091139115659897, "pass within": 0.0007696350858963753, "examples is": 0.0008351605945268187, "shaping": 0.0008298272993657165, "classes to": 0.0008637241337018897, "of examples from": 0.0006526576017704936, "p 2": 0.0008713091829024274, "p 1": 0.00017157648542737985, "the general class": 0.0006743602501766612, "of using lazy": 0.0008091139115659897, "h": -4.055921844324362e-05, "no turn with": 0.0008091139115659897, "if the paths": 0.0006069246369921007, "human teacher are": 0.0008091139115659897, "payoff function defined": 0.0008091139115659897, "the paths": 0.0003147644852783128, "the form": 0.00020896765346185814, "the two versions": 0.0005596382660342995, "first learner": 0.0007696350858963753, "k nn on": 0.004045569557829949, "specifying a": 0.000391902140873557, "topics programming robots": 0.0008091139115659897, "much faster": 0.0003338822091906335, "in search credit": 0.0008091139115659897, "the experiments were": 0.00046866225128631864, "success with": 0.0005559058853301298, "a given": 0.00013784657442422282, "frame": 0.0001558260871614339, "1995 developed the": 0.0008091139115659897, "tied to": 0.0004382027886649359, "possible to": 0.00021759912547793638, "select best plan": 0.0008091139115659897, "6 discussion": 0.00044854462015967935, "game we gave": 0.0008091139115659897, "algorithm run the": 0.0008091139115659897, "currently playing at": 0.0008091139115659897, "discarded the ritter": 0.0008091139115659897, "training agents to": 0.0016182278231319793, "two pursuer": 0.013083796460238379, "incorrect e might": 0.0008091139115659897, "and gas": 0.0006628410843555166, "optimal strategy for": 0.0005954580987137418, "using all": 0.00041758029726340933, "case obtained nearly": 0.0008091139115659897, "rule compilation": 0.000702264802583379, "learning most effectively": 0.0008091139115659897, "population of": 0.0004560919846500759, "0 3": 0.0002541283390836954, "a lookup table": 0.0006526576017704936, "success in": 0.00044153169724958527, "the task the": 0.0006069246369921007, "improve classification": 0.0006628410843555166, "reinformement": 0.0007021965884209132, "seeded into": 0.000702264802583379, "neighbor algorithm": 0.0005803901647646488, "in a plan": 0.0006526576017704936, "experiments the": 0.0002882806874477652, "game was": 0.001404529605166758, "we can": 0.00010764331750516268, "surprising in that": 0.0007417488271393706, "the estimates of": 0.0005039721952628732, "teacher which": 0.000702264802583379, "two classes": 0.00031672395822701763, "to create a": 0.00036238524153671306, "frequently to": 0.000702264802583379, "in search optimization": 0.0006526576017704936, "the multidit algorithm": 0.0008091139115659897, "powerful combination": 0.0006628410843555166, "a neural": 0.0004288371693587632, "the genetic": 0.003891341197310908, "grab e figure": 0.0008091139115659897, "turns out that": 0.0003256977768864979, "unable to": 0.0002882806874477652, "highly dynamic": 0.0005060701527920558, "zero radius of": 0.0008091139115659897, "applied to chess": 0.0008091139115659897, "learning solves delayed": 0.0008091139115659897, "done to evaluate": 0.0007417488271393706, "e both": 0.0005456354281782176, "w sheppard colearning": 0.0007417488271393706, "this confirms": 0.0004938405038742361, "planning and": 0.0008830633944991705, "adjusted": 0.0002366638432639197, "co": 0.000484472385939208, "arm to follow": 0.0008091139115659897, "values of": 9.737293501231306e-05, "are much greater": 0.0007417488271393706, "problems we studied": 0.0007417488271393706, "the game was": 0.0008091139115659897, "and salzberg 1993": 0.0008091139115659897, "trials 5 2": 0.0008091139115659897, "since e": 0.0004004979458675273, "examined several methods": 0.0008091139115659897, "noise into the": 0.0008091139115659897, "delayed reinforcement tasks": 0.0008091139115659897, "simon kasif": 0.000702264802583379, "eventually reached a": 0.0007417488271393706, "10 000": 0.0014535229798610942, "correct action or": 0.0008091139115659897, "envelope of the": 0.0006199211760863129, "trajectory": 0.00031669319339377555, "random sets": 0.0005559058853301298, "and mutate those": 0.0008091139115659897, "problems plagued": 0.0007696350858963753, "by adding a": 0.0004167376361167208, "as we see": 0.0004882999224935485, "genetic": 0.009588035267760885, "been no": 0.00048825248710181613, "their control": 0.0006131469602829721, "the ga gle": 0.0008091139115659897, "idea being that": 0.0007417488271393706, "sharing rate our": 0.0008091139115659897, "striking difference in": 0.0008091139115659897, "that studies": 0.0006131469602829721, "genetic operators to": 0.0007023330300003208, "will continue to": 0.00046289837369057756, "to learn evasion": 0.0008091139115659897, "and led": 0.000634859264718638, "not to construct": 0.0008091139115659897, "markov decision": 0.003819447997247523, "matcher has failed": 0.0008091139115659897, "new along": 0.0007696350858963753, "3 p 201": 0.0005954580987137418, "games the number": 0.0008091139115659897, "the decisions": 0.00044854462015967935, "accuracy in": 0.0003327228091591544, "have been shown": 0.00041159621990674106, "nn to create": 0.0008091139115659897, "the correct control": 0.0008091139115659897, "colombetti and": 0.0007696350858963753, "tasks tolerating noisy": 0.0008091139115659897, "the ga in": 0.0008091139115659897, "mccallum showed through": 0.0008091139115659897, "examples in our": 0.0006743602501766612, "achieve similar coverage": 0.0008091139115659897, "classifier which searched": 0.0008091139115659897, "to the end": 0.00039472486509154587, "success was": 0.000634859264718638, "simple task": 0.0005559058853301298, "so that any": 0.0005039721952628732, "the correct action": 0.002225246481418112, "a method similar": 0.0005524148804057065, "game change the": 0.0008091139115659897, "player some": 0.0007696350858963753, "difficulty scaling up": 0.0007417488271393706, "a race track": 0.0008091139115659897, "well and the": 0.0006349209434580451, "computational time is": 0.0007023330300003208, "tends to learn": 0.0007417488271393706, "solving a": 0.0009111496045847714, "learning to teach": 0.0008091139115659897, "theory is": 0.0007176449336352503, "5 700": 0.0007696350858963753, "evades if": 0.0007696350858963753, "which of the": 0.0004051279487445566, "theory in": 0.0006978323846666046, "pursuer game would": 0.0008091139115659897, "the 1 700": 0.0008091139115659897, "game is": 0.0031202537373035194, "again this makes": 0.0007417488271393706, "forever at": 0.0006628410843555166, "recognition literature e": 0.0008091139115659897, "single learning": 0.0006628410843555166, "first trained": 0.0007696350858963753, "boundaries between classes": 0.0008091139115659897, "game as": 0.001904577794155914, "of smoke": 0.000634859264718638, "a relatively small": 0.00041499427023074183, "game at": 0.0015392701717927505, "parameters is to": 0.0008091139115659897, "was binary emitting": 0.0008091139115659897, "experiments indicate that": 0.0004919901420568756, "the game over": 0.0008091139115659897, "methods have been": 0.0003892305354108736, "helpful teacher prototype": 0.0008091139115659897, "fitness rather": 0.0007696350858963753, "methods apply": 0.0005456354281782176, "percent success": 0.003078540343585501, "be included": 0.0003177175902857743, "a fixed radius": 0.0008091139115659897, "our earlier": 0.0003681525887744991, "the task was": 0.0006743602501766612, "ball": 0.0002890118751735629, "a series": 0.00047337366745716996, "be appended": 0.0005954002535516364, "9116843": 0.0006347975979615015, "formulation has": 0.00052785331295456, "upon": 6.199184677305917e-05, "success while the": 0.0007417488271393706, "the best examples": 0.0007417488271393706, "a level of": 0.0009839802841137512, "example using all": 0.0008091139115659897, "generation were": 0.0006628410843555166, "were edited": 0.0007696350858963753, "nn in particular": 0.0008091139115659897, "problem using a": 0.0010787894924506108, "and grefenstette use": 0.0008091139115659897, "expand": 0.00021985083825553804, "evade and then": 0.0008091139115659897, "good and needed": 0.0008091139115659897, "outperformed by both": 0.0007417488271393706, "limits of": 0.00035445902764197844, "discounted": 0.00039606968857753465, "rule would be": 0.0007023330300003208, "ga experiments": 0.0007696350858963753, "related to": 0.00013097269336206875, "multidit algorithm": 0.0007696350858963753, "nearby neighbors 4": 0.0008091139115659897, "s actions": 0.0004997652289300559, "evasion within 5": 0.0008091139115659897, "evasive maneuvers problem": 0.0008091139115659897, "the profit sharing": 0.0016182278231319793, "study we": 0.0003147644852783128, "359": 0.00035161598665633655, "was not": 0.0004340379687435999, "optimal play by": 0.0016182278231319793, "represented as binary": 0.0007023330300003208, "as few as": 0.0005596382660342995, "accuracy and": 0.000310019848849804, "a margin": 0.0011908005071032729, "and one rule": 0.0007023330300003208, "less": -0.00035979193749756513, "almost all the": 0.0004882999224935485, "eral to map": 0.0008091139115659897, "to produce learning": 0.0008091139115659897, "stored state should": 0.0008091139115659897, "system strength": 0.0007696350858963753, "heading and distance": 0.0008091139115659897, "will also pit": 0.0008091139115659897, "significant information": 0.0006131469602829721, "5 sample games": 0.0008091139115659897, "grefenstette 1991 has": 0.0008091139115659897, "is the": 1.872501227806004e-05, "that action": 0.0005456354281782176, "algorithm at that": 0.0008091139115659897, "information in both": 0.0007023330300003208, "7 results of": 0.0006743602501766612, "a certain performance": 0.0007417488271393706, "of the three": 0.0002775158074633715, "were left": 0.0005803901647646488, "problem was the": 0.0007023330300003208, "a spatial knowledge": 0.0008091139115659897, "the ga was": 0.0032364556462639586, "arm to": 0.000702264802583379, "indeed the": 0.0002882806874477652, "of an": 3.573548071413949e-05, "their study they": 0.0008091139115659897, "eventual payoff both": 0.0008091139115659897, "is difficult we": 0.0006349209434580451, "requirements without significantly": 0.0008091139115659897, "for all": 4.454987739202789e-05, "arena while the": 0.0008091139115659897, "games require": 0.0007696350858963753, "using a lookup": 0.0008091139115659897, "fold first minimal": 0.0008091139115659897, "termination at which": 0.0008091139115659897, "which the terms": 0.0007417488271393706, "the tasks": 0.001023376366474943, "example to": 0.00025807848985967736, "represented as": 0.0002311124137898519, "increased": 7.96350134953714e-05, "that such points": 0.0007023330300003208, "and torras 1992": 0.0008091139115659897, "we reset": 0.0006131469602829721, "well as": 8.365445033991404e-05, "curvature and the": 0.0008091139115659897, "increases": 2.034561420388105e-05, "five": 9.46924804298419e-05, "learning 7": 0.0006628410843555166, "like to": 0.00014893430341662872, "develops a": 0.00046861672357587705, "converted into": 0.0003462531725087664, "problem previous turn": 0.0008091139115659897, "gll obtained a": 0.0008091139115659897, "popular temporal": 0.0007696350858963753, "a level": 0.0009947286924941704, "explicitly provides": 0.000702264802583379, "the ga surpassing": 0.0008091139115659897, "rules called": 0.000634859264718638, "described another": 0.0007696350858963753, "each rule is": 0.0006069246369921007, "corrected actions": 0.0007696350858963753, "architecture should expand": 0.0008091139115659897, "become": 0.0, "p for a": 0.0005039721952628732, "produce a": 0.00023156689856445445, "began to": 0.0005128077770266814, "incorrect e": 0.0007696350858963753, "not storing": 0.0006628410843555166, "course the": 0.0003028459277060942, "4 1 lazy": 0.0008091139115659897, "in related": 0.00048825248710181613, "algorithms can be": 0.00038529791840416234, "caught a": 0.0007696350858963753, "different actions": 0.0005954002535516364, "developed the": 0.0003820967919236623, "is consistent": 0.0002546842039466833, "a relative coordinate": 0.0008091139115659897, "of fuel if": 0.0008091139115659897, "is to head": 0.0008091139115659897, "correctly classified we": 0.0008091139115659897, "recognition": 0.0005138336085897021, "will be": 0.00011803523282305153, "steps our current": 0.0008091139115659897, "achieve similar": 0.000567383102523159, "collecting examples": 0.0007696350858963753, "for solving these": 0.0006069246369921007, "find a": 0.00017385346182484084, "pair s q": 0.0008091139115659897, "small set": 0.0006978323846666046, "1 nn percent": 0.0008091139115659897, "avoid": 2.548462986571064e-05, "temporal difference learning": 0.004046161501059968, "substantially harder to": 0.0007417488271393706, "or penalty typically": 0.0008091139115659897, "does": -0.0002905465232654813, "and a genetic": 0.0014834976542787413, "algorithm to cover": 0.0008091139115659897, "maintained throughout the": 0.0006526576017704936, "generating the first": 0.0007023330300003208, "7 we call": 0.0006526576017704936, "even further": 0.00045224640365867626, "and has yielded": 0.0008091139115659897, "stated above a": 0.0008091139115659897, "this sequence": 0.0003449470981709676, "selecting": 0.0003820313583596335, "1992 used a": 0.0008091139115659897, "a successful game": 0.0008091139115659897, "using edited": 0.0007696350858963753, "hill climbing algorithms": 0.0007417488271393706, "evaluation for": 0.00042590150453082544, "consequently we decided": 0.0007417488271393706, "k nearest": 0.005566771680712612, "possible future": 0.0004997652289300559, "each algorithm": 0.00039398316601407357, "in which an": 0.0013645129055394755, "and action": 0.001766126788998341, "database the system": 0.0007417488271393706, "of teaching": 0.0005954002535516364, "fuel if": 0.0015392701717927505, "considered to be": 0.00033009897175506186, "training set": 0.00037315955974098747, "selected it as": 0.0007417488271393706, "that still": 0.00048296474811893784, "can change": 0.000335054731187079, "the evader additional": 0.0008091139115659897, "similar to hart": 0.0008091139115659897, "have to result": 0.0008091139115659897, "to handle": 0.00019000245717040344, "how two": 0.0005200422895505865, "performance the": 0.000529165478461885, "where a game": 0.0008091139115659897, "the ga to": 0.002427341734697969, "that outperformed both": 0.0008091139115659897, "solving the games": 0.0008091139115659897, "1963 shows": 0.0007696350858963753, "teacher are shown": 0.0008091139115659897, "environments specifically": 0.000702264802583379, "any lazy or": 0.0008091139115659897, "r t 8s2rules": 0.0008091139115659897, "of a homogenous": 0.0008091139115659897, "sharpness": 0.00044493294905444163, "such as those": 0.0007108944879689356, "outcome of a": 0.0005596382660342995, "control problems we": 0.0007417488271393706, "observation was": 0.00052785331295456, "to control problems": 0.0006743602501766612, "actions i e": 0.0007023330300003208, "control laws for": 0.0007417488271393706, "if the speed": 0.0007023330300003208, "and then communicate": 0.0008091139115659897, "performance when": 0.0003898632748579793, "learn several": 0.000702264802583379, "plus lazy": 0.0007696350858963753, "bounds only": 0.0006131469602829721, "sequence can": 0.00044153169724958527, "edited data": 0.0007696350858963753, "the sequence one": 0.0007023330300003208, "the graph are": 0.0005039721952628732, "the behaviors and": 0.0007417488271393706, "neighbor rule differential": 0.0008091139115659897, "whereas for two": 0.0008091139115659897, "either p1 or": 0.0008091139115659897, "to aerial dogfighting": 0.0008091139115659897, "in their two": 0.0007023330300003208, "play i e": 0.0008091139115659897, "number of games": 0.0014046660600006416, "naturally": 0.0001342177283211427, "function": -0.0007616637768550174, "space or the": 0.0007023330300003208, "was not completely": 0.0007023330300003208, "the robot and": 0.0013053152035409873, "learning learning with": 0.0007417488271393706, "or memory": 0.00044153169724958527, "i are the": 0.0004319040237213277, "the lower and": 0.0004813101872060044, "games genetic": 0.0007696350858963753, "learner and": 0.0006131469602829721, "convergence": 0.0002406686022295794, "vector of": 0.00022622594443259307, "plan fitness rather": 0.0008091139115659897, "than both the": 0.0006069246369921007, "pursuer relative to": 0.0008091139115659897, "whitehead 1992 mccallum": 0.0008091139115659897, "in fact we": 0.00034985342360325584, "location where": 0.0005060701527920558, "typical formulation": 0.0007696350858963753, "and grefenstette": 0.0013256821687110331, "millan and": 0.0007696350858963753, "algorithm was": 0.0002945105957876159, "reinforcement": 0.011659143189550063, "can change direction": 0.0008091139115659897, "result is that": 0.00038659182444107513, "meta": 0.0002645570391105703, "possible for": 0.000238123300320931, "complicated planning": 0.0007696350858963753, "the points for": 0.0006349209434580451, "problem": -0.006217281330165478, "smoke bomb": 0.0007696350858963753, "the optimal": 0.0010873590281449115, "of the correct": 0.00046866225128631864, "learning as": 0.0010121403055841115, "ga using": 0.0007696350858963753, "bearing": 0.0012295797101047423, "based upon work": 0.0005954580987137418, "learning approach k": 0.0008091139115659897, "achieving 2 10": 0.0008091139115659897, "and gray applied": 0.0008091139115659897, "not better than": 0.0006743602501766612, "games 320 generations": 0.0008091139115659897, "still worked quite": 0.0008091139115659897, "of the experiment": 0.0009839802841137512, "our difficult": 0.0007696350858963753, "second pursuer which": 0.0008091139115659897, "and target tracking": 0.0008091139115659897, "planning and control": 0.0007023330300003208, "with bad": 0.0006628410843555166, "table 1 shows": 0.000356410000254863, "compared": -1.466837880743959e-05, "given in": 0.00010374287478096576, "variety": 0.0001733987790624461, "outperforming either": 0.0007696350858963753, "trials": 0.0008283025941331521, "future location of": 0.0008091139115659897, "8 a logarithmic": 0.0008091139115659897, "sharing plan": 0.0007696350858963753, "additional 5 000": 0.0008091139115659897, "at the same": 0.0004207569019029011, "compares": 0.0003046655107420069, "details": -5.188203695950369e-05, "reduction in speed": 0.0008091139115659897, "competition initially all": 0.0008091139115659897, "reaching a plateau": 0.0008091139115659897, "the effects of": 0.0005643609447369757, "then performance": 0.001404529605166758, "position in play": 0.0008091139115659897, "with each rule": 0.0007417488271393706, "task substantially harder": 0.0008091139115659897, "33 points": 0.0007696350858963753, "of escaping from": 0.0008091139115659897, "generated games the": 0.0008091139115659897, "to successfully": 0.00042304989757217126, "10 trials": 0.0006131469602829721, "agents through learning": 0.0008091139115659897, "4 2 k": 0.0007417488271393706, "this problem": 0.00011340931712465806, "evader from": 0.0007696350858963753, "right and 85": 0.0008091139115659897, "next steps": 0.000702264802583379, "22 games assuming": 0.0008091139115659897, "the strengths": 0.00044153169724958527, "q learning we": 0.0008091139115659897, "searches": 0.00023955459123611926, "modeled by differential": 0.0008091139115659897, "plateau was": 0.0007696350858963753, "actions we specify": 0.0008091139115659897, "evasion neither the": 0.0008091139115659897, "compares the performance": 0.0005524148804057065, "were disappointing": 0.0007696350858963753, "rule": 0.0012290456711953042, "and refines the": 0.0008091139115659897, "locations on a": 0.0007023330300003208, "requirements b introduction": 0.0007023330300003208, "good examples such": 0.0008091139115659897, "compete": 0.00032928840029762313, "then show": 0.00035882246681762515, "called delayed reinforcement": 0.0008091139115659897, "searched": 0.00029368324706416615, "e was": 0.0006628410843555166, "was set to": 0.0008406368850312431, "by itself to": 0.0007417488271393706, "asymptotic performance": 0.00052785331295456, "the advantages": 0.00026519336172906905, "successful evasion the": 0.0008091139115659897, "a homogenous": 0.000634859264718638, "based reasoning": 0.0005060701527920558, "to throw": 0.000634859264718638, "to equalize": 0.0005803901647646488, "the game the": 0.0006349209434580451, "after only 5": 0.0007417488271393706, "generate examples and": 0.0008091139115659897, "very good examples": 0.0008091139115659897, "correct ones in": 0.0008091139115659897, "of identifying": 0.00039398316601407357, "eventually reached": 0.001269718529437276, "close to 1": 0.00040993954193880374, "when we found": 0.0008091139115659897, "that fired for": 0.0008091139115659897, "actually a three": 0.0008091139115659897, "1981 markov": 0.0007696350858963753, "after storing": 0.0007696350858963753, "of bad examples": 0.0008091139115659897, "developed an": 0.0003665369780185166, "time step however": 0.0007023330300003208, "meant that": 0.00048825248710181613, "which different learning": 0.0008091139115659897, "radius of": 0.0021896797727306377, "types of learning": 0.0007023330300003208, "performed better than": 0.0017863742961412258, "the state matcher": 0.0016182278231319793, "to label each": 0.0007023330300003208, "100 randomly generated": 0.0007417488271393706, "performs well": 0.000783804281747114, "speeds dropped": 0.0007696350858963753, "the delay": 0.0002953154240675878, "achieving a level": 0.0008091139115659897, "and it reached": 0.0008091139115659897, "almost every state": 0.0008091139115659897, "was maintained": 0.000634859264718638, "evasion were allowed": 0.0008091139115659897, "of actions at": 0.0007023330300003208, "other source of": 0.0007023330300003208, "90 after": 0.0007696350858963753, "better for the": 0.0005596382660342995, "with a separate": 0.0006199211760863129, "moore 1990 took": 0.0008091139115659897, "only the best": 0.0005759152096655707, "action are less": 0.0008091139115659897, "summarized": 0.00015332242514950298, "perfectly q": 0.0007696350858963753, "it still": 0.00038024507112555464, "envision a more": 0.0008091139115659897, "strategy of": 0.00036338074496527356, "the amount": 0.00017271023122164848, "are given": 0.00012568079543406752, "through a continuous": 0.0008091139115659897, "as the first": 0.0003975888325128001, "nearest neighbors those": 0.0008091139115659897, "into a genetic": 0.0008091139115659897, "for a more": 0.00036035437821275464, "states the action": 0.0008091139115659897, "b introduction": 8.593689846726967e-06, "by e is": 0.0006526576017704936, "uses a genetic": 0.0008091139115659897, "chosen set": 0.0005954002535516364, "in fact at": 0.0006743602501766612, "study the": 0.0002033187844386837, "gammon is": 0.000702264802583379, "same task hoping": 0.0008091139115659897, "two of which": 0.0005596382660342995, "tasks in which": 0.0006526576017704936, "experiments to": 0.00035445902764197844, "and perceptions is": 0.0008091139115659897, "quite small": 0.0004149539560409001, "task acknowledgments thanks": 0.0008091139115659897, "game called a": 0.0008091139115659897, "experiments where": 0.0005200422895505865, "adding a second": 0.0006743602501766612, "simulator the simulator": 0.0007023330300003208, "almost every": 0.00042027761111456123, "which players": 0.000702264802583379, "of a single": 0.00024561146620549973, "is an extension": 0.00037434295450873773, "devijver 1986": 0.0007696350858963753, "edited data selecting": 0.0008091139115659897, "is described further": 0.0007417488271393706, "a race": 0.0005363412876789271, "will focus": 0.00037664034839981597, "which in": 0.00022195263924232946, "where e evades": 0.0016182278231319793, "different machine": 0.0005456354281782176, "a player": 0.00052785331295456, "well k": 0.000702264802583379, "slowed consider": 0.0007696350858963753, "throughout its": 0.000634859264718638, "constraint therefore": 0.0006628410843555166, "plan fitness": 0.0023089052576891257, "consequent": 0.00038394579071886724, "is significantly": 0.0002945105957876159, "our implementation": 0.0007742354695790322, "to the ga": 0.0006743602501766612, "above": -0.0015355517724922783, "ga indeed the": 0.0008091139115659897, "assist agents": 0.0007696350858963753, "the more complicated": 0.0006069246369921007, "perform sequential": 0.001404529605166758, "turn sharply": 0.0015392701717927505, "the goal is": 0.0003256977768864979, "differential games includes": 0.0008091139115659897, "strategy generation and": 0.0008091139115659897, "simultaneously": 8.16324462699643e-05, "learner in": 0.0005559058853301298, "show we": 0.0006131469602829721, "motivated the": 0.0009558929329372694, "range to be": 0.0008091139115659897, "in a q": 0.0006199211760863129, "by barto et": 0.0008091139115659897, "a level equal": 0.0008091139115659897, "step further and": 0.0006526576017704936, "as 11 examples": 0.0008091139115659897, "p 201 233": 0.0007417488271393706, "pursuit": 0.006673994235816624, "called temporal difference": 0.0008091139115659897, "not have good": 0.0007417488271393706, "techniques to": 0.00022666187998126376, "90 success with": 0.0008091139115659897, "and in": 7.004031551736161e-05, "obtained": -0.00021795764181340818, "gll": 0.006982773577576516, "neighboring states will": 0.0008091139115659897, "what it has": 0.0006743602501766612, "hoping to demonstrate": 0.0008091139115659897, "study": -0.0004139092529794618, "gle": 0.002269311960125652, "tr on the": 0.0006069246369921007, "evasion after only": 0.0008091139115659897, "techniques such as": 0.0003790659936968334, "work in learning": 0.0008091139115659897, "smoke": 0.0027279121406831334, "conjunctive": 0.0006541614045626953, "that objective examples": 0.0008091139115659897, "random games at": 0.0008091139115659897, "obtained nearly perfect": 0.0008091139115659897, "moore atkeson": 0.000702264802583379, "a dynamic": 0.00025807848985967736, "of the examples": 0.0004548376351798251, "significantly more": 0.0006951521067430843, "1994 have used": 0.0008091139115659897, "about its opponents": 0.0008091139115659897, "recently systems for": 0.0008091139115659897, "achieving 2": 0.0007696350858963753, "highly": 0.00022804119432256095, "highly nonlinear thus": 0.0008091139115659897, "and payoff": 0.0007696350858963753, "sequential behavior robot": 0.0008091139115659897, "then is": 0.0002727971730761859, "our extended version": 0.0007417488271393706, "car is much": 0.0008091139115659897, "prototype and": 0.0005363412876789271, "probably not storing": 0.0008091139115659897, "linearly": 0.00013957065156949944, "to the number": 0.00026101329737339364, "reason that determining": 0.0008091139115659897, "reward is determined": 0.0007417488271393706, "example if": 0.00019295402328989292, "induction efficient memory": 0.0008091139115659897, "of learning how": 0.0007417488271393706, "motivate": 0.0002366638432639197, "plan the number": 0.0008091139115659897, "example in": 0.00014701812508756683, "used to control": 0.00045745222770795314, "of using these": 0.0006743602501766612, "strategies for more": 0.0008091139115659897, "using fitness proportional": 0.0008091139115659897, "task together they": 0.0008091139115659897, "or the action": 0.0007417488271393706, "learning control problems": 0.0007417488271393706, "actions until": 0.0007696350858963753, "gll because it": 0.0008091139115659897, "much smoother indicating": 0.0008091139115659897, "k nn experiments": 0.0008091139115659897, "on random sets": 0.0008091139115659897, "began by examining": 0.0008091139115659897, "discussed applicable": 0.0007696350858963753, "selected arbitrarily and": 0.0008091139115659897, "development of niches": 0.0008091139115659897, "curvature": 0.0018434547134114452, "player learning": 0.0007696350858963753, "in analyzing this": 0.0007417488271393706, "as they maneuver": 0.0008091139115659897, "this rule form": 0.0008091139115659897, "the application of": 0.0002658331951878856, "30 000": 0.00052785331295456, "satisfy several": 0.0006628410843555166, "axis to": 0.0005200422895505865, "achieving a": 0.0004349818647972793, "the ritter": 0.0007696350858963753, "1991": 0.0010671318976863621, "1990": 0.00227516511748189, "1993": 0.001303056618145308, "1992": 0.0025240509711237855, "1995": 0.00015086051772282924, "1994": 0.0008563893476495033, "knowledge of the": 0.0003122377618813423, "permits": 0.000227516511748189, "1998": 0.00011398254956139872, "turn angle which": 0.0008091139115659897, "work": -0.0031975962700620383, "use the term": 0.0003892305354108736, "1994 and": 0.0004123948992280552, "will match all": 0.0008091139115659897, "figure 3 performance": 0.0005674382257236372, "learning after 50": 0.0008091139115659897, "optimal strategy": 0.0018243679386003035, "until we have": 0.0005759152096655707, "environment one": 0.0006628410843555166, "learning algorithm to": 0.0006526576017704936, "indicated": 0.00022718569038110192, "of its previous": 0.0007023330300003208, "it did not": 0.0005524148804057065, "robot shaping genetic": 0.0008091139115659897, "complexity td": 0.0007696350858963753, "did extremely well": 0.0008091139115659897, "indicates": 2.9505941881507826e-05, "backgammon classifier systems": 0.0008091139115659897, "more traditional lazy": 0.0008091139115659897, "for e is": 0.0006069246369921007, "structures in which": 0.0007023330300003208, "lin 1991": 0.000702264802583379, "remained at a": 0.0008091139115659897, "knew the": 0.000567383102523159, "t j is": 0.0004882999224935485, "thus a stored": 0.0008091139115659897, "history of the": 0.0004657382758148953, "takes a": 0.00028903995093373133, "provide": -0.00027439310816019353, "learning given the": 0.0008091139115659897, "experiments where we": 0.0006743602501766612, "work recently": 0.0007696350858963753, "game k 0": 0.0008091139115659897, "colombetti 1994 and": 0.0008091139115659897, "appropriate actions distance": 0.0008091139115659897, "apparent plateau": 0.0007696350858963753, "interactions in": 0.00045224640365867626, "euclidean distance to": 0.0006526576017704936, "at developing a": 0.0007023330300003208, "our lazy learning": 0.0008091139115659897, "a system to": 0.0005039721952628732, "classifying": 0.0008163498667446772, "only plans that": 0.0008091139115659897, "railroad monitoring and": 0.0008091139115659897, "earlier": 8.13824568155242e-05, "considerable work": 0.0005363412876789271, "learning method genetic": 0.0008091139115659897, "of researchers": 0.0004731713358791195, "a co": 0.0009201862149591017, "zigzags back and": 0.0008091139115659897, "difference algorithms": 0.0007696350858963753, "law": 0.00022151212119868156, "system gle ga": 0.0008091139115659897, "we deleted": 0.000634859264718638, "sequences we": 0.00042590150453082544, "multiple solutions for": 0.0007023330300003208, "system learned to": 0.0008091139115659897, "is applied": 0.0002069735289986681, "experiments ae is": 0.0008091139115659897, "second algorithm": 0.001345633860479038, "fixed solution to": 0.0008091139115659897, "many valuable": 0.0005128077770266814, "performance on this": 0.0006199211760863129, "the edited nearest": 0.0008091139115659897, "two evasion tasks": 0.0008091139115659897, "8 a": 0.00026157905702535613, "differences in": 0.00030198240340165204, "and later": 0.00035165014402826746, "order": -0.0008323856841827538, "66 examples thus": 0.0008091139115659897, "expected discounted reward": 0.0008091139115659897, "we must at": 0.0008091139115659897, "draft of": 0.00044497617160632185, "environment rather than": 0.0008091139115659897, "they provided an": 0.0008091139115659897, "science foundation under": 0.00038402039400084893, "evaluate the": 0.00019196261776044306, "construct a": 0.00018743431824375768, "problem we therefore": 0.0006743602501766612, "again this": 0.00035027405940034004, "use rules called": 0.0008091139115659897, "an approach to": 0.0007289147843956187, "this hybrid approach": 0.0007417488271393706, "to this algorithm": 0.0005596382660342995, "escape because": 0.0007696350858963753, "better than 80": 0.0008091139115659897, "terms in": 0.000271492817488675, "limited time": 0.000567383102523159, "adaptation in natural": 0.0006526576017704936, "similarly using": 0.0005559058853301298, "spaces atkeson": 0.0007696350858963753, "by the genetic": 0.0006743602501766612, "caught1 12334 figure": 0.0008091139115659897, "game of": 0.0005456354281782176, "neighbor our": 0.0007696350858963753, "actions it will": 0.0008091139115659897, "then": -0.011961258830330926, "them": -0.0002675591794117965, "train a backgammon": 0.0008091139115659897, "help to hide": 0.0008091139115659897, "evader pursuer pursuer": 0.0016182278231319793, "state i following": 0.0008091139115659897, "examples finally": 0.0006131469602829721, "11 and k": 0.0008091139115659897, "amenable": 0.00027746189472758456, "25 this probability": 0.0008091139115659897, "points whereas": 0.0007696350858963753, "they": -0.0056906987355917205, "failed to": 0.0007922163287168681, "store examples stores": 0.0008091139115659897, "the examples in": 0.0004601378070916638, "increasingly difficult control": 0.0008091139115659897, "replayed with": 0.0007696350858963753, "a rule and": 0.0006349209434580451, "of curvature is": 0.0007417488271393706, "pursuer evasion": 0.0015392701717927505, "this case": 6.418417571466791e-05, "reasonably": 0.00018805333444124348, "classified": 0.0005364161887214156, "each training game": 0.0008091139115659897, "genetic algorithms perform": 0.0008091139115659897, "tests during testing": 0.0008091139115659897, "s stochastic": 0.000702264802583379, "pedestrian can": 0.0007696350858963753, "generations i e": 0.0008091139115659897, "small in": 0.0003147644852783128, "disappointing when e": 0.0008091139115659897, "teaching markov games": 0.0008091139115659897, "classifies": 0.00035442459743045417, "classifier": 0.001573669553887786, "and one of": 0.00041328080567602945, "it one": 0.00046861672357587705, "throughout training even": 0.0008091139115659897, "just keeps": 0.0007696350858963753, "turn angle and": 0.0008091139115659897, "goal is to": 0.0002526838665262274, "environments an": 0.0005803901647646488, "combination in related": 0.0008091139115659897, "like games": 0.0007696350858963753, "also wins": 0.0007696350858963753, "same system can": 0.0008091139115659897, "1991 algorithms": 0.0007696350858963753, "ritter et": 0.001404529605166758, "network": 0.00016694681543613757, "nn and q": 0.0016182278231319793, "thus only": 0.00043186206685094484, "of ga": 0.0012262939205659443, "two distance parameters": 0.0008091139115659897, "20 rules": 0.001404529605166758, "between 5": 0.00045224640365867626, "one surprising result": 0.0008091139115659897, "general they were": 0.0008091139115659897, "following a": 0.00030818023003300325, "letting the": 0.00048825248710181613, "the rewards": 0.000567383102523159, "of examples are": 0.0008091139115659897, "forth": 0.0002830829420950543, "form suitable for": 0.0006526576017704936, "100 generations for": 0.0008091139115659897, "nearest neighbors k": 0.0007417488271393706, "1989 holland 1975": 0.0008091139115659897, "the fact": 0.00016194540861491166, "could be": 0.0004179353069237163, "iri 9116843": 0.000702264802583379, "the study in": 0.0006349209434580451, "with careful": 0.0005803901647646488, "systems based on": 0.0009257967473811551, "interpolation so": 0.000702264802583379, "standard": -0.00017853564662575195, "some goal": 0.0006131469602829721, "k murthy": 0.0005954002535516364, "difference in": 0.00024204374110161736, "directly using genetic": 0.0008091139115659897, "when they showed": 0.0008091139115659897, "locates all": 0.0006628410843555166, "algorithms perform well": 0.0007023330300003208, "sweeping algorithm in": 0.0008091139115659897, "the teacher are": 0.0008091139115659897, "game theory originated": 0.0008091139115659897, "keeps turning": 0.0007696350858963753, "between p": 0.00037315955974098747, "to the database": 0.0005128575980484463, "yield excellent": 0.000702264802583379, "did well on": 0.0007417488271393706, "nn percent evasion": 0.0008091139115659897, "always possible however": 0.0007417488271393706, "between k": 0.0005128077770266814, "typical in nearest": 0.0008091139115659897, "single car": 0.000702264802583379, "at 90": 0.0011908005071032729, "between a": 0.00019734139522959736, "together they": 0.00048296474811893784, "to design": 0.00025750558543057484, "between e": 0.00048825248710181613, "game consists of": 0.0008091139115659897, "we estimated": 0.0004938405038742361, "1 for": 0.00010026029172547316, "game even though": 0.0008091139115659897, "nn and lazy": 0.0016182278231319793, "000 games this": 0.0008091139115659897, "update the": 0.0002627707973273995, "nn in": 0.0006628410843555166, "learning now": 0.000702264802583379, "nn is": 0.0017411704942939465, "but despite": 0.000702264802583379, "are non markovian": 0.0007023330300003208, "another": -0.0010242941980875121, "models and": 0.0005060495639651796, "learning uses a": 0.0008091139115659897, "at convergence": 0.001404529605166758, "our strategy": 0.00040989971878532225, "a closer": 0.0003898632748579793, "illustrate": 5.9820835964866313e-05, "is facing": 0.0013256821687110331, "approximately": 0.0003198672136769526, "pedestrian traveling": 0.0007696350858963753, "ga and": 0.002539437058874552, "was a": 0.0005316147421932984, "examples of a": 0.0010913768770361549, "observations": 0.0001195279098310498, "also performed": 0.0004349818647972793, "example set the": 0.0008091139115659897, "nearest neighbor our": 0.0008091139115659897, "john": 0.00025892290940629514, "version of": 0.00028198485319459076, "to take": 0.00017646145382793692, "rate continued to": 0.0008091139115659897, "illustrated the complexity": 0.0008091139115659897, "problems frequently": 0.0007696350858963753, "to the problem": 0.0002850786819641552, "aliasing by appending": 0.0008091139115659897, "stores examples similar": 0.0008091139115659897, "explanation based learning": 0.0007417488271393706, "has begun to": 0.0006199211760863129, "only the": 0.0002657809726650879, "with strategic games": 0.0008091139115659897, "of players follow": 0.0008091139115659897, "equations for even": 0.0008091139115659897, "performance on 10": 0.0008091139115659897, "of good examples": 0.0008091139115659897, "be included in": 0.0003919402155010585, "target": 0.0001900933658113501, "the goal": 0.00018244487591961847, "even when only": 0.0006349209434580451, "in temporal": 0.0009372334471517541, "the power of": 0.0006587047665528087, "outperform either individually": 0.0008091139115659897, "a long sequence": 0.0006069246369921007, "modified accounted for": 0.0008091139115659897, "range of e": 0.0007023330300003208, "uses and": 0.0005128077770266814, "space denoting": 0.0007696350858963753, "problem such as": 0.0006069246369921007, "0 3 of": 0.0006743602501766612, "learning by all": 0.0008091139115659897, "were not to": 0.0008091139115659897, "and operators": 0.00045224640365867626, "of our": 6.876406976172203e-05, "until reaching a": 0.0006526576017704936, "navigate": 0.0007837281472855552, "their starting positions": 0.0007417488271393706, "during the": 0.00035381245083971566, "actions two popular": 0.0008091139115659897, "from ga evades": 0.0008091139115659897, "payoff isaacs 1963": 0.0008091139115659897, "that arise": 0.00034112545549164767, "to play othello": 0.0008091139115659897, "phase are given": 0.0008091139115659897, "generations i": 0.0007696350858963753, "a prespecified": 0.0006628410843555166, "the selected": 0.0002727971730761859, "information includes": 0.0005954002535516364, "below to determine": 0.0007417488271393706, "same time": 0.00018871202900716462, "strength": 0.001972773800670293, "a solution to": 0.0003411585969912582, "examplars to": 0.0007696350858963753, "to achieve some": 0.0005759152096655707, "in both": 0.0001282001025608576, "the system": 0.0003241261796110323, "convergence algorithm": 0.0006628410843555166, "set at": 0.00039610816435843403, "task our approach": 0.0008091139115659897, "nn from": 0.0007696350858963753, "is 70 scaled": 0.0008091139115659897, "transmit": 0.0005149611454924404, "numerous important": 0.0007696350858963753, "for the one": 0.000943350950791552, "games and": 0.0026002114477529322, "line performance of": 0.0007417488271393706, "the eventual payoff": 0.0008091139115659897, "coverage of the": 0.0005226282087022614, "selected for mutation": 0.0007417488271393706, "our type": 0.0005803901647646488, "determined as strength": 0.0008091139115659897, "which a highly": 0.0008091139115659897, "lazy learning and": 0.0008091139115659897, "phase": 0.000385067647289048, "evaluate the power": 0.0007023330300003208, "vector in": 0.0003197335749799009, "of difficulty for": 0.0006526576017704936, "the state for": 0.0006743602501766612, "must learn to": 0.0007417488271393706, "play ended in": 0.0008091139115659897, "and aim for": 0.0008091139115659897, "to equalize their": 0.0007417488271393706, "to believe it": 0.0007417488271393706, "stages these observations": 0.0008091139115659897, "the literature the": 0.0005279045957013737, "calculated": 0.00011832515194928532, "experiments the most": 0.0007417488271393706, "had to": 0.0012011045087850461, "to deal with": 0.00027982312119228083, "accounted": 0.00029528673874227766, "to state x": 0.0008091139115659897, "watkins 1990": 0.0007696350858963753, "of examples": 0.004690766236619105, "case based": 0.0009876810077484722, "significantly affecting performance": 0.0007417488271393706, "helpful teacher": 0.0021067944077501365, "we ran ten": 0.0008091139115659897, "and upper bounds": 0.0004473842663752093, "difficult reinforcement learning": 0.0008091139115659897, "payoff function": 0.0021067944077501365, "for editing was": 0.0008091139115659897, "by clouse": 0.0007696350858963753, "own speed the": 0.0008091139115659897, "speed and we": 0.0008091139115659897, "we call a": 0.00037550322647033875, "the accuracy": 0.00022842192123212336, "instances indicated turns": 0.0008091139115659897, "4 3": 0.00022526620678890486, "1987 as our": 0.0008091139115659897, "of combining": 0.0004050885930083273, "game lasts": 0.0007696350858963753, "requires that one": 0.0007417488271393706, "learned very": 0.000702264802583379, "implementation": -0.0003239923199256594, "guidance": 0.00032928840029762313, "appended": 0.0003731233130620422, "which the control": 0.0006349209434580451, "a homogenous region": 0.0008091139115659897, "its very first": 0.0008091139115659897, "success the": 0.0006131469602829721, "the antecedant compares": 0.0008091139115659897, "truly combined": 0.0007696350858963753, "consisted of 20": 0.0007417488271393706, "particular had": 0.0007696350858963753, "pair already": 0.0007696350858963753, "ability of": 0.0015500992442490198, "3 1 differential": 0.0008091139115659897, "beginning of its": 0.0007417488271393706, "do": -0.0015313082357122122, "our approach uses": 0.0006199211760863129, "solves delayed": 0.0007696350858963753, "control movement adaptation": 0.0008091139115659897, "each of the": 0.0004968246480983164, "produced a relatively": 0.0008091139115659897, "step one example": 0.0008091139115659897, "these delayed": 0.0007696350858963753, "yielded": 0.0005442332444964514, "is consistent with": 0.0003256977768864979, "the maximum turn": 0.0008091139115659897, "and with relatively": 0.0008091139115659897, "for multi agent": 0.0005851984448616567, "determines the payoff": 0.0008091139115659897, "dt": 0.0002695386947059894, "building an": 0.0004382027886649359, "future direction": 0.0006131469602829721, "passing k": 0.0007696350858963753, "multi step control": 0.0008091139115659897, "fundamental problem was": 0.0007417488271393706, "is caught": 0.000634859264718638, "and therefore": 0.0001460690329335417, "on this difficult": 0.0007417488271393706, "problems called": 0.0006131469602829721, "into a": 0.0004318329033494251, "another agent": 0.0005954002535516364, "classroom building": 0.0007696350858963753, "family of": 0.00022279508543139435, "init population": 0.0007696350858963753, "that the best": 0.00044270962419637705, "while a lazy": 0.0008091139115659897, "here has also": 0.0008091139115659897, "we estimated the": 0.0005759152096655707, "edited the memory": 0.0008091139115659897, "the expected rewards": 0.0008091139115659897, "to solve k": 0.0007417488271393706, "observed": 8.583443463410184e-05, "depends": -6.359987353667352e-05, "agents through": 0.0006628410843555166, "generating them the": 0.0008091139115659897, "in time and": 0.00046289837369057756, "a very high": 0.00045745222770795314, "strategies for each": 0.0007417488271393706, "techniques": -0.00026937956035669896, "running each plan": 0.0008091139115659897, "performance remained": 0.001404529605166758, "is notoriously slow": 0.0008091139115659897, "step however even": 0.0008091139115659897, "well in solving": 0.0008091139115659897, "first assuming that": 0.0008091139115659897, "away": 0.00022563178632570746, "how actions taken": 0.0008091139115659897, "control action to": 0.0008091139115659897, "symmetric": 8.230188056213731e-05, "caught1": 0.0007021965884209132, "unable": 0.0002150007175874767, "includes a": 0.0002921317927643509, "a population of": 0.0005456884385180774, "after a": 0.000205132681196716, "a random action": 0.0008091139115659897, "by itself": 0.00036338074496527356, "observations suggested": 0.0007696350858963753, "control theory in": 0.0008091139115659897, "game theory is": 0.0014834976542787413, "we": -0.04462469640546538, "their multistrategy": 0.0007696350858963753, "terms": -0.0003067777515799866, "challenging in": 0.000702264802583379, "the sharpness of": 0.0006069246369921007, "is using": 0.000391902140873557, "right and": 0.00035165014402826746, "on our": 0.0002658073710966492, "but instead use": 0.0008091139115659897, "around 45": 0.000702264802583379, "not work": 0.0003338822091906335, "has applied": 0.0005954002535516364, "something close": 0.000634859264718638, "this results in": 0.0003362733529976494, "a sample": 0.0009008283815887847, "is similar to": 0.0006258351720047341, "added at": 0.0005803901647646488, "achieving some goal": 0.0007417488271393706, "received": 0.0001986880112468958, "essentially": 5.399871998760988e-05, "one exception to": 0.0007417488271393706, "until termination at": 0.0008091139115659897, "after 5": 0.000702264802583379, "each of": 0.00032877727787457013, "ga 0 ga": 0.0008091139115659897, "their prioritized": 0.0007696350858963753, "using reinforcement": 0.0012262939205659443, "other source": 0.000567383102523159, "e must": 0.0004997652289300559, "exceeds": 0.00019326742916589608, "pursuers figure 2": 0.0008091139115659897, "motivate the need": 0.0005759152096655707, "pursuers figure 4": 0.0008091139115659897, "agents that": 0.0004560919846500759, "1993 4": 0.000702264802583379, "game these": 0.001404529605166758, "p to": 0.0005027788987694298, "were left with": 0.0008091139115659897, "proportional selection": 0.0007696350858963753, "pursuit strategies": 0.0007696350858963753, "used temporal difference": 0.0008091139115659897, "assist agents in": 0.0008091139115659897, "developing a": 0.0003489161923333023, "e p 2": 0.0006526576017704936, "gen eral to": 0.0008091139115659897, "markovian decision problem": 0.0008091139115659897, "applicability": 0.00022151212119868156, "sample game where": 0.0008091139115659897, "e g if": 0.0004240325865444586, "the most traditional": 0.0008091139115659897, "succeeds we": 0.0006131469602829721, "the form dt": 0.0008091139115659897, "to perform well": 0.00151191658578862, "escapes and": 0.0007696350858963753, "than 80": 0.00052785331295456, "speeds with": 0.000702264802583379, "solve yet": 0.0007696350858963753, "their control values": 0.0008091139115659897, "a variation on": 0.0005759152096655707, "toward the value": 0.0008091139115659897, "faced with one": 0.0008091139115659897, "being good ones": 0.0008091139115659897, "stated above": 0.00044153169724958527, "between 5 000": 0.0008091139115659897, "method such as": 0.0005039721952628732, "to the games": 0.0008091139115659897, "change direction much": 0.0008091139115659897, "1993 a": 0.0005363412876789271, "theory differential": 0.0007696350858963753, "contrast a ga": 0.0008091139115659897, "games assuming": 0.0007696350858963753, "two players": 0.001134766205046318, "performance would": 0.0005456354281782176, "maze like environments": 0.0016182278231319793, "refined through a": 0.0008091139115659897, "and oe": 0.00028383407364771163, "applied": -0.0012051881324348097, "in search": 0.0008764055773298718, "has": 0, "equations for": 0.00030198240340165204, "and classifying": 0.0005559058853301298, "tolerating noisy irrelevant": 0.0008091139115659897, "to have converged": 0.0006743602501766612, "ever achieved by": 0.0008091139115659897, "air": 0.00026096259056477324, "aim": 0.00015786036938199673, "our problem": 0.00035445902764197844, "immediately delayed reinforcement": 0.0008091139115659897, "applies": 8.297316541302093e-05, "e and aim": 0.0008091139115659897, "idea of using": 0.0005128575980484463, "characterizing": 0.00046955208579092735, "mistake": 0.00034362401526488896, "ga system": 0.0007696350858963753, "turning sharply": 0.0007696350858963753, "learn plans": 0.0007696350858963753, "bounds followed": 0.000702264802583379, "q learning after": 0.0016182278231319793, "occurs through": 0.0006131469602829721, "finally with": 0.0006131469602829721, "quantization of the": 0.0007023330300003208, "the population for": 0.0008091139115659897, "example of": 0.0001320515398417877, "behaviors of the": 0.0005334812968668691, "2 performance": 0.0007965581392262904, "perform": -0.00024260630956666408, "learning algorithm i": 0.0008091139115659897, "show how performance": 0.0008091139115659897, "reached almost": 0.0007696350858963753, "learning solves": 0.0007696350858963753, "the instance database": 0.0008091139115659897, "so that it": 0.00030374604195717594, "single pedestrian crossing": 0.0008091139115659897, "teacher for the": 0.0008091139115659897, "incorrectly": 0.0002657815520222347, "strength and fitness": 0.0008091139115659897, "otherwise the optimal": 0.0007023330300003208, "et al and": 0.0011348764514472745, "smoother indicating that": 0.0008091139115659897, "a high degree": 0.0004548376351798251, "performance flattened out": 0.0008091139115659897, "training data": 0.00038024507112555464, "examples gll converged": 0.0008091139115659897, "experiments best plan": 0.0008091139115659897, "paper to be": 0.0006743602501766612, "its performance will": 0.0008091139115659897, "car i e": 0.0008091139115659897, "games can": 0.0006628410843555166, "outperformed": 0.0014176983897218167, "each state": 0.0013308912366366177, "hand": -8.875724878785499e-05, "use genetic algorithms": 0.0008091139115659897, "the ga consequently": 0.0008091139115659897, "suggests that": 0.00023020870590980126, "beyond what either": 0.0008091139115659897, "the task": 0.0024277003270990506, "this is grefenstette": 0.0008091139115659897, "it will take": 0.0005674382257236372, "convergence algorithm one": 0.0008091139115659897, "and solutions for": 0.0006526576017704936, "the starting position": 0.0005954580987137418, "in memory": 0.0006091886955370409, "involves simultaneous": 0.0007696350858963753, "dependent on the": 0.0006402089504842591, "1976": 0.00035161598665633655, "1975": 0.0007678915814377345, "percent evasion examples": 0.0008091139115659897, "1 to": 0.00012841175229188933, "1972": 0.0004004590436872584, "1971": 0.0004258601347877918, "above and beyond": 0.0006743602501766612, "game play": 0.0007696350858963753, "players called the": 0.0007417488271393706, "all states": 0.0007965581392262904, "teacher is similar": 0.0008091139115659897, "the": 0, "performance but not": 0.0008091139115659897, "in these experiments": 0.00044270962419637705, "excellent performance": 0.0005363412876789271, "et al which": 0.0006743602501766612, "evader has": 0.0007696350858963753, "embedded linear": 0.0007696350858963753, "different skills": 0.0006628410843555166, "require similar actions": 0.0008091139115659897, "results of comparing": 0.0008091139115659897, "predicted are": 0.0007696350858963753, "early work by": 0.0006743602501766612, "to another": 0.00020440393960270134, "the rules": 0.0014155522094757064, "away examples": 0.0007696350858963753, "new set of": 0.00041328080567602945, "and e y": 0.0006349209434580451, "time t each": 0.0007417488271393706, "of temporal": 0.001129921045199448, "thanks": 0.000414649748957163, "of their control": 0.0007417488271393706, "learning is a": 0.0006526576017704936, "good actions but": 0.0008091139115659897, "step and": 0.0003238859962113274, "adding": 3.268307300837425e-05, "genetic algo rithms": 0.0007417488271393706, "suggested that": 0.00039398316601407357, "algorithm this choice": 0.0007417488271393706, "good ones i": 0.0008091139115659897, "our definition": 0.00036183856746138145, "nn expects": 0.0007696350858963753, "storing many": 0.000702264802583379, "while e must": 0.0008091139115659897, "examples which is": 0.0007023330300003208, "neighbors 4 3": 0.0008091139115659897, "studied in the": 0.0004382453615580345, "fitness a": 0.0007696350858963753, "learning has been": 0.0006199211760863129, "action regardless": 0.0007696350858963753, "we now": 0.00011536426798956731, "turns i": 0.0007696350858963753, "this class": 0.000541692813051437, "numeric values we": 0.0008091139115659897, "rate if": 0.0004731713358791195, "can also": 0.0002082260094068415, "stored games": 0.0015392701717927505, "cart and": 0.0012262939205659443, "well initially figure": 0.0008091139115659897, "the heart": 0.0003839830887362287, "each action for": 0.0008091139115659897, "an exact match": 0.0005954580987137418, "fixed minimum radius": 0.0008091139115659897, "above 70 and": 0.0008091139115659897, "to converge and": 0.0006526576017704936, "permits it to": 0.0007417488271393706, "it to provide": 0.0007023330300003208, "to decide which": 0.0004601378070916638, "robot shaping": 0.0015392701717927505, "together can outperform": 0.0008091139115659897, "determining relevant": 0.0007696350858963753, "well or better": 0.0006526576017704936, "designed initial training": 0.0008091139115659897, "on determining": 0.0005803901647646488, "classifying the points": 0.0008091139115659897, "storing examples": 0.0021067944077501365, "perceptual aliasing by": 0.0008091139115659897, "temporally": 0.0003766037636160957, "then its learning": 0.0008091139115659897, "modeled with a": 0.0012698418869160901, "open parking": 0.0007696350858963753, "games with": 0.0005803901647646488, "p 201": 0.0004642630166224529, "experiments to produce": 0.0007417488271393706, "indicated turns": 0.0007696350858963753, "game extremely": 0.0007696350858963753, "tasks more recently": 0.0008091139115659897, "initially searches a": 0.0008091139115659897, "3 q learning": 0.0008091139115659897, "its own k": 0.0007417488271393706, "g in dasarathy": 0.0008091139115659897, "maneuvers q learning": 0.0008091139115659897, "difficulty for lazy": 0.0008091139115659897, "1992 skalak": 0.0007696350858963753, "fitness values described": 0.0008091139115659897, "the actions correspond": 0.0008091139115659897, "assignment in": 0.0008055339991709317, "way of": 0.000205132681196716, "nearest neighbor second": 0.0008091139115659897, "see in": 0.00029371177661993307, "common eager": 0.0007696350858963753, "subramanian 1993a": 0.0007696350858963753, "and iri 9223591": 0.0008091139115659897, "population they": 0.0007696350858963753, "experiments indicate": 0.00044854462015967935, "demonstrating how two": 0.0008091139115659897, "within 5": 0.0005200422895505865, "in a relative": 0.0006526576017704936, "the rules and": 0.0006069246369921007, "example 359 degrees": 0.0008091139115659897, "condensed nearest": 0.0007696350858963753, "dynamic programming learning": 0.0008091139115659897, "comments": 0.00014166806984649107, "editing then": 0.0007696350858963753, "of pruning": 0.001040084579101173, "simultaneously chapman 1987": 0.0008091139115659897, "4 results": 0.00040276699958546587, "varied k": 0.000702264802583379, "and payoff or": 0.0008091139115659897, "initially all": 0.0004560919846500759, "is rather": 0.0003063720986511328, "performing at": 0.0006628410843555166, "tasks has only": 0.0008091139115659897, "correspond to": 0.00027466355844336606, "x axis": 0.0003315762308313901, "we considered an": 0.0006743602501766612, "this permits it": 0.0008091139115659897, "above a lazy": 0.0008091139115659897, "describes how a": 0.0005759152096655707, "so does": 0.0003898632748579793, "learning did": 0.0007696350858963753, "speed reduction is": 0.0008091139115659897, "sharing plan grefenstette": 0.0008091139115659897, "approach to develop": 0.0007023330300003208, "discuss the": 0.00019837578175446472, "has learned to": 0.0007023330300003208, "a limited": 0.00028529602391613707, "properties": -5.889484777017088e-05, "by the ga": 0.0014834976542787413, "second lazy methods": 0.0008091139115659897, "algorithm lies": 0.0005559058853301298, "algorithms as": 0.00035165014402826746, "and because of": 0.0004958241803403253, "using 1 nn": 0.0008091139115659897, "ishihara 1993": 0.0007696350858963753, "to apply": 0.0003981402298588186, "within d": 0.0006131469602829721, "both the car": 0.0008091139115659897, "in that points": 0.0008091139115659897, "within a": 0.00028884434123882064, "the idea of": 0.0002895772501451416, "study whether a": 0.0008091139115659897, "b two pursuers": 0.0008091139115659897, "to attempt to": 0.0005128575980484463, "than all": 0.0003839830887362287, "set produced a": 0.0008091139115659897, "and the optimal": 0.0004601378070916638, "generation as": 0.0005559058853301298, "ga eventually achieved": 0.0008091139115659897, "turn of course": 0.0008091139115659897, "if smoke": 0.0007696350858963753, "bound": -5.728446510268425e-05, "robot control tasks": 0.0008091139115659897, "in such an": 0.0004919901420568756, "as described": 0.000163091198657296, "on its": 0.0010672355631125992, "widespread application in": 0.0007023330300003208, "two phase approach": 0.0006743602501766612, "player assuming": 0.000702264802583379, "distance is computed": 0.0007023330300003208, "function approximators": 0.0006628410843555166, "achieved 86": 0.0007696350858963753, "q x": 0.0003839830887362287, "wal": 0.0006347975979615015, "purpose of these": 0.0005674382257236372, "and high": 0.00031672395822701763, "and two": 0.0007976748903589915, "difficult task": 0.0004779464664686347, "complete sequences": 0.0013256821687110331, "except that it": 0.0004747836164770488, "we edited the": 0.0008091139115659897, "a plan": 0.0033807532368325646, "system which uses": 0.0006743602501766612, "way": -0.0007081228277396051, "one implementation": 0.000634859264718638, "and a single": 0.00039905202450766993, "was": -0.010693723887884624, "examples finally with": 0.0008091139115659897, "the game for": 0.0006743602501766612, "if it stores": 0.0007417488271393706, "algorithms have": 0.0002768061441929089, "example 359": 0.0007696350858963753, "first set of": 0.0008947685327504186, "improves somewhat erratically": 0.0008091139115659897, "and crosses i": 0.0008091139115659897, "shows a": 0.00019665647605370202, "theory originated": 0.0007696350858963753, "converged to near": 0.0008091139115659897, "taken": -9.392919185154877e-05, "of both lazy": 0.0008091139115659897, "in related research": 0.0007417488271393706, "abilities further": 0.0007696350858963753, "random mutation hill": 0.0007417488271393706, "encoded": 0.00018489791318496634, "the feature space": 0.0005524148804057065, "the pursuer": 0.005618118420667032, "reset": 0.0002445400551532689, "of training examples": 0.0005128575980484463, "games third traditional": 0.0008091139115659897, "equations model how": 0.0008091139115659897, "lasts for 20": 0.0008091139115659897, "called tag the": 0.0008091139115659897, "will learn better": 0.0008091139115659897, "hard to decide": 0.0006743602501766612, "ten example sets": 0.0008091139115659897, "reinforcement learning can": 0.0016182278231319793, "maximum": -0.00012167765532973088, "the idea being": 0.0007023330300003208, "after storing approximately": 0.0008091139115659897, "direction and": 0.00036494662878843966, "nearly correct": 0.0007696350858963753, "20 times": 0.0005456354281782176, "the general if": 0.0008091139115659897, "and suggested that": 0.0008091139115659897, "p 2 have": 0.0008091139115659897, "least some": 0.00042027761111456123, "recognition a statistical": 0.0007417488271393706, "second pursuer": 0.0015392701717927505, "much greater than": 0.0005334812968668691, "moore": 0.0009747565959597815, "to learn rapidly": 0.0008091139115659897, "computing": -0.000207465595530891, "with its class": 0.0007417488271393706, "associated with a": 0.00028556935796810834, "maneuvers game as": 0.0008091139115659897, "states to": 0.00041758029726340933, "control movement": 0.001404529605166758, "replicate those results": 0.0008091139115659897, "an apparent plateau": 0.0008091139115659897, "or teaching": 0.0007696350858963753, "90 after only": 0.0008091139115659897, "natural and": 0.00038024507112555464, "distributions": 0.00014511170716971887, "sample 1": 0.0007696350858963753, "a task and": 0.0006069246369921007, "specifically predictions are": 0.0008091139115659897, "on the learning": 0.0006526576017704936, "long sequence": 0.00052785331295456, "examples used": 0.0005559058853301298, "with its": 0.0006276583597518346, "0 which meant": 0.0008091139115659897, "action pairs for": 0.0008091139115659897, "on a simple": 0.0004813101872060044, "spaces such as": 0.0006743602501766612, "including e s": 0.0008091139115659897, "evasive": 0.010532948826313698, "correct control action": 0.0008091139115659897, "test": 0.0, "relevant attributes": 0.0011118117706602597, "chauffeur game because": 0.0008091139115659897, "the problem such": 0.0007023330300003208, "ga during training": 0.0008091139115659897, "degree of": 0.00018429376188905006, "of three": 0.0003946827904591947, "stores examples with": 0.0008091139115659897, "state hidden state": 0.0008091139115659897, "optimal strategy imado": 0.0008091139115659897, "in which different": 0.0005954580987137418, "small memory base": 0.0008091139115659897, "update": 8.669938953122305e-05, "predictions are": 0.0004642630166224529, "play random": 0.000702264802583379, "evasion once evasion": 0.0008091139115659897, "the same way": 0.00027087272017640594, "measurement the": 0.0005200422895505865, "class was": 0.0005559058853301298, "differential games in": 0.0008091139115659897, "neighbor rule": 0.0015392701717927505, "subramanian 1993a 1993b": 0.0008091139115659897, "approaches see figure": 0.0008091139115659897, "rewards reinforcement": 0.0007696350858963753, "for solving a": 0.0004958241803403253, "kittler": 0.0005455824281366266, "selected with": 0.0005363412876789271, "class of": 0.0008269586765558446, "together": -9.746026977277858e-05, "to machine": 0.00043186206685094484, "either wins": 0.0007696350858963753, "likely reason": 0.0006628410843555166, "too have minimized": 0.0008091139115659897, "good examples in": 0.0008091139115659897, "the lazy learning": 0.0016182278231319793, "relatively easy to": 0.0004747836164770488, "actual reward at": 0.0008091139115659897, "methods can reduce": 0.0007417488271393706, "point the ga": 0.0008091139115659897, "players this": 0.000702264802583379, "switched": 0.0002747565959466888, "this game it": 0.0008091139115659897, "and r": 0.00016577247801789, "and s": 0.00016823024680878972, "gll performed": 0.0007696350858963753, "traveling at": 0.000702264802583379, "with which": 0.0002621733301065935, "where performance": 0.0005803901647646488, "and k": 0.0005920241856887921, "k between": 0.0006131469602829721, "finds in the": 0.0006526576017704936, "improve rapidly passing": 0.0008091139115659897, "and d": 0.0001701723464750686, "and e": 0.0003612429804234207, "in grefenstette et": 0.0008091139115659897, "and a": 3.552258138984947e-05, "two pursuer problem": 0.002427341734697969, "of 90 degrees": 0.0007417488271393706, "that can solve": 0.0006526576017704936, "distance metrics": 0.0011118117706602597, "contains all": 0.00030027612719626154, "tasks are non": 0.0007417488271393706, "graph": 2.2549231909228563e-05, "history is": 0.0004731713358791195, "holland 1989": 0.0007696350858963753, "first trained a": 0.0008091139115659897, "examples stored for": 0.0008091139115659897, "context of markov": 0.0008091139115659897, "multidit": 0.0007021965884209132, "how to label": 0.0008091139115659897, "might enable k": 0.0008091139115659897, "immediately delayed": 0.0007696350858963753, "algorithms for": 0.00011933847638685871, "data the": 0.00023340273528180345, "turn 90 the": 0.0008091139115659897, "network millan": 0.0007696350858963753, "generated actions randomly": 0.0008091139115659897, "predicate": 0.0001899840013707754, "actions randomly evaded": 0.0008091139115659897, "tried a": 0.0005954002535516364, "zhang": 0.00017703070693490127, "and 5": 0.00018711684273839185, "it with probability": 0.0008091139115659897, "store examples": 0.0007696350858963753, "during training but": 0.0008091139115659897, "captured at time": 0.0008091139115659897, "members of the": 0.00038790254623973576, "anonymous": 0.00014324262941653454, "is still": 0.00015160954195390258, "ga gle achieved": 0.0008091139115659897, "evaded": 0.0007021965884209132, "was performing": 0.000702264802583379, "from two": 0.00029943314463829254, "sutton 1988 temporal": 0.0008091139115659897, "turns": 0.0007870509350248208, "fi is the": 0.0005176213124249083, "at least some": 0.0004601378070916638, "stored here is": 0.0008091139115659897, "that the cart": 0.0007417488271393706, "p": -0.006480754088177697, "is based upon": 0.0004259428823122818, "irrelevant and novel": 0.0008091139115659897, "evades": 0.0042131795305254795, "evader": 0.008887166371461022, "which locates all": 0.0008091139115659897, "show that": 9.68481456958817e-05, "a stored game": 0.0008091139115659897, "or specialized": 0.0006628410843555166, "turns they": 0.0007696350858963753, "improve this figure": 0.0008091139115659897, "upper": 6.207254763938525e-05, "done to apply": 0.0008091139115659897, "attributes booker goldberg": 0.0008091139115659897, "not supported": 0.0004560919846500759, "to include": 0.00022886607492290744, "needed an approach": 0.0008091139115659897, "to determine": 0.0010080620506021409, "this algorithm": 0.0001818342895766069, "game into": 0.0007696350858963753, "action is passed": 0.0008091139115659897, "the implementation": 0.00017558653025519325, "the set of": 0.0006277706056065088, "but the most": 0.0005759152096655707, "homicidal chauffeur game": 0.0032364556462639586, "combined strategy": 0.000702264802583379, "233 nov": 0.0006131469602829721, "prevent the evader": 0.0008091139115659897, "with as few": 0.0006199211760863129, "learn a task": 0.0008091139115659897, "the fewest time": 0.0008091139115659897, "the memory": 0.00047337366745716996, "and depends": 0.0004349818647972793, "that editing": 0.000702264802583379, "learning now achieving": 0.0008091139115659897, "on translating": 0.000702264802583379, "differential game the": 0.0008091139115659897, "algorithms did well": 0.0008091139115659897, "uniform": 6.73285265235498e-05, "a high probability": 0.0004998137828238603, "navigate the halls": 0.0008091139115659897, "sequential": 0.0007030264105869721, "evader attempts": 0.0007696350858963753, "performance jumped to": 0.0008091139115659897, "is currently": 0.0002747832868924773, "pursue and": 0.000702264802583379, "pursuer adversely": 0.0007696350858963753, "can outperform": 0.0005363412876789271, "satisfy": 2.034561420388105e-05, "steps to": 0.000378426656892181, "correct or nearly": 0.0008091139115659897, "tesauro 1992 the": 0.0008091139115659897, "the object of": 0.0005393947462253054, "state for": 0.0003530449562101758, "correct or": 0.0005060701527920558, "in their": 0.0004908701828076215, "are stored as": 0.0005851984448616567, "appending history information": 0.0008091139115659897, "there was": 0.00029943314463829254, "about which examples": 0.0008091139115659897, "us to believe": 0.0005851984448616567, "to capture": 0.0005104856643564933, "the same point": 0.0004882999224935485, "teacher": 0.004974227224078343, "change": -0.00011288434172167143, "when we": 0.000178822766106048, "choice was": 0.00052785331295456, "paper demonstrates": 0.0006131469602829721, "52 the": 0.0005559058853301298, "the pursuer p": 0.0008091139115659897, "b two": 0.00048296474811893784, "adapt q": 0.0007696350858963753, "consisted of": 0.0010996109340555497, "from the different": 0.0005596382660342995, "implementation of": 0.00036897863987901637, "advantages to": 0.0004997652289300559, "experiments performance": 0.000702264802583379, "achieved near": 0.000702264802583379, "the most striking": 0.0005759152096655707, "play occurs in": 0.0008091139115659897, "widrow 1989 using": 0.0008091139115659897, "yielded performance at": 0.0008091139115659897, "problems to": 0.0003573471911393542, "against the number": 0.0005596382660342995, "domains": 0.00015086051772282924, "upon work supported": 0.0005954580987137418, "task known as": 0.0008091139115659897, "above and": 0.0005842635855287018, "that p will": 0.0006526576017704936, "plotted": 0.00020957743974090145, "achieving 100": 0.0007696350858963753, "very good": 0.0006898941963419351, "regardless": 0.00029591761523070013, "function defined": 0.00036338074496527356, "for our problem": 0.0005851984448616567, "good examples the": 0.0008091139115659897, "operators or": 0.0005363412876789271, "to evolve": 0.00046861672357587705, "to jump start": 0.0016182278231319793, "under grant nos": 0.0008091139115659897, "we applied a": 0.0006349209434580451, "was capable of": 0.0007023330300003208, "rarely": 0.00023955459123611926, "a spatial": 0.00042027761111456123, "applied to multi": 0.0006349209434580451, "generation the": 0.0003982790696131452, "90 degrees left": 0.0008091139115659897, "the state of": 0.0005243976022767461, "for differential": 0.00105570662590912, "second algorithm takes": 0.0008091139115659897, "it reached": 0.0023089052576891257, "and after each": 0.0005851984448616567, "when achieved": 0.0015392701717927505, "apprach a": 0.0007696350858963753, "it reaches": 0.0003820967919236623, "least one": 0.0001474949011655475, "the severity of": 0.0005954580987137418, "evades if evade": 0.0008091139115659897, "minimum radius of": 0.0007023330300003208, "pairs are stored": 0.0008091139115659897, "selects": 0.00034824771932790636, "initial training": 0.000567383102523159, "e tic tac": 0.0008091139115659897, "learning solutions": 0.0007696350858963753, "hand if the": 0.00044270962419637705, "envelope": 0.0003410923204304051, "system that": 0.00025750558543057484, "nguyen": 0.00038782718877567753, "one class of": 0.0005176213124249083, "first 5": 0.0005954002535516364, "study we begin": 0.0008091139115659897, "into a plan": 0.0007417488271393706, "algorithm pattern": 0.0006131469602829721, "first 3": 0.0005363412876789271, "theta 10": 0.0012955862005528346, "playing against": 0.000702264802583379, "with genetic": 0.0005954002535516364, "failed to find": 0.0007023330300003208, "part our": 0.000702264802583379, "approach we": 0.0002664248079582193, "where c is": 0.0003802820132290351, "car": 0.0034109232043040513, "performance of gll": 0.0008091139115659897, "in these random": 0.0008091139115659897, "opponents this information": 0.0008091139115659897, "generation and": 0.0003109518286556765, "aliasing by": 0.000702264802583379, "defined below": 0.0003839830887362287, "labeled": 0.00024967425823186435, "to robot": 0.0011908005071032729, "specifically predictions": 0.0007696350858963753, "can": -0.022470290829469223, "the path of": 0.00048474305809383046, "current turn angle": 0.0008091139115659897, "ideas during": 0.0007696350858963753, "since editing served": 0.0008091139115659897, "1 lazy": 0.0006628410843555166, "the ability to": 0.0002761545129894362, "heart": 0.0002860067002590034, "heading and": 0.0006131469602829721, "to reduce the": 0.00042641476937393594, "of instances produced": 0.0008091139115659897, "able to obtain": 0.0004813101872060044, "in which": 0.0010289629874421031, "be correct": 0.0003665369780185166, "attribute": 0.00040302273221612964, "the performance": 0.0006047663549486056, "problem van": 0.0007696350858963753, "success further gll": 0.0008091139115659897, "generate random actions": 0.0008091139115659897, "plan are": 0.0005954002535516364, "with issues of": 0.0007417488271393706, "are dependent on": 0.0004958241803403253, "solution to study": 0.0008091139115659897, "next we edited": 0.0008091139115659897, "thanks to": 0.0006542249523968281, "examining the": 0.00029776693520311534, "p until inside": 0.0008091139115659897, "95 4": 0.000567383102523159, "simple task with": 0.0008091139115659897, "margin of": 0.00105570662590912, "the ga each": 0.0007417488271393706, "at any given": 0.0004005368556067546, "from a": 0.00027800079354524035, "fixed control law": 0.0008091139115659897, "discussion": 1.970913180158695e-06, "dasarathy 1991": 0.000702264802583379, "value for all": 0.0005524148804057065, "will for": 0.0006131469602829721, "games the results": 0.0008091139115659897, "prespecified trajectory": 0.0007696350858963753, "construct an": 0.0002961263574580495, "and solutions": 0.00044854462015967935, "of learning complex": 0.0008091139115659897, "a simple": 7.212669973989186e-05, "plan from": 0.0007696350858963753, "simulation run beginning": 0.0008091139115659897, "then proceeds using": 0.0008091139115659897, "better examples consisted": 0.0008091139115659897, "pursuer in fact": 0.0008091139115659897, "during each": 0.0003603193719587997, "adversely affects two": 0.0008091139115659897, "produce": 0.0001978364329404926, "dimensional simulation a": 0.0008091139115659897, "achieved near perfect": 0.0008091139115659897, "indicated the": 0.0004938405038742361, "every time": 0.0003228323139879973, "as well": 5.5679350321430386e-05, "1992 tesauro": 0.0007696350858963753, "to achieve an": 0.0004882999224935485, "equations finding": 0.0007696350858963753, "have limited fuel": 0.0008091139115659897, "own thus only": 0.0008091139115659897, "in natural and": 0.0006526576017704936, "whenever": 5.218008356502963e-05, "own around": 0.0007696350858963753, "genetic algorithm the": 0.0006743602501766612, "initializing the simulator": 0.0008091139115659897, "payoff received is": 0.0008091139115659897, "state matcher": 0.0015392701717927505, "by setting": 0.00027345521625013827, "probability 0 01": 0.0008091139115659897, "ga as": 0.0006628410843555166, "reinforcement learning for": 0.0014046660600006416, "perception and action": 0.0014834976542787413, "next set": 0.0005200422895505865, "success for e": 0.0008091139115659897, "selection by": 0.00052785331295456, "sure that the": 0.0004319040237213277, "typical": 0.00023065686555391314, "intelligent highways air": 0.0008091139115659897, "this game": 0.0016369062845346528, "complex task thus": 0.0008091139115659897, "nn rather than": 0.0008091139115659897, "indeed": 4.026530872714109e-05, "actions through a": 0.0008091139115659897, "and associated with": 0.0006349209434580451, "games is somewhat": 0.0008091139115659897, "decisions about": 0.0005200422895505865, "ended": 0.0006676995553974513, "the advice with": 0.0008091139115659897, "space denoting a": 0.0008091139115659897, "reasoning papers": 0.000702264802583379, "statistical": 0.0001518403883371117, "escapes and wins": 0.0008091139115659897, "be able": 0.00016045971209060242, "still": -0.0007895341163312534, "minimum threshold": 0.000702264802583379, "the context of": 0.00021717442371520405, "could produce": 0.0005363412876789271, "s performance but": 0.0007417488271393706, "the other hand": 0.0001468737995664351, "in nearest": 0.0006628410843555166, "examples it": 0.0004938405038742361, "use a lazy": 0.0008091139115659897, "algorithm i": 0.0004642630166224529, "algorithm k": 0.0006131469602829721, "second we gave": 0.0008091139115659897, "set of states": 0.0003892305354108736, "evasion within": 0.0015392701717927505, "helpful teacher which": 0.0008091139115659897, "ae is the": 0.0009626203744120089, "at which": 0.0002092194532506115, "both players the": 0.0007417488271393706, "at the end": 0.00044199744441496616, "part our earlier": 0.0008091139115659897, "the best ever": 0.0008091139115659897, "success examples ga": 0.0008091139115659897, "be produced": 0.0003898632748579793, "to optimize": 0.00028677803128412173, "mathematical theory": 0.0004642630166224529, "algorithm s": 0.0003714629793944916, "s performance on": 0.0012138492739842013, "non": -0.0007518649288633268, "halt": 0.00032708070228134765, "experiments show how": 0.0007417488271393706, "antecedent and the": 0.0006743602501766612, "nearest neighbor percent": 0.0008091139115659897, "related research": 0.0004938405038742361, "the problems we": 0.0005334812968668691, "poor performance of": 0.0011518304193311414, "scaling": 0.00014324262941653454, "to run down": 0.0008091139115659897, "combination in": 0.0005456354281782176, "approach that we": 0.0005524148804057065, "not": 0, "nov": 0.00029691465080304623, "now": -0.00033697932110502305, "genetic algorithm applied": 0.0007417488271393706, "discuss": 1.970913180158695e-06, "nor": 9.682657545975398e-05, "nos": 0.000567327990031413, "the object": 0.00024610297224105296, "pursuit games with": 0.0008091139115659897, "as the children": 0.0007417488271393706, "they have had": 0.0007417488271393706, "game playing has": 0.0008091139115659897, "teaching method for": 0.0008091139115659897, "we ran": 0.0003197335749799009, "could be solved": 0.0005226282087022614, "specifying a range": 0.0008091139115659897, "can learn to": 0.0007023330300003208, "of competitive": 0.0005128077770266814, "stored in": 0.00020623389645783668, "training examples and": 0.0005759152096655707, "e g when": 0.0004548376351798251, "it turns": 0.000268298100835417, "domain": 3.1525834822279164e-05, "fired": 0.0016201969796707997, "bound don": 0.0007696350858963753, "been applied to": 0.0007951776650256002, "for our": 0.0002832785262959759, "including e": 0.0006628410843555166, "wilson 1972 showed": 0.0008091139115659897, "exception to this": 0.0005176213124249083, "method when used": 0.0008091139115659897, "lot with": 0.0007696350858963753, "nn and a": 0.0008091139115659897, "torras 1992": 0.0015392701717927505, "on sequential decision": 0.0008091139115659897, "et": 0.00020910460600799763, "reasoning papers from": 0.0008091139115659897, "performance 4 4": 0.0008091139115659897, "50 of the": 0.0004319040237213277, "cart and pole": 0.0016182278231319793, "environment is": 0.0003697942966553643, "shown": -0.0006878689197241546, "accomplish": 0.00023955459123611926, "form solutions": 0.0005559058853301298, "differential game is": 0.0016182278231319793, "function in": 0.0002174224613812204, "space": -0.001171048544457217, "discussed applicable to": 0.0008091139115659897, "furthermore": -2.815495632842451e-07, "then used it": 0.0008091139115659897, "showed no": 0.000634859264718638, "a ga": 0.004292028721980805, "produce agents": 0.0007696350858963753, "fitness proportional selection": 0.0008091139115659897, "navigating": 0.00040504924491769994, "for only 500": 0.0008091139115659897, "receiving": 0.00017527911559062502, "e from the": 0.0005759152096655707, "shows": -0.0010276672171794041, "those encountered": 0.0006628410843555166, "problem of escaping": 0.0008091139115659897, "selecting typical": 0.0015392701717927505, "course be": 0.0005363412876789271, "the methods": 0.0002430451200871382, "cart": 0.0008898658981088833, "table that contains": 0.0008091139115659897, "ga during": 0.001404529605166758, "advantages": 0.00010225925052666218, "take this": 0.0004382027886649359, "i and fi": 0.0006199211760863129, "corresponding range": 0.000702264802583379, "itself to explore": 0.0008091139115659897, "for nearby neighbors": 0.0008091139115659897, "probability was selected": 0.0008091139115659897, "care": 0.00016254520394587348, "e the state": 0.0006743602501766612, "metrics for": 0.0008699637295945586, "with less data": 0.0007417488271393706, "both players": 0.000634859264718638, "strategy to the": 0.0007023330300003208, "a relative": 0.0003573471911393542, "is the class": 0.00042031844251562157, "begins by generating": 0.0008091139115659897, "state we formulate": 0.0008091139115659897, "at that": 0.0005231581140507123, "surprised with k": 0.0008091139115659897, "and refines": 0.0005954002535516364, "developing a method": 0.0007023330300003208, "each clause in": 0.0006743602501766612, "most 20": 0.0007696350858963753, "performance early work": 0.0008091139115659897, "plug itself into": 0.0008091139115659897, "considered an eager": 0.0008091139115659897, "then the nearest": 0.0007417488271393706, "accuracy with 1": 0.0008091139115659897, "and conclusions": 0.000335054731187079, "000 games but": 0.0016182278231319793, "begin by": 0.0002689296688222252, "striking": 0.0009560693198021333, "of the variance": 0.0005128575980484463, "game playing": 0.001904577794155914, "variables": -9.291916311576667e-06, "nearly perfect accuracy": 0.0008091139115659897, "use a": 0.000220647294459857, "each of these": 0.000485802421857951, "prespecified trajectory moore": 0.0008091139115659897, "directly": -0.00015382236705804053, "one striking": 0.0007696350858963753, "ga during that": 0.0008091139115659897, "for helpful": 0.0003157396500417892, "a single pedestrian": 0.0008091139115659897, "size": -0.0008973135493278559, "in the context": 0.00022183435892289156, "checked": 0.00014940265895948467, "can of course": 0.0006069246369921007, "learning and pattern": 0.0007023330300003208, "small only 20": 0.0008091139115659897, "caught": 0.0004004590436872584, "fact we were": 0.0008091139115659897, "task of": 0.0005093684078933666, "encouraging it reached": 0.0008091139115659897, "lazy learning algorithm": 0.0016182278231319793, "attributes booker": 0.0007696350858963753, "a special type": 0.0005334812968668691, "are simple": 0.00033988242810104627, "2 10 success": 0.0008091139115659897, "symmetric chess like": 0.0008091139115659897, "by traveling": 0.000634859264718638, "the end": 0.0005170441383492692, "p 2 and": 0.0004958241803403253, "that": 0, "abilities one classic": 0.0008091139115659897, "equalize their effect": 0.0008091139115659897, "eliminates": 0.00018805333444124348, "degrees right": 0.0015392701717927505, "use of temporal": 0.0008091139115659897, "set to 50": 0.0006743602501766612, "because k nn": 0.0008091139115659897, "5 and": 0.00013161915316028684, "state space as": 0.0006526576017704936, "than": -0.009695679719391939, "editing rate of": 0.0016182278231319793, "difficulty by": 0.0006131469602829721, "lb i and": 0.0007023330300003208, "action for": 0.0004779464664686347, "the eventual": 0.0005200422895505865, "form of lazy": 0.0007417488271393706, "only 66 examples": 0.0008091139115659897, "perhaps a different": 0.0008091139115659897, "apply zero payoff": 0.0008091139115659897, "well the": 0.0002727971730761859, "values with these": 0.0007417488271393706, "s radius": 0.001404529605166758, "algorithm on one": 0.0007023330300003208, "editing was that": 0.0008091139115659897, "discount factor": 0.0005803901647646488, "lazy learning therefore": 0.0008091139115659897, "to navigate the": 0.0007417488271393706, "remained": 0.0009747565959597815, "thus only plans": 0.0008091139115659897, "of computing the": 0.0003665725883340726, "crossover": 0.0004258601347877918, "it provides": 0.00027886722524113144, "the typical formulation": 0.0008091139115659897, "the same": 3.886118546834083e-05, "details of the": 0.0009077600992164754, "induction efficient": 0.000702264802583379, "to the maximum": 0.0004020439867656976, "systems practical": 0.0006628410843555166, "i and ub": 0.0007417488271393706, "the figure shows": 0.0004382453615580345, "games 2060100 percent": 0.0008091139115659897, "q function then": 0.0008091139115659897, "up to 20": 0.0011909161974274836, "both directions could": 0.0008091139115659897, "still only": 0.0015392701717927505, "have the": 0.00014136122443571606, "more complicated predator": 0.0008091139115659897, "pursuer attempts to": 0.0008091139115659897, "original work by": 0.0007417488271393706, "objective": 0.00023585205562208402, "ga nor k": 0.0008091139115659897, "high n": 0.0006628410843555166, "the appropriate actions": 0.0007023330300003208, "begin": 0.00015926480030152598, "be possible": 0.0002311124137898519, "pass through": 0.00034112545549164767, "setting the corresponding": 0.0007417488271393706, "using lazy": 0.0006131469602829721, "the angle of": 0.0005039721952628732, "to satisfy": 0.00022364354062897208, "abilities different": 0.0007696350858963753, "what it finds": 0.0008091139115659897, "pairs learning proceeds": 0.0008091139115659897, "graph shows": 0.00041758029726340933, "successive": 0.00013377958970589826, "lazy version of": 0.0016182278231319793, "has yielded": 0.0005200422895505865, "the genetic algorithm": 0.004916331210002246, "in part because": 0.0006199211760863129, "learner to": 0.0005954002535516364, "examples this confirms": 0.0008091139115659897, "forever": 0.0003054498199398159, "high 1": 0.000634859264718638, "reaching 80": 0.0007696350858963753, "application in": 0.0003028459277060942, "of direction although": 0.0008091139115659897, "was also": 0.0002727971730761859, "two pursuers k": 0.0008091139115659897, "have had widespread": 0.0008091139115659897, "end of the": 0.0004912229324109995, "simulator generated": 0.0007696350858963753, "sequential behavior": 0.0011908005071032729, "typically": 9.050279074516665e-05, "two pursuers e": 0.0008091139115659897, "early phases": 0.0005803901647646488, "quickly exceeds 90": 0.0008091139115659897, "adaptation of q": 0.0008091139115659897, "work this material": 0.0008091139115659897, "by examining": 0.0003157396500417892, "are modeled with": 0.0007023330300003208, "9 theta 10": 0.0008091139115659897, "gll obtained": 0.0007696350858963753, "ability of genetic": 0.0008091139115659897, "about 3": 0.00046861672357587705, "of experiments": 0.0003054794925471542, "examples to store": 0.0008091139115659897, "fifty": 0.00039606968857753465, "provide feedback": 0.0005803901647646488, "fired for state": 0.0008091139115659897, "pairs for": 0.00045224640365867626, "long sequence of": 0.0005851984448616567, "soccer he embedded": 0.0008091139115659897, "framework for a": 0.0005759152096655707, "nn to games": 0.0008091139115659897, "to throw away": 0.0008091139115659897, "working together": 0.0006131469602829721, "in a game": 0.0006349209434580451, "ratio": 7.503486379761692e-05, "further to be": 0.0008091139115659897, "introduction when two": 0.0008091139115659897, "proportion": 0.00025521803928536867, "size are known": 0.0008091139115659897, "would require": 0.00028456257763219726, "with corresponding action": 0.0008091139115659897, "only": -0.01131150597291407, "with each state": 0.0012698418869160901, "of which compete": 0.0008091139115659897, "typically an": 0.0005456354281782176, "nguyen widrow": 0.0007696350858963753, "the simulation": 0.00024405533553294298, "359 degrees is": 0.0008091139115659897, "developed a set": 0.0007023330300003208, "intelligent highways": 0.0007696350858963753, "away examples if": 0.0008091139115659897, "produce learning": 0.0007696350858963753, "much harder unlike": 0.0008091139115659897, "interesting we": 0.0006628410843555166, "initial state": 0.00029776693520311534, "is considered": 0.00022279508543139435, "a modified accounted": 0.0008091139115659897, "for the states": 0.0006199211760863129, "database if the": 0.0007023330300003208, "samuel": 0.0023036747443132034, "succeeds we also": 0.0008091139115659897, "truly": 0.0002695386947059894, "of identifying differences": 0.0008091139115659897, "cannot": -0.00010521734451816734, "agent must": 0.0005559058853301298, "sampling and random": 0.0006743602501766612, "s direction": 0.0013256821687110331, "1993b use": 0.0007696350858963753, "through 500 games": 0.0008091139115659897, "to make it": 0.00038659182444107513, "enormous improvement": 0.0007696350858963753, "temporally successive": 0.0007696350858963753, "one pursuer and": 0.0008091139115659897, "s fundamental": 0.000634859264718638, "genetic algorithm performed": 0.0008091139115659897, "above 70": 0.0006628410843555166, "perf evaluate performance": 0.0008091139115659897, "are selected for": 0.0005851984448616567, "has eight features": 0.0008091139115659897, "at any": 0.00018398380653845094, "from deterministic": 0.000702264802583379, "fitness of other": 0.0008091139115659897, "the on line": 0.0004779929005953682, "aircraft attempts to": 0.0008091139115659897, "for solving": 0.0006498505632591278, "nearest neighbors": 0.003139812341117755, "of how to": 0.0003919402155010585, "involves simultaneous learning": 0.0008091139115659897, "as stated above": 0.0005279045957013737, "requirements as": 0.0004642630166224529, "good function": 0.000702264802583379, "here is": 0.0001852280409905605, "we are exploring": 0.0005596382660342995, "nn for": 0.003078540343585501, "averaging cyclic": 0.0007696350858963753, "namely": 0.00010678299311942778, "to characterize": 0.000310019848849804, "methods directly": 0.000702264802583379, "86 evasion performance": 0.0008091139115659897, "and s k": 0.0005674382257236372, "are provided": 0.0002921317927643509, "algorithm planning": 0.0007696350858963753, "and all 20": 0.0008091139115659897, "100 randomly": 0.000634859264718638, "nn figure 3": 0.0008091139115659897, "pursuers one evader": 0.0008091139115659897, "which we first": 0.0007417488271393706, "state for the": 0.0005596382660342995, "a mathematical theory": 0.0005759152096655707, "to 1 degree": 0.0008091139115659897, "1963 this": 0.0007696350858963753, "successfully evades": 0.0007696350858963753, "3": 0, "widrow 1987 nguyen": 0.0008091139115659897, "bearing would": 0.0007696350858963753, "jth": 0.0002563435968543233, "between": -0.004123488183178668, "attribute in": 0.0004779464664686347, "one must avoid": 0.0008091139115659897, "do run genetic": 0.0008091139115659897, "time we are": 0.0005954580987137418, "by their": 0.000268298100835417, "a variation": 0.00034112545549164767, "most traditional lazy": 0.0008091139115659897, "differential game that": 0.0016182278231319793, "it to fill": 0.0008091139115659897, "exploring the state": 0.0006526576017704936, "olsder 1982 in": 0.0008091139115659897, "taken by e": 0.0008091139115659897, "nn is rarely": 0.0008091139115659897, "suggest solution": 0.0007696350858963753, "analyzed": 0.00011752779062308569, "in the application": 0.00040830984894046896, "two distance": 0.0006131469602829721, "from two pursuers": 0.0008091139115659897, "games 2060100": 0.0007696350858963753, "location of e": 0.0007417488271393706, "perceptions": 0.00046004841655118944, "for that": 0.0006099563533160512, "date little": 0.000702264802583379, "surprising in": 0.0005954002535516364, "even possible for": 0.0008091139115659897, "of using": 0.0004095355502235029, "classifier which": 0.0006131469602829721, "missile we": 0.0007696350858963753, "devijver kittler 1982": 0.0008091139115659897, "continuously in": 0.0005954002535516364, "also demonstrate": 0.00044497617160632185, "perform sequential behavior": 0.0016182278231319793, "optimal control": 0.0004288371693587632, "nearby": 0.0005749976229874555, "escape from": 0.0010912708563564353, "e because of": 0.0007417488271393706, "algorithms and for": 0.0006349209434580451, "to produce agents": 0.0008091139115659897, "agents to perform": 0.0016182278231319793, "reviewers of this": 0.0006349209434580451, "develop multiple solutions": 0.0008091139115659897, "problems with": 0.00046959769994342314, "methods however": 0.0004560919846500759, "use the same": 0.0003085145861027124, "learning a parallel": 0.0008091139115659897, "a small well": 0.0007417488271393706, "learning": 0.02640877475052615, "difficult control": 0.0007696350858963753, "within which": 0.00041758029726340933, "involves solving": 0.0006131469602829721, "contains all states": 0.0007417488271393706, "angle between": 0.00039398316601407357, "the variables": 0.00022666187998126376, "prey interactions": 0.0007696350858963753, "difficult for algorithm": 0.0008091139115659897, "its opponents": 0.0007696350858963753, "the adaptive control": 0.0014046660600006416, "also pit a": 0.0008091139115659897, "examples because k": 0.0008091139115659897, "inferior to": 0.00046009310747955083, "ga consequently": 0.0007696350858963753, "phase we": 0.0003898632748579793, "fitness is used": 0.0008091139115659897, "the general problem": 0.0004548376351798251, "evades two pursuers": 0.0008091139115659897, "adaptation in": 0.0005363412876789271, "of differential strategies": 0.0008091139115659897, "of opponents": 0.000702264802583379, "but instead": 0.0003449470981709676, "aha and the": 0.0008091139115659897, "standard ga": 0.0006628410843555166, "taken by p": 0.0007417488271393706, "think of the": 0.00045745222770795314, "complexity of differential": 0.0008091139115659897, "the examples continue": 0.0008091139115659897, "test games which": 0.0008091139115659897, "comparable in size": 0.0007023330300003208, "teacher the": 0.0007696350858963753, "accuracy of each": 0.0006069246369921007, "state to the": 0.0004779929005953682, "memory requirements without": 0.0008091139115659897, "random otherwise the": 0.0008091139115659897, "as they tackle": 0.0008091139115659897, "performance above 90": 0.0008091139115659897, "series of": 0.0006760766079994993, "performance was": 0.0008405552222291225, "developing": 0.00039481910518659335, "these": -0.010233457828252157, "quite fast 6": 0.0008091139115659897, "general class of": 0.000471675475395776, "through the data": 0.0005759152096655707, "threshold thus": 0.000634859264718638, "example sets with": 0.0008091139115659897, "neighbor algorithms aha": 0.0007417488271393706, "curvature and then": 0.0007417488271393706, "ones i": 0.0006131469602829721, "ga in their": 0.0008091139115659897, "training examples": 0.00045224640365867626, "series of experiments": 0.0004813101872060044, "of training k": 0.0008091139115659897, "eral": 0.00038394579071886724, "single missile we": 0.0008091139115659897, "1983 1990 clouse": 0.0008091139115659897, "that the performance": 0.0003731958134629092, "used alone": 0.000567383102523159, "of these games": 0.0007023330300003208, "five nearest": 0.0007696350858963753, "to multi": 0.00041758029726340933, "adversely": 0.00035442459743045417, "single constant": 0.000634859264718638, "a highly dynamic": 0.0007023330300003208, "develop": 0.0002718508166847631, "complex solving": 0.0007696350858963753, "combining the ga": 0.0008091139115659897, "tested using 1": 0.0008091139115659897, "escaping however many": 0.0008091139115659897, "plan and r": 0.0008091139115659897, "learning tesauro 1992": 0.0008091139115659897, "show how a": 0.0005176213124249083, "to this is": 0.0004998137828238603, "what he": 0.0005954002535516364, "prey interactions in": 0.0008091139115659897, "strategy is": 0.000268298100835417, "class name the": 0.0008091139115659897, "approach ritter": 0.0007696350858963753, "range around": 0.000702264802583379, "its own around": 0.0008091139115659897, "a performance of": 0.0006526576017704936, "both q learning": 0.0008091139115659897, "wilson in that": 0.0008091139115659897, "performance learning": 0.0007696350858963753, "ga started slowly": 0.0008091139115659897, "the fewest": 0.0004560919846500759, "scaling up to": 0.0006743602501766612, "begin the game": 0.0008091139115659897, "a wide variety": 0.0007418794663306229, "experiments by averaging": 0.0008091139115659897, "were successful at": 0.0008091139115659897, "in contrast": 0.00015433376548639827, "would like to": 0.00020418180881123067, "space has": 0.00046861672357587705, "algorithms take turns": 0.0008091139115659897, "successful game": 0.0007696350858963753, "solve complex": 0.000702264802583379, "isaacs 1963 this": 0.0008091139115659897, "performance at an": 0.0007417488271393706, "use genetic": 0.0015392701717927505, "we show": 9.417141608588533e-05, "with probability": 0.0005522553724888803, "case obtained": 0.000702264802583379, "01 regardless": 0.0007696350858963753, "less data and": 0.0008091139115659897, "the ga learned": 0.0016182278231319793, "where we use": 0.0004919901420568756, "generating bad examples": 0.0008091139115659897, "determine the applicability": 0.0008091139115659897, "deal with": 0.0001890334320045962, "coordinate": 0.00014940265895948467, "efficiency provided by": 0.0008091139115659897, "players are": 0.0005954002535516364, "avoid prematurely converging": 0.0008091139115659897, "checkers noughts and": 0.0008091139115659897, "al 1990 namely": 0.0008091139115659897, "when playing against": 0.0008091139115659897, "then the stored": 0.0008091139115659897, "probability of selection": 0.0016182278231319793, "the actions": 0.0020246423755918524, "and time than": 0.0008091139115659897, "valuable": 0.0001735498948296754, "quite well": 0.000783804281747114, "and selected": 0.0005363412876789271, "models to": 0.0006564211468598551, "step in": 0.00022153363976495309, "random for": 0.0006131469602829721, "actions but": 0.0006628410843555166, "speed": 0.0008897246723866275, "trying to run": 0.0008091139115659897, "wilson s": 0.0013256821687110331, "the game to": 0.0007417488271393706, "form suitable": 0.0006131469602829721, "level 3": 0.0004050885930083273, "and study whether": 0.0008091139115659897, "discovery systems based": 0.0016182278231319793, "improvement": 0.00018411014867336265, "attribute in each": 0.0008091139115659897, "genetic algorithm as": 0.0008091139115659897, "very rapidly": 0.0005363412876789271, "program called td": 0.0008091139115659897, "occurred prior to": 0.0008091139115659897, "to determine the": 0.0017098309970024097, "that the on": 0.0006199211760863129, "actions we": 0.0004731713358791195, "each time": 0.0006486481840859748, "real": -0.00010921394785824422, "object of": 0.00036338074496527356, "to navigating": 0.0007696350858963753, "learning curve": 0.0004938405038742361, "back and forth": 0.0005039721952628732, "read": 9.504668290567505e-05, "be labeled with": 0.0006199211760863129, "this game play": 0.0008091139115659897, "for meta game": 0.0008091139115659897, "is known": 0.00015433376548639827, "early": 0.0004734624021492095, "of those bad": 0.0008091139115659897, "turn with no": 0.0008091139115659897, "the ten experiments": 0.0008091139115659897, "learning problems": 0.0014488942443568135, "using": -0.01816020157177938, "making in gabriel": 0.0008091139115659897, "actions but a": 0.0007417488271393706, "after a successful": 0.0006743602501766612, "pursuer task was": 0.0008091139115659897, "which makes": 0.0002905747481074539, "us to": 0.00011205306324259125, "fitness determined": 0.0007696350858963753, "profit sharing": 0.0015392701717927505, "even the": 0.0002921317927643509, "is the use": 0.00040993954193880374, "the remaining examples": 0.0006743602501766612, "the speed": 0.00115010696107555, "furthermore such": 0.000567383102523159, "fired in": 0.000702264802583379, "benefit": 0.00012650411943999416, "by classifying each": 0.0007417488271393706, "state spaces such": 0.0008091139115659897, "t": 0, "a statistical approach": 0.0006199211760863129, "consistent with": 0.00022111610710477507, "probability 0 25": 0.0007023330300003208, "are then compared": 0.0007023330300003208, "closer to the": 0.0003975888325128001, "and selects the": 0.0006743602501766612, "did not work": 0.0007023330300003208, "general problem of": 0.0004813101872060044, "lazy learning initially": 0.0008091139115659897, "state is similar": 0.0007023330300003208, "control a combining": 0.0008091139115659897, "using these techniques": 0.0006349209434580451, "call the resulting": 0.0005334812968668691, "each plan against": 0.0008091139115659897, "rule will be": 0.0007417488271393706, "one such approach": 0.0006199211760863129, "pursuer problem is": 0.0008091139115659897, "motivated by": 0.0002603999475929679, "traditional lazy learning": 0.0016182278231319793, "1968 basically keeps": 0.0008091139115659897, "these actions do": 0.0008091139115659897, "examples in kd": 0.0008091139115659897, "than a player": 0.0008091139115659897, "co adaptive ga": 0.0008091139115659897, "to incorporate advice": 0.0008091139115659897, "than 90": 0.0004642630166224529, "games involves simultaneous": 0.0008091139115659897, "1 shows": 0.00019597523926923044, "editing procedure of": 0.0008091139115659897, "dropped below": 0.0007696350858963753, "then selected": 0.0005803901647646488, "soccer he": 0.0007696350858963753, "state should": 0.000634859264718638, "examples this alternation": 0.0008091139115659897, "include a complete": 0.0007023330300003208, "and neural": 0.0004779464664686347, "eager approaches": 0.0015392701717927505, "e has": 0.0003530449562101758, "what either method": 0.0008091139115659897, "of the multidit": 0.0008091139115659897, "increased this": 0.0005200422895505865, "problems in their": 0.0007023330300003208, "appending history": 0.0007696350858963753, "example can": 0.00042590150453082544, "selected an action": 0.0008091139115659897, "first state": 0.0004642630166224529, "poor whenever": 0.0007696350858963753, "counter a single": 0.0008091139115659897, "both of its": 0.0006069246369921007, "stored the": 0.0004560919846500759, "action pairs these": 0.0008091139115659897, "k nn s": 0.004045569557829949, "throw": 0.00039606968857753465, "same point": 0.00044497617160632185, "comparison": -3.3823847863842846e-05, "the military": 0.000702264802583379, "memory base guarantees": 0.0008091139115659897, "began by generating": 0.0008091139115659897, "where for example": 0.0006199211760863129, "for the ga": 0.005618664240002566, "games can be": 0.0007023330300003208, "of course the": 0.00034628681218354623, "of the relative": 0.0004167376361167208, "pedestrian able": 0.0007696350858963753, "characteristics metagamer has": 0.0008091139115659897, "now achieving": 0.0007696350858963753, "game is a": 0.0016182278231319793, "relative coordinate": 0.000702264802583379, "and pattern recognition": 0.0005456884385180774, "backgammon s stochastic": 0.0008091139115659897, "base and high": 0.0008091139115659897, "of ritter et": 0.0008091139115659897, "learning with": 0.001567608563494228, "for intelligent highways": 0.0008091139115659897, "even though": 0.00017793240093027558, "success further": 0.0007696350858963753, "goal or performing": 0.0008091139115659897, "solutions to": 0.00024507456027777314, "optimal play": 0.0021067944077501365, "20 state": 0.0023089052576891257, "number of researchers": 0.0005759152096655707, "algorithms planning for": 0.0008091139115659897, "state to encapsulate": 0.0008091139115659897, "the ga alone": 0.0008091139115659897, "includes numerous important": 0.0008091139115659897, "since e s": 0.0008091139115659897, "pursuer problem": 0.004617810515378251, "and operators for": 0.0006743602501766612, "this paper demonstrates": 0.0006526576017704936, "later when playing": 0.0008091139115659897, "as follows instance": 0.0007417488271393706, "start": -2.8167266454843504e-05, "low": 7.602264036220847e-06, "lot": 0.000371045860088017, "took advantage": 0.000567383102523159, "reached approximately": 0.0007696350858963753, "payoff at intermediate": 0.0008091139115659897, "class the class": 0.0006349209434580451, "their often competing": 0.0008091139115659897, "the performance on": 0.0005226282087022614, "state of the": 0.0007227294391742491, "random locations": 0.000567383102523159, "we took": 0.0004149539560409001, "the performance of": 0.0007455886698846824, "bearing measures": 0.0007696350858963753, "players at": 0.0007696350858963753, "starting position": 0.00052785331295456, "delayed": 0.0018933107461113576, "the initial speeds": 0.0008091139115659897, "we counted": 0.000567383102523159, "determining good actions": 0.0008091139115659897, "called td gammon": 0.0008091139115659897, "is the payoff": 0.0007417488271393706, "agent trying to": 0.0008091139115659897, "trying": 0.0003358773949365012, "reinforcement program": 0.0015392701717927505, "multi agent reinforcement": 0.0006743602501766612, "the sensor": 0.00045224640365867626, "only its turn": 0.0008091139115659897, "memory even further": 0.0008091139115659897, "the ga at": 0.0007417488271393706, "the ga as": 0.0007417488271393706, "antecedant": 0.0007021965884209132, "embedded": 0.0002530082388799883, "and hands off": 0.0008091139115659897, "work supported": 0.00046009310747955083, "of knowledge": 0.00036494662878843966, "that pruning improves": 0.0008091139115659897, "fixed radius": 0.0007696350858963753, "than either": 0.0008899523432126437, "p s radius": 0.0008091139115659897, "be more": 0.00018213923060557638, "issue for": 0.00040989971878532225, "plan the": 0.0005128077770266814, "to incorporate": 0.00028239161378183786, "game in": 0.00211141325181824, "within the bounds": 0.0005851984448616567, "study the limitations": 0.0007417488271393706, "frequency with": 0.0004779464664686347, "formal analysis": 0.00045224640365867626, "describe": -0.00013275967327250717, "game if": 0.0005954002535516364, "play and": 0.0005456354281782176, "in figure 8": 0.00027797337528372303, "evade and": 0.0007696350858963753, "environment for deriving": 0.0008091139115659897, "for simple": 0.00037315955974098747, "studied by": 0.00032932038867923357, "moves": 0.00015037298577266536, "in figure 4": 0.00021372887462530122, "in our": 0.000120271849311487, "game it": 0.0011908005071032729, "in figure 7": 0.00026062091866328816, "table are": 0.0004349818647972793, "e succeeded in": 0.0008091139115659897, "a plateau at": 0.0008091139115659897, "players to update": 0.0008091139115659897, "are stored": 0.000592252714916099, "algorithms to have": 0.0007417488271393706, "storage": 0.00011242863416134463, "this question": 0.0002985967834217994, "in differential game": 0.0008091139115659897, "in both directions": 0.0004779929005953682, "atkeson 1992": 0.0007696350858963753, "atkeson 1993": 0.0015392701717927505, "atkeson 1990": 0.0015392701717927505, "program more": 0.000567383102523159, "set through the": 0.0007023330300003208, "to reinforcement": 0.0021067944077501365, "by using its": 0.0006349209434580451, "terms of": 7.864990980729683e-05, "grefenstette 1988 as": 0.0008091139115659897, "which differs from": 0.0005851984448616567, "ability of three": 0.0008091139115659897, "poor": 0.0010907826101300374, "different defense mechanisms": 0.0008091139115659897, "fill in more": 0.0007417488271393706, "knowledge base and": 0.0006199211760863129, "genetic algorithm on": 0.0007417488271393706, "applying learning": 0.000702264802583379, "based learning algorithms": 0.0006743602501766612, "for more": 0.0004117314688807753, "best plan": 0.0015392701717927505, "nn it begins": 0.0008091139115659897, "flattened": 0.00047790004136261533, "peak": 0.00023477604289546367, "coverage": 0.00023858294210396408, "when two people": 0.0007417488271393706, "later when": 0.0004938405038742361, "it is possible": 0.0001863971674711706, "these random games": 0.0008091139115659897, "examples and then": 0.0006743602501766612, "for example suppose": 0.0004259428823122818, "building": 0.0001788946920960117, "future reinforcement": 0.0007696350858963753, "angle between e": 0.0007417488271393706, "the correct ones": 0.0008091139115659897, "approach discussed applicable": 0.0008091139115659897, "probability was": 0.0006131469602829721, "scaled linearly": 0.000702264802583379, "of interest probability": 0.0008091139115659897, "teaching a": 0.0006628410843555166, "required during training": 0.0008091139115659897, "should be": 0.00012493013849813577, "lazy approach": 0.0038481754294818755, "teaching k": 0.0007696350858963753, "we conducted a": 0.0005393947462253054, "and wins the": 0.0008091139115659897, "in this game": 0.0014046660600006416, "release evader pursuer": 0.0008091139115659897, "recognizing the difficulty": 0.0008091139115659897, "the oracle": 0.0004560919846500759, "a roll of": 0.0007417488271393706, "prioritized": 0.0012775804043633756, "1960s isaacs 1963": 0.0008091139115659897, "20 state action": 0.002427341734697969, "much better": 0.0005811494962149078, "to assist agents": 0.0008091139115659897, "remaining examples editing": 0.0008091139115659897, "solving a system": 0.0010558091914027474, "intuition of": 0.00048296474811893784, "achieved above 90": 0.0008091139115659897, "the ga eventually": 0.0008091139115659897, "high probability": 0.0003228323139879973, "i and": 0.0001961820371048006, "approach similar": 0.00048825248710181613, "at 80 this": 0.0008091139115659897, "we would like": 0.0002373461178569456, "to apply these": 0.0005954580987137418, "second algorithm to": 0.0007417488271393706, "whether a single": 0.0007417488271393706, "towards a": 0.00029943314463829254, "the players to": 0.0013487205003533224, "is to optimize": 0.0005759152096655707, "ability to": 0.00019768525039907866, "learning algorithm and": 0.0005456884385180774, "that poor": 0.000702264802583379, "fixed control": 0.0006628410843555166, "towards p": 0.000702264802583379, "task we envision": 0.0008091139115659897, "which gives some": 0.0008091139115659897, "s 90": 0.0007696350858963753, "the sampling idea": 0.0008091139115659897, "correct in random": 0.0008091139115659897, "very": -0.0012269538091343752, "the lazy": 0.0026002114477529322, "issues of co": 0.0008091139115659897, "as our experiments": 0.0007023330300003208, "pairs after generating": 0.0008091139115659897, "1986 we began": 0.0008091139115659897, "curve is much": 0.0006743602501766612, "actions i": 0.000634859264718638, "nearly perfectly q": 0.0008091139115659897, "of sharp": 0.000634859264718638, "task requires": 0.0005803901647646488, "method clouse": 0.0007696350858963753, "decide": 0.00011515664523045955, "skills that each": 0.0008091139115659897, "were allowed to": 0.0005851984448616567, "earlier research showed": 0.0008091139115659897, "actions d": 0.000702264802583379, "learning assume the": 0.0008091139115659897, "examples are summarized": 0.0008091139115659897, "a successful": 0.0007330739560370332, "determining relevant attributes": 0.0008091139115659897, "after reaching": 0.0005954002535516364, "is outside the": 0.0005039721952628732, "benefits above": 0.0007696350858963753, "it might be": 0.0007630256714120074, "then switched": 0.0007696350858963753, "game into a": 0.0008091139115659897, "action a is": 0.0006199211760863129, "improve its performance": 0.0006069246369921007, "on genetic algorithms": 0.0006743602501766612, "stores in": 0.0005363412876789271, "together can": 0.0006131469602829721, "editing served": 0.0007696350858963753, "as the ga": 0.0008091139115659897, "contains 7 5": 0.0008091139115659897, "simple games the": 0.0008091139115659897, "networks barto et": 0.0008091139115659897, "also resembles complicated": 0.0008091139115659897, "action pairs our": 0.0008091139115659897, "from right to": 0.0005176213124249083, "the corresponding state": 0.0005851984448616567, "the three values": 0.0007417488271393706, "algorithm which": 0.00022195263924232946, "idea requires that": 0.0008091139115659897, "complicated predator prey": 0.0008091139115659897, "of the rule": 0.0004278905317797242, "lazy and": 0.0006131469602829721, "escaping however": 0.0007696350858963753, "the competitive goals": 0.0008091139115659897, "therefore we specified": 0.0008091139115659897, "population to": 0.0005954002535516364, "metagamer focused on": 0.0008091139115659897, "hit the pedestrian": 0.0008091139115659897, "lazy approach stores": 0.0008091139115659897, "state based on": 0.0006199211760863129, "be produced by": 0.0005039721952628732, "90 there was": 0.0008091139115659897, "and then to": 0.0008166196978809379, "learner": 0.0028129278932506924, "and very": 0.00040276699958546587, "the same pursuit": 0.0008091139115659897, "ga 90": 0.0007696350858963753, "1991 used q": 0.0008091139115659897, "learned": 0.001492147519239715, "ga 99": 0.0007696350858963753, "acknowledgments": 8.16324462699643e-05, "thus we": 0.0006035006916481552, "approach to learn": 0.0014046660600006416, "edited": 0.0016394396134729896, "the evader": 0.005618118420667032, "the states": 0.0005874235532398661, "words the differential": 0.0008091139115659897, "goals more": 0.0006628410843555166, "can develop multiple": 0.0008091139115659897, "the bounds only": 0.0007023330300003208, "on 10": 0.0010726825753578542, "modify": 0.00010116113402896175, "each brings to": 0.0008091139115659897, "of the turn": 0.0007417488271393706, "coordinate system centered": 0.0007417488271393706, "we first": 0.00012862366934550902, "at first however": 0.0007417488271393706, "lazy learning methods": 0.002427341734697969, "to result in": 0.00048474305809383046, "railroad monitoring": 0.0007696350858963753, "arena": 0.00046004841655118944, "approach are three": 0.0008091139115659897, "other methods": 0.0003118921235356357, "ahead": 0.0004952783236377992, "substantially better than": 0.0006526576017704936, "such points": 0.0004779464664686347, "e successfully evades": 0.0008091139115659897, "makes the problem": 0.0006349209434580451, "ub i are": 0.0007417488271393706, "map this": 0.00048825248710181613, "game well": 0.0007696350858963753, "it one surprising": 0.0008091139115659897, "amount": 1.6893387772578182e-06, "is hard to": 0.00038402039400084893, "systems to teach": 0.0008091139115659897, "plateau at": 0.0015392701717927505, "lazy learner and": 0.0008091139115659897, "et al": 0.001617654943754307, "nn will": 0.0007696350858963753, "evasion figure": 0.0007696350858963753, "are analyzed to": 0.0007023330300003208, "the players speeds": 0.0008091139115659897, "a logarithmic": 0.0004050885930083273, "family": 0.0001195279098310498, "of the communication": 0.00040830984894046896, "parallel network that": 0.0014834976542787413, "are difficult": 0.00036338074496527356, "rules which is": 0.0007417488271393706, "superficial level": 0.0007696350858963753, "nn based on": 0.0008091139115659897, "analyzing": 0.0004079467132171959, "trained": 0.0006541614045626953, "second threshold": 0.0007696350858963753, "the player must": 0.0008091139115659897, "and to turn": 0.0008091139115659897, "rewards for": 0.0006628410843555166, "pursuit games the": 0.0008091139115659897, "takes": -8.506374217425025e-05, "deriving strategies in": 0.0008091139115659897, "1990 clouse utgoff": 0.0008091139115659897, "learning for example": 0.0007023330300003208, "8instance if": 0.0007696350858963753, "contains": -0.00027459134658049274, "identical to": 0.00022842192123212336, "the figure": 0.00021112298341276222, "we have determined": 0.0005128575980484463, "value is updated": 0.0007023330300003208, "removed from a": 0.0005674382257236372, "12334": 0.0007021965884209132, "algorithm to": 0.0009350473483545535, "it is learning": 0.0008091139115659897, "the broader domain": 0.0008091139115659897, "85 then": 0.0007696350858963753, "of having": 0.0003063720986511328, "are directed": 0.0004731713358791195, "s 90 success": 0.0008091139115659897, "experiments performance would": 0.0008091139115659897, "p2 individually": 0.0007696350858963753, "have different abilities": 0.0007417488271393706, "but were dependent": 0.0008091139115659897, "game the strengths": 0.0008091139115659897, "chess but": 0.0007696350858963753, "ga by specifying": 0.0008091139115659897, "agent is performing": 0.0008091139115659897, "bound don t": 0.0008091139115659897, "to the simulated": 0.0006069246369921007, "producing": 0.00017470025801004697, "when action a": 0.0008091139115659897, "the first": 0.0002255179816139378, "they can": 0.00048373221152380586, "points probably represent": 0.0008091139115659897, "attributes which": 0.0005060701527920558, "occurs in": 0.00025357520810241374, "p to capture": 0.0008091139115659897, "included in": 0.00020884227107457117, "behaviors of": 0.00040276699958546587, "case based method": 0.0007417488271393706, "task furthermore": 0.000702264802583379, "same task": 0.00044497617160632185, "game including e": 0.0008091139115659897, "games that": 0.0006131469602829721, "for differential games": 0.0016182278231319793, "history": 0.0004813323777350154, "idea which": 0.0005954002535516364, "is using the": 0.0005954580987137418, "of 11": 0.0003530449562101758, "of 10": 0.00025750558543057484, "this alternation": 0.0007696350858963753, "e the action": 0.0008091139115659897, "generations and its": 0.0008091139115659897, "is typical in": 0.0006526576017704936, "aliasing in which": 0.0007417488271393706, "4 theta": 0.0003982790696131452, "time step thus": 0.0006743602501766612, "neighbors finally": 0.0007696350858963753, "at that point": 0.0008638080474426554, "of learning": 0.002281470426753328, "is more difficult": 0.00041159621990674106, "to dynamic": 0.00039398316601407357, "we varied k": 0.0008091139115659897, "rules will": 0.0005200422895505865, "can work together": 0.0014834976542787413, "equations model": 0.0006628410843555166, "1993 a pursuit": 0.0008091139115659897, "to our type": 0.0008091139115659897, "ga at": 0.000702264802583379, "the standard": 0.00014773385227787492, "we specify": 0.0003530449562101758, "example set": 0.0023816010142065458, "to predict both": 0.0008091139115659897, "around obstacles": 0.000702264802583379, "which point": 0.00042590150453082544, "1975 the knowledge": 0.0008091139115659897, "values we therefore": 0.0008091139115659897, "schultz": 0.00046004841655118944, "control prioritized": 0.0007696350858963753, "achieves near": 0.000702264802583379, "tried": 0.0002022233631198131, "solve the": 0.000562302954731273, "networks tesauro sejnowski": 0.0008091139115659897, "that reinforcement learning": 0.0008091139115659897, "task and payoff": 0.0008091139115659897, "we designed initial": 0.0008091139115659897, "apprach a spatial": 0.0008091139115659897, "as follows": 0.0001903518452021058, "the dynamics": 0.0004004979458675273, "an action and": 0.0006349209434580451, "it from deterministic": 0.0008091139115659897, "fi": 9.646940000726047e-05, "good examples a": 0.0008091139115659897, "to explanation based": 0.0008091139115659897, "fl": 0.00014511170716971887, "torras": 0.001269595195923003, "classical approach": 0.0005363412876789271, "a": 0, "is how to": 0.00040993954193880374, "learning we": 0.00048825248710181613, "of dice": 0.0007696350858963753, "solved using this": 0.0008091139115659897, "current environment": 0.0006131469602829721, "this paper describes": 0.00039614664761543957, "generation thus": 0.0006628410843555166, "particular had considerable": 0.0008091139115659897, "and then used": 0.0005596382660342995, "by appending history": 0.0008091139115659897, "accuracy decreases as": 0.0007417488271393706, "learner to jump": 0.0008091139115659897, "ga because": 0.0007696350858963753, "see sheppard salzberg": 0.0016182278231319793, "provide feedback on": 0.0007023330300003208, "asymptotic performance and": 0.0008091139115659897, "help": 6.261487514961484e-05, "the lazy approach": 0.0008091139115659897, "typically classification tasks": 0.0008091139115659897, "these random": 0.00052785331295456, "it stored": 0.0007696350858963753, "noughts": 0.0007021965884209132, "the term game": 0.0008091139115659897, "r t": 0.0002809681012316349, "agents are learning": 0.0008091139115659897, "it stores": 0.001433839399405904, "we focused on": 0.0005393947462253054, "curvature is zero": 0.0008091139115659897, "but they lose": 0.0008091139115659897, "stores complete sequences": 0.0016182278231319793, "ours could be": 0.0008091139115659897, "of approximately 97": 0.0008091139115659897, "and pursuit": 0.0007696350858963753, "problem much": 0.0005803901647646488, "solving": 0.000330769169982842, "of the other": 0.0002515944278346912, "is updated using": 0.0006526576017704936, "actually": 6.478035405407687e-06, "anticipate the future": 0.0008091139115659897, "state if the": 0.0005279045957013737, "systems": -0.001187508459139648, "by averaging the": 0.0010787894924506108, "the tests for": 0.0006349209434580451, "the number of": 0.0007175621803659096, "credit assignment in": 0.0014834976542787413, "surpassing both q": 0.0008091139115659897, "the consequent are": 0.0007417488271393706, "characterizing the solution": 0.0008091139115659897, "our experiments": 0.0015051512252711784, "motivated": 0.0004214417970543282, "learner with": 0.000634859264718638, "we wish to": 0.0002890680321492111, "42 3": 0.0005363412876789271, "vector within": 0.000702264802583379, "successful game where": 0.0008091139115659897, "except that": 0.00021621606136199158, "still likely": 0.0007696350858963753, "frequently used": 0.0004123948992280552, "means that": 0.00011575777607317329, "chromosome for": 0.000702264802583379, "sweeping": 0.0012295797101047423, "sensing abilities further": 0.0008091139115659897, "in classifier systems": 0.0007417488271393706, "results in": 8.756309651119547e-05, "component each": 0.000634859264718638, "problem using": 0.0007176449336352503, "case based reasoning": 0.0006069246369921007, "solution to the": 0.0005711387159362167, "allowed of 135": 0.0008091139115659897, "scale is": 0.0004642630166224529, "editing to reduce": 0.0008091139115659897, "finally with performance": 0.0008091139115659897, "e must learn": 0.0008091139115659897, "distance parameters one": 0.0008091139115659897, "performing nearly perfectly": 0.0008091139115659897, "the approach": 0.0001913059091344491, "stopped": 0.000280236063377934, "properties of nearest": 0.0008091139115659897, "a smoke": 0.0007696350858963753, "will also": 0.00022492770365485792, "the rules by": 0.0006526576017704936, "outperform either": 0.0015392701717927505, "game as grefenstette": 0.0008091139115659897, "reward from the": 0.0008091139115659897, "c is the": 0.00030912606171066274, "michael littman 1994": 0.0008091139115659897, "learning because": 0.0006628410843555166, "a learning": 0.0007797265497159586, "valuable comments": 0.00037664034839981597, "starting position and": 0.0007417488271393706, "mingers 1989": 0.0006628410843555166, "training we": 0.0006131469602829721, "differential games one": 0.0008091139115659897, "part because of": 0.0006743602501766612, "fitness is": 0.0013256821687110331, "task hoping to": 0.0008091139115659897, "decision making when": 0.0008091139115659897, "by solving": 0.00028167752214893036, "intermediate level for": 0.0008091139115659897, "they tackle": 0.0007696350858963753, "of optimal control": 0.0006069246369921007, "part by": 0.00044306727952990617, "beyond": 9.048646954880461e-05, "been used to": 0.0003471669233594786, "97 success the": 0.0008091139115659897, "several robot control": 0.0008091139115659897, "most 20 time": 0.0008091139115659897, "call the": 0.00022237311719812292, "after about 3": 0.0008091139115659897, "gll remained": 0.0007696350858963753, "and an": 0.00010429832891415313, "since editing": 0.0007696350858963753, "tomek devijver": 0.0007696350858963753, "since": -0.0023622939099382212, "function then updates": 0.0008091139115659897, "difficulty because it": 0.0008091139115659897, "80 85": 0.000634859264718638, "limited fuel if": 0.0008091139115659897, "games is complex": 0.0008091139115659897, "7": -0.0018830188180804786, "relative frame of": 0.0008091139115659897, "given time such": 0.0008091139115659897, "defined by p": 0.0007023330300003208, "issue": 4.916858875782827e-05, "tesauro 1992": 0.001904577794155914, "1990 employed": 0.0007696350858963753, "above 45": 0.0007696350858963753, "ga learned": 0.0015392701717927505, "variable speed": 0.0007696350858963753, "2 3 p": 0.00033950437196557105, "halls of": 0.0007696350858963753, "represents a": 0.00018680013899656254, "that escape": 0.000702264802583379, "reason": 4.9620019361598346e-05, "base": 0.0002221788421107941, "one step further": 0.0005596382660342995, "every state": 0.0004123948992280552, "ase": 0.001269595195923003, "the car having": 0.0008091139115659897, "the players": 0.005432245542616597, "harder to study": 0.0008091139115659897, "some intuition of": 0.0008091139115659897, "during training since": 0.0008091139115659897, "rules which": 0.00041758029726340933, "with two": 0.00020623389645783668, "closer to": 0.00028529602391613707, "instances in instance": 0.0016182278231319793, "results show the": 0.0005279045957013737, "performance this": 0.00038024507112555464, "its poor": 0.0006628410843555166, "our problem and": 0.0006526576017704936, "and one for": 0.0004240325865444586, "knowledge for the": 0.0006743602501766612, "causes problems with": 0.0007417488271393706, "of the robot": 0.0006199211760863129, "pursuer problem and": 0.0008091139115659897, "below we describe": 0.0005596382660342995, "1 comparing": 0.0005456354281782176, "always possible": 0.00036494662878843966, "the anonymous reviewers": 0.00040670626310009803, "due east then": 0.0008091139115659897, "for classification": 0.00042304989757217126, "playing and": 0.000634859264718638, "that knew": 0.000702264802583379, "the halls of": 0.0008091139115659897, "probability": 0.0005335658082865482, "encoding": 0.0001724091647315856, "k nearest neighbor": 0.0029772904935687094, "new state": 0.00041758029726340933, "complexity of": 0.00013248506752184532, "process of identifying": 0.0007023330300003208, "work by": 0.001270870361143097, "we call": 0.00028236050076262034, "agent environments specifically": 0.0008091139115659897, "nn for the": 0.002427341734697969, "in fact the": 0.0005417454403528119, "ability to change": 0.0006743602501766612, "payoff values with": 0.0008091139115659897, "conversely for e": 0.0008091139115659897, "them in a": 0.0004259428823122818, "the classifiers": 0.00052785331295456, "evasion was": 0.0007696350858963753, "after 20 time": 0.0008091139115659897, "enable k": 0.0007696350858963753, "with the remaining": 0.0005674382257236372, "use until": 0.000702264802583379, "system of differential": 0.0011909161974274836, "gll because": 0.0007696350858963753, "is clear that": 0.0002687448506519112, "to play": 0.0036457973370749453, "respectively of the": 0.0005083144306061808, "constraints of a": 0.0006069246369921007, "h t": 0.0004074652591731264, "shifted": 0.0002465967250837866, "plateau between": 0.0007696350858963753, "seeded into the": 0.0007417488271393706, "of escaping": 0.0006628410843555166, "ga made the": 0.0008091139115659897, "clock heading is": 0.0008091139115659897, "basar": 0.0007021965884209132, "represent noise": 0.0007696350858963753, "in their multistrategy": 0.0008091139115659897, "figure shows": 0.000271492817488675, "all of the": 0.0012699371962941934, "off": 6.199184677305917e-05, "which naturally": 0.0005559058853301298, "of pursuit games": 0.0008091139115659897, "classifiers": 0.0006541614045626953, "salzberg 1991 we": 0.0008091139115659897, "and action spaces": 0.0008091139115659897, "positions develop continuously": 0.0008091139115659897, "as a differential": 0.0007023330300003208, "anticipate": 0.00033620802548856775, "that an": 0.0001463057524172468, "q learning stores": 0.0008091139115659897, "competing goals": 0.0006628410843555166, "training consists primarily": 0.0008091139115659897, "as with": 0.0002546842039466833, "to modify": 0.0002664248079582193, "be good": 0.00046861672357587705, "toward": 0.0003325975382216613, "jumped to": 0.0006628410843555166, "accuracy with": 0.00046861672357587705, "deciding": 0.00021033758092698209, "do not": 0.00012149504271992332, "as the teacher": 0.0008091139115659897, "possible with": 0.00036183856746138145, "defined below to": 0.0008091139115659897, "the opponent in": 0.0008091139115659897, "colombetti and dorigo": 0.0008091139115659897, "solving the": 0.0006175972033211629, "randomly": 0.0008767664701609671, "it eventually reached": 0.0008091139115659897, "better than they": 0.0007417488271393706, "location of": 0.0002508495615030361, "examples could": 0.0005954002535516364, "problems this paper": 0.0006526576017704936, "the complete": 0.0004095355502235029, "to turn randomly": 0.0008091139115659897, "an open parking": 0.0008091139115659897, "state information in": 0.0006069246369921007, "85 then performance": 0.0008091139115659897, "this figure 5": 0.0008091139115659897, "games 320": 0.0007696350858963753, "in play": 0.000634859264718638, "performance between k": 0.0008091139115659897, "evasion": 0.013097533231795239, "4 the learning": 0.0007417488271393706, "irrelevant attributes which": 0.0008091139115659897, "lin": 0.00020009941290167403, "frame of reference": 0.0006526576017704936, "was used to": 0.000345414170940388, "sharply since e": 0.0008091139115659897, "success after": 0.0015392701717927505, "implementation see sheppard": 0.0008091139115659897, "a pursuit game": 0.002427341734697969, "estimates of the": 0.0003975888325128001, "with the pursuit": 0.0008091139115659897, "aliasing": 0.0006108996398796318, "problems of this": 0.0007023330300003208, "either individually": 0.0006628410843555166, "towards": 0.00013847052678092888, "monitoring and ship": 0.0008091139115659897, "best ever": 0.0007696350858963753, "effects of hidden": 0.0008091139115659897, "strength of": 0.0003665369780185166, "determined using the": 0.0005759152096655707, "of any lazy": 0.0008091139115659897, "operationalizes": 0.0007021965884209132, "can reduce the": 0.00036445739219780933, "experiences": 0.0005060004090779561, "distances are normalized": 0.0008091139115659897, "of differential game": 0.0016182278231319793, "members in the": 0.0005456884385180774, "sensor readings of": 0.0008091139115659897, "consequently we": 0.00035027405940034004, "indicate that the": 0.00032078747889677304, "only achieving": 0.0015392701717927505, "we halt": 0.0007696350858963753, "the agent": 0.0004149539560409001, "throw away examples": 0.0008091139115659897, "clear": 1.1828726503159279e-05, "noisy irrelevant and": 0.0008091139115659897, "that at": 0.0003946827904591947, "after twice": 0.0007696350858963753, "first step": 0.00022622594443259307, "algorithms learning to": 0.0008091139115659897, "here is higher": 0.0008091139115659897, "tested using": 0.0004997652289300559, "in conjunction with": 0.0006443340359039737, "initial speeds": 0.0007696350858963753, "that the actions": 0.0006199211760863129, "the database if": 0.0006743602501766612, "of its parent": 0.0005393947462253054, "ga consequently we": 0.0008091139115659897, "of any": 0.00011933847638685871, "action to": 0.0017274482674037794, "an enormous": 0.0005128077770266814, "lot and": 0.0006628410843555166, "master level 3": 0.0008091139115659897, "game we": 0.003809155588311828, "nn from the": 0.0008091139115659897, "considerably poorer than": 0.0008091139115659897, "intuitive the actual": 0.0008091139115659897, "troubles we": 0.0007696350858963753, "resembles complicated": 0.0007696350858963753, "accuracy in the": 0.0004958241803403253, "is presence": 0.0007696350858963753, "80 evasion which": 0.0008091139115659897, "mccallum 1995": 0.0007696350858963753, "to approximate a": 0.0005524148804057065, "learning in": 0.0015594530994319173, "were then stored": 0.0008091139115659897, "parameters": -1.7743089754738915e-05, "identical to the": 0.00033009897175506186, "these results": 0.00035943819260773863, "this will become": 0.0007023330300003208, "than they": 0.0004731713358791195, "game e has": 0.0008091139115659897, "with large": 0.00028603448408455804, "methods on this": 0.0007023330300003208, "show how": 0.0005080100359906776, "circle": 0.0002126468044753682, "effects on sequential": 0.0008091139115659897, "resulting algorithm": 0.00041758029726340933, "the jth": 0.0003374403959319754, "guarantees that": 0.0005082566781673908, "the database evasion": 0.0008091139115659897, "dynamic control": 0.0005363412876789271, "sequence of states": 0.0004813101872060044, "to features": 0.00052785331295456, "environment one must": 0.0008091139115659897, "the simulator the": 0.0005851984448616567, "trees": 0.00023665030389857065, "threshold then": 0.0005559058853301298, "plans is determined": 0.0007417488271393706, "database full of": 0.0008091139115659897, "system to provide": 0.0006069246369921007, "competing": 0.0005633003230696627, "during": -0.00043685579143297687, "label each step": 0.0008091139115659897, "the next": 0.00016155614694074376, "2 reaching 80": 0.0008091139115659897, "we had to": 0.0009202756141833276, "action pair that": 0.0008091139115659897, "example set was": 0.0008091139115659897, "1989 td": 0.0007696350858963753, "first however our": 0.0008091139115659897, "1971 3 1": 0.0008091139115659897, "stochastic dynamic programming": 0.0007023330300003208, "assuming all of": 0.0007417488271393706, "with one": 0.0003981402298588186, "series of sharp": 0.0008091139115659897, "that was 95": 0.0008091139115659897, "than the speed": 0.0007417488271393706, "x": -0.0005785692245482657, "predict by": 0.001269718529437276, "very slowly": 0.0004997652289300559, "example suppose": 0.00035027405940034004, "e the evader": 0.0008091139115659897, "of approximately": 0.0003681525887744991, "our hypothesis was": 0.0006743602501766612, "the experiments reported": 0.0005039721952628732, "playing case based": 0.0008091139115659897, "learning k nn": 0.0008091139115659897, "by using": 0.00020527318335873766, "crossover rules": 0.0007696350858963753, "6 94 5": 0.0007417488271393706, "1989 to": 0.0006131469602829721, "methods have": 0.00030027612719626154, "players the": 0.0005803901647646488, "game to include": 0.0008091139115659897, "our hypothesis": 0.0013682759539502276, "for reinforcement": 0.0006628410843555166, "highways air": 0.0007696350858963753, "close": 2.789466838489197e-05, "control tasks we": 0.0008091139115659897, "rl problems studied": 0.0008091139115659897, "video game pacman": 0.0008091139115659897, "neighbors and the": 0.0006199211760863129, "engagement were": 0.0007696350858963753, "by setting the": 0.0004319040237213277, "considerably poorer": 0.0007696350858963753, "encoded using rule": 0.0008091139115659897, "the angle": 0.0010271509478634948, "a framework": 0.0004840874822032347, "state variables": 0.0004288371693587632, "700 examples": 0.0015392701717927505, "over k nn": 0.0008091139115659897, "to replicate": 0.00048296474811893784, "probably": 0.0005155270497751225, "highways air traffic": 0.0008091139115659897, "conditions": -3.704395886635297e-05, "it first uses": 0.0008091139115659897, "addressed the": 0.00038024507112555464, "pursuer attempts": 0.0007696350858963753, "the experiment": 0.0006456646279759946, "notoriously": 0.00044493294905444163, "tactics while another": 0.0008091139115659897, "showed good": 0.0006628410843555166, "point in training": 0.0008091139115659897, "achieving around": 0.0007696350858963753, "poorer": 0.00038020813619878184, "pursuers is captured": 0.0008091139115659897, "still requires": 0.0005060701527920558, "it is exploring": 0.0008091139115659897, "points shown in": 0.0006743602501766612, "hit the": 0.0005060701527920558, "specify two": 0.000634859264718638, "rate of the": 0.0007630256714120074, "algorithm gll performs": 0.0008091139115659897, "both": -0.0061852322747680015, "in general": 0.00017171133915032643, "more difficult than": 0.0004998137828238603, "and ending when": 0.0008091139115659897, "normalized to": 0.0003859053049699601, "time in": 0.00015813203154174468, "finally tesauro used": 0.0008091139115659897, "time is": 0.00017101310854322703, "and lazy": 0.0017411704942939465, "of which": 0.00038396615743658104, "task the": 0.0014726103550979964, "as 11": 0.0006131469602829721, "parking lot with": 0.0008091139115659897, "well on the": 0.0005279045957013737, "games with a": 0.0008091139115659897, "to be": 2.1682151067327708e-05, "type this": 0.0004779464664686347, "using hill climbing": 0.0008091139115659897, "bombs which": 0.0007696350858963753, "000 examples which": 0.0008091139115659897, "mechanisms and different": 0.0008091139115659897, "behavior on": 0.00045224640365867626, "hybrid approach": 0.0004938405038742361, "as our": 0.00028529602391613707, "jump start": 0.0015392701717927505, "control values with": 0.0008091139115659897, "interesting we will": 0.0008091139115659897, "speed by": 0.000567383102523159, "ga because it": 0.0008091139115659897, "two learning": 0.0012262939205659443, "r learning": 0.000634859264718638, "two genetic": 0.0007696350858963753, "some interesting": 0.000391902140873557, "above 90 success": 0.0008091139115659897, "increased this figure": 0.0008091139115659897, "developing autonomous agents": 0.0008091139115659897, "generating a": 0.000667764418381267, "task together": 0.0007696350858963753, "function in grefenstette": 0.0008091139115659897, "described": -0.0005899222972697993, "any action": 0.0005456354281782176, "and utgoff": 0.0013256821687110331, "is rather than": 0.0007417488271393706, "this work this": 0.0005954580987137418, "adjust its speed": 0.0008091139115659897, "for even": 0.00039610816435843403, "a separate teacher": 0.0008091139115659897, "improve its": 0.0004731713358791195, "not work well": 0.0005083144306061808, "that learns to": 0.0014046660600006416, "describes": 4.647792550976728e-05, "shown in the": 0.00025867947411109033, "collected": 0.0001718423499250408, "perceptions is not": 0.0008091139115659897, "an example of": 0.0002169058629816909, "learning differential": 0.0007696350858963753, "an extension of": 0.00030087107663277584, "differential games differential": 0.0008091139115659897, "games littman expanded": 0.0008091139115659897, "of the tasks": 0.0004813101872060044, "generating": 0.0004897946776197858, "s t where": 0.0005954580987137418, "nn to solve": 0.0008091139115659897, "1976 modified this": 0.0008091139115659897, "a particular differential": 0.0008091139115659897, "search credit assignment": 0.0008091139115659897, "with a system": 0.0005759152096655707, "having good examples": 0.0008091139115659897, "players friedman": 0.0007696350858963753, "future games states": 0.0008091139115659897, "the variance of": 0.0004360863081445778, "that an exact": 0.0006349209434580451, "midst of a": 0.0007417488271393706, "pedestrian crossing": 0.0007696350858963753, "the applicability of": 0.0003905762619993037, "yielded performance": 0.000702264802583379, "a random": 0.00041995463274415004, "n high": 0.000702264802583379, "to pursue and": 0.0007417488271393706, "p1 and": 0.0037489337886070164, "on learning": 0.0004050885930083273, "neighbors if": 0.000567383102523159, "to work": 0.0004348449227624408, "training on 100": 0.0008091139115659897, "adaptive genetic algorithm": 0.0008091139115659897, "the single": 0.0006608561888026272, "into the": 0.00022074141445811715, "full of": 0.0005559058853301298, "while": -0.001435789290109078, "are discrete": 0.0004997652289300559, "difficulty achieving a": 0.0008091139115659897, "basic game is": 0.0008091139115659897, "construct a plan": 0.0007023330300003208, "these algorithms": 0.00024405533553294298, "maze like": 0.0015392701717927505, "the opponent": 0.0005954002535516364, "guide": 0.00014748057431744982, "starting positions p": 0.0008091139115659897, "theory classifier systems": 0.0008091139115659897, "success with only": 0.0008091139115659897, "bad actions": 0.0015392701717927505, "states there": 0.0005363412876789271, "state x reward": 0.0008091139115659897, "these examples our": 0.0008091139115659897, "history of": 0.0003177175902857743, "up the ga": 0.0008091139115659897, "phases of": 0.0003462531725087664, "and the actions": 0.0006199211760863129, "high level strategic": 0.0008091139115659897, "in a dynamic": 0.00048474305809383046, "reveals some": 0.0006628410843555166, "task but": 0.0004997652289300559, "match its changes": 0.0008091139115659897, "can be generated": 0.00036238524153671306, "the nearest sequence": 0.0008091139115659897, "accelerate it": 0.0007696350858963753, "evaded p for": 0.0008091139115659897, "to change its": 0.0005674382257236372, "grant": 8.364632460408693e-05, "converged when": 0.000634859264718638, "exploring the ability": 0.0008091139115659897, "envelope of": 0.0005060701527920558, "of instances": 0.0007298932575768793, "system which": 0.00030112584215908326, "without significantly affecting": 0.0006743602501766612, "multi agent environments": 0.0014834976542787413, "in addition we": 0.0003180818046332927, "assuming that neighboring": 0.0008091139115659897, "determine the set": 0.0005176213124249083, "of genetic": 0.0005363412876789271, "interpolation": 0.00021985083825553804, "modified the": 0.0003898632748579793, "related to theoretical": 0.0008091139115659897, "used": -0.01433700124087846, "4 performance": 0.00042027761111456123, "instances the": 0.0004149539560409001, "best examples of": 0.0008091139115659897, "the term": 0.00019328620393072667, "to run": 0.0002455876065332435, "000": 0.002671894033064208, "uses": -0.0007316857416215559, "together they can": 0.0007023330300003208, "fact that": 0.00016328075273932047, "the need": 0.00019097880800054482, "those directly": 0.000702264802583379, "changed as": 0.0005363412876789271, "determine the value": 0.0005393947462253054, "since it was": 0.0005334812968668691, "othello a": 0.0007696350858963753, "database": 0.0020664950121968783, "every time step": 0.0005674382257236372, "john w sheppard": 0.0007417488271393706, "game theory classifier": 0.0008091139115659897, "and then switched": 0.0008091139115659897, "generated another": 0.000702264802583379, "the task one": 0.0007417488271393706, "occurred after 20": 0.0008091139115659897, "with where each": 0.0008091139115659897, "be incorrect e": 0.0008091139115659897, "while the pursuer": 0.0008091139115659897, "e is to": 0.0007417488271393706, "treated in": 0.0003681525887744991, "continue to accumulate": 0.0008091139115659897, "distances": 0.00019460472410897658, "some other recent": 0.0007023330300003208, "temporal differences distance": 0.0008091139115659897, "less time the": 0.0007417488271393706, "lazy approach k": 0.0008091139115659897, "4 3 ga": 0.0008091139115659897, "which terms": 0.000634859264718638, "any nearby states": 0.0008091139115659897, "approaches lazy q": 0.0008091139115659897, "equalize their": 0.000702264802583379, "players the ability": 0.0008091139115659897, "shows that": 9.48787245474689e-05, "we gave": 0.0009372334471517541, "we considered the": 0.0004958241803403253, "lies in the": 0.00035168430803720827, "1 degree": 0.000634859264718638, "were able to": 0.0011195874403887279, "learning and": 0.0017867359556967707, "the turn": 0.00105570662590912, "actions d 1": 0.0008091139115659897, "only 5 000": 0.0007417488271393706, "still inferior": 0.0007696350858963753, "genetic algorithms planning": 0.0008091139115659897, "a population": 0.0009765049742036323, "space for the": 0.0004404523980181757, "task thus": 0.0006131469602829721, "how a genetic": 0.0008091139115659897, "averaging control": 0.0007696350858963753, "one pursuer": 0.011544526288445626, "stores the actual": 0.0007417488271393706, "guarantees": 0.00024637238885809017, "game e only": 0.0008091139115659897, "remaining": 1.1839710306851558e-05, "states were": 0.0006628410843555166, "outperformed the ga": 0.0008091139115659897, "payoff and": 0.0007696350858963753, "most frequently used": 0.0006199211760863129, "evaluate": 0.000152917862538059, "game": 0.02519961088374034, "the action space": 0.0007023330300003208, "nn and the": 0.0008091139115659897, "more quickly": 0.00042027761111456123, "simulator to": 0.00048825248710181613, "proportional selection goldberg": 0.0008091139115659897, "kasif and s": 0.0008091139115659897, "consists of computing": 0.0006526576017704936, "pattern recognition a": 0.0006349209434580451, "with applications": 0.0002645827392309425, "regardless of performance": 0.0008091139115659897, "games we": 0.0006628410843555166, "maneuvering and sensing": 0.0008091139115659897, "nn eventually": 0.0007696350858963753, "was used for": 0.00040670626310009803, "should be able": 0.0003790659936968334, "they have limited": 0.0006743602501766612, "improvement through": 0.0007696350858963753, "learning uses": 0.0007696350858963753, "popular": 0.0005206496844890262, "size our": 0.0005128077770266814, "does the potential": 0.0008091139115659897, "distance to find": 0.0008091139115659897, "deterministic games": 0.0006628410843555166, "it stores examples": 0.0008091139115659897, "of 20 state": 0.0008091139115659897, "mathematical": 9.682657545975398e-05, "almost immediately reaches": 0.0008091139115659897, "games states": 0.0007696350858963753, "summarized in figure": 0.0004882999224935485, "rules and constraints": 0.0007023330300003208, "some": -0.005696082912551631, "based learning for": 0.0007023330300003208, "of opponents finally": 0.0008091139115659897, "the system would": 0.0005393947462253054, "an earlier": 0.0003028459277060942, "game that has": 0.0008091139115659897, "task the results": 0.0008091139115659897, "a sequence": 0.00026497013504369065, "rewards associated": 0.000702264802583379, "a given state": 0.0005334812968668691, "in solving": 0.0003714629793944916, "tasks they": 0.0005559058853301298, "q value": 0.0011607803295292977, "the state is": 0.0005279045957013737, "of e s": 0.0012398423521726258, "describing": 0.00012236660164685297, "decreases as": 0.0003681525887744991, "then e escapes": 0.0008091139115659897, "small only": 0.0005803901647646488, "what he calls": 0.0008091139115659897, "compete against each": 0.0008091139115659897, "table our implementation": 0.0008091139115659897, "exceeding": 0.0006585768005952463, "data the example": 0.0007417488271393706, "99 6": 0.0005803901647646488, "an agent has": 0.0005759152096655707, "behaviors and": 0.0005128077770266814, "approaches such": 0.0004997652289300559, "teaching method": 0.000702264802583379, "minimal": 0.00016290815170764085, "order to approximate": 0.0006526576017704936, "simultaneous learning": 0.000702264802583379, "the different skills": 0.0007417488271393706, "run": -3.5209083068554376e-05, "than either method": 0.0016182278231319793, "markov games": 0.001269718529437276, "and determined that": 0.0007417488271393706, "but not better": 0.0008091139115659897, "instead of": 9.399495106486359e-05, "a lazy algorithm": 0.0008091139115659897, "roughly 5 4": 0.0008091139115659897, "step": -0.0008395331723500727, "results of": 0.0012389641373389765, "ga each plan": 0.0008091139115659897, "lasts": 0.0004202367876457788, "chess and": 0.000702264802583379, "we too have": 0.0008091139115659897, "guidance from a": 0.0008091139115659897, "path during the": 0.0006349209434580451, "nn on the": 0.0007417488271393706, "idea of": 0.00039744494010191835, "agents in optimizing": 0.0008091139115659897, "games machine learning": 0.0007023330300003208, "size training set": 0.0008091139115659897, "encountered in": 0.0003748850085915968, "a version of": 0.00036983022343051777, "task but were": 0.0008091139115659897, "in the antecedant": 0.0008091139115659897, "knowledge for": 0.0004779464664686347, "simulation": 0.00031151603018977973, "further they": 0.0006131469602829721, "no turn": 0.001404529605166758, "our difficult reinforcement": 0.0008091139115659897, "examples illustrate a": 0.0007417488271393706, "tag the popular": 0.0008091139115659897, "performance of lazy": 0.0014834976542787413, "until e": 0.0006628410843555166, "to be maximally": 0.0007023330300003208, "readings of": 0.0006131469602829721, "switched to k": 0.0008091139115659897, "ten experiments to": 0.0008091139115659897, "ably in fact": 0.0008091139115659897, "theoretically minimal number": 0.0008091139115659897, "refines the advice": 0.0008091139115659897, "a complete": 0.0005464176918167291, "describing the": 0.0002689296688222252, "e controls only": 0.0008091139115659897, "within": -0.000594988538930123, "bootstrap k nn": 0.0008091139115659897, "of states": 0.0005735560625682435, "more of the": 0.00040830984894046896, "strength plan": 0.0007696350858963753, "editing method which": 0.0008091139115659897, "perform well on": 0.0020704852496996333, "described another editing": 0.0008091139115659897, "editing would": 0.000702264802583379, "way around in": 0.0008091139115659897, "readings of p1": 0.0008091139115659897, "profound differences": 0.0007696350858963753, "5 700 games": 0.0008091139115659897, "then switched to": 0.0008091139115659897, "for planning and": 0.0007023330300003208, "conditions can be": 0.000449806936615026, "john w": 0.0005559058853301298, "stopped was": 0.0007696350858963753, "are generalized or": 0.0008091139115659897, "sequential decision making": 0.0019579728053114812, "in the fewest": 0.0006743602501766612, "state matcher which": 0.0008091139115659897, "hypothesis that k": 0.0007417488271393706, "nearby states the": 0.0008091139115659897, "selection goldberg 1989": 0.0008091139115659897, "tesauro sejnowski": 0.0007696350858963753, "agents that perform": 0.0007023330300003208, "presence of": 0.00016496272185669375, "evasion tactics": 0.0007696350858963753, "adaptive ga is": 0.0007417488271393706, "and go": 0.00042027761111456123, "limited fuel": 0.0007696350858963753, "its parent": 0.00036183856746138145, "games the ga": 0.0008091139115659897, "only on the": 0.000301439879235054, "affecting performance early": 0.0008091139115659897, "the remaining": 0.0001353314298958535, "action comparator": 0.0015392701717927505, "its own for": 0.0007417488271393706, "type of differential": 0.0008091139115659897, "on learning to": 0.0007023330300003208, "or memory based": 0.0008091139115659897, "we conducted": 0.00039610816435843403, "ability of q": 0.0008091139115659897, "with delayed rewards": 0.0008091139115659897, "are deleted from": 0.0005851984448616567, "that both will": 0.0008091139115659897, "finally the": 0.0001890334320045962, "both p1": 0.0015392701717927505, "no reduction": 0.0005559058853301298, "highlight the": 0.00040989971878532225, "significant information must": 0.0008091139115659897, "intuitive": 0.00015888831673156617, "refines the": 0.0005128077770266814, "process might enable": 0.0008091139115659897, "a logarithmic scale": 0.0005851984448616567, "it even": 0.0005128077770266814, "fact the simulation": 0.0008091139115659897, "similar": -0.002570531907546482, "ishihara 1993 and": 0.0008091139115659897, "games this": 0.0006628410843555166, "algorithms aha": 0.000702264802583379, "reduced and": 0.00044854462015967935, "individual trials on": 0.0008091139115659897, "if a point": 0.0005851984448616567, "samuel then uses": 0.0008091139115659897, "typically an agent": 0.0008091139115659897, "85 after": 0.000702264802583379, "have known": 0.000634859264718638, "reinforcement learning problems": 0.0016182278231319793, "or nearly": 0.00046009310747955083, "3 o clock": 0.0008091139115659897, "through the": 0.0004846246585028844, "the plan": 0.0004560919846500759, "the midst": 0.0006628410843555166, "steps later": 0.0007696350858963753, "in multi": 0.0006898941963419351, "traffic control": 0.0004938405038742361, "and perceptions": 0.000702264802583379, "mutate those": 0.0007696350858963753, "simulation ran for": 0.0008091139115659897, "opponents this": 0.0007696350858963753, "value is": 0.0001913059091344491, "the evader attempts": 0.0008091139115659897, "of the delay": 0.0005279045957013737, "the accuracy of": 0.0002900888907481309, "bootstrap k": 0.0007696350858963753, "the same reactive": 0.0008091139115659897, "application": -0.00017682597101462317, "rules a": 0.0004050885930083273, "computing the mean": 0.0006199211760863129, "of determining optimal": 0.0007417488271393706, "analyzing learning algorithms": 0.0008091139115659897, "arithmetic": 0.00014324262941653454, "is calculated": 0.00029776693520311534, "dynamic environment rather": 0.0008091139115659897, "declarative formulation": 0.0007696350858963753, "most commonly": 0.0003820967919236623, "poor quality of": 0.0007023330300003208, "fewest": 0.00038020813619878184, "different speeds": 0.0006131469602829721, "1983 barto": 0.000702264802583379, "population do run": 0.0008091139115659897, "strategy that": 0.000391902140873557, "strict a constraint": 0.0008091139115659897, "size of the": 0.00033778199678819706, "state space which": 0.0006199211760863129, "that each brings": 0.0008091139115659897, "is due east": 0.0008091139115659897, "this approach by": 0.0006069246369921007, "in real": 0.00025357520810241374, "antecedent": 0.0004004590436872584, "type of task": 0.0007417488271393706, "games in the": 0.0007417488271393706, "e": -0.023392023430409973, "initial placements of": 0.0008091139115659897, "learning has": 0.0005363412876789271, "of irrelevant": 0.0005363412876789271, "required": -0.0002991184343375483, "classification and suggested": 0.0008091139115659897, "game follows a": 0.0008091139115659897, "games states were": 0.0008091139115659897, "unlike the": 0.0002741172369601924, "by the k": 0.0005674382257236372, "players called": 0.000702264802583379, "a robot arm": 0.0006526576017704936, "combining different": 0.001134766205046318, "usually applied": 0.0006131469602829721, "requires": -0.00036194587819521844, "1993a 1993b use": 0.0008091139115659897, "to control": 0.0015018734402804294, "trees mingers": 0.0007696350858963753, "climbing to": 0.000634859264718638, "figure 8 a": 0.00039905202450766993, "to the broader": 0.0007023330300003208, "experiments in figure": 0.0007023330300003208, "our implementation uses": 0.0005674382257236372, "control railroad monitoring": 0.0008091139115659897, "terms have numeric": 0.0008091139115659897, "technique to": 0.0002530247819825898, "ga": 0.024202713703061495, "were still": 0.0005363412876789271, "go": 8.910203451235566e-05, "experiment since": 0.0006131469602829721, "applied to the": 0.0002512336057807549, "examples for k": 0.0008091139115659897, "outperforming": 0.00046857120471006095, "to obtain such": 0.0005954580987137418, "than rule strength": 0.0008091139115659897, "the dynamics of": 0.0004657382758148953, "database i": 0.0012262939205659443, "can be used": 0.0003918819861354057, "is 70": 0.000634859264718638, "to this family": 0.0008091139115659897, "classification tasks": 0.0005559058853301298, "a complete lookup": 0.0008091139115659897, "to turn sharply": 0.0016182278231319793, "utgoff 1992": 0.0021067944077501365, "nearest neighbor applications": 0.0008091139115659897, "successful at developing": 0.0008091139115659897, "to another plateau": 0.0008091139115659897, "pursuers e can": 0.0008091139115659897, "outperforms its own": 0.0008091139115659897, "methods usually": 0.0007696350858963753, "the actions d": 0.0007417488271393706, "general architecture": 0.0005456354281782176, "4 4 comparing": 0.0008091139115659897, "found that editing": 0.0008091139115659897, "previous work by": 0.0005954580987137418, "with where": 0.00044497617160632185, "of rl problems": 0.0008091139115659897, "compete against": 0.000634859264718638, "the competition initially": 0.0008091139115659897, "how increasing the": 0.0007417488271393706, "for intelligent": 0.0004642630166224529, "game called": 0.0015392701717927505, "predicate the bounds": 0.0008091139115659897, "one to one": 0.0003655094953325257, "explicitly generating them": 0.0008091139115659897, "solving these": 0.00046861672357587705, "determined similarly using": 0.0008091139115659897, "9223591 r learning": 0.0008091139115659897, "homicidal": 0.002808786353683653, "time the truck": 0.0008091139115659897, "to a lower": 0.0004919901420568756, "positions": 0.0002632127367910622, "michael": 0.0001364264012638399, "decision trees mingers": 0.0008091139115659897, "the simulator determines": 0.0008091139115659897, "the new": 9.80910185524003e-05, "algorithm by testing": 0.0008091139115659897, "lower and upper": 0.0008557810635594484, "shows performance plotted": 0.0008091139115659897, "action can": 0.0005060701527920558, "widespread application": 0.0006628410843555166, "payoff isaacs": 0.0007696350858963753, "to david aha": 0.0008091139115659897, "of selection for": 0.0007417488271393706, "this results": 0.00028456257763219726, "at random locations": 0.0007023330300003208, "have minimized the": 0.0007417488271393706, "ga to perform": 0.0008091139115659897, "jump": 0.00048304570024672967, "led to the": 0.0004259428823122818, "in section 3": 0.00014482674913558768, "of all": 5.1882891580557405e-05, "succeeded in escaping": 0.0008091139115659897, "later used": 0.0005363412876789271, "types of": 0.000270662859791707, "we had no": 0.0006526576017704936, "a search through": 0.0006349209434580451, "of perceptual aliasing": 0.0016182278231319793, "booker goldberg holland": 0.0008091139115659897, "is the poor": 0.0014834976542787413, "program to": 0.00030112584215908326, "the database for": 0.0011518304193311414, "evasion usually occurred": 0.0008091139115659897, "objective examples": 0.0007696350858963753, "many games as": 0.0008091139115659897, "goals of the": 0.0005083144306061808, "experiment": 0.0003100901736562235, "networks tesauro": 0.0007696350858963753, "are the averages": 0.0006526576017704936, "bootstrapping algorithm gll": 0.0008091139115659897, "corresponding action a": 0.0008091139115659897, "this makes": 0.00028529602391613707, "examples similar": 0.000702264802583379, "only 500": 0.0007696350858963753, "examples have": 0.0004731713358791195, "the bounds shift": 0.0008091139115659897, "reinforcement throughout": 0.0007696350858963753, "in the one": 0.0010079443905257465, "perform as": 0.00042590150453082544, "would assist": 0.000634859264718638, "extension of traditional": 0.0007417488271393706, "algorithms take": 0.0005954002535516364, "for mutation": 0.0005954002535516364, "ramsey": 0.0015382738970507988, "focused": 0.00033808563994142024, "stepwise forward selection": 0.0008091139115659897, "bomb which": 0.0007696350858963753, "actions do not": 0.0006743602501766612, "the previous": 7.47166395509877e-05, "then select the": 0.0006526576017704936, "nn still": 0.0007696350858963753, "were dependent on": 0.0008091139115659897, "below the": 0.00022028539626754243, "eight features": 0.0007696350858963753, "is also": 5.082689720099552e-05, "when e": 0.0004642630166224529, "might be to": 0.0005393947462253054, "is substantially better": 0.0007417488271393706, "naturally causes": 0.000702264802583379, "an extension": 0.00023386624774719507, "for the general": 0.00041328080567602945, "learning algorithm the": 0.0006199211760863129, "tried a traditional": 0.0008091139115659897, "games as a": 0.0006743602501766612, "is no possibility": 0.0005851984448616567, "in this paper": 9.365154993897332e-05, "sutton anderson": 0.000702264802583379, "examining": 0.00017412385966395318, "expected rewards": 0.0007696350858963753, "if we": 8.214232827795022e-05, "90 there": 0.000702264802583379, "used by": 0.00042976963372155335, "simulated robot to": 0.0008091139115659897, "when history": 0.0007696350858963753, "and then uses": 0.0005083144306061808, "approximators in": 0.0007696350858963753, "set with the": 0.0005083144306061808, "by using a": 0.0002916385948209471, "noncooperative game theory": 0.0008091139115659897, "addressed": 0.00011515664523045955, "and determining the": 0.0005954580987137418, "statistical approach": 0.0005200422895505865, "to catch": 0.0010256155540533628, "gordon and subramanian": 0.0007417488271393706, "games this was": 0.0008091139115659897, "complete game the": 0.0008091139115659897, "which uses": 0.0002708464065257185, "it is even": 0.0005176213124249083, "agents in": 0.00046009310747955083, "its performance": 0.000620039697699608, "measurement the results": 0.0008091139115659897, "of the two": 0.00037532926011678324, "change its": 0.0004123948992280552, "action or something": 0.0008091139115659897, "own speed": 0.000702264802583379, "pursuit game earlier": 0.0008091139115659897, "ase with": 0.0007696350858963753, "teacher and lazy": 0.0008091139115659897, "the lethal": 0.0007696350858963753, "learning rate ae": 0.0008091139115659897, "algorithm train on": 0.0008091139115659897, "evasion examples": 0.0007696350858963753, "the remainder": 0.0003872384988585797, "optimizing": 0.00016201702300936287, "in kd": 0.0006628410843555166, "in size to": 0.0005851984448616567, "varied k between": 0.0008091139115659897, "compare with": 0.0004123948992280552, "started": 0.0001718423499250408, "of the difficulty": 0.0005334812968668691, "passed to": 0.0006654456183183088, "task one": 0.0005200422895505865, "speeds and p": 0.0008091139115659897, "of the memory": 0.00037434295450873773, "don t": 0.00028239161378183786, "missile": 0.0005953424196270563, "of the evasive": 0.0016182278231319793, "first 3 000": 0.0007417488271393706, "to construct a": 0.00030087107663277584, "a ga and": 0.0016182278231319793, "deciding how to": 0.0007417488271393706, "learning plus editing": 0.0008091139115659897, "implementation uses euclidean": 0.0008091139115659897, "p2 are": 0.0006131469602829721, "crosses": 0.00031473391077755725, "algorithms learning": 0.0006131469602829721, "in performance": 0.0002898046105948889, "pruning methods": 0.0011908005071032729, "a case": 0.0002174224613812204, "discrete sutton 1988": 0.0008091139115659897, "within the first": 0.0005759152096655707, "given time": 0.0003327228091591544, "81 7": 0.0005954002535516364, "single pursuer problem": 0.0008091139115659897, "problem is significantly": 0.0008091139115659897, "different sensing abilities": 0.0008091139115659897, "networks strategy generation": 0.0008091139115659897, "drops": 0.00022490585540778116, "averages": 0.0002708200979869593, "and study": 0.0004074652591731264, "control": -0.00048405650064550646, "e a pursuit": 0.0008091139115659897, "p2 individually speed": 0.0008091139115659897, "is not": 1.6899336793379442e-05, "escapes": 0.00047790004136261533, "we selected": 0.00037315955974098747, "attributes however": 0.0005954002535516364, "is relatively easy": 0.0004882999224935485, "nn to the": 0.0008091139115659897, "an example": 9.558837313491353e-05, "smoke bomb which": 0.0008091139115659897, "ga learned excellent": 0.0008091139115659897, "figure 5 combining": 0.0008091139115659897, "it substantially": 0.0006628410843555166, "rewards for some": 0.0008091139115659897, "problems can": 0.00034757605337154215, "achieved by k": 0.0008091139115659897, "more complicated task": 0.0008091139115659897, "modeled with": 0.0009765049742036323, "locates": 0.00038782718877567753, "1993 but": 0.0006131469602829721, "algorithm one": 0.00042304989757217126, "distance metrics for": 0.0016182278231319793, "needed an": 0.000567383102523159, "the potential effect": 0.0008091139115659897, "to train k": 0.0008091139115659897, "1994 describe": 0.000702264802583379, "four parameters the": 0.0007417488271393706, "difficult class of": 0.0008091139115659897, "algorithm can work": 0.0007417488271393706, "down the pedestrian": 0.0008091139115659897, "to train a": 0.002697441000706645, "game consists": 0.0007696350858963753, "until many successful": 0.0008091139115659897, "ahead of the": 0.0005456884385180774, "right to": 0.00037315955974098747, "at intermediate states": 0.0008091139115659897, "and machine": 0.0002905747481074539, "6 using": 0.00042304989757217126, "based teacher to": 0.0008091139115659897, "variance of rule": 0.0008091139115659897, "given that": 0.0002410510306265817, "2 it": 0.0002084662442079054, "difficult for": 0.0011194786792229625, "the differential game": 0.0008091139115659897, "no known": 0.0005200422895505865, "due east": 0.0007696350858963753, "selection devijver kittler": 0.0008091139115659897, "a more formal": 0.0005176213124249083, "accomplish we": 0.000702264802583379, "1991 we": 0.0005456354281782176, "correctly classified": 0.0009995304578601118, "1982 in analyzing": 0.0008091139115659897, "1992 and neural": 0.0008091139115659897, "by p players": 0.0008091139115659897, "state space contains": 0.0008091139115659897, "instance bsed learning": 0.0008091139115659897, "produce by itself": 0.0008091139115659897, "the pursuit game": 0.0016182278231319793, "a one": 0.0002134471126225199, "directions could": 0.0007696350858963753, "the turns they": 0.0008091139115659897, "reinforcement tasks has": 0.0008091139115659897, "to evaluate": 0.00017734209036133165, "and fitness values": 0.0008091139115659897, "these parameters": 0.00030112584215908326, "and evaluation": 0.0003327228091591544, "own training": 0.000702264802583379, "and gray": 0.0005803901647646488, "alone if": 0.000634859264718638, "on 100 games": 0.0008091139115659897, "that such": 0.00022321855588123063, "genetic algo": 0.0006628410843555166, "read from right": 0.0007417488271393706, "games the end": 0.0008091139115659897, "including": -2.405386802549835e-05, "examplars to bootstrap": 0.0008091139115659897, "then stored": 0.0005128077770266814, "simply as 8instance": 0.0008091139115659897, "particular we examined": 0.0008091139115659897, "shown to be": 0.000279357728231019, "common feature": 0.0005363412876789271, "a constraint": 0.0003063720986511328, "in play i": 0.0008091139115659897, "both of": 0.00021383882269906333, "was set": 0.0010720415734180625, "the literature": 0.00019196261776044306, "temporal": 0.001498870374366185, "any editing methods": 0.0008091139115659897, "and lazy learning": 0.0008091139115659897, "1992 and": 0.00044153169724958527, "nearest neighbors finally": 0.0008091139115659897, "ga by": 0.0007696350858963753, "is highly": 0.0003118921235356357, "changing strategy": 0.0007696350858963753, "the task we": 0.0007417488271393706, "valued turn": 0.0007696350858963753, "to control movement": 0.0014834976542787413, "neighbor rule stochastic": 0.0008091139115659897, "e thus": 0.0004349818647972793, "to fill in": 0.0005393947462253054, "determined simply": 0.000634859264718638, "game to the": 0.0008091139115659897, "is somewhat": 0.0003037165348615905, "that point k": 0.0008091139115659897, "those results for": 0.0007417488271393706, "probably a necessary": 0.0008091139115659897, "k nn had": 0.0008091139115659897, "deleted from": 0.00039610816435843403, "hands": 0.00039606968857753465, "by running each": 0.0007417488271393706, "the application": 0.00015609398501714912, "action pairs initially": 0.0008091139115659897, "effectively at": 0.0007696350858963753, "classified we deleted": 0.0008091139115659897, "earlier hypothesis that": 0.0008091139115659897, "been using": 0.0005456354281782176, "to 20 state": 0.0008091139115659897, "comparing the": 0.0002508495615030361, "straight ahead but": 0.0008091139115659897, "current state the": 0.0005954580987137418, "examples editing": 0.0007696350858963753, "the strongest": 0.0004288371693587632, "crossing": 0.0002985677793631863, "occurred the corresponding": 0.0008091139115659897, "neural networks tesauro": 0.0008091139115659897, "summarized in": 0.0002727971730761859, "of the algorithms": 0.0006839915309017282, "method k nearest": 0.0008091139115659897, "could perform as": 0.0008091139115659897, "control variables": 0.0005559058853301298, "it could": 0.0005591260304530555, "difficulty scaling": 0.000702264802583379, "learning called temporal": 0.0008091139115659897, "based learning tr": 0.0008091139115659897, "terms in the": 0.00038275883369467365, "700": 0.0009163494598194479, "where for": 0.00032932038867923357, "examples are": 0.0009033775264772498, "that are in": 0.00039905202450766993, "measure": 2.6057696609488038e-05, "a version": 0.00030459434776852046, "learns to play": 0.0014834976542787413, "single plan the": 0.0007417488271393706, "special": -6.710501547184021e-05, "to 0": 0.00020224300789959939, "the differential": 0.0007117858259431993, "positions p uses": 0.0008091139115659897, "identifying differences": 0.0007696350858963753, "shows performance": 0.000567383102523159, "since our approach": 0.0006069246369921007, "entertainment": 0.00044493294905444163, "k nn after": 0.0008091139115659897, "or nearly correct": 0.0008091139115659897, "two pursuers figure": 0.002427341734697969, "away indicates": 0.0007696350858963753, "a database i": 0.0008091139115659897, "conclusions this": 0.0003982790696131452, "its learned rules": 0.0008091139115659897, "cause": 0.00011840644026673537, "considered how to": 0.0007023330300003208, "on the ratio": 0.0005128575980484463, "tasks are markov": 0.0008091139115659897, "concluded was that": 0.0008091139115659897, "game guarantees": 0.0007696350858963753, "that rely on": 0.0005524148804057065, "exact match would": 0.0008091139115659897, "a classroom building": 0.0008091139115659897, "task to": 0.0003573471911393542, "robots using": 0.0006628410843555166, "2 10": 0.00032821057342992757, "to a": 4.1683344214060853e-05, "this study on": 0.0007023330300003208, "completely": 4.737282237446687e-05, "of ga teaching": 0.0008091139115659897, "way of characterizing": 0.0007417488271393706, "simple and": 0.000238123300320931, "example generator randomly": 0.0008091139115659897, "we will also": 0.00037434295450873773, "literature the": 0.0004349818647972793, "the system examines": 0.0008091139115659897, "g if": 0.0002695648787641501, "evader caught1 12334": 0.0008091139115659897, "accuracy and in": 0.0008091139115659897, "fl is": 0.00038024507112555464, "strategies for": 0.0025035827049526937, "other way around": 0.0006743602501766612, "both will learn": 0.0008091139115659897, "replicate those": 0.0007696350858963753, "g in": 0.00021946041611737508, "determining": 0.00032245756620382656, "games is": 0.0013256821687110331, "is determined": 0.0009046182653576715, "times": -7.211969374671653e-05, "this phase we": 0.0008091139115659897, "values were normalized": 0.0008091139115659897, "1963 shows that": 0.0008091139115659897, "as before the": 0.00040993954193880374, "of 52": 0.000634859264718638, "games in": 0.004539064820185272, "to turn": 0.0012691496927165137, "to take this": 0.0005954580987137418, "the large": 0.00022622594443259307, "greater than the": 0.0003256977768864979, "games possible": 0.0007696350858963753, "will require similar": 0.0008091139115659897, "additional capabilities in": 0.0008091139115659897, "hybrid approach can": 0.0008091139115659897, "with fitness": 0.0007696350858963753, "and determining": 0.00044854462015967935, "succeeds": 0.00024869125320661913, "multiedit algorithm pattern": 0.0008091139115659897, "for 20 time": 0.0008091139115659897, "powerful": 0.00011476444375656894, "perform better": 0.00036183856746138145, "for k nn": 0.006472911292527917, "and turn angle": 0.0008091139115659897, "evade a single": 0.0008091139115659897, "date": 0.00017412385966395318, "plagued by": 0.000634859264718638, "45 from": 0.0006628410843555166, "of examples is": 0.0006199211760863129, "the best": 0.0008020585115610661, "t 8s2rules strength": 0.0008091139115659897, "1989": 0.0018933107461113576, "quality": 8.944734604800586e-05, "for the cart": 0.0007023330300003208, "decision making": 0.001169589824573938, "game it turns": 0.0008091139115659897, "ga experiments in": 0.0008091139115659897, "best plan from": 0.0008091139115659897, "is presence of": 0.0008091139115659897, "of task in": 0.0008091139115659897, "this value": 0.00028529602391613707, "adopted": 0.0001899840013707754, "examples continue to": 0.0007417488271393706, "successfully evades at": 0.0008091139115659897, "competition learning": 0.000702264802583379, "temporal differences practical": 0.0008091139115659897, "considerable work has": 0.0006743602501766612, "evades two": 0.0007696350858963753, "perfectly": 0.000227516511748189, "a threshold": 0.00031379828866509775, "beginning with the": 0.0005334812968668691, "of each": 6.908259358811139e-05, "5 2 reducing": 0.0007417488271393706, "plan against a": 0.0008091139115659897, "strategy generation": 0.0007696350858963753, "networks strategy": 0.0007696350858963753, "similar game": 0.0007696350858963753, "to explore": 0.0005765613748955304, "at a": 0.00041238769389189794, "power of having": 0.0008091139115659897, "law to attempt": 0.0008091139115659897, "the algorithm": 0.0001954633371780492, "neighbors we varied": 0.0008091139115659897, "1982 in": 0.000702264802583379, "delayed reinforcement learning": 0.0016182278231319793, "we found": 0.000721673624663542, "a high level": 0.0003471669233594786, "of standard": 0.0003304421841245212, "those in which": 0.0005393947462253054, "updating": 0.00016904281997071012, "machine learning methods": 0.0006069246369921007, "actions before": 0.001269718529437276, "choice was motivated": 0.0007417488271393706, "for simple multi": 0.0008091139115659897, "pole prob lem": 0.0008091139115659897, "distinguishes": 0.0002747565959466888, "a single": 0.0005037522889723558, "indicating that": 0.0003109518286556765, "memory size": 0.0009201862149591017, "to fifty plans": 0.0008091139115659897, "nearest neighbor algorithms": 0.0013053152035409873, "valuable comments on": 0.0005279045957013737, "behaviors": 0.0004603726893900911, "we were successful": 0.0007023330300003208, "making the approach": 0.0008091139115659897, "these games smith": 0.0008091139115659897, "roll of": 0.000702264802583379, "in addition dorigo": 0.0008091139115659897, "curvature our": 0.0007696350858963753, "usually applied to": 0.0006526576017704936, "capture e or": 0.0008091139115659897, "goldberg": 0.0007837281472855552, "need": -0.00018741611189910064, "the database given": 0.0007023330300003208, "complete simulation run": 0.0008091139115659897, "perform well in": 0.0005334812968668691, "to our": 0.00015210114198964975, "three approaches": 0.00044497617160632185, "multistrategy": 0.0005127579656835996, "is difficult": 0.0004870982251337406, "so it is": 0.00035738190863582157, "problems in general": 0.0008091139115659897, "the simulated aircraft": 0.0008091139115659897, "another plateau": 0.0007696350858963753, "that one algorithm": 0.0007023330300003208, "able": -0.00020653965225201476, "stored game": 0.0007696350858963753, "ably": 0.000567327990031413, "instance": 1.3796392261110866e-05, "see section 5": 0.0004240325865444586, "task our": 0.0006131469602829721, "predicted reward": 0.0015392701717927505, "and hands": 0.0006628410843555166, "so": -0.0019121386396042665, "generated games": 0.0023089052576891257, "pursuer": 0.033009475093998084, "which compete": 0.0007696350858963753, "recently considerable work": 0.0008091139115659897, "assigned we": 0.000702264802583379, "any number of": 0.00038402039400084893, "was a lazy": 0.0008091139115659897, "discussion and": 0.00036338074496527356, "here then": 0.0005559058853301298, "algorithm embedded": 0.0007696350858963753, "e also wins": 0.0008091139115659897, "testing the plan": 0.0008091139115659897, "was 95": 0.0006628410843555166, "basic game": 0.0007696350858963753, "so does the": 0.0005039721952628732, "that is new": 0.0007417488271393706, "tasks such": 0.00040276699958546587, "were surprised": 0.0005954002535516364, "effect on": 0.0002530247819825898, "were still likely": 0.0008091139115659897, "n space denoting": 0.0008091139115659897, "degrees right the": 0.0008091139115659897, "studied here": 0.00048296474811893784, "and constraints": 0.00039610816435843403, "ga instead": 0.0007696350858963753, "to apply one": 0.0007023330300003208, "to update the": 0.00037786441809092093, "and gas we": 0.0008091139115659897, "matcher which locates": 0.0008091139115659897, "adjusted by shifting": 0.0008091139115659897, "high success rate": 0.0008091139115659897, "50 games in": 0.0008091139115659897, "91 evasion": 0.0007696350858963753, "value of": 0.0001455437171543203, "chapman 1987": 0.0007696350858963753, "the delay between": 0.0005674382257236372, "to capture e": 0.0014834976542787413, "closer examination of": 0.0006743602501766612, "level strategic guidance": 0.0008091139115659897, "performed moderately well": 0.0008091139115659897, "pedestrian traveling at": 0.0008091139115659897, "the population to": 0.0007023330300003208, "of the actions": 0.0009996275656477206, "to know": 0.00024006682541839522, "our experiments best": 0.0008091139115659897, "and competition": 0.0015392701717927505, "better than either": 0.0006743602501766612, "the evasive": 0.007696350858963751, "based": -0.0046937147000878626, "the path": 0.00021502160361016836, "dynamics of": 0.00038024507112555464, "e 25": 0.000702264802583379, "still likely to": 0.0008091139115659897, "reactive": 0.0002761008647110507, "most often the": 0.0007417488271393706, "for both": 0.00015308925641449857, "fuel": 0.0010255159313671991, "employed": 0.0001342177283211427, "one example can": 0.0008091139115659897, "running gle on": 0.0008091139115659897, "pursuer two": 0.003078540343585501, "achieve": 0.00012456001887788755, "the boundaries": 0.00032711247619841404, "the simulator to": 0.0006199211760863129, "strategy for e": 0.0007417488271393706, "on line performance": 0.0006743602501766612, "on an earlier": 0.000471675475395776, "stored at": 0.00037664034839981597, "achieved above": 0.000702264802583379, "that we adopted": 0.0007417488271393706, "overall": 2.8067052301095283e-05, "stored as": 0.0004004979458675273, "1 nn": 0.0007696350858963753, "3 performance": 0.0008197994375706445, "joint": 0.00020293944515403705, "of gll zhang": 0.0008091139115659897, "words the": 0.0002430451200871382, "simulation ran": 0.0007696350858963753, "well the agent": 0.0007417488271393706, "least some of": 0.0005674382257236372, "the threshold thus": 0.0007417488271393706, "gray": 0.00026096259056477324, "another study": 0.000634859264718638, "of planning and": 0.0008091139115659897, "approaches see": 0.000634859264718638, "plans all": 0.0007696350858963753, "game these actions": 0.0008091139115659897, "reaches some": 0.0006131469602829721, "proceeds using wilson": 0.0008091139115659897, "algorithms to differential": 0.0008091139115659897, "1992 as": 0.000634859264718638, "of the most": 0.0002911195380491245, "they use the": 0.0005083144306061808, "first algorithm adds": 0.0008091139115659897, "chess like games": 0.0008091139115659897, "performance q learning": 0.0008091139115659897, "contain": -8.733909935157048e-06, "spaces such": 0.0005803901647646488, "grab": 0.000452202474916213, "nn developed a": 0.0008091139115659897, "close enough to": 0.0005083144306061808, "learning in multi": 0.0007417488271393706, "must have": 0.0003912719745846033, "payoff used in": 0.0008091139115659897, "requirements as a": 0.0007417488271393706, "by generating ten": 0.0008091139115659897, "a rule": 0.0006724813721400439, "computed": -4.2031544493010187e-05, "right the": 0.000335054731187079, "its opponents this": 0.0008091139115659897, "a difficult": 0.00040276699958546587, "evader have different": 0.0008091139115659897, "and pole problem": 0.0008091139115659897, "did not q": 0.0008091139115659897, "playing field": 0.0007696350858963753, "these experiments indicate": 0.0007417488271393706, "plateau was maintained": 0.0008091139115659897, "murthy": 0.000452202474916213, "with applications to": 0.00035836314958925027, "no reduction in": 0.0006743602501766612, "having a teacher": 0.0007417488271393706, "a success": 0.00052785331295456, "where we": 0.00038195761600108964, "name the": 0.0003878648638474452, "state": -0.0030089154136915945, "correctly": 0.00029370526711411686, "of games is": 0.0008091139115659897, "conjunction with": 0.0005563517122117097, "neither": 9.187953736685217e-05, "performed on": 0.0002513894493847149, "euclidean n": 0.0007696350858963753, "evades at convergence": 0.0008091139115659897, "comparable": 0.00015086051772282924, "difference between": 0.00016989322833662986, "the pedestrian although": 0.0008091139115659897, "by the simulator": 0.0005954580987137418, "efficiency": 7.732463755389735e-05, "cyclic values where": 0.0008091139115659897, "key": 2.8354580724750073e-05, "assume a": 0.00025524283217824665, "either individually we": 0.0008091139115659897, "1983 demonstrated that": 0.0008091139115659897, "reference the": 0.0003982790696131452, "see sheppard": 0.0015392701717927505, "is caught a": 0.0008091139115659897, "be maximally": 0.0006131469602829721, "simultaneously chapman": 0.0007696350858963753, "we examined several": 0.0008091139115659897, "the simulation ran": 0.0008091139115659897, "limits": 0.00013776633414645854, "can think": 0.0003878648638474452, "methods directly on": 0.0008091139115659897, "the knowledge for": 0.0007417488271393706, "5 combining": 0.0006628410843555166, "non maze like": 0.0016182278231319793, "furthermore such a": 0.0006349209434580451, "of p1 and": 0.0012398423521726258, "a strategy against": 0.0008091139115659897, "reactive control task": 0.0008091139115659897, "when achieved 50": 0.0008091139115659897, "of games in": 0.0008091139115659897, "is determined using": 0.0005851984448616567, "the players and": 0.0006743602501766612, "and k nn": 0.002427341734697969, "the reward for": 0.0007023330300003208, "since training": 0.0006628410843555166, "s k": 0.00030459434776852046, "stages these": 0.000702264802583379, "receiving a reward": 0.0008091139115659897, "incorporate advice": 0.0007696350858963753, "ga alone": 0.0007696350858963753, "on random": 0.00042590150453082544, "the potential": 0.00021946041611737508, "bootstrapping idea requires": 0.0008091139115659897, "problems that arise": 0.0005596382660342995, "initializing samuel": 0.0007696350858963753, "s q": 0.0003982790696131452, "q learning s": 0.0032364556462639586, "of relevant attributes": 0.0006526576017704936, "s t": 0.0002455876065332435, "to produce": 0.0007285569224223055, "loses i": 0.0007696350858963753, "nn eventually reached": 0.0008091139115659897, "adjust its": 0.0005363412876789271, "the averages": 0.00046861672357587705, "that follows": 0.00038024507112555464, "addition": -0.0003493684084283484, "an experiment": 0.0003697942966553643, "its learning for": 0.0008091139115659897, "slowly": 0.0004463937473028437, "significantly more space": 0.0007417488271393706, "estimate of the": 0.0006542885125787377, "in particular": 0.00023150371687512354, "noughts and": 0.0007696350858963753, "to be labeled": 0.0006199211760863129, "steps and": 0.0003338822091906335, "e loses i": 0.0008091139115659897, "corresponding": -0.0007715938717420997, "a particular game": 0.0008091139115659897, "experiences for lazy": 0.0008091139115659897, "game if the": 0.0007023330300003208, "result all": 0.0005128077770266814, "all the": 4.692968823202498e-05, "robot to": 0.0023816010142065458, "a result all": 0.0005596382660342995, "in a highly": 0.0005279045957013737, "the error": 0.0002069735289986681, "90 figure 7": 0.0008091139115659897, "additional examples this": 0.0007417488271393706, "identical maneuvering and": 0.0008091139115659897, "novel": 0.00014464230613706644, "steadily until": 0.0007696350858963753, "before deciding how": 0.0008091139115659897, "harder": 0.0004300014351749534, "planning tasks": 0.000702264802583379, "for each player": 0.0014834976542787413, "strengths of the": 0.0006199211760863129, "performance when the": 0.0005393947462253054, "material is based": 0.0005596382660342995, "the experiment q": 0.0008091139115659897, "markov games as": 0.0006743602501766612, "a smoke bomb": 0.0008091139115659897, "to a set": 0.0003403281695183581, "competitive games": 0.0007696350858963753, "can learn": 0.0004731713358791195, "the bounds of": 0.0004958241803403253, "theory classifier": 0.0007696350858963753, "examines": 0.0004870509110759325, "truck backer upper": 0.0008091139115659897, "that we": 0.00011872656211723222, "only recently": 0.0004642630166224529, "of escape second": 0.0008091139115659897, "figure a": 0.000391902140873557, "learning system": 0.00048825248710181613, "by considering a": 0.000471675475395776, "surface": 0.00036608102799389977, "much better for": 0.0007023330300003208, "the ga s": 0.0016182278231319793, "for the robot": 0.0006743602501766612, "optimal strategy from": 0.0007417488271393706, "examined": 0.00014185549618976322, "action space": 0.0006628410843555166, "examples can yield": 0.0008091139115659897, "against each": 0.0005559058853301298, "strength s": 0.000702264802583379, "strength r": 0.0007696350858963753, "able to": 0.0005388114579118352, "motivated the next": 0.0008091139115659897, "catching q learning": 0.0008091139115659897, "al which": 0.0006131469602829721, "capture": 0.00045905777502627576, "of lazy": 0.0024412624355090807, "their approach": 0.000378426656892181, "the pair": 0.00025636849908832897, "however the": 8.517618470877676e-05, "91 evasion was": 0.0008091139115659897, "began": 0.0009684028674674435, "important control problems": 0.0008091139115659897, "pursuit game as": 0.0008091139115659897, "first step towards": 0.0004779929005953682, "by each action": 0.0008091139115659897, "of tomek": 0.0007696350858963753, "good examples": 0.004292028721980805, "become important for": 0.0006743602501766612, "single learning algorithm": 0.0007023330300003208, "recognition literature": 0.000702264802583379, "ga began to": 0.0008091139115659897, "experimented": 0.0005340395486196883, "the point": 0.00017734209036133165, "used for classification": 0.0006743602501766612, "the table this": 0.0005954580987137418, "a format": 0.0005456354281782176, "domains and": 0.00044497617160632185, "effect": -1.3519823564680955e-05, "relatively easy": 0.00040276699958546587, "pursuer one": 0.0007696350858963753, "figure 8": 0.00030272869983418495, "this study we": 0.00042987704457580605, "encoded using": 0.00048825248710181613, "differential equations which": 0.0006199211760863129, "task at first": 0.0008091139115659897, "frequently": 0.0005093751444795113, "figure 2": 0.00011965329439640545, "games machine": 0.0006628410843555166, "figure 4": 0.0001656264268756948, "figure 5": 0.00020270717021348322, "figure 6": 0.00013226816050562659, "figure 7": 0.00026758517117198813, "q table are": 0.0008091139115659897, "before storing": 0.000634859264718638, "ga right": 0.0007696350858963753, "each player of": 0.0008091139115659897, "learning at the": 0.0007417488271393706, "which the two": 0.0005759152096655707, "way at": 0.0005456354281782176, "bootstrapping": 0.0019116001654504613, "i": -0.007678915814377345, "three learning algorithms": 0.0008091139115659897, "modeled": 0.0004733006077971413, "well": -0.004705144074559092, "require the": 0.00023764249209833115, "some of": 0.00019224432742280021, "position in": 0.0003109518286556765, "will be incorrect": 0.0007023330300003208, "served to identify": 0.0008091139115659897, "make arbitrarily": 0.0007696350858963753, "as 50": 0.000567383102523159, "perform better examples": 0.0008091139115659897, "actions associated with": 0.0006743602501766612, "learning 93": 0.0007696350858963753, "slowly until almost": 0.0008091139115659897, "their effect": 0.0004560919846500759, "between e s": 0.0007417488271393706, "general they": 0.0005456354281782176, "increasingly": 0.0002150007175874767, "60 evasion within": 0.0008091139115659897, "that is rather": 0.0007417488271393706, "hidden state hidden": 0.0008091139115659897, "to reinforcement learning": 0.002225246481418112, "helpful teacher is": 0.0008091139115659897, "we therefore": 0.0007901144877037123, "pursuer adversely affects": 0.0008091139115659897, "could be used": 0.0003271442562893689, "method for k": 0.0007417488271393706, "store games": 0.0007696350858963753, "generate examples": 0.0007696350858963753, "simply editing would": 0.0008091139115659897, "to result": 0.00042304989757217126, "the behaviors of": 0.0005393947462253054, "other way": 0.00046009310747955083, "widrow 1987 atkeson": 0.0008091139115659897, "solving the single": 0.0008091139115659897, "sequences we too": 0.0008091139115659897, "movement neuronlike": 0.0007696350858963753, "actions taken": 0.0015182104583761672, "be to": 0.0002311124137898519, "we cannot be": 0.0006349209434580451, "primary cause": 0.000634859264718638, "i e": 0.0005671095900305804, "this probability was": 0.0008091139115659897, "lookup": 0.000560472126755868, "the agent is": 0.0005456884385180774, "from a set": 0.0007581319873936668, "severity of the": 0.0005954580987137418, "traditional game theory": 0.0008091139115659897, "1992 moore atkeson": 0.0008091139115659897, "to dynamic control": 0.0008091139115659897, "form of": 0.00035500993957195235, "agent first": 0.000702264802583379, "a common source": 0.0007417488271393706, "that gll": 0.0015392701717927505, "ga then we": 0.0008091139115659897, "out that the": 0.0003471669233594786, "represent noise tomek": 0.0008091139115659897, "as a single": 0.0003665725883340726, "will take bad": 0.0008091139115659897, "problems for this": 0.0006526576017704936, "the use of": 0.0003004800294128413, "immediately": 8.420115690328586e-05, "substantially more": 0.0004731713358791195, "intermediate level": 0.0005803901647646488, "is determined in": 0.0005759152096655707, "1 tended": 0.0007696350858963753, "operationalizes the rules": 0.0008091139115659897, "estimated the accuracy": 0.0008091139115659897, "separate reinforcement program": 0.0008091139115659897, "necessary": -7.308791325192099e-05, "likely to be": 0.0002980717900644726, "added at each": 0.0007417488271393706, "show how increasing": 0.0008091139115659897, "follow the optimal": 0.0008091139115659897, "a human teacher": 0.0007417488271393706, "had to learn": 0.0007417488271393706, "a human": 0.00036338074496527356, "as a teacher": 0.0008091139115659897, "family of problems": 0.0006743602501766612, "agent that knew": 0.0008091139115659897, "way at first": 0.0008091139115659897, "lose": 0.0002476391618188996, "learning 93 3": 0.0008091139115659897, "based on the": 0.000245053470753134, "random otherwise": 0.0007696350858963753, "averages of": 0.00046009310747955083, "approach we took": 0.0008091139115659897, "has learned": 0.0005954002535516364, "provided by storing": 0.0008091139115659897, "that the primary": 0.0005674382257236372, "would be": 0.000342742455197957, "above 45 this": 0.0008091139115659897, "one approach to": 0.00046866225128631864, "game we had": 0.0008091139115659897, "the k": 0.0008323654581859349, "to classes typically": 0.0008091139115659897, "interesting examples in": 0.0008091139115659897, "the pedestrian traveling": 0.0008091139115659897, "the q": 0.0007330739560370332, "keeps only": 0.0005954002535516364, "700 games": 0.0007696350858963753, "gll zhang": 0.0007696350858963753, "nearly perfect": 0.0005559058853301298, "game e also": 0.0008091139115659897, "the x": 0.00021946041611737508, "to demonstrate lazy": 0.0008091139115659897, "samuel to use": 0.0008091139115659897, "set with": 0.0006415126326567875, "ending when either": 0.0008091139115659897, "both in": 0.00028026328662092783, "performance of approximately": 0.0007417488271393706, "a classifier which": 0.0007417488271393706, "demonstrates": 0.0003470997896593508, "sweeping training": 0.0007696350858963753, "12334 figure 1": 0.0008091139115659897, "sharply since": 0.0007696350858963753, "least one implementation": 0.0008091139115659897, "formulation of": 0.00027748884847682954, "goldberg 1989": 0.0006628410843555166, "editing approach we": 0.0008091139115659897, "mutation": 0.0011882090657326042, "did extremely": 0.0007696350858963753, "hypothesize this": 0.0007696350858963753, "factor up": 0.000702264802583379, "demonstrated": 0.0003537780834331261, "limitations": 0.00015037298577266536, "sequential decision rules": 0.0016182278231319793, "with the car": 0.0007417488271393706, "taking a": 0.0003748850085915968, "reaching": 0.000662035776426976, "steps since": 0.0005200422895505865, "are correctly classified": 0.0007023330300003208, "x reward": 0.0007696350858963753, "0 25 this": 0.0008091139115659897, "mutation hill": 0.000702264802583379, "the 1": 0.0002481880961215303, "approximate a": 0.00048825248710181613, "were encouraging": 0.000634859264718638, "performance early": 0.0007696350858963753, "striking difference": 0.0006628410843555166, "small number": 0.000476246600641862, "algorithms most often": 0.0007417488271393706, "the state to": 0.0005851984448616567, "relevant attributes in": 0.0008091139115659897, "barto sutton watkins": 0.0008091139115659897, "figure 4 as": 0.0005456884385180774, "pursuit games table": 0.0008091139115659897, "games we therefore": 0.0008091139115659897, "this figure": 0.0006091886955370409, "game contains up": 0.0008091139115659897, "first threshold was": 0.0008091139115659897, "classic pursuit": 0.0007696350858963753, "control e the": 0.0008091139115659897, "maneuvers game we": 0.0016182278231319793, "33 n 2": 0.00048474305809383046, "1990 took": 0.0007696350858963753, "updates the database": 0.0007417488271393706, "chauffeur game": 0.003078540343585501, "following each training": 0.0008091139115659897, "task at convergence": 0.0008091139115659897, "own k": 0.000702264802583379, "the size": 0.00029265667501370755, "that accuracy decreased": 0.0008091139115659897, "to start the": 0.0004747836164770488, "converging on a": 0.0007417488271393706, "lazy learner": 0.005387445601274626, "ga on": 0.0007696350858963753, "learning to control": 0.0008091139115659897, "e to": 0.00027886722524113144, "different skills that": 0.0008091139115659897, "additional": -0.000300650416904431, "of rule strength": 0.0008091139115659897, "in which terms": 0.0007417488271393706, "this value differential": 0.0008091139115659897, "fast 6": 0.0006628410843555166, "pruning improves": 0.0007696350858963753, "achieved at": 0.0004642630166224529, "of the turns": 0.0008091139115659897, "the database is": 0.00048474305809383046, "conversely for": 0.000567383102523159, "games third": 0.0007696350858963753, "over later": 0.0007696350858963753, "set out": 0.0004938405038742361, "its turn angle": 0.0016182278231319793, "expand the capabilities": 0.0008091139115659897, "with state information": 0.0007417488271393706, "applicability of": 0.0003315762308313901, "planning and intelligent": 0.0008091139115659897, "north": 0.00025082519534844617, "solving control": 0.0007696350858963753, "the need for": 0.000270016628185254, "of temporally successive": 0.0008091139115659897, "this phase": 0.0003820967919236623, "colearning in": 0.000702264802583379, "or makes a": 0.0008091139115659897, "pursuit game our": 0.0008091139115659897, "problem of": 0.00031012029704593174, "goals": 0.000862045823657928, "evader e because": 0.0008091139115659897, "somewhat erratically but": 0.0008091139115659897, "run the": 0.0002768061441929089, "highest": 0.00026149013345933963, "complex control": 0.0009876810077484722, "he": 0.00020894735548677683, "genetic algorithms using": 0.0007417488271393706, "elements that can": 0.0005851984448616567, "gabriel dynamic": 0.0007696350858963753, "exists the predicted": 0.0008091139115659897, "are those": 0.0002530247819825898, "we must": 0.00016850602830659672, "states in the": 0.0004240325865444586, "nn had": 0.0007696350858963753, "stored the number": 0.0007417488271393706, "learning given": 0.000634859264718638, "perception and": 0.0010726825753578542, "converted": 0.0002022233631198131, "limit": 0.0001831788225611581, "et al 1991": 0.0004601378070916638, "et al 1990": 0.002051430392193785, "eight features that": 0.0008091139115659897, "searched the database": 0.0008091139115659897, "we decided": 0.00041758029726340933, "target tracking ramsey": 0.0008091139115659897, "then performance jumped": 0.0008091139115659897, "agent reinforcement learning": 0.0006743602501766612, "set to perform": 0.0007417488271393706, "therefore provided": 0.0006628410843555166, "the training data": 0.0004404523980181757, "1989 wilson": 0.0007696350858963753, "once evasion occurred": 0.0008091139115659897, "around in addition": 0.0008091139115659897, "editing method": 0.0007696350858963753, "learning did extremely": 0.0008091139115659897, "good performance above": 0.0008091139115659897, "chromosome": 0.0010911648562732532, "the control": 0.00023433161380612713, "only 500 generations": 0.0008091139115659897, "state the": 0.00022028539626754243, "85 degrees right": 0.0008091139115659897, "barto": 0.0026390102008519863, "be maximally gen": 0.0008091139115659897, "experiments using k": 0.0008091139115659897, "achieving that objective": 0.0008091139115659897, "using the same": 0.000301439879235054, "decision problems are": 0.0007023330300003208, "termination it also": 0.0008091139115659897, "points that are": 0.0009314765516297905, "in other words": 0.00019897345570576047, "multi agent": 0.0023004655373977537, "after 50": 0.0015392701717927505, "wins by": 0.0007696350858963753, "performed on the": 0.0003919402155010585, "the best performance": 0.0016463848796269642, "lazy or memory": 0.0008091139115659897, "same way": 0.00022753861360478008, "a series of": 0.0005662758940772533, "similar to explanation": 0.0008091139115659897, "movement adaptation": 0.0007696350858963753, "same system": 0.0005060701527920558, "updating mccallum": 0.0007696350858963753, "nearby states": 0.0007696350858963753, "neural net": 0.0004997652289300559, "the averaging": 0.000567383102523159, "either method": 0.0030657348014148603, "and pursuit games": 0.0008091139115659897, "can yield": 0.0004074652591731264, "we envision a": 0.0006349209434580451, "individually we": 0.0006628410843555166, "which the mapping": 0.0007417488271393706, "later we extended": 0.0008091139115659897, "work by wilson": 0.0008091139115659897, "from a human": 0.0007417488271393706, "gll performs well": 0.0008091139115659897, "s own speed": 0.0008091139115659897, "further this": 0.0005363412876789271, "neighbor second": 0.0007696350858963753, "littman": 0.0010255159313671991, "the three algorithms": 0.0005596382660342995, "reinformement learning": 0.0007696350858963753, "task with one": 0.0008091139115659897, "evasion examples figure": 0.0008091139115659897, "by a genetic": 0.0008091139115659897, "of 135": 0.0007696350858963753, "neighbor is determined": 0.0008091139115659897, "this special issue": 0.0007023330300003208, "to generate examples": 0.0008091139115659897, "differential equations": 0.0017670635747256956, "sheppard colearning in": 0.0007417488271393706, "examples that are": 0.0005954580987137418, "games of course": 0.0008091139115659897, "ramsey schultz 1990": 0.0008091139115659897, "the second": 0.00010284414949149814, "the most": 0.0004738825283579426, "dynamic": 5.4960704128260725e-05, "a hybrid": 0.0003128408899145216, "in particular had": 0.0008091139115659897, "fitness of": 0.0005363412876789271, "games the resulting": 0.0008091139115659897, "of trials": 0.0005060701527920558, "of multi": 0.000310019848849804, "game showed": 0.0007696350858963753, "uniform probability": 0.0005363412876789271, "gll remained ahead": 0.0008091139115659897, "consists": -0.00016656395696419772, "minimal size": 0.0005803901647646488, "that the ga": 0.0014834976542787413, "as the genetic": 0.0007417488271393706, "use an approach": 0.0007417488271393706, "point k nn": 0.0008091139115659897, "show the": 0.0002832785262959759, "70 and quickly": 0.0008091139115659897, "success after 50": 0.0008091139115659897, "grefenstette et al": 0.005663797380961928, "up with e": 0.0008091139115659897, "sample games": 0.0007696350858963753, "strength of a": 0.0006526576017704936, "actions associated": 0.000634859264718638, "a parallel": 0.0004932413609359984, "teaching": 0.002238739878372254, "algorithm train": 0.0007696350858963753, "to transmit examples": 0.0008091139115659897, "performing some": 0.0005128077770266814, "updated": 0.00044048707468844286, "climbing algorithms learning": 0.0008091139115659897, "poor performance on": 0.0006069246369921007, "error back": 0.000702264802583379, "memory store": 0.0006131469602829721, "have been used": 0.00033085096496788017, "escape in the": 0.0008091139115659897, "on how well": 0.0006069246369921007, "decision trees": 0.0003820967919236623, "updates": 0.00014605484458648645, "be treated": 0.00030112584215908326, "correct because of": 0.0007023330300003208, "how accuracy decreases": 0.0008091139115659897, "margin of 11": 0.0008091139115659897, "a hybrid system": 0.0006199211760863129, "loses at most": 0.0008091139115659897, "problem while a": 0.0008091139115659897, "lazy method i": 0.0008091139115659897, "skills": 0.00041491364968285823, "difficulty because": 0.000634859264718638, "1 performance": 0.00042590150453082544, "e the heart": 0.0008091139115659897, "solution": -0.0003850676472890479, "careful editing": 0.0007696350858963753, "the teacher": 0.0006131469602829721, "our case we": 0.0004779929005953682, "ga representation": 0.0007696350858963753, "vector": 1.774308975473892e-05, "differences k nn": 0.0008091139115659897, "decisions about which": 0.0008091139115659897, "indicated turns of": 0.0008091139115659897, "markov": 0.0019068497449157848, "all points": 0.0003423836492878316, "heading": 0.0008100984898353999, "that we were": 0.0006069246369921007, "typically consisted of": 0.0008091139115659897, "grefenstette ramsey schultz": 0.0008091139115659897, "o clock heading": 0.0008091139115659897, "was binary": 0.000702264802583379, "our task": 0.00042590150453082544, "5 did": 0.0007696350858963753, "of generating": 0.0003489161923333023, "the reward so": 0.0008091139115659897, "examples could be": 0.0006743602501766612, "used to learn": 0.0006199211760863129, "class of planning": 0.0007417488271393706, "learned rules": 0.0006628410843555166, "likely": 0.00011840644026673537, "learn how to": 0.0005759152096655707, "well for": 0.0003063720986511328, "for plans is": 0.0008091139115659897, "chess but despite": 0.0008091139115659897, "implemented": -1.6084969692922886e-05, "even": -0.001912873267246254, "propagation algorithm this": 0.0008091139115659897, "achieving some": 0.000634859264718638, "different learning algorithms": 0.0006743602501766612, "algorithm applies": 0.0005060701527920558, "strategy from a": 0.0008091139115659897, "set was tested": 0.0008091139115659897, "training data but": 0.0007417488271393706, "to cover": 0.0003449470981709676, "algorithm applied": 0.00044497617160632185, "direct proportion to": 0.0006526576017704936, "arbitrarily and": 0.000567383102523159, "learn to evade": 0.0008091139115659897, "performs quite": 0.0005363412876789271, "estimated the": 0.0004382027886649359, "new": -0.0010164146177863275, "net": 0.00013866592451435602, "asymptotic properties": 0.0005456354281782176, "ever": 0.00024391649793422616, "usually assume": 0.000702264802583379, "own around 45": 0.0008091139115659897, "same reason that": 0.0006526576017704936, "problems is as": 0.0008091139115659897, "level greater than": 0.0006743602501766612, "performance of percent": 0.0008091139115659897, "robot made": 0.0007696350858963753, "a certain": 0.00015584122472575893, "faced with": 0.0004382027886649359, "in many": 0.00015685490627235702, "decreases as the": 0.0004473842663752093, "strategy they": 0.0006131469602829721, "the applicability": 0.0003436573962650119, "around each 3": 0.0008091139115659897, "refined through": 0.000702264802583379, "pursuit strategies we": 0.0008091139115659897, "the other way": 0.0005393947462253054, "of planning": 0.0005559058853301298, "to q learning": 0.0008091139115659897, "100": 0.0003258163034152817, "editing to": 0.0006628410843555166, "interpret": 0.00020957743974090145, "slowly being": 0.0007696350858963753, "method for reinforcement": 0.0007417488271393706, "high level": 0.0006380023854888039, "on the current": 0.0007866458119033079, "the first 5": 0.0006349209434580451, "to a second": 0.0010558091914027474, "has been": 0.00023793716987652183, "tolerating": 0.0007330027492418862, "same in": 0.00035445902764197844, "credit": 0.0009560693198021333, "t care conditions": 0.0007417488271393706, "sequence can be": 0.0004882999224935485, "nor k nn": 0.0008091139115659897, "permit": 0.00021033758092698209, "that outperformed": 0.0007696350858963753, "experiments by": 0.00052785331295456, "be assigned": 0.00030198240340165204, "suitable": 5.7357263380268285e-05, "highest expected": 0.000702264802583379, "1 differential game": 0.0008091139115659897, "evade store": 0.0007696350858963753, "that are correctly": 0.0006743602501766612, "with the two": 0.0004221582211223312, "bounds of the": 0.00046289837369057756, "10 000 examples": 0.0007417488271393706, "our bootstrapping": 0.0015392701717927505, "plans or": 0.000634859264718638, "random the": 0.0004779464664686347, "rapidly passing k": 0.0008091139115659897, "did well": 0.000634859264718638, "a single missile": 0.0008091139115659897, "nn performed better": 0.0008091139115659897, "other areas and": 0.0008091139115659897, "reinforcement learning in": 0.0006526576017704936, "e s actions": 0.0008091139115659897, "evasion which": 0.0007696350858963753, "with each": 0.0007592756935742009, "games for k": 0.0008091139115659897, "the ga through": 0.0008091139115659897, "using knowledge": 0.0005456354281782176, "rule discovery systems": 0.0016182278231319793, "players in": 0.0011607803295292977, "novel attributes in": 0.0008091139115659897, "e example set": 0.0008091139115659897, "roll of dice": 0.0008091139115659897, "e fails": 0.000634859264718638, "call": -0.0001180237675260313, "4 1 performance": 0.0006526576017704936, "about each attribute": 0.0008091139115659897, "agent develops": 0.0007696350858963753, "which gives": 0.00030027612719626154, "type": -0.0002517074247102099, "learning assume": 0.0007696350858963753, "most common eager": 0.0008091139115659897, "the initial state": 0.0003731958134629092, "three instances indicated": 0.0008091139115659897, "and eliminates examples": 0.0008091139115659897, "p1 or p2": 0.0007417488271393706, "a task together": 0.0008091139115659897, "random factor": 0.0007696350858963753, "deterministic games such": 0.0007417488271393706, "maximum speed": 0.0006131469602829721, "differential games we": 0.0008091139115659897, "grefenstette use a": 0.0008091139115659897, "algorithms perform": 0.0004731713358791195, "for each": 0.00016039350504896315, "a game the": 0.0016182278231319793, "form into a": 0.0008091139115659897, "approach is the": 0.0004167376361167208, "the state action": 0.0008091139115659897, "tests during": 0.0007696350858963753, "solving a wide": 0.0008091139115659897, "is even possible": 0.0006526576017704936, "is probably": 0.0006873147925300238, "feature of": 0.0002621733301065935, "constant strategy the": 0.0007417488271393706, "an artifact": 0.00046861672357587705, "e might escape": 0.0008091139115659897, "very first": 0.0004938405038742361, "as grefenstette et": 0.0008091139115659897, "and suggested": 0.0005954002535516364, "backer upper": 0.0007696350858963753, "to markovian problems": 0.0008091139115659897, "directly towards": 0.000702264802583379, "relative coordinate system": 0.0008091139115659897, "simulator to a": 0.0008091139115659897, "these problems": 0.0004860902401742764, "in overall accuracy": 0.0008091139115659897, "and conclusions this": 0.0007417488271393706, "the first state": 0.0005596382660342995, "classifier in": 0.0005200422895505865, "reward the resulting": 0.0008091139115659897, "section 4 4": 0.0004319040237213277, "used q learning": 0.0008091139115659897, "state should be": 0.0007417488271393706, "the learning": 0.0020854563202292527, "speed as": 0.0005060701527920558, "be in": 0.00019163384403187916, "to use": 0.0004023656772398244, "learning watkins 1989": 0.0008091139115659897, "evasive maneuvers grefenstette": 0.0016182278231319793, "33 points the": 0.0008091139115659897, "capabilities of learning": 0.0008091139115659897, "does the": 0.0002708464065257185, "sample game in": 0.0008091139115659897, "led to": 0.00026767013033800354, "is exploring the": 0.0008091139115659897, "of the q": 0.0005083144306061808, "from achieving that": 0.0008091139115659897, "using a lazy": 0.0007417488271393706, "when either wins": 0.0008091139115659897, "of the k": 0.00035738190863582157, "back and": 0.0003839830887362287, "date little has": 0.0008091139115659897, "best learning": 0.0006628410843555166, "can solve difficult": 0.0007023330300003208, "in using a": 0.0005674382257236372, "in which a": 0.0005812059568674108, "chauffeur": 0.0031739879898075077, "instances produced": 0.0007696350858963753, "through the instance": 0.0008091139115659897, "to outperform either": 0.0008091139115659897, "on a fixed": 0.0010913768770361549, "study considered": 0.0006628410843555166, "we applied": 0.0003681525887744991, "have identical": 0.0004123948992280552, "complete sequences non": 0.0008091139115659897, "sections discuss": 0.0005954002535516364, "plan with": 0.0005954002535516364, "they addressed": 0.000702264802583379, "achieves near perfect": 0.0008091139115659897, "generating ten example": 0.0008091139115659897, "or control": 0.00044854462015967935, "attempt": 0.0001893849608596838, "third": -1.5801519744199603e-05, "to using": 0.0003489161923333023, "that measure p1": 0.0008091139115659897, "must at least": 0.0007417488271393706, "was selected arbitrarily": 0.0008091139115659897, "of pursuit": 0.000702264802583379, "climbing to modify": 0.0008091139115659897, "it toward the": 0.0007417488271393706, "in pursuit games": 0.0008091139115659897, "to study the": 0.0003331401991494251, "and after": 0.0002953154240675878, "e had to": 0.0008091139115659897, "nov dec": 0.0005954002535516364, "few as": 0.0005128077770266814, "use the": 0.00012345475809612638, "would have been": 0.0003790659936968334, "for this study": 0.0010079443905257465, "decided to take": 0.0008091139115659897, "simulator and the": 0.0012398423521726258, "this type": 0.0004658821202250575, "the evader e": 0.002427341734697969, "ga to": 0.0033142054217775822, "nn k": 0.0007696350858963753, "p will": 0.00040276699958546587, "p we cannot": 0.0008091139115659897, "technique to train": 0.0008091139115659897, "current turn": 0.0007696350858963753, "nn s": 0.0035113240129168942, "those points that": 0.0007023330300003208, "always superb": 0.0007696350858963753, "k murthy for": 0.0008091139115659897, "was not supported": 0.0007417488271393706, "class of rl": 0.0007417488271393706, "nn were": 0.0007696350858963753, "before": -0.0005229802669186793, "variations of": 0.00034112545549164767, "90 for the": 0.0007417488271393706, "a complete simulation": 0.0007417488271393706, "generate actions": 0.0007696350858963753, "at 90 to": 0.0008091139115659897, "of smoke bombs": 0.0008091139115659897, "this was not": 0.0005083144306061808, "their approach uses": 0.0008091139115659897, "player pursuit": 0.0023089052576891257, "analysis of competitive": 0.0008091139115659897, "to have the": 0.000345414170940388, "better": -0.0008941056825891067, "applicable to the": 0.000449806936615026, "a performer we": 0.0008091139115659897, "basar olsder": 0.0007696350858963753, "is performing to": 0.0008091139115659897, "1991 used": 0.0007696350858963753, "problems the two": 0.0007023330300003208, "crosses i": 0.000702264802583379, "combination": 4.976899626760552e-05, "which e": 0.0008699637295945586, "after generating the": 0.0006743602501766612, "was set at": 0.0006526576017704936, "which a": 0.00034885739219831413, "theoretically minimal": 0.0007696350858963753, "being an open": 0.0008091139115659897, "nn 5": 0.0007696350858963753, "examples and the": 0.0005759152096655707, "that assuming optimal": 0.0008091139115659897, "focused on a": 0.0006526576017704936, "niches": 0.0006347975979615015, "the capabilities": 0.0008576743387175264, "rely on": 0.0002386061189975044, "nearest neighbor rule": 0.0016182278231319793, "70 scaled": 0.0007696350858963753, "not q": 0.0006131469602829721, "a fixed": 0.0007919440682901491, "run down the": 0.0007417488271393706, "stuck forever at": 0.0008091139115659897, "1990 millan": 0.0007696350858963753, "1990 we": 0.0005954002535516364, "performing considerably poorer": 0.0008091139115659897, "time steps": 0.0013695345971513264, "learning problems by": 0.0008091139115659897, "form solutions we": 0.0008091139115659897, "some other": 0.00022535886933316643, "r is the": 0.00031098203868469185, "of traditional": 0.00042027761111456123, "successful evasion": 0.0023089052576891257, "mutation using fitness": 0.0008091139115659897, "of k nn": 0.004854683469395938, "will see": 0.00026337149590123743, "success examples": 0.0007696350858963753, "mean": 9.89182164702463e-05, "strongest examples in": 0.0008091139115659897, "games achieving 100": 0.0008091139115659897, "using a formulation": 0.0007417488271393706, "a position in": 0.0005759152096655707, "direction when": 0.0005803901647646488, "payoff received": 0.0015392701717927505, "applied what they": 0.0008091139115659897, "axis to highlight": 0.0008091139115659897, "rules by": 0.00046861672357587705, "initially it stores": 0.0008091139115659897, "reported here show": 0.0007023330300003208, "also periodically": 0.0007696350858963753, "also been studied": 0.0005759152096655707, "most likely": 0.00032711247619841404, "to stepwise forward": 0.0008091139115659897, "10 000 test": 0.0008091139115659897, "speeds and": 0.00052785331295456, "have a": 0.00011074828296794869, "which interesting examples": 0.0008091139115659897, "adaptive elements that": 0.0007417488271393706, "of actions to": 0.0006349209434580451, "in part by": 0.0005316663903757712, "algorithm this has": 0.0008091139115659897, "by taking": 0.0002311124137898519, "teacher prototype and": 0.0008091139115659897, "later the first": 0.0008091139115659897, "the pairs": 0.0007363051775489982, "the game as": 0.0007417488271393706, "would consider two": 0.0008091139115659897, "task was quite": 0.0008091139115659897, "general if low": 0.0008091139115659897, "agents are": 0.0004382027886649359, "nearly correct because": 0.0008091139115659897, "turning": 0.0002708200979869593, "linear": -5.766421638847829e-05, "to a lazy": 0.0007417488271393706, "as ours could": 0.0008091139115659897, "1992 q": 0.0007696350858963753, "of the pedestrian": 0.0008091139115659897, "profit sharing rate": 0.0008091139115659897, "we could assume": 0.0006743602501766612, "attempt to capture": 0.0006199211760863129, "approach are": 0.00039610816435843403, "maximum turn": 0.0007696350858963753, "three values were": 0.0008091139115659897, "track lin 1991": 0.0008091139115659897, "and motivate": 0.0005803901647646488, "set was": 0.00043186206685094484, "edited when": 0.000702264802583379, "they call": 0.0004938405038742361, "when read from": 0.0007417488271393706, "used a ga": 0.0016182278231319793, "each pass through": 0.0006349209434580451, "a learning rate": 0.0006743602501766612, "pairs in": 0.001109382889966093, "solving the problem": 0.0004657382758148953, "1 degree improving": 0.0008091139115659897, "starts": 8.635819149254943e-05, "estimate of": 0.0004953264369391046, "of state action": 0.0007417488271393706, "trained a ga": 0.0008091139115659897, "in the training": 0.0004382453615580345, "reward fl is": 0.0008091139115659897, "of irrelevant attributes": 0.0006743602501766612, "a teacher is": 0.0008091139115659897, "mean of their": 0.0008091139115659897, "off the results": 0.0007417488271393706, "their starting": 0.000634859264718638, "delay between taking": 0.0008091139115659897, "popular video": 0.0007696350858963753, "features": 0.00014032802300640608, "example when achieved": 0.0008091139115659897, "set of": 0.00041534661551059164, "have been generated": 0.0005226282087022614, "game called tag": 0.0008091139115659897, "the current state": 0.001081063134638264, "comparator selects": 0.000702264802583379, "begun to": 0.0005060701527920558, "each set consisted": 0.0008091139115659897, "to change": 0.00025693559916562507, "three dimensional vector": 0.0008091139115659897, "program more recently": 0.0008091139115659897, "the search space": 0.0008334752722334416, "on its very": 0.0008091139115659897, "updated based": 0.0005803901647646488, "stores in the": 0.0006349209434580451, "agent that": 0.00046009310747955083, "to evade p": 0.0008091139115659897, "implementation of this": 0.0004221582211223312, "and the sampling": 0.0007023330300003208, "order differential equations": 0.0006199211760863129, "or two": 0.00031379828866509775, "playing against one": 0.0008091139115659897, "examples with": 0.0004642630166224529, "given state depends": 0.0007417488271393706, "evolve a database": 0.0008091139115659897, "e thus we": 0.0006199211760863129, "approach might": 0.00052785331295456, "sensing abilities": 0.0015392701717927505, "assuming all": 0.0005363412876789271, "the edited": 0.000634859264718638, "to evade a": 0.0008091139115659897, "mutate": 0.0005953424196270563, "initially searches": 0.0007696350858963753, "agent to": 0.0004560919846500759, "history is significant": 0.0008091139115659897, "of a": 0.0, "centered on": 0.0009121839693001518, "will continue": 0.0003898632748579793, "from the example": 0.0005393947462253054, "of k": 0.0010801152935166094, "the initial": 0.0004919715198386885, "pursuer evasion the": 0.0008091139115659897, "well on difficult": 0.0007417488271393706, "s poor performance": 0.0006743602501766612, "somewhat": 0.00020894735548677683, "of p": 0.00029403625017513366, "only recently been": 0.0006743602501766612, "and go and": 0.0008091139115659897, "1990 and q": 0.0008091139115659897, "general class": 0.00042590150453082544, "problem the": 0.00019462362878394347, "begins": 0.00030963898272242253, "distance": 0.0005245106791610914, "also learned very": 0.0008091139115659897, "more generally strategies": 0.0008091139115659897, "s fundamental problem": 0.0008091139115659897, "3 000 games": 0.0016182278231319793, "connectionist": 0.0008898658981088833, "or perhaps": 0.00048296474811893784, "provided by": 0.0005778681066234589, "then e loses": 0.0008091139115659897, "determine optimal": 0.000567383102523159, "al 1991 that": 0.0008091139115659897, "initial state of": 0.00044501940255663815, "a mistake": 0.0004731713358791195, "pursuer game typically": 0.0008091139115659897, "for our task": 0.0006526576017704936, "positions p": 0.0005803901647646488, "get stuck forever": 0.0008091139115659897, "small in comparison": 0.0006199211760863129, "ga is": 0.000567383102523159, "the fitness": 0.0005363412876789271, "of the search": 0.00039332290595165396, "figure compares the": 0.0006349209434580451, "learning on one": 0.0008091139115659897, "both in overall": 0.0008091139115659897, "payoff to each": 0.0008091139115659897, "task to demonstrate": 0.0008091139115659897, "in success for": 0.0008091139115659897, "ga if": 0.0007696350858963753, "control the": 0.0002541283390836954, "abilities different speeds": 0.0008091139115659897, "database given that": 0.0008091139115659897, "lb i": 0.0006131469602829721, "ga in": 0.0006628410843555166, "read from": 0.00035445902764197844, "problem in": 0.00014395486319755308, "the resulting algorithm": 0.00045745222770795314, "learner by using": 0.0008091139115659897, "between p1": 0.0006628410843555166, "these pairs": 0.0004779464664686347, "littman 1994": 0.0006628410843555166, "to hide": 0.00039398316601407357, "play differential": 0.0015392701717927505, "with state y": 0.0008091139115659897, "up to": 0.0005458972063088678, "set produced": 0.0006628410843555166, "chess": 0.0017272804725259354, "extensions to the": 0.0004360863081445778, "when the": 0.00012301322942711933, "ever achieved": 0.0006628410843555166, "problem is": 0.00024109636990578718, "and d 2": 0.0004779929005953682, "that engagement": 0.0007696350858963753, "the prior state": 0.0007023330300003208, "which in this": 0.0005128575980484463, "finally tesauro": 0.0007696350858963753, "samuel with a": 0.0008091139115659897, "increasingly difficult": 0.0005456354281782176, "contains 7": 0.0006131469602829721, "non zero radius": 0.0008091139115659897, "experiments were stopped": 0.0008091139115659897, "lot and a": 0.0008091139115659897, "regular": 8.979318678556632e-05, "d 1 of": 0.0006526576017704936, "we made the": 0.0005851984448616567, "wins the game": 0.0006743602501766612, "1 respectively": 0.00035165014402826746, "algorithms and motivate": 0.0008091139115659897, "examples figure": 0.0005456354281782176, "this range measurement": 0.0008091139115659897, "game and to": 0.0008091139115659897, "algorithms that": 0.00024714075462412216, "radius circle": 0.000702264802583379, "don": 0.00019393432558271667, "observation": 4.707430607584847e-05, "had to adapt": 0.0007023330300003208, "purpose of": 0.00019768525039907866, "development of": 0.0002033187844386837, "speed reduction": 0.000702264802583379, "could assume": 0.000634859264718638, "we are": 0.00016383683600164532, "something close to": 0.0007023330300003208, "in success": 0.0006628410843555166, "points": -0.00014911394487429267, "of 90": 0.0005200422895505865, "of 97": 0.0006131469602829721, "that resulted in": 0.0006349209434580451, "conjunctive goals": 0.0015392701717927505, "a margin of": 0.0014046660600006416, "s ability": 0.0003982790696131452, "these parameters is": 0.0007023330300003208, "the winners of": 0.0007417488271393706, "dynamic environment": 0.001040084579101173, "a reinforcement learning": 0.0007417488271393706, "ending": 0.0002476391618188996, "scale is used": 0.0007023330300003208, "attempts": 0.0004132990024393757, "poor examples": 0.0007696350858963753, "1990 took advantage": 0.0008091139115659897, "caught1 12334": 0.0007696350858963753, "fi is": 0.0003436573962650119, "examples were still": 0.0008091139115659897, "correct action to": 0.0014834976542787413, "s approach": 0.00042590150453082544, "different speeds different": 0.0008091139115659897, "pair in the": 0.0005279045957013737, "a time and": 0.0004522903409367932, "4 performance of": 0.0005456884385180774, "early 1960s": 0.0007696350858963753, "took combined the": 0.0008091139115659897, "consider ably in": 0.0008091139115659897, "ga we store": 0.0008091139115659897, "step control": 0.0005803901647646488, "3 performance of": 0.0010913768770361549, "difference learning rule": 0.0008091139115659897, "70 and": 0.0005363412876789271, "its turn": 0.0012262939205659443, "is intuitive the": 0.0008091139115659897, "selected for": 0.0003423836492878316, "algorithm for solving": 0.00040357410968453735, "translating the": 0.0004731713358791195, "system in which": 0.0004548376351798251, "classifier in order": 0.0007417488271393706, "barto sutton anderson": 0.0007417488271393706, "have determined": 0.0004642630166224529, "initializing the": 0.0004997652289300559, "idea which examples": 0.0008091139115659897, "genetic algorithm ga": 0.0007417488271393706, "speed and": 0.0014352898672705006, "turn angle allowed": 0.0008091139115659897, "successfully evade and": 0.0008091139115659897, "and where the": 0.0004473842663752093, "begin the": 0.0004050885930083273, "actual surface characterizing": 0.0008091139115659897, "the pattern": 0.00032075631632839377, "done applying learning": 0.0008091139115659897, "should expand": 0.0007696350858963753, "random for a": 0.0008091139115659897, "navigate around": 0.000702264802583379, "of states to": 0.0006199211760863129, "then updates": 0.0006131469602829721, "differs from": 0.0002546842039466833, "we envision": 0.00046861672357587705, "they call a": 0.0007417488271393706, "players and ending": 0.0008091139115659897, "for the competitive": 0.0006199211760863129, "properties of": 0.0001199422963712659, "of memory even": 0.0008091139115659897, "the state": 0.002892929890076166, "bag": 0.00039606968857753465, "bad": 0.001303056618145308, "evasion the": 0.0015392701717927505, "architecture": 0.0001302392662313883, "upper bound": 0.00017328064858167062, "and in memory": 0.0007023330300003208, "game studied": 0.000702264802583379, "by specifying a": 0.0005128575980484463, "if the state": 0.0010257151960968926, "performed even better": 0.0008091139115659897, "prior to editing": 0.0008091139115659897, "reference": 6.859827704004837e-05, "turns of 90": 0.0008091139115659897, "industries but more": 0.0008091139115659897, "testing": 0.0002052532442442783, "we next": 0.0002898046105948889, "lazy test on": 0.0008091139115659897, "actions at": 0.00105570662590912, "provided examples to": 0.0007417488271393706, "classification tasks assume": 0.0008091139115659897, "decided": 0.0002080711516893155, "n state": 0.000634859264718638, "teacher or other": 0.0008091139115659897, "delayed rewards reinforcement": 0.0008091139115659897, "and it": 0.0004575367645542761, "with respect": 8.773453497863107e-05, "base by classifying": 0.0008091139115659897, "in evasion once": 0.0008091139115659897, "to converge": 0.00032495042922757434, "a highly": 0.0006586407773584671, "control values to": 0.0008091139115659897, "01": 9.790175570470561e-05, "encouraging and led": 0.0008091139115659897, "theory is an": 0.0006743602501766612, "almost perfect performance": 0.0008091139115659897, "pursuer game e": 0.0008091139115659897, "to accelerate": 0.00045224640365867626, "the following rule": 0.0004601378070916638, "for the players": 0.0014834976542787413, "artificial": 0.00017412385966395318, "of determining": 0.000310019848849804, "observation was that": 0.0007417488271393706, "state is an": 0.0005759152096655707, "for a particular": 0.00032641850536544673, "previous turn": 0.0015392701717927505, "difference learning sutton": 0.0008091139115659897, "the action comparator": 0.0016182278231319793, "its strategy": 0.0006628410843555166, "lazy": 0.01707209620677516, "using the ga": 0.0008091139115659897, "than they would": 0.0006526576017704936, "ga we developed": 0.0008091139115659897, "the pedestrian isaacs": 0.0008091139115659897, "representation and operators": 0.0007023330300003208, "objective frequently to": 0.0008091139115659897, "between the": 8.88031630971765e-05, "resulted in": 0.0006314793000835784, "and torras": 0.0007696350858963753, "is not checked": 0.0006743602501766612, "combining different machine": 0.0008091139115659897, "the capabilities of": 0.000976599844987097, "memory algorithm": 0.000634859264718638, "modeled as": 0.00028677803128412173, "maneuvering game": 0.0007696350858963753, "suggested": 0.00021871808194857568, "maneuvers": 0.008887166371461022, "from no": 0.000702264802583379, "yet are important": 0.0008091139115659897, "at least 50": 0.0006069246369921007, "moderately well and": 0.0008091139115659897, "eliminates examples that": 0.0008091139115659897, "since our": 0.0009137830433055614, "a similar game": 0.0008091139115659897, "socket to recharge": 0.0008091139115659897, "against": 0.0005690889101500989, "start of the": 0.0003815128357060037, "example this results": 0.0007417488271393706, "genetic algorithm can": 0.0016182278231319793, "to perform the": 0.00032078747889677304, "1992 moore": 0.0007696350858963753, "an empirical comparison": 0.0010558091914027474, "run genetic algorithm": 0.0008091139115659897, "adjusted by": 0.0005060701527920558, "and p2 run": 0.0008091139115659897, "than 80 evasion": 0.0008091139115659897, "eager approaches to": 0.0016182278231319793, "for future games": 0.0007417488271393706, "being outperformed": 0.0007696350858963753, "combined learning system": 0.0008091139115659897, "the highest expected": 0.0007417488271393706, "fixed minimum": 0.000702264802583379, "and provide feedback": 0.0008091139115659897, "ways for example": 0.0005851984448616567, "a result": 0.0002764578384106608, "algorithm lies in": 0.0006199211760863129, "lazy learner to": 0.0008091139115659897, "is determined similarly": 0.0008091139115659897, "many games": 0.0015392701717927505, "example standard": 0.0006628410843555166, "without significantly": 0.0005363412876789271, "on this class": 0.0007417488271393706, "at first see": 0.0008091139115659897, "algorithm ga we": 0.0008091139115659897, "significant improvement": 0.00036183856746138145, "and utgoff 1992": 0.0014834976542787413, "directly on": 0.00038024507112555464, "the results": 0.0007025798525132768, "control values": 0.0013256821687110331, "observed after comparing": 0.0008091139115659897, "time steps and": 0.0005596382660342995, "three": -0.002061577230890107, "can begin": 0.0004642630166224529, "has been done": 0.0010634803936305818, "replicate": 0.00034362401526488896, "interest": 4.856909958532185e-05, "basic": -5.4302717235880276e-05, "makes sense since": 0.0006743602501766612, "genetic algorithms to": 0.0013487205003533224, "which introduces noise": 0.0008091139115659897, "each brings": 0.0007696350858963753, "2 and the": 0.0002911195380491245, "strength for more": 0.0008091139115659897, "local models": 0.0013256821687110331, "a more general": 0.0003249819992683037, "was motivated": 0.0004779464664686347, "to characterize grefenstette": 0.0008091139115659897, "algorithm planning for": 0.0008091139115659897, "which were real": 0.0008091139115659897, "of generating a": 0.0005596382660342995, "use until many": 0.0008091139115659897, "this suggests that": 0.0003731958134629092, "john grefenstette": 0.0007696350858963753, "of standard q": 0.0008091139115659897, "exception": 0.000148919836752868, "50 plans": 0.0007696350858963753, "typical in": 0.0005200422895505865, "learning experiments": 0.000702264802583379, "a game": 0.005257411131154981, "the single pursuer": 0.002427341734697969, "same or": 0.0003898632748579793, "other in": 0.0006091886955370409, "because of": 0.0006769611152777808, "an enormous improvement": 0.0008091139115659897, "despite this": 0.00046009310747955083, "troubles we concluded": 0.0008091139115659897, "near": 0.0003550289951514199, "suppose": 7.0418166137108894e-06, "prototype and feature": 0.0007417488271393706, "were passed by": 0.0008091139115659897, "characterizing the": 0.0003697942966553643, "12334 figure": 0.0007696350858963753, "fixed speeds with": 0.0008091139115659897, "a q table": 0.0008091139115659897, "stored with almost": 0.0008091139115659897, "be solved by": 0.0003766769402922088, "with these pairs": 0.0008091139115659897, "is": 0, "ga made": 0.0007696350858963753, "it": 0, "pair that": 0.0004997652289300559, "the appropriate": 0.00017646145382793692, "the poor quality": 0.0007023330300003208, "small well chosen": 0.0008091139115659897, "shows the results": 0.0003766769402922088, "gle achieved": 0.0015392701717927505, "pairs after": 0.0007696350858963753, "in": 0, "found in": 0.000122787841394551, "a lower and": 0.0006349209434580451, "if": -0.012695951959230031, "we used": 0.0005207002624649821, "which the system": 0.0005279045957013737, "three learning approaches": 0.0008091139115659897, "approach is": 0.0002585220691746346, "al 1975 described": 0.0008091139115659897, "nn had great": 0.0008091139115659897, "of researchers atkeson": 0.0008091139115659897, "make": -0.0004813372044591588, "need for a": 0.00041851198115822714, "so we had": 0.0007417488271393706, "learning ebl": 0.0007696350858963753, "autonomous agents through": 0.0008091139115659897, "evades p we": 0.0008091139115659897, "algorithm is that": 0.0004319040237213277, "dogfighting and target": 0.0008091139115659897, "observed that reinforcement": 0.0008091139115659897, "a given generation": 0.0007417488271393706, "randomly selecting actions": 0.0008091139115659897, "players we": 0.000634859264718638, "is still inferior": 0.0008091139115659897, "difficulty here": 0.000702264802583379, "evolve": 0.000284534936779586, "holland 1989 holland": 0.0008091139115659897, "involved one agent": 0.0008091139115659897, "already exists the": 0.0007417488271393706, "an additional": 0.00019872247005095917, "increasing the difficulty": 0.0008091139115659897, "environment is difficult": 0.0008091139115659897, "clearly the power": 0.0008091139115659897, "uses a lazy": 0.0007417488271393706, "declarative": 0.00027884013760390546, "e the ability": 0.0007417488271393706, "these experiments demonstrated": 0.0007417488271393706, "perfect performance q": 0.0008091139115659897, "the predicate the": 0.0006526576017704936, "and provide": 0.0003315762308313901, "and apply": 0.00032932038867923357, "less data": 0.00052785331295456, "work well": 0.0003304421841245212, "differences practical issues": 0.0008091139115659897, "lazy learner that": 0.0008091139115659897, "cover two": 0.000702264802583379, "zigzags back": 0.0007696350858963753, "using the stored": 0.0008091139115659897, "pursuer task": 0.0069267157730673766, "uses one": 0.00044854462015967935, "instances we reset": 0.0008091139115659897, "left": -0.00010239860714071547, "only achieving around": 0.0008091139115659897, "one to": 0.0002118927759850183, "just": -5.9820835964866313e-05, "at an": 0.0002708464065257185, "that contains": 0.00023668683372858498, "algorithm ga": 0.000702264802583379, "assigned": 5.5826631812271125e-05, "on problems": 0.00048296474811893784, "identify": 5.6744189744260164e-05, "that perform well": 0.0006526576017704936, "human": 0.00016044412591167178, "the ritter method": 0.0008091139115659897, "turn a": 0.0004938405038742361, "yet": 3.3552507735920094e-05, "would frequently improve": 0.0008091139115659897, "good performance": 0.0006334479164540353, "of first": 0.0003260258433095744, "learning methods for": 0.0011703968897233135, "lose speed": 0.0007696350858963753, "specifically we wish": 0.0007023330300003208, "examples one striking": 0.0008091139115659897, "be too": 0.0003072722989859923, "been studied in": 0.0004240325865444586, "step one": 0.00048296474811893784, "nn did not": 0.0008091139115659897, "two player": 0.0019885232530665498, "rules that": 0.0007117858259431993, "examples can then": 0.0007417488271393706, "advice into": 0.0007696350858963753, "control problems plagued": 0.0008091139115659897, "store during the": 0.0007417488271393706, "selected arbitrarily": 0.0006628410843555166, "program called": 0.0005456354281782176, "for some state": 0.0014046660600006416, "the payoff function": 0.0016182278231319793, "al 1983 1990": 0.0008091139115659897, "members in": 0.00045224640365867626, "that it still": 0.0007023330300003208, "from there": 0.00044153169724958527, "moore 1990": 0.0007696350858963753, "the remainder of": 0.0004905382916143706, "several agents are": 0.0007023330300003208, "must adapt its": 0.0008091139115659897, "is a rule": 0.0005674382257236372, "bounds respectively of": 0.0007023330300003208, "characterizing these": 0.000702264802583379, "performing": 0.00044630579749388075, "actions were": 0.0012262939205659443, "perform a": 0.0002513894493847149, "were the": 0.00033865419457809065, "class of differential": 0.0016182278231319793, "each example": 0.0018570520664898116, "of course we": 0.0004473842663752093, "learning to predict": 0.0013487205003533224, "system gll because": 0.0008091139115659897, "earlier research": 0.0006628410843555166, "against itself": 0.0006628410843555166, "the ga achieved": 0.0008091139115659897, "on a": 9.851297984863495e-05, "issue for their": 0.0008091139115659897, "then compared with": 0.0006199211760863129, "dynamic environment is": 0.0007417488271393706, "led us to": 0.00048474305809383046, "deal": 7.864227018516886e-05, "obtain such": 0.0005363412876789271, "prematurely converging on": 0.0008091139115659897, "current state if": 0.0007023330300003208, "an initial database": 0.0007023330300003208, "value state i": 0.0008091139115659897, "against one": 0.001269718529437276, "produce benefits above": 0.0008091139115659897, "a classical": 0.0003449470981709676, "with its own": 0.00046866225128631864, "current state is": 0.0006069246369921007, "1989 using knowledge": 0.0008091139115659897, "parent systems": 0.0007696350858963753, "differences between the": 0.00038659182444107513, "perfectly q learning": 0.0008091139115659897, "problems the experiments": 0.0008091139115659897, "q learning by": 0.0008091139115659897, "p1 is due": 0.0008091139115659897, "with some": 0.00019196261776044306, "we explored several": 0.0008091139115659897, "examples next": 0.0007696350858963753, "ability through": 0.0007696350858963753, "strategy from": 0.0005803901647646488, "be a version": 0.0008091139115659897, "evolve a": 0.0006131469602829721, "specialized by": 0.0006131469602829721, "receiving a": 0.0003697942966553643, "lamarkian learning in": 0.0008091139115659897, "pursuer evader caught1": 0.0008091139115659897, "this rule would": 0.0007417488271393706, "considerable difficulty scaling": 0.0008091139115659897, "1975 described": 0.0007696350858963753, "moore atkeson 1993": 0.0008091139115659897, "attrib then the": 0.0008091139115659897, "rules in a": 0.0005596382660342995, "version includes": 0.000702264802583379, "k nn in": 0.0008091139115659897, "adopted in which": 0.0008091139115659897, "50 000": 0.0009765049742036323, "predicting": 0.00022235151708960437, "80 success while": 0.0008091139115659897, "using this approach": 0.0005128575980484463, "evaded p": 0.0007696350858963753, "as a markovian": 0.0008091139115659897, "q learning also": 0.0008091139115659897, "were generating bad": 0.0008091139115659897, "reduce its": 0.0004997652289300559, "in an": 6.686029247253483e-05, "and it eventually": 0.0008091139115659897, "the distance": 0.0008383911956994679, "and novel attributes": 0.0008091139115659897, "learning evasion strategies": 0.0008091139115659897, "requires rules in": 0.0008091139115659897, "both will": 0.0005954002535516364, "very high level": 0.0005851984448616567, "stored with": 0.00048296474811893784, "learning or through": 0.0008091139115659897, "first threshold": 0.0007696350858963753, "nn k nn": 0.0008091139115659897, "attrib": 0.0007021965884209132, "on neural": 0.0006628410843555166, "were allowed": 0.00048825248710181613, "higher than the": 0.0003919402155010585, "to accomplish": 0.00033865419457809065, "94 5": 0.0005954002535516364, "generator randomly": 0.0007696350858963753, "reaching a": 0.0009285260332449058, "refines": 0.0003731233130620422, "to achieve a": 0.0003554472439844678, "down": 5.0069548647158126e-05, "lies": 0.00011633833815564259, "towards a truly": 0.0008091139115659897, "to teach the": 0.0006526576017704936, "continued to": 0.00105570662590912, "refined": 0.0001912873267246254, "1992 as we": 0.0008091139115659897, "specified a range": 0.0008091139115659897, "the algorithms": 0.0006175972033211629, "and then select": 0.0006526576017704936, "learning stores examples": 0.0008091139115659897, "q learning 93": 0.0008091139115659897, "initial": -0.00031285717770978134, "maintained throughout": 0.0005803901647646488, "approximate": 6.923526339046444e-05, "which will for": 0.0008091139115659897, "here then is": 0.0007417488271393706, "right the selected": 0.0008091139115659897, "causes problems": 0.0005954002535516364, "all three": 0.00023909096676526717, "for a": 4.055431700295474e-05, "excellent strategies for": 0.0008091139115659897, "playing case": 0.0007696350858963753, "atkeson 1993 developed": 0.0008091139115659897, "was clear": 0.0005803901647646488, "devijver 1986 we": 0.0008091139115659897, "form": -0.0012028964494752857, "on having good": 0.0008091139115659897, "on which": 0.0001913059091344491, "time such an": 0.0006526576017704936, "to 20 examples": 0.0007417488271393706, "correct behavior for": 0.0008091139115659897, "selected action would": 0.0008091139115659897, "after comparing two": 0.0008091139115659897, "algorithms working": 0.0006131469602829721, "dimensional simulation": 0.000702264802583379, "question of whether": 0.000449806936615026, "sutton watkins 1990": 0.0008091139115659897, "2 the": 3.1528897366948124e-05, "the ga performs": 0.0008091139115659897, "supported as we": 0.0008091139115659897, "system to": 0.00022195263924232946, "known closed form": 0.0008091139115659897, "is added": 0.00023957786251951118, "a declarative": 0.00044854462015967935, "rithms": 0.00030368703349832073, "to handle several": 0.0007417488271393706, "limitations of lazy": 0.0008091139115659897, "bounds": 0.0002533567960695823, "mutation and": 0.0006628410843555166, "is difficult for": 0.0005674382257236372, "common eager approach": 0.0008091139115659897, "of differential": 0.00336222088891649, "a teacher or": 0.0008091139115659897, "over k": 0.0004731713358791195, "consider ably": 0.0007696350858963753, "stages": 0.0004269494982144601, "to highlight the": 0.0005393947462253054, "not have": 0.00040269230029128545, "through the use": 0.00038659182444107513, "plan determine performance": 0.0008091139115659897, "our task of": 0.0007417488271393706, "to one": 0.0002869779341392189, "its speed and": 0.0016182278231319793, "classic": 0.00026096259056477324, "single aircraft attempts": 0.0008091139115659897, "rate of 97": 0.0007023330300003208, "are in the": 0.00028705490932799915, "hoping to": 0.000634859264718638, "the strongest examples": 0.0008091139115659897, "fixed speeds": 0.0007696350858963753, "aha 1992": 0.0007696350858963753, "for p": 0.0002481880961215303, "rather than a": 0.00035168430803720827, "advice into a": 0.0008091139115659897, "g when history": 0.0008091139115659897, "affects two of": 0.0008091139115659897, "ship": 0.00046004841655118944, "the associated": 0.00022153363976495309, "database using": 0.0005128077770266814, "in which interesting": 0.0008091139115659897, "we initially implemented": 0.0008091139115659897, "search space": 0.0007033002880565349, "differential games a": 0.0008091139115659897, "nearest neighbor": 0.0059097474902111025, "would be 3": 0.0006743602501766612, "based learning ebl": 0.0008091139115659897, "using differential game": 0.0008091139115659897, "generally": 3.6168962284634534e-05, "collected many bad": 0.0008091139115659897, "here show that": 0.0006743602501766612, "games involves solving": 0.0008091139115659897, "improved efficiency": 0.0006628410843555166, "given the": 0.00045262551873611636, "demonstrate lazy": 0.0007696350858963753, "out of": 0.00016124407050793527, "around 95": 0.0007696350858963753, "is substantially": 0.00040989971878532225, "variant of standard": 0.0007023330300003208, "to a plan": 0.0007023330300003208, "the competitive": 0.00048825248710181613, "equations of the": 0.0004382453615580345, "details of": 0.0005920241856887921, "at the point": 0.00037550322647033875, "of the attribute": 0.0006069246369921007, "an attempt": 0.00032711247619841404, "t each": 0.00042590150453082544, "possible with careful": 0.0008091139115659897, "speeds different": 0.000702264802583379, "of performance the": 0.0006199211760863129, "state to": 0.0006163604600660065, "no improvement through": 0.0008091139115659897, "to develop": 0.00044728708125794416, "neighbor second lazy": 0.0008091139115659897, "frequently improve": 0.0007696350858963753, "lazy learning to": 0.0032364556462639586, "s path during": 0.0007417488271393706, "ga this": 0.0006131469602829721, "assume": -0.0005899222972697993, "agent first used": 0.0008091139115659897, "we developed": 0.00032495042922757434, "that editing the": 0.0007417488271393706, "often competing": 0.0007696350858963753, "we specified": 0.0006131469602829721, "or through 100": 0.0008091139115659897, "alone and with": 0.0008091139115659897, "which fitness": 0.0007696350858963753, "a problem": 0.00019462362878394347, "for some initial": 0.0007417488271393706, "1987 atkeson": 0.0007696350858963753, "in performance between": 0.0005759152096655707, "from a given": 0.0003919402155010585, "trajectory moore": 0.0007696350858963753, "of learning algorithms": 0.0013053152035409873, "decision problem is": 0.0005674382257236372, "p until": 0.000702264802583379, "for learning 7": 0.0008091139115659897, "could be a": 0.000449806936615026, "factor and e": 0.0008091139115659897, "performed using": 0.00035445902764197844, "t a": 0.0001818342895766069, "make a": 0.00022364354062897208, "1 700": 0.0013256821687110331, "t k": 0.0003197335749799009, "t j": 0.0002882806874477652, "learning can be": 0.0013487205003533224, "gammon backgammon s": 0.0008091139115659897, "a database full": 0.0008091139115659897, "specialized by the": 0.0007417488271393706, "game for the": 0.0007023330300003208, "technique": -4.558496018158411e-05, "amount of knowledge": 0.0006526576017704936, "experiments show": 0.00034757605337154215, "0": -0.001971551130743819, "finally": -0.00047490067753959647, "solving these games": 0.0008091139115659897, "to hit the": 0.0006743602501766612, "angle allowed": 0.0007696350858963753, "as many games": 0.0008091139115659897, "a relatively": 0.00026157905702535613, "both lazy and": 0.0008091139115659897, "to 20": 0.0007298932575768793, "approach to using": 0.0006349209434580451, "left 5 degrees": 0.0008091139115659897, "states will require": 0.0008091139115659897, "generated by setting": 0.0007417488271393706, "play the": 0.0012777045135924764, "games in particular": 0.0014834976542787413, "respectively noting": 0.0007696350858963753, "which fitness values": 0.0008091139115659897, "games of": 0.0006131469602829721, "variance of": 0.0003665369780185166, "ritter method which": 0.0008091139115659897, "genetic algorithm learns": 0.0008091139115659897, "an evasive": 0.0007696350858963753, "while the ga": 0.0016182278231319793, "9116843 and iri": 0.0008091139115659897, "of instances the": 0.0007417488271393706, "to show": 0.0001189370679850816, "we begin by": 0.0003249819992683037, "also learned": 0.0006628410843555166, "strategies in what": 0.0008091139115659897, "to control the": 0.0003634160486420408, "did": 0.0003068502477889377, "holland 1975 the": 0.0008091139115659897, "throughout training": 0.0007696350858963753, "homicidal chauffeur": 0.003078540343585501, "a chromosome": 0.000634859264718638, "its changes": 0.000702264802583379, "evasion tasks pursuer": 0.0008091139115659897, "game in a": 0.0007417488271393706, "when fleeing": 0.0007696350858963753, "the pursuers for": 0.0008091139115659897, "classification and": 0.00037664034839981597, "a data set": 0.0005039721952628732, "perceptual": 0.0006977646010449759, "examining the ability": 0.0008091139115659897, "the car": 0.004827071589110344, "to bootstrap": 0.000567383102523159, "new along with": 0.0008091139115659897, "the typical": 0.00034112545549164767, "98 and it": 0.0008091139115659897, "had great difficulty": 0.0008091139115659897, "where rules": 0.000702264802583379, "we considered how": 0.0007417488271393706, "96 9": 0.000634859264718638, "only on": 0.0001980300438984334, "has variable speed": 0.0008091139115659897, "models to control": 0.0014834976542787413, "associated with state": 0.0006743602501766612, "used to teach": 0.0008091139115659897, "with the reward": 0.0007417488271393706, "examples similar to": 0.0007417488271393706, "other examples in": 0.0007023330300003208, "adds": 0.0001573491221273818, "of rules": 0.001005164193561237, "both future": 0.000702264802583379, "but then performance": 0.0008091139115659897, "to be assigned": 0.0004919901420568756, "random locations on": 0.0007417488271393706, "pursuers k": 0.0007696350858963753, "most traditional": 0.000634859264718638, "learning with less": 0.0008091139115659897, "after 15": 0.0006628410843555166, "delayed reinformement learning": 0.0008091139115659897, "after 16": 0.000702264802583379, "been done applying": 0.0008091139115659897, "5 000 games": 0.004854683469395938, "run beginning with": 0.0008091139115659897, "several learning": 0.0007696350858963753, "rule is a": 0.0005176213124249083, "between the car": 0.0008091139115659897, "feature selection by": 0.0007417488271393706, "demonstrate the ability": 0.0007023330300003208, "by p": 0.0004658821202250575, "actions until play": 0.0008091139115659897, "random games": 0.003078540343585501, "sharpness of": 0.0005456354281782176, "each player some": 0.0008091139115659897, "the experiments with": 0.0005596382660342995, "is trying": 0.0005060701527920558, "out of fuel": 0.0008091139115659897, "by a": 6.087584808680633e-05, "below determine": 0.0007696350858963753, "dynamic noncooperative": 0.0007696350858963753, "by e": 0.0002875267402688875, "by k": 0.00030459434776852046, "traditional game": 0.0007696350858963753, "against a set": 0.0006526576017704936, "corresponding sequence of": 0.0006349209434580451, "wait": 0.00017586045852300558, "p2 ever": 0.0007696350858963753, "and atkeson 1993": 0.0008091139115659897, "all rules are": 0.0007023330300003208, "games and continued": 0.0008091139115659897, "shift": 0.0001724091647315856, "optimizing their": 0.0006628410843555166, "these games can": 0.0008091139115659897, "peak performance when": 0.0008091139115659897, "simultaneous": 0.00016467783894012493, "to improve this": 0.0005596382660342995, "amenable to this": 0.0007417488271393706, "as a result": 0.00044648048464808856, "for meta": 0.0006131469602829721, "turn angle at": 0.0016182278231319793, "not usually": 0.0004560919846500759, "a target their": 0.0008091139115659897, "turn angle as": 0.0008091139115659897, "the strength": 0.0003839830887362287, "10 22 games": 0.0008091139115659897, "even outperforms": 0.000702264802583379, "maneuvers task": 0.004617810515378251, "toe and": 0.000702264802583379, "is that": 7.819053691497116e-05, "and distance bearing": 0.0008091139115659897, "action is": 0.0007298932575768793, "algorithm takes over": 0.0007417488271393706, "differences in the": 0.0004221582211223312, "are the lower": 0.0006349209434580451, "angle which": 0.0006131469602829721, "network learning": 0.0006628410843555166, "difficult class": 0.0007696350858963753, "dimensional vector of": 0.0006349209434580451, "a learning strategy": 0.0008091139115659897, "associated with": 0.0005159448375462663, "angle allowed of": 0.0008091139115659897, "perf": 0.000567327990031413, "laws in": 0.00048296474811893784, "the cart": 0.0011908005071032729, "following sections discuss": 0.0006526576017704936, "before deciding": 0.0006628410843555166, "outperformed by": 0.0005954002535516364, "step were the": 0.0008091139115659897, "history information with": 0.0008091139115659897, "dice distinguishes it": 0.0008091139115659897, "received from": 0.00035165014402826746, "improve classification accuracy": 0.0007417488271393706, "drops below": 0.0005060701527920558, "in another study": 0.0007417488271393706, "state is within": 0.0008091139115659897, "with uniform probability": 0.0006349209434580451, "sharing": 0.00032193300472501194, "to accumulate": 0.0005363412876789271, "superficial level with": 0.0008091139115659897, "appending": 0.00038782718877567753, "der wal 1981": 0.0008091139115659897, "margin of 52": 0.0008091139115659897, "tolerating noisy using": 0.0008091139115659897, "by all of": 0.0005954580987137418, "for that sequence": 0.0006526576017704936, "by each": 0.0002481880961215303, "the action with": 0.0008091139115659897, "the starting": 0.00028383407364771163, "another possible reason": 0.0008091139115659897, "our hypothesis that": 0.0013487205003533224, "they were not": 0.0005851984448616567, "most striking": 0.0005363412876789271, "much faster than": 0.0004259428823122818, "phase approach that": 0.0008091139115659897, "to head directly": 0.0008091139115659897, "81 7 ga": 0.0008091139115659897, "100 success": 0.0007696350858963753, "making": 9.392919185154878e-05, "have identical maneuvering": 0.0008091139115659897, "games that resulted": 0.0008091139115659897, "pursuit game": 0.005387445601274626, "term game": 0.0007696350858963753, "with genetic algorithms": 0.0006526576017704936, "e tic": 0.0007696350858963753, "nearest": 0.004667607238542853, "reaching 80 evasion": 0.0008091139115659897, "is sufficient": 0.0004455901708627887, "makes a": 0.0003028459277060942, "predict": 0.0004940335168203749, "better than k": 0.0007417488271393706, "experiments were": 0.0006022516843181665, "in the literature": 0.00025051539973936805, "achieved 50": 0.0007696350858963753, "agent": 0.0035933188685417887, "this rule": 0.0006925063450175328, "sample": 0.0005718654024188584, "ended in": 0.001404529605166758, "q learning did": 0.0008091139115659897, "edited nearest": 0.0007696350858963753, "are given in": 0.0002545233354905152, "learning to produce": 0.0008091139115659897, "of 100 games": 0.0008091139115659897, "pursuit games optimal": 0.0008091139115659897, "race track": 0.0007696350858963753, "begins an": 0.000702264802583379, "were real": 0.0006628410843555166, "learn to": 0.0019117858658745388, "extreme for": 0.000702264802583379, "100 evasion": 0.0007696350858963753, "modify the": 0.00023479884997171157, "to differential games": 0.0008091139115659897, "a simplified game": 0.0008091139115659897, "game where e": 0.002427341734697969, "this credit assignment": 0.0008091139115659897, "performance this was": 0.0007417488271393706, "a lower": 0.00017971909630386932, "e the": 0.0011706267000548302, "actions were responsible": 0.0008091139115659897, "algorithms for reducing": 0.0007023330300003208, "variety of solutions": 0.0007417488271393706, "its performance we": 0.0007023330300003208, "for the eventual": 0.0007417488271393706, "sequence memory": 0.0007696350858963753, "taking an": 0.00052785331295456, "map": 9.433886102309801e-05, "their many": 0.0005200422895505865, "11 examples": 0.0006628410843555166, "differences k": 0.0007696350858963753, "was replayed": 0.0007696350858963753, "may": -0.00030368703349832073, "even simple games": 0.0008091139115659897, "othello a co": 0.0008091139115659897, "4 2 performance": 0.0005851984448616567, "designed": 5.613221329895249e-05, "p1 is": 0.0004997652289300559, "methods should": 0.0005200422895505865, "further and attempted": 0.0008091139115659897, "greater than": 0.0003096690622816534, "developing strategies for": 0.0007417488271393706, "teacher to train": 0.0008091139115659897, "also resembles": 0.000702264802583379, "game before deciding": 0.0008091139115659897, "the upper and": 0.0004404523980181757, "players follow the": 0.0008091139115659897, "lazy method such": 0.0008091139115659897, "turns of": 0.0006628410843555166, "variable to": 0.00036494662878843966, "difficulty solving the": 0.0008091139115659897, "the memory store": 0.0008091139115659897, "this method": 0.0001913059091344491, "experiments demonstrate": 0.0014647574613054484, "torras 1992 used": 0.0008091139115659897, "q": -0.0003118343727017067, "wins or loses": 0.0008091139115659897, "all three algorithms": 0.0005759152096655707, "problem much harder": 0.0008091139115659897, "of the strategy": 0.0005759152096655707, "fundamental problem": 0.0004349818647972793, "because it": 0.0004563034259689492, "basar olsder 1982": 0.0008091139115659897, "in part our": 0.0008091139115659897, "also periodically release": 0.0008091139115659897, "16 000": 0.000702264802583379, "used examples these": 0.0008091139115659897, "the pedestrian that": 0.0008091139115659897, "methods of temporal": 0.0014046660600006416, "problems studied here": 0.0007417488271393706, "instance bsed": 0.0007696350858963753, "knew the correct": 0.0008091139115659897, "developed a": 0.0005303867234581381, "controls its turn": 0.0008091139115659897, "1981 markov decision": 0.0008091139115659897, "some individual trials": 0.0008091139115659897, "of these states": 0.0005851984448616567, "match its": 0.0005954002535516364, "ga to use": 0.0008091139115659897, "differs": 0.00014940265895948467, "showed through": 0.0006628410843555166, "evasion the game": 0.0008091139115659897, "their two dimensional": 0.0007417488271393706, "through the first": 0.0006526576017704936, "nn table 1": 0.0008091139115659897, "rate our experiments": 0.0008091139115659897, "monitor": 0.00024556375149618344, "is computed as": 0.00038402039400084893, "interesting": 1.4361924114185042e-05, "this method clouse": 0.0008091139115659897, "approximately equal to": 0.0005393947462253054, "algorithm one pursuer": 0.0008091139115659897, "differences distance": 0.0007696350858963753, "class the": 0.00034112545549164767, "has been using": 0.0007417488271393706, "nn percent": 0.0007696350858963753, "of optimal": 0.000335054731187079, "of the prior": 0.0005456884385180774, "ours": 0.00019393432558271667, "games possible to": 0.0008091139115659897, "that the solution": 0.0003790659936968334, "the ga and": 0.0016182278231319793, "learner in contrast": 0.0008091139115659897, "of correctly labeled": 0.0008091139115659897, "strategy imado": 0.0007696350858963753, "will require": 0.00032821057342992757, "training since training": 0.0008091139115659897, "from wilson in": 0.0008091139115659897, "be selected with": 0.0007417488271393706, "and forth": 0.0004642630166224529, "explore our": 0.0007696350858963753, "000 examples gll": 0.0008091139115659897, "is very": 0.00012862366934550902, "the population": 0.001766126788998341, "in the same": 0.0003483153862314968, "tasks more": 0.0006628410843555166, "three learning": 0.001404529605166758, "a range about": 0.0008091139115659897, "find any": 0.0009372334471517541, "next we": 0.00020260056961542738, "by a random": 0.0005596382660342995, "editing algorithm": 0.0007696350858963753, "strategies for game": 0.0008091139115659897, "was actually": 0.0005363412876789271, "format amenable": 0.0007696350858963753, "from there it": 0.0006743602501766612, "examples these": 0.0005803901647646488, "memory based": 0.0015384233310800442, "pursuit game these": 0.0008091139115659897, "succeeded in": 0.0005363412876789271, "variation on": 0.00046009310747955083, "surpassing both": 0.0007696350858963753, "application of two": 0.0007417488271393706, "variables were": 0.0005200422895505865, "the rewards for": 0.0007417488271393706, "to learn plans": 0.0008091139115659897, "as before": 0.00021112298341276222, "a ga initially": 0.0008091139115659897, "genetic algorithms in": 0.0017555953345849704, "to the oracle": 0.0005954580987137418, "compare with the": 0.0005393947462253054, "alone this class": 0.0008091139115659897, "those in": 0.0002546842039466833, "bsed learning": 0.0007696350858963753, "empirical comparison of": 0.0010669625937337382, "distances are": 0.0005060701527920558, "can reduce": 0.0002921317927643509, "attributes to use": 0.0008091139115659897, "catch applying nearest": 0.0008091139115659897, "the future location": 0.0008091139115659897, "and the lethal": 0.0008091139115659897, "ability of an": 0.0006743602501766612, "rule stochastic dynamic": 0.0008091139115659897, "which e succeeded": 0.0008091139115659897, "through a": 0.00057985861179218, "done to": 0.0007267614899305471, "dasarathy": 0.000567327990031413, "and ending": 0.00039398316601407357, "number of": 9.804645564720463e-05, "own likewise": 0.0007696350858963753, "3 of": 0.0002455876065332435, "to editing": 0.000702264802583379, "to the best": 0.0007052243195203462, "are refined": 0.0005363412876789271, "actions later and": 0.0008091139115659897, "to guide a": 0.0007023330300003208, "sensor": 0.00026214786402304745, "correct": 0.00020363127917662495, "the data the": 0.0004360863081445778, "halt learning after": 0.0008091139115659897, "is within the": 0.00048474305809383046, "after": -0.002906834315635248, "figure 1 we": 0.0003892305354108736, "teaching k nn": 0.0008091139115659897, "between states": 0.00045224640365867626, "or other": 0.0005955338704062307, "real valued turn": 0.0008091139115659897, "these techniques the": 0.0006526576017704936, "mechanisms": 0.00013074506672966981, "constraint therefore we": 0.0008091139115659897, "state of": 0.0004940815091962074, "to near perfect": 0.0008091139115659897, "fl is a": 0.0005176213124249083, "learned to a": 0.0008091139115659897, "nn 5 1": 0.0008091139115659897, "grant nos iri": 0.0008091139115659897, "3 o": 0.0005456354281782176, "demonstrate lazy learning": 0.0008091139115659897, "will show we": 0.0006743602501766612, "show the ga": 0.0008091139115659897, "rules in the": 0.0004779929005953682, "sejnowski": 0.0005455824281366266, "requirements b": 0.0006131469602829721, "as classification": 0.000634859264718638, "rule stochastic": 0.0007696350858963753, "evader e the": 0.0016182278231319793, "of being good": 0.0008091139115659897, "same pursuit game": 0.0008091139115659897, "e 25 000": 0.0008091139115659897, "through 5": 0.0005060701527920558, "algorithms the": 0.00024006682541839522, "hypothesis that the": 0.0005226282087022614, "to study these": 0.0006069246369921007, "think": 0.00016360750078749084, "first": -0.006578171248013558, "p2 ever pass": 0.0008091139115659897, "that is": 6.65996525698728e-05, "that it": 0.0002069274125469662, "pattern recognition most": 0.0008091139115659897, "fleeing": 0.0007021965884209132, "which one": 0.0003128408899145216, "100 generations": 0.0006628410843555166, "in general they": 0.0006069246369921007, "learning rate if": 0.0008091139115659897, "presence of irrelevant": 0.0007417488271393706, "driver of the": 0.0006743602501766612, "fast": 1.636848798714132e-05, "nn classifier": 0.0007696350858963753, "and other topics": 0.0007417488271393706, "two problems": 0.00034757605337154215, "system examines all": 0.0008091139115659897, "using rule": 0.000634859264718638, "making in": 0.0005559058853301298, "this motivated": 0.0006131469602829721, "the result is": 0.00026916714655292177, "basically keeps": 0.0007696350858963753, "little": 9.653939030700799e-05, "non maze": 0.0015392701717927505, "approach using": 0.000391902140873557, "angle defined": 0.000702264802583379, "even better": 0.000391902140873557, "combined strategy where": 0.0008091139115659897, "to solve our": 0.0006069246369921007, "of the pairs": 0.0010558091914027474, "when two": 0.0003315762308313901, "e or": 0.0004004979458675273, "process might": 0.000634859264718638, "solve k": 0.000702264802583379, "database later": 0.0007696350858963753, "play i": 0.0007696350858963753, "planning tasks in": 0.0007417488271393706, "watkins q learning": 0.0008091139115659897, "pursuers in fact": 0.0008091139115659897, "of problems called": 0.0007417488271393706, "solve a": 0.0003315762308313901, "also been": 0.00024714075462412216, "course we are": 0.0006349209434580451, "based learning": 0.0030768466621600883, "despite this additional": 0.0008091139115659897, "1988 as": 0.0006628410843555166, "was an": 0.0003697942966553643, "continuous": 0.0003787699217193676, "flattened out peak": 0.0008091139115659897, "penalty for that": 0.0008091139115659897, "position of": 0.0002541283390836954, "for nearest": 0.0005456354281782176, "because lazy learning": 0.0008091139115659897, "ace ase with": 0.0008091139115659897, "call this": 0.0002546842039466833, "however because": 0.0003260258433095744, "run out of": 0.0006069246369921007, "selects the": 0.00035589291297159965, "algorithm using samuel": 0.0008091139115659897, "editing examples provided": 0.0008091139115659897, "cancel out": 0.0005128077770266814, "agent has to": 0.0006199211760863129, "centered on the": 0.001104829760811413, "11": -0.0005291140782211406, "10": -0.0027982946204598157, "13": -0.00020957743974090145, "condensed nearest neighbor": 0.0008091139115659897, "15": -0.00036608102799389977, "can also periodically": 0.0008091139115659897, "ones for": 0.00042590150453082544, "16": -0.00014652860552152888, "know which": 0.0003982790696131452, "applied what": 0.0007696350858963753, "ga and k": 0.0008091139115659897, "sets of": 0.0001357738039274401, "by traveling straight": 0.0008091139115659897, "version of q": 0.0014834976542787413, "to each player": 0.0008091139115659897, "to a classifier": 0.0007417488271393706, "were": -0.003780674120880367, "90 figure": 0.0006628410843555166, "learning complex": 0.0007696350858963753, "editing examples": 0.0007696350858963753, "the ga on": 0.0008091139115659897, "ga for evasive": 0.0008091139115659897, "the study": 0.0002558042537419382, "the first learner": 0.0008091139115659897, "topics": 0.0002476391618188996, "nn was having": 0.0008091139115659897, "of problem": 0.0003338822091906335, "using samuel": 0.0007696350858963753, "predicate the": 0.0005060701527920558, "to escape in": 0.0008091139115659897, "variables correspond": 0.0006628410843555166, "other words": 0.00015111956082571626, "knowledge base": 0.0004123948992280552, "follow a": 0.0003820967919236623, "editing the example": 0.0008091139115659897, "they make": 0.00046861672357587705, "the previous work": 0.0004548376351798251, "when using the": 0.00042031844251562157, "000 examples one": 0.0008091139115659897, "efficient": -5.9203220133367686e-05, "search through": 0.0004642630166224529, "size training": 0.000702264802583379, "potential": 4.588240339370516e-05, "converged": 0.0006456019116449623, "performance": -0.003177674625678569, "game theory to": 0.0008091139115659897, "success stored games": 0.0016182278231319793, "adaptive control": 0.0011607803295292977, "was selected": 0.00044153169724958527, "finding a": 0.00025636849908832897, "201": 0.00029691465080304623, "key idea behind": 0.0006743602501766612, "another editing method": 0.0008091139115659897, "motivate the": 0.0003714629793944916, "problem requires": 0.0004731713358791195, "track": 0.00014139585245160095, "friedman": 0.00036334544814691844, "dorigo and": 0.000702264802583379, "game contains": 0.0007696350858963753, "strengths of": 0.0004560919846500759, "rules called classifiers": 0.0008091139115659897, "friedman 1971 3": 0.0008091139115659897, "50 000 examples": 0.0014834976542787413, "1991 we experimented": 0.0008091139115659897, "pair": -2.252401237232038e-06, "we are building": 0.0006349209434580451, "approach and": 0.00028456257763219726, "other members": 0.0004997652289300559, "learn better": 0.000702264802583379, "sutton": 0.001808809899664852, "of moves where": 0.0008091139115659897, "and other": 0.00033371896193400683, "surprising": 0.00035880444580774077, "nos iri": 0.0007696350858963753, "easy to": 0.00010522756574844889, "at developing": 0.0005803901647646488, "run the ga": 0.0008091139115659897, "5 combining the": 0.0008091139115659897, "produced a": 0.0004349818647972793, "examples for lazy": 0.0008091139115659897, "editing and after": 0.0008091139115659897, "because it evaluates": 0.0008091139115659897, "approach can of": 0.0008091139115659897, "we should": 0.00024977745859821677, "superb exceeding the": 0.0008091139115659897, "a different approach": 0.00042987704457580605, "to make a": 0.000345414170940388, "for the poor": 0.0006526576017704936, "show": -0.0018131189062862586, "the pairs in": 0.0012138492739842013, "s performance": 0.0020934971539998135, "performance flattened": 0.0007696350858963753, "from the beginning": 0.00044270962419637705, "threshold": 0.0009273053905283274, "learn evasion tactics": 0.0008091139115659897, "player pursuit games": 0.002427341734697969, "results of temporally": 0.0008091139115659897, "sufficient to": 0.0004300432072203367, "recent work": 0.0003037165348615905, "store games in": 0.0008091139115659897, "dice": 0.0005953424196270563, "reward for state": 0.0008091139115659897, "for two pursuer": 0.0008091139115659897, "to catch a": 0.0008091139115659897, "remained ahead": 0.0007696350858963753, "set of discrete": 0.0005954580987137418, "enough": -3.942232162707948e-06, "the database that": 0.0005674382257236372, "algorithms to compare": 0.0008091139115659897, "utgoff": 0.001583406120511192, "two lazy methods": 0.0016182278231319793, "as follows where": 0.0012502129083501626, "with each plan": 0.0007417488271393706, "alternation": 0.0004004590436872584, "lazy learning approach": 0.004045569557829949, "sensor readings": 0.0006628410843555166, "during testing": 0.0004938405038742361, "of this type": 0.0003802820132290351, "get": -2.405386802549835e-05, "that simply editing": 0.0008091139115659897, "the two learners": 0.0007417488271393706, "complex solving the": 0.0008091139115659897, "simulator and": 0.000946342671758239, "an adaptation": 0.0004288371693587632, "our current": 0.0003177175902857743, "work this": 0.00037664034839981597, "nearly": 0.0003883843641094428, "s asymptotic": 0.000634859264718638, "other methods directly": 0.0008091139115659897, "use a ga": 0.0007023330300003208, "conjunction": 0.0003017210354456585, "set of rules": 0.0013281288725891312, "gen": 0.00027884013760390546, "a simulated robot": 0.0007417488271393706, "that all distances": 0.0008091139115659897, "by both": 0.0006822509109832953, "learning rule watkins": 0.0008091139115659897, "data selecting": 0.000702264802583379, "indeed the ga": 0.0008091139115659897, "e the initial": 0.0007023330300003208, "yield": 0.00016864276445969448, "learning selecting typical": 0.0008091139115659897, "speed to the": 0.0007417488271393706, "simple and depends": 0.0008091139115659897, "storing many bad": 0.0008091139115659897, "make it": 0.00025357520810241374, "gammon": 0.0011906848392541126, "to accelerate it": 0.0008091139115659897, "games table": 0.0007696350858963753, "measure p1": 0.000702264802583379, "gas we observed": 0.0008091139115659897, "well chosen": 0.0005559058853301298, "optimize competing": 0.0007696350858963753, "started slowly": 0.0007696350858963753, "occurred after": 0.000702264802583379, "pursuer task is": 0.0016182278231319793, "changes of direction": 0.0007417488271393706, "escape is": 0.0006628410843555166, "it was rare": 0.0008091139115659897, "reward at the": 0.0008091139115659897, "set of differential": 0.0006526576017704936, "relative": 2.2530260378960393e-05, "on how": 0.0002558042537419382, "pursuer task in": 0.0008091139115659897, "self learning": 0.000702264802583379, "performed using a": 0.0005596382660342995, "escape in": 0.0007696350858963753, "all of players": 0.0008091139115659897, "lazy or": 0.000702264802583379, "rate 0 1": 0.0008091139115659897, "for lazy learning": 0.0032364556462639586, "supported in part": 0.0002775158074633715, "harder unlike": 0.0007696350858963753, "are known": 0.00022492770365485792, "yielded the best": 0.0006526576017704936, "the pursuer has": 0.0008091139115659897, "we can also": 0.0003067011091234993, "a helpful": 0.001904577794155914, "reducing memory size": 0.0016182278231319793, "label": 0.00015381975734280533, "boundaries": 0.00015037298577266536, "behind": 0.00013911764076789997, "continues until termination": 0.0016182278231319793, "most commonly in": 0.0008091139115659897, "of 97 98": 0.0008091139115659897, "fact it": 0.0003197335749799009, "learning 7 next": 0.0008091139115659897, "rule for the": 0.0005279045957013737, "for algorithm gll": 0.0008091139115659897, "is determined simply": 0.0007023330300003208, "1 state 1": 0.0008091139115659897, "parent": 0.00019870316723696684, "for the problems": 0.0005176213124249083, "plan consists of": 0.0008091139115659897, "examine the frequency": 0.0008091139115659897, "from right": 0.00046861672357587705, "two player pursuit": 0.002427341734697969, "studied the": 0.00030459434776852046, "algorithms can": 0.0006005522543925231, "games as": 0.0017862007606549094, "games at": 0.0007696350858963753, "for deriving strategies": 0.0008091139115659897, "of nearest": 0.00052785331295456, "formulate markov decision": 0.0008091139115659897, "we studied tends": 0.0008091139115659897, "by the reinforcement": 0.0008091139115659897, "is not usually": 0.0005954580987137418, "evasive maneuvers lazy": 0.0008091139115659897, "examines the": 0.000378426656892181, "having a fixed": 0.0006069246369921007, "for 20 times": 0.0008091139115659897, "differential equations learning": 0.0008091139115659897, "begin with a": 0.00041159621990674106, "player learning to": 0.0008091139115659897, "to highlight": 0.00044153169724958527, "there it": 0.0005456354281782176, "considered an": 0.0004349818647972793, "capture another i": 0.0008091139115659897, "nn performed": 0.0015392701717927505, "20 rules are": 0.0008091139115659897, "there is": 2.1059556998699127e-05, "at least one": 0.00019441863565199553, "task grefenstette": 0.0007696350858963753, "earlier hypothesis": 0.0007696350858963753, "and for some": 0.0005083144306061808, "being outperformed by": 0.0008091139115659897, "it evaluates 50": 0.0008091139115659897, "reason for the": 0.00042031844251562157, "is learning most": 0.0008091139115659897, "maintained": 0.0001498870374366185, "the game then": 0.0016182278231319793, "tomek 1976 modified": 0.0008091139115659897, "to include a": 0.0004919901420568756, "neural networks strategy": 0.0008091139115659897, "cancel": 0.00031473391077755725, "pursuer has variable": 0.0008091139115659897, "particular we": 0.00041919559784973394, "values where": 0.0005128077770266814, "considering": 3.967803263549106e-05, "of actions possibly": 0.0008091139115659897, "third traditional eager": 0.0008091139115659897, "have determined the": 0.0006199211760863129, "a robot": 0.001892685343516478, "capable": 0.00036485430844420633, "for example": 0.00016270727524310302, "difficult problems this": 0.0008091139115659897, "examples in the": 0.002389964502976841, "pursuer and the": 0.0008091139115659897, "catch applying": 0.0007696350858963753, "are exploring": 0.0005200422895505865, "was correctly classified": 0.0007417488271393706, "it passes": 0.00048296474811893784, "given state": 0.0004642630166224529, "described above and": 0.0005176213124249083, "game and h": 0.0008091139115659897, "describes how": 0.0003681525887744991, "include such simple": 0.0008091139115659897, "version of optimal": 0.0008091139115659897, "maneuvers task grefenstette": 0.0008091139115659897, "possible reason for": 0.0014046660600006416, "based control a": 0.0008091139115659897, "single aircraft": 0.0007696350858963753, "differential strategies with": 0.0008091139115659897, "gave the evader": 0.0008091139115659897, "imado": 0.0007021965884209132, "its batteries below": 0.0008091139115659897, "is hard": 0.000310019848849804, "random games one": 0.0008091139115659897, "it with": 0.0002558042537419382, "80 this": 0.0007696350858963753, "be solved using": 0.00048474305809383046, "neighbors k": 0.000702264802583379, "field of differential": 0.0008091139115659897, "combined learning": 0.000702264802583379, "in what": 0.00027612768624444016, "to obtain": 0.00010318896750925328, "examples to k": 0.002427341734697969, "those": -0.0010594475304833268, "task of learning": 0.0012698418869160901, "thus making the": 0.0006349209434580451, "threshold our experiments": 0.0008091139115659897, "stochastic component": 0.0007696350858963753, "pair s": 0.00044153169724958527, "several methods for": 0.0006349209434580451, "has begun": 0.0005060701527920558, "are dependent": 0.00042590150453082544, "comparing one and": 0.0008091139115659897, "game in which": 0.0007023330300003208, "still play": 0.0006628410843555166, "programming learning": 0.000702264802583379, "margin": 0.0006676995553974513, "considering a differential": 0.0008091139115659897, "during that generation": 0.0008091139115659897, "they lose speed": 0.0008091139115659897, "markovian decision": 0.0006628410843555166, "neighbor rules": 0.0007696350858963753, "eventually": 0.0003883843641094428, "characteristics": 9.718435723615092e-05, "grefenstette 1994": 0.0007696350858963753, "many successful examples": 0.0008091139115659897, "of the current": 0.0005487309125612286, "and pursue": 0.0006628410843555166, "examples in a": 0.0013487205003533224, "1992 the advantages": 0.0008091139115659897, "part by the": 0.00035168430803720827, "path finding": 0.0011607803295292977, "generate actions randomly": 0.0008091139115659897, "through 100": 0.000702264802583379, "different": -0.00196329000944989, "nn s fundamental": 0.0008091139115659897, "dynamic noncooperative game": 0.0008091139115659897, "until it reaches": 0.0004998137828238603, "where performance remained": 0.0008091139115659897, "poor performance is": 0.0006743602501766612, "same": -0.0048055085242471015, "learning complex control": 0.0008091139115659897, "100 games figure": 0.0008091139115659897, "problems by using": 0.0006743602501766612, "perhaps it": 0.0005954002535516364, "q learning uses": 0.0008091139115659897, "evasion occurred": 0.0007696350858963753, "the number": 0.00021651427360780209, "extended": -3.500653860740964e-05, "noise tomek 1976": 0.0008091139115659897, "which searched the": 0.0008091139115659897, "section 4": 5.936328105861611e-05, "section 5": 8.399177309583478e-05, "assist": 0.0006108996398796318, "neighbor percent": 0.0007696350858963753, "10 33": 0.0006628410843555166, "1975 the": 0.000634859264718638, "such a helpful": 0.0008091139115659897, "a truly": 0.00048825248710181613, "running": 8.938776505993754e-05, "pedestrian the pedestrian": 0.0008091139115659897, "the action associated": 0.0008091139115659897, "climbing": 0.0007756543775513551, "recently been": 0.0003859053049699601, "and games increased": 0.0008091139115659897, "achieved better than": 0.0008091139115659897, "that follows when": 0.0008091139115659897, "out peak": 0.0007696350858963753, "actions possibly": 0.0007696350858963753, "for multi": 0.0003072722989859923, "rule that": 0.0008699637295945586, "k nn 96": 0.0008091139115659897, "of games": 0.0016677176559903894, "roughly": 0.00011204217902080954, "now see profound": 0.0008091139115659897, "figure 4 performance": 0.0005851984448616567, "the car and": 0.002225246481418112, "solve": 0.0002645925482804818, "how two learning": 0.0008091139115659897, "interpolation so that": 0.0007417488271393706, "anticipate the": 0.0005363412876789271, "neighbor algorithm k": 0.0008091139115659897, "consisted": 0.0008763102500387261, "by the": 1.2389514337488974e-05, "1 lazy q": 0.0008091139115659897, "learning watkins": 0.0007696350858963753, "model how": 0.000634859264718638, "theta 10 33": 0.0008091139115659897, "learning algorithms in": 0.0013053152035409873, "a process of": 0.0005039721952628732, "and the": 0.0, "we too": 0.0007696350858963753, "ga performs": 0.0007696350858963753, "will be unable": 0.0006526576017704936, "quite well as": 0.0007417488271393706, "next section 4": 0.0004919901420568756, "described below": 0.0002831104418951413, "which e evades": 0.0008091139115659897, "attribute bounds": 0.0007696350858963753, "difference methods": 0.0004642630166224529, "evasion the state": 0.0008091139115659897, "threshold was": 0.0016090238630367814, "for plans": 0.000702264802583379, "along with the": 0.0003135086419505659, "computed as": 0.00026157905702535613, "question of how": 0.0004548376351798251, "when the experiments": 0.0008091139115659897, "to provide these": 0.0006743602501766612, "at most": 0.00011974079430072804, "j is": 0.0002893127145290653, "maximum q value": 0.0008091139115659897, "td methods usually": 0.0008091139115659897, "ahead of": 0.0003982790696131452, "throughout a": 0.0005559058853301298, "4": 0, "points the": 0.0002898046105948889, "algorithms in multi": 0.0006526576017704936, "though much better": 0.0008091139115659897, "using a form": 0.0006349209434580451, "rule and oe": 0.0008091139115659897, "difference learning on": 0.0008091139115659897, "produced by the": 0.0003249819992683037, "architecture should": 0.000702264802583379, "learning how": 0.000634859264718638, "grefenstette use": 0.0007696350858963753, "such approach": 0.00052785331295456, "course be applied": 0.0008091139115659897, "have on their": 0.0008091139115659897, "well chosen set": 0.0008091139115659897, "not checked for": 0.0008091139115659897, "method such": 0.00044497617160632185, "success in addition": 0.0008091139115659897, "railroad": 0.0005127579656835996, "have minimized": 0.000634859264718638, "climbing algorithms": 0.000702264802583379, "with respect to": 0.00013959777109763885, "comparison with k": 0.0007417488271393706, "of percent success": 0.0008091139115659897, "network millan and": 0.0008091139115659897, "when fleeing two": 0.0008091139115659897, "identifying": 0.00015940505074087255, "utgoff 1992 except": 0.0008091139115659897, "antecedent and": 0.0005954002535516364, "by specifying": 0.0003489161923333023, "facing": 0.0007146249607748444, "frequently modeled": 0.0007696350858963753, "td gammon backgammon": 0.0008091139115659897, "problem has no": 0.0006526576017704936, "either": -0.001296136184074903, "mapping from": 0.00031379828866509775, "where the": 0.00012920754851869468, "served": 0.0002574805727462202, "then communicate": 0.000702264802583379, "solutions we illustrated": 0.0008091139115659897, "are less": 0.0002905747481074539, "competing control": 0.0007696350858963753, "required for learning": 0.0007023330300003208, "system in": 0.00020586573444038764, "in real euclidean": 0.0008091139115659897, "algorithms have been": 0.0003593539089640634, "can adjust its": 0.0007417488271393706, "performance after": 0.0012262939205659443, "is the profit": 0.0008091139115659897, "learning v 33": 0.0007417488271393706, "is as learning": 0.0008091139115659897, "one evader a": 0.0008091139115659897, "of this special": 0.0006349209434580451, "around each": 0.0005128077770266814, "specified": 2.6344398503953476e-05, "a lazy variant": 0.0016182278231319793, "set consisted": 0.0005456354281782176, "used to successfully": 0.0007023330300003208, "difference learning tesauro": 0.0008091139115659897, "have good": 0.00048825248710181613, "theoretical work by": 0.0008091139115659897, "solving this": 0.00039398316601407357, "learning agent": 0.000634859264718638, "the ga so": 0.0008091139115659897, "gave e the": 0.0008091139115659897, "phase of": 0.000851502220943135, "the limitations": 0.00035882246681762515, "learning agent first": 0.0008091139115659897, "action spaces": 0.000702264802583379, "a superficial level": 0.0008091139115659897, "evade in": 0.0007696350858963753, "that studies the": 0.0007417488271393706, "if the distance": 0.0005759152096655707, "2 also": 0.00035882246681762515, "algorithm in addition": 0.0006349209434580451, "games but then": 0.0016182278231319793, "position and generate": 0.0008091139115659897, "previous turn 90": 0.0008091139115659897, "each action": 0.0004642630166224529, "is that the": 0.0001776541794077676, "uses a form": 0.0007417488271393706, "each": -0.020732132269191815, "was superior": 0.000634859264718638, "examples decreases with": 0.0008091139115659897, "placements of all": 0.0008091139115659897, "one or two": 0.0003905762619993037, "evasion performance remained": 0.0008091139115659897, "p even the": 0.0008091139115659897, "system would consider": 0.0007417488271393706, "remaining examples": 0.000634859264718638, "above 95 with": 0.0008091139115659897, "7 ga": 0.0007696350858963753, "finding in": 0.0012262939205659443, "it finds in": 0.0007023330300003208, "algorithms that lazy": 0.0008091139115659897, "euclidean distance": 0.0003982790696131452, "while the": 0.0002575670087254897, "learned much": 0.0007696350858963753, "sutton anderson 1983": 0.0007417488271393706, "that is considered": 0.0006199211760863129, "develops": 0.00031669319339377555, "evaluate performance": 0.000567383102523159, "practical": 2.6506686343218516e-05, "typically gas use": 0.0008091139115659897, "networks barto": 0.0007696350858963753, "feature selection": 0.00042590150453082544, "1994 describe an": 0.0008091139115659897, "analyzing this game": 0.0008091139115659897, "problems widrow 1987": 0.0016182278231319793, "by shifting it": 0.0007417488271393706, "noisy irrelevant": 0.0007696350858963753, "provides the theoretically": 0.0008091139115659897, "is also capable": 0.0006349209434580451, "action and receiving": 0.0008091139115659897, "much more quickly": 0.0006526576017704936, "uses one algorithm": 0.0008091139115659897, "ship routing": 0.0007696350858963753, "requires significantly": 0.0005559058853301298, "has been performed": 0.0004882999224935485, "in performing": 0.00044497617160632185, "follows instance attrib": 0.0008091139115659897, "the history of": 0.00042987704457580605, "gammon backgammon": 0.0007696350858963753, "be 3 o": 0.0008091139115659897, "arbitrarily sharp": 0.0007696350858963753, "examples editing then": 0.0008091139115659897, "neighbor applications that": 0.0008091139115659897, "game over": 0.000702264802583379, "with the highest": 0.0007866458119033079, "while a": 0.00027886722524113144, "is released": 0.00044497617160632185, "resulting set": 0.0004731713358791195, "while e": 0.0005559058853301298, "resulting system gle": 0.0008091139115659897, "depends on the": 0.00019622097359821194, "was a hybrid": 0.0008091139115659897, "can develop": 0.00052785331295456, "however many": 0.0004123948992280552, "that both the": 0.0004051279487445566, "was also encouraging": 0.0008091139115659897, "having difficulty because": 0.0008091139115659897, "make it substantially": 0.0008091139115659897, "a search": 0.0003157396500417892, "separate teacher for": 0.0008091139115659897, "not one to": 0.0006743602501766612, "no way at": 0.0008091139115659897, "simulation models and": 0.0016182278231319793, "compared with": 0.00021823349779900937, "1990 can be": 0.0008091139115659897, "crosses i e": 0.0008091139115659897, "required for the": 0.000345414170940388, "nn figure": 0.0007696350858963753, "could have": 0.00029776693520311534, "we limit": 0.0003982790696131452, "to limit": 0.00033624068607002194, "of course": 0.0004698024713351916, "lookup table that": 0.0007417488271393706, "1 500 games": 0.0008091139115659897, "a separate reinforcement": 0.0008091139115659897, "itself and": 0.0003449470981709676, "be used in": 0.00023357972535372216, "the pair already": 0.0008091139115659897, "that contains all": 0.0005456884385180774, "to the evasive": 0.0016182278231319793, "challenging in part": 0.0008091139115659897, "pacman": 0.0007021965884209132, "passed to the": 0.0004240325865444586, "and the task": 0.0005226282087022614, "a necessary": 0.0003304421841245212, "forward selection devijver": 0.0008091139115659897, "capture in": 0.0005803901647646488, "control tasks the": 0.0008091139115659897, "range about each": 0.0008091139115659897, "extended version includes": 0.0008091139115659897, "a second algorithm": 0.0013487205003533224, "with lazy learning": 0.002427341734697969, "of success approximately": 0.0008091139115659897, "results motivated": 0.000634859264718638, "but more recently": 0.0008091139115659897, "of pairs": 0.0003327228091591544, "several goals": 0.000634859264718638, "of gll": 0.0015392701717927505, "the poor": 0.0012296991563559667, "sample with": 0.0005559058853301298, "by a small": 0.0004259428823122818, "general": -0.0013482279432434254, "is close to": 0.0003122377618813423, "case we had": 0.0007417488271393706, "examine": 9.433886102309801e-05, "in classifying the": 0.0007023330300003208, "a single learning": 0.0007417488271393706, "pursuit game is": 0.0008091139115659897, "task hoping": 0.0007696350858963753, "inferior to the": 0.0006199211760863129, "provide these examples": 0.0008091139115659897, "fill": 0.0002126468044753682, "again": -6.168079529588807e-05, "incorporate advice into": 0.0008091139115659897, "90 for": 0.000567383102523159, "consisted of randomly": 0.0008091139115659897, "the outcome": 0.0003374403959319754, "hybrid": 0.0003436846998500816, "solutions dependent": 0.0007696350858963753, "success games": 0.0007696350858963753, "pell 1993": 0.0007696350858963753, "field": 0.0002052532442442783, "learning after": 0.0023089052576891257, "passes the": 0.0007879663320281471, "it eventually": 0.0005363412876789271, "and 85": 0.000634859264718638, "e is": 0.0009581692201593957, "strategies we": 0.0004938405038742361, "the theoretically": 0.0005200422895505865, "euclidean n space": 0.0008091139115659897, "path during": 0.000567383102523159, "result was": 0.0007463191194819749, "performance of q": 0.0008091139115659897, "players we can": 0.0007417488271393706, "s strategy is": 0.0006349209434580451, "combining eager": 0.0007696350858963753, "deriving": 0.00020584573776875667, "performance of k": 0.004450492962836224, "important": -0.00041195531869101654, "the 85 range": 0.0008091139115659897, "range difference between": 0.0007417488271393706, "problems as": 0.00036338074496527356, "tackle": 0.00030024696001537796, "ga started": 0.0007696350858963753, "to approach": 0.0004382027886649359, "game was stored": 0.0008091139115659897, "learning called": 0.000702264802583379, "and aim": 0.0006628410843555166, "the game and": 0.0014834976542787413, "and the game": 0.0013487205003533224, "states and actions": 0.0007023330300003208, "in learning the": 0.0007417488271393706, "the k nearest": 0.0019579728053114812, "work together": 0.0014195140076373584, "difference methods apply": 0.0008091139115659897, "set of actions": 0.0016789147981028988, "database that": 0.00046009310747955083, "learning can": 0.0011607803295292977, "between 1": 0.0003436573962650119, "that has": 0.00014893430341662872, "algorithm and a": 0.0004882999224935485, "with some individual": 0.0008091139115659897, "resembles": 0.00030368703349832073, "in our definition": 0.0006069246369921007, "follows where": 0.001129921045199448, "of which was": 0.0006199211760863129, "starting": 2.198428165130429e-05, "reinforcement learning a": 0.0006743602501766612, "that any action": 0.0008091139115659897, "usually occurred": 0.0007696350858963753, "represent": -4.6964595925774384e-05, "credit assignment": 0.0019885232530665498, "capture another": 0.0006131469602829721, "that the resulting": 0.00036035437821275464, "game these experiments": 0.0008091139115659897, "feedback on": 0.0008637241337018897, "selects the action": 0.0008091139115659897, "to vary": 0.0003714629793944916, "experiments demonstrated": 0.0006628410843555166, "evasion instead the": 0.0008091139115659897, "storage of bad": 0.0008091139115659897, "if low 1": 0.0008091139115659897, "that action is": 0.0007417488271393706, "children": 0.0002150007175874767, "most popular": 0.0003839830887362287, "a case based": 0.0007023330300003208, "can of": 0.0005559058853301298, "demonstrated that the": 0.0005226282087022614, "points near": 0.0005200422895505865, "inside s radius": 0.0008091139115659897, "search through the": 0.0005596382660342995, "lamarkian": 0.0007021965884209132, "to navigate": 0.0009876810077484722, "up with": 0.0003054794925471542, "incorrectly classified": 0.0006131469602829721, "be percent success": 0.0008091139115659897, "it to make": 0.0006743602501766612, "000 random": 0.0005954002535516364, "all distances": 0.0005954002535516364, "solving control problems": 0.0008091139115659897, "therefore we used": 0.0006526576017704936, "to make arbitrarily": 0.0008091139115659897, "in the form": 0.0002519564065658282, "by wilson": 0.000702264802583379, "1 we use": 0.00044501940255663815, "not have to": 0.00033950437196557105, "details see sheppard": 0.0008091139115659897, "to reduce": 0.00042491778944396384, "fitness a population": 0.0008091139115659897, "in non": 0.0006978323846666046, "curves we combined": 0.0008091139115659897, "to represent the": 0.0002911195380491245, "1993 4 4": 0.0008091139115659897, "environment where": 0.00043186206685094484, "was an apparent": 0.0008091139115659897, "a fixed playing": 0.0008091139115659897, "to solve": 0.0015210114198964972, "difference": -0.00013253343171609245, "that achieved at": 0.0008091139115659897, "of storing examples": 0.0008091139115659897, "gll converged": 0.0007696350858963753, "below the threshold": 0.0006349209434580451, "distance bearing measures": 0.0008091139115659897, "solve yet are": 0.0008091139115659897, "depending on": 0.00013313751781342164, "master level": 0.0006628410843555166, "of problems": 0.0008086946362924504, "of the ten": 0.0005954580987137418, "applicable": 0.00010189254826254972, "learning rl is": 0.0008091139115659897, "still performing considerably": 0.0008091139115659897, "right away": 0.00052785331295456, "his metagamer": 0.0007696350858963753, "figure 5 sample": 0.0007417488271393706, "specifically tied to": 0.0008091139115659897, "of sharp turns": 0.0008091139115659897, "data and classifying": 0.0008091139115659897, "procedure of ritter": 0.0008091139115659897, "using local": 0.0008576743387175264, "s asymptotic performance": 0.0008091139115659897, "instance attrib": 0.0007696350858963753, "rewards reinforcement learning": 0.0008091139115659897, "self learning in": 0.0008091139115659897, "ritter": 0.0014057136141301832, "the strategy that": 0.0006743602501766612, "determine the optimal": 0.0010352426248498167, "turn sharply otherwise": 0.0008091139115659897, "zero": -0.00010239860714071547, "one pursuer game": 0.0016182278231319793, "problems the class": 0.0007417488271393706, "were dependent": 0.000634859264718638, "further": -0.0007974410037594244, "reasonably expect": 0.0006131469602829721, "millan torras": 0.0007696350858963753, "he embedded": 0.000702264802583379, "ability through the": 0.0008091139115659897, "the turn angle": 0.0008091139115659897, "on performance learning": 0.0008091139115659897, "play for p": 0.0008091139115659897, "target their approach": 0.0008091139115659897, "the ratio": 0.00022028539626754243, "k nn will": 0.0008091139115659897, "n 2 3": 0.00033085096496788017, "10 15 points": 0.0008091139115659897, "we can think": 0.0004601378070916638, "benefit from the": 0.00045745222770795314, "requires rules": 0.0007696350858963753, "and h t": 0.0006349209434580451, "attrib then": 0.0007696350858963753, "three different": 0.0002768061441929089, "population to handle": 0.0008091139115659897, "ably in": 0.0007696350858963753, "movement": 0.00044809657392201705, "at fixed speeds": 0.0008091139115659897, "control laws in": 0.0008091139115659897, "actions when": 0.0006131469602829721, "type of": 0.00038587100803652704, "learning to solve": 0.0016182278231319793, "zero basar olsder": 0.0008091139115659897, "turn randomly if": 0.0008091139115659897, "experimented with a": 0.0005334812968668691, "compilation": 0.00020882198527844928, "nn on its": 0.0016182278231319793, "component": 2.4810009680799173e-05, "6 94": 0.0006131469602829721, "of analyzing": 0.00044854462015967935, "maneuvers grefenstette": 0.0015392701717927505, "navigate the": 0.0006628410843555166, "and p2": 0.0024412624355090807, "and p1": 0.0005954002535516364, "game are": 0.0005954002535516364, "learning and sequential": 0.0007417488271393706, "the tasks are": 0.0010166288612123615, "method which": 0.000607433069723181, "a position": 0.0003423836492878316, "search": 0.00015329681870731955, "and selects": 0.0004997652289300559, "at random otherwise": 0.0008091139115659897, "new plan can": 0.0008091139115659897, "beginning exceeding": 0.0007696350858963753, "playing and other": 0.0008091139115659897, "having good": 0.000702264802583379, "called classifiers which": 0.0008091139115659897, "the task but": 0.0007023330300003208, "each pass": 0.0005060701527920558, "passes the first": 0.0008091139115659897, "are maximally general": 0.0008091139115659897, "of the data": 0.00025526762988855244, "the sample with": 0.0007417488271393706, "action to store": 0.0014834976542787413, "1994 and colombetti": 0.0008091139115659897, "theory originated in": 0.0008091139115659897, "involved one": 0.0005803901647646488, "not able to": 0.0003905762619993037, "actions with": 0.0005060701527920558, "by sampling and": 0.0007023330300003208, "play and applied": 0.0008091139115659897, "instance database the": 0.0008091139115659897, "effect from smoke": 0.0008091139115659897, "like environments": 0.0015392701717927505, "wins by successfully": 0.0008091139115659897, "population they found": 0.0008091139115659897, "exists the": 0.00038024507112555464, "their own": 0.0005691251552643945, "expected reward the": 0.0008091139115659897, "of tests": 0.00040989971878532225, "algorithm to learn": 0.0006526576017704936, "agent to apply": 0.0008091139115659897, "and sensing abilities": 0.0008091139115659897, "tesauro": 0.0028366399501570656, "playing at a": 0.0008091139115659897, "maximum q": 0.0007696350858963753, "is shifted by": 0.0007417488271393706, "e escapes": 0.0007696350858963753, "sample games where": 0.0008091139115659897, "in optimizing": 0.0005060701527920558, "more interesting we": 0.0007417488271393706, "two": 0, "worked quite well": 0.0007417488271393706, "range still an": 0.0008091139115659897, "comparing": 0.0002975371983292538, "reached approximately 95": 0.0008091139115659897, "able to replicate": 0.0007023330300003208, "1 high": 0.0005803901647646488, "grefenstette 1991": 0.0007696350858963753, "of problems frequently": 0.0008091139115659897, "problem we": 0.00020224300789959939, "least 50 evasion": 0.0008091139115659897, "equations of": 0.00032821057342992757, "achieving": 0.001119465535710044, "our implementation of": 0.0008231924398134821, "overall accuracy and": 0.0008091139115659897, "the experiments": 0.0011246385182742894, "difference algorithms are": 0.0008091139115659897, "atkeson 1990 employed": 0.0008091139115659897, "as evasive": 0.0007696350858963753, "differences practical": 0.0007696350858963753, "nn failed to": 0.0008091139115659897, "learning algorithm can": 0.0006526576017704936, "determined by the": 0.0002429012109289755, "began to improve": 0.0008091139115659897, "using simulation models": 0.0016182278231319793, "the national": 0.0002905747481074539, "particular": -0.0009471622162919805, "agent has": 0.0004779464664686347, "game the system": 0.0008091139115659897, "based method our": 0.0008091139115659897, "determined similarly": 0.0006131469602829721, "games are": 0.0017021493075694769, "genetic algorithms": 0.004750482735360393, "der": 0.00025521803928536867, "tasks has": 0.0006131469602829721, "1972 showed that": 0.0008091139115659897, "of what it": 0.0006526576017704936, "step towards": 0.0003714629793944916, "powerful combination in": 0.0008091139115659897, "2 respectively for": 0.0006349209434580451, "strategies": 0.001659724764247128, "dec": 0.00023571610137951204, "specialized": 0.00020293944515403705, "maximally gen": 0.0007696350858963753, "of accuracy outperforming": 0.0008091139115659897, "approximately 97": 0.0007696350858963753, "compare": 1.3536233211317274e-05, "approximately 95": 0.0006628410843555166, "its learning": 0.0011607803295292977, "knowledge required": 0.000702264802583379, "inflated for": 0.000702264802583379, "experimented with an": 0.0007417488271393706, "for algorithm": 0.00043186206685094484, "k nn 5": 0.0008091139115659897, "trees in using": 0.0008091139115659897, "of a given": 0.00027392272821231614, "go and has": 0.0008091139115659897, "experiments will show": 0.0007417488271393706, "minimum": 6.757866165209442e-06, "found they were": 0.0008091139115659897, "learner needs": 0.000634859264718638, "sharp": 0.0005195796058503163, "theory with": 0.00048296474811893784, "penalty for": 0.00039398316601407357, "p2 are much": 0.0008091139115659897, "using fitness": 0.0007696350858963753, "needs": 1.0992140825652145e-05, "all distances are": 0.0008091139115659897, "1983 1990": 0.0007696350858963753, "superior to q": 0.0008091139115659897, "level above": 0.0006628410843555166, "gas use rules": 0.0008091139115659897, "a ga this": 0.0008091139115659897, "was rare in": 0.0008091139115659897, "in rule discovery": 0.0016182278231319793, "sequence of": 0.0005326796454137717, "attempted to reduce": 0.0006743602501766612, "followed by": 0.000178822766106048, "a powerful combination": 0.0007417488271393706, "learning control": 0.0006628410843555166, "hypothesis that": 0.0010720415734180625, "search optimization and": 0.0006526576017704936, "prioritized sweeping training": 0.0008091139115659897, "comments on an": 0.0004882999224935485, "al 1990 we": 0.0008091139115659897, "amenable to": 0.00035165014402826746, "advice": 0.0006456019116449623, "and ship": 0.000702264802583379, "were normalized": 0.0005803901647646488, "modified the standard": 0.0008091139115659897, "that any": 0.00018491587490180968, "action are": 0.000634859264718638, "context of": 0.00016631492403302914, "to cause": 0.0003839830887362287, "problems better than": 0.0008091139115659897, "and to determine": 0.0005674382257236372, "along with": 0.0002033187844386837, "problems for": 0.0005522553724888803, "also has": 0.0005378593376444504, "taken in": 0.0003260258433095744, "individual trials": 0.000702264802583379, "the start": 0.00024977745859821677, "k nearest neighbors": 0.0035727485922824515, "examples thus": 0.0007696350858963753, "minimal size training": 0.0008091139115659897, "backgammon program": 0.0007696350858963753, "complicated predator": 0.0007696350858963753, "after comparing": 0.000702264802583379, "selection by sampling": 0.0007417488271393706, "were extreme": 0.0007696350858963753, "been no turn": 0.0008091139115659897, "playing": 0.0022450761186975617, "most often": 0.0003982790696131452, "if a": 6.972071413848937e-05, "1 700 examples": 0.0016182278231319793, "generation select best": 0.0008091139115659897, "93 evasion": 0.0007696350858963753, "if e": 0.0006499008584551487, "been performed": 0.0003462531725087664, "if k": 0.00029135044701075676, "alone demonstrating how": 0.0008091139115659897, "any lazy": 0.0007696350858963753, "algorithm learns": 0.0006628410843555166, "of hidden state": 0.0008091139115659897, "then be converted": 0.0007023330300003208, "through": -0.0014247020326187897, "within which the": 0.0005596382660342995, "finding in non": 0.0016182278231319793, "a new set": 0.0004319040237213277, "to navigating a": 0.0008091139115659897, "as a performer": 0.0008091139115659897, "25": -0.000120879252890063, "experiment q learning": 0.0008091139115659897, "20": -0.0011752779062308568, "21": -7.996680341923815e-05, "22": -8.330950921753584e-05, "we observed": 0.0003118921235356357, "further to": 0.00048296474811893784, "point the second": 0.0007417488271393706, "found that": 0.0006333689502382867, "learning occurs": 0.0006628410843555166, "if e is": 0.0004473842663752093, "method for": 0.0003720651934649094, "standard ga representation": 0.0008091139115659897, "pedestrian although the": 0.0008091139115659897, "initializing": 0.0006977646010449759, "using a temporal": 0.0007417488271393706, "1994 in the": 0.0006743602501766612, "called temporal": 0.000702264802583379, "set out to": 0.0005954580987137418, "play the game": 0.0014834976542787413, "good": -0.0004050201277145396, "test on 100": 0.0008091139115659897, "aha and salzberg": 0.0008091139115659897, "was maintained throughout": 0.0008091139115659897, "10 15": 0.0003859053049699601, "encouraging": 0.0005549237894551691, "several learning algorithms": 0.0008091139115659897, "applied to control": 0.0007417488271393706, "as editing methods": 0.0008091139115659897, "reinforcement learning rl": 0.0007023330300003208, "in performing the": 0.0006069246369921007, "the payoff received": 0.0016182278231319793, "co adaptive genetic": 0.0008091139115659897, "usually assume that": 0.0008091139115659897, "as learning to": 0.0008091139115659897, "pursuer evader b": 0.0008091139115659897, "update the estimates": 0.0008091139115659897, "generated by": 0.00015111956082571626, "requires several steps": 0.0008091139115659897, "evade": 0.0038087855877690095, "issues in temporal": 0.0014834976542787413, "comparing learning": 0.000702264802583379, "a reinforcement": 0.001904577794155914, "payoff for": 0.000702264802583379, "consequent are": 0.000702264802583379, "tasks in addition": 0.0007023330300003208, "an additional 5": 0.0007023330300003208, "minimized the": 0.0004731713358791195, "on the 1": 0.0005759152096655707, "examples such a": 0.0008091139115659897, "nn it": 0.0007696350858963753, "is that both": 0.0005456884385180774, "first see section": 0.0008091139115659897, "sheppard colearning": 0.000702264802583379, "hard": 5.0972620846019654e-05, "idea": -3.3795390568440644e-05, "to evade in": 0.0008091139115659897, "1989 holland": 0.0007696350858963753, "10 success": 0.000702264802583379, "combined system reaches": 0.0008091139115659897, "hart": 0.00041491364968285823, "for more details": 0.0007441230060993622, "strength for": 0.001404529605166758, "100 success in": 0.0008091139115659897, "and computing": 0.000335054731187079, "after any number": 0.0007417488271393706, "random sets of": 0.0006743602501766612, "5b for a": 0.0008091139115659897, "on the two": 0.0028037579892472827, "game the dynamics": 0.0008091139115659897, "gll converged to": 0.0008091139115659897, "that involved": 0.0005559058853301298, "positions develop": 0.0007696350858963753, "at a high": 0.0005039721952628732, "then to turn": 0.0008091139115659897, "study considered approaches": 0.0008091139115659897, "the database later": 0.0008091139115659897, "learners": 0.0004004590436872584, "a similar fashion": 0.0004779929005953682, "evaluation": 9.862692493387353e-06, "then uses and": 0.0008091139115659897, "based teacher": 0.0007696350858963753, "at a superficial": 0.0008091139115659897, "pass through the": 0.0004657382758148953, "starts performing": 0.000702264802583379, "on the x": 0.0004548376351798251, "000 games and": 0.002427341734697969, "backer": 0.000567327990031413, "additional examples": 0.0006131469602829721, "difficulty": 0.0012238401396515875, "problems plagued by": 0.0008091139115659897, "upper and lower": 0.00036136475461896376, "means that the": 0.0002537839367108705, "members": 0.0003600034590079319, "section 3": 5.476451966410896e-05, "beginning": 0.00026112327087614447, "constructing a": 0.0003118921235356357, "ga for": 0.0012262939205659443, "the ga for": 0.0007023330300003208, "at fixed": 0.0005060701527920558, "paper also thanks": 0.0007417488271393706, "benefits": 0.00015837342863484787, "learning algorithms most": 0.0008091139115659897, "increasing the": 0.0002240700519004841, "own after": 0.0007696350858963753, "of e are": 0.0005524148804057065, "the complete game": 0.0016182278231319793, "examines all of": 0.0007417488271393706, "evader has a": 0.0008091139115659897, "approach to machine": 0.0007417488271393706, "reached almost perfect": 0.0008091139115659897, "conducted": 0.00017586045852300558, "another editing": 0.0007696350858963753, "with only": 0.0005016991230060722, "pedestrian although": 0.0007696350858963753, "curvature of": 0.00046009310747955083, "a high success": 0.0008091139115659897, "allowed of": 0.0006628410843555166, "4 as with": 0.0007023330300003208, "learning a": 0.0012014938376025818, "generations for": 0.000634859264718638, "rules we": 0.0004004979458675273, "actions two": 0.0015392701717927505, "in order": 9.74472385404858e-05, "approach can": 0.00028903995093373133, "learning k": 0.001269718529437276, "instances": 0.0006745718049680679, "learning v": 0.0003898632748579793, "learning ctr john": 0.0008091139115659897, "done": -0.00023791098953084307, "85 range still": 0.0008091139115659897, "noisy using": 0.0007696350858963753, "had difficulty achieving": 0.0008091139115659897, "the boundaries between": 0.0005674382257236372, "be generated": 0.0002513894493847149, "random games every": 0.0008091139115659897, "game including": 0.0007696350858963753, "a genetic": 0.003950724030993889, "clock the": 0.0005128077770266814, "success rate on": 0.0016182278231319793, "examples that": 0.001175706422620671, "determining the optimal": 0.0005674382257236372, "smoother": 0.00033862129956161867, "of a rule": 0.000471675475395776, "when several agents": 0.0008091139115659897, "construct": 1.4083633227421779e-05, "recognizing the": 0.00048296474811893784, "characterize": 0.00016959819790576504, "take turns": 0.0006131469602829721, "level equal to": 0.0008091139115659897, "problems learning and": 0.0007417488271393706, "will show": 0.0002115072724598256, "from the ga": 0.0007417488271393706, "s 1968": 0.0007696350858963753, "this sequence can": 0.0007417488271393706, "that are within": 0.0006199211760863129, "stored where a": 0.0008091139115659897, "we made": 0.00037315955974098747, "the same in": 0.00039472486509154587, "s poor": 0.000634859264718638, "it improves": 0.00046009310747955083, "random action": 0.0007696350858963753, "are important": 0.00030198240340165204, "then we": 0.00011147481947740276, "environments learning sequential": 0.0008091139115659897, "in our case": 0.0003316084445913076, "bootstrapping nearest": 0.0007696350858963753, "part": -0.0005510653365858342, "very first set": 0.0008091139115659897, "generator randomly selecting": 0.0008091139115659897, "the first algorithm": 0.0009202756141833276, "when several": 0.0004642630166224529, "below a minimum": 0.0008091139115659897, "or better": 0.0003982790696131452, "believe": 9.433886102309801e-05, "discuss the details": 0.0005954580987137418, "produce better solutions": 0.0008091139115659897, "b": 0, "for predicting": 0.0004149539560409001, "95 with some": 0.0008091139115659897, "cyclic": 0.00020882198527844928, "and we also": 0.0004813101872060044, "strategic guidance": 0.0007696350858963753, "games suggest": 0.0007696350858963753, "it turns out": 0.0003141498861200171, "each clause": 0.0004642630166224529, "as we": 0.0002097106910317121, "ten experiments": 0.0013256821687110331, "aerial dogfighting": 0.0007696350858963753, "4 comparing one": 0.0008091139115659897, "ones i e": 0.0006526576017704936, "treated": 0.00011165652219179202, "86 evasion": 0.0007696350858963753, "each plan consists": 0.0008091139115659897, "ga 99 6": 0.0008091139115659897, "a prespecified trajectory": 0.0008091139115659897, "resulting joint system": 0.0008091139115659897, "with a population": 0.0007417488271393706, "a non zero": 0.0004278905317797242, "algorithm at": 0.0003859053049699601, "be a powerful": 0.0005674382257236372, "was tested": 0.00044854462015967935, "algorithm as": 0.00026157905702535613, "a temporal": 0.000391902140873557, "and e at": 0.0008091139115659897, "the players must": 0.0007417488271393706, "results led": 0.0007696350858963753, "confirms": 0.0002905465232654813, "recognition most commonly": 0.0008091139115659897, "paths": 8.364632460408693e-05, "together to": 0.0011194786792229625, "90 degrees": 0.0005803901647646488, "depending": 2.548462986571064e-05, "rate on their": 0.0008091139115659897, "ran ten": 0.0007696350858963753, "difficulty of the": 0.0010913768770361549, "explore our hypothesis": 0.0008091139115659897, "the combined system": 0.0012698418869160901, "members of": 0.00028677803128412173, "program to monitor": 0.0008091139115659897, "recently considerable": 0.0007696350858963753, "pacman and much": 0.0008091139115659897, "we formulate markov": 0.0008091139115659897, "i e example": 0.0008091139115659897, "solved by": 0.0002603999475929679, "wilson s approach": 0.0007417488271393706, "discussion and conclusions": 0.0005674382257236372, "behavior for": 0.0003423836492878316, "with which the": 0.0004259428823122818, "controls only": 0.0007696350858963753, "1990 watkins": 0.0007696350858963753, "a new": 0.00010588377810090795, "the lower": 0.00016631492403302914, "reset the": 0.0004779464664686347, "these results motivated": 0.0007417488271393706, "select the": 0.0002689296688222252, "achieve a level": 0.0007417488271393706, "game pacman": 0.0007696350858963753, "most": -0.0026701977430984417, "all rules": 0.0009765049742036323, "significant": 2.6506686343218516e-05, "the resulting system": 0.0004882999224935485, "studied tends": 0.0007696350858963753, "extremely": 0.00024555182891024924, "study these": 0.0005128077770266814, "actual payoff": 0.0007696350858963753, "algorithm embedded in": 0.0008091139115659897, "evades a single": 0.0008091139115659897, "in the pattern": 0.0005596382660342995, "kd": 0.00039606968857753465, "tactics while": 0.0007696350858963753, "distributions of games": 0.0008091139115659897, "if low": 0.0005803901647646488, "nn by": 0.000702264802583379, "q learning on": 0.0008091139115659897, "of examples required": 0.0007417488271393706, "small number of": 0.0005672397541634788, "learners would assist": 0.0008091139115659897, "evasive maneuvers game": 0.002427341734697969, "two pursuers": 0.0069267157730673766, "of the large": 0.0004339731734948358, "particularly": 7.699628712063898e-05, "bomb which introduces": 0.0008091139115659897, "system can": 0.0002603999475929679, "pursuer problem previous": 0.0008091139115659897, "games such": 0.0011908005071032729, "almost immediately": 0.0011908005071032729, "steps they": 0.000702264802583379, "converge": 0.00017412385966395318, "solve a markov": 0.0008091139115659897, "the driver": 0.0004997652289300559, "find": -0.0002579660529630613, "for a sample": 0.0005954580987137418, "this additional complexity": 0.0008091139115659897, "we reset the": 0.0007417488271393706, "showed through his": 0.0008091139115659897, "real valued": 0.00034757605337154215, "of the first": 0.00021637053021847865, "as 50 games": 0.0008091139115659897, "studied by a": 0.0006349209434580451, "a lazy version": 0.0016182278231319793, "movement neuronlike adaptive": 0.0008091139115659897, "conjunctive goals training": 0.0008091139115659897, "experiments also": 0.0004997652289300559, "optimal strategies for": 0.0029669953085574826, "instead the algorithm": 0.0007023330300003208, "these examples illustrate": 0.0006743602501766612, "alone this paper": 0.0008091139115659897, "and receiving a": 0.0006349209434580451, "goals simultaneously chapman": 0.0008091139115659897, "8": -0.0007330027492418862, "this algorithm further": 0.0008091139115659897, "grefenstette s": 0.0007696350858963753, "system examines": 0.0007696350858963753, "in the table": 0.0003180818046332927, "had considerable": 0.000702264802583379, "modified accounted": 0.0007696350858963753, "parameters one for": 0.0008091139115659897, "games littman": 0.0007696350858963753, "described further in": 0.0007417488271393706, "though small in": 0.0008091139115659897, "is passed to": 0.00048474305809383046, "classifying the sample": 0.0008091139115659897, "1987 as": 0.0007696350858963753, "action associated": 0.0007696350858963753, "most frequently": 0.0004382027886649359, "neuronlike adaptive": 0.000702264802583379, "learning by": 0.0009659294962378757, "games figure": 0.000702264802583379, "as editing occurred": 0.0008091139115659897, "target their": 0.000702264802583379, "is facing e": 0.0008091139115659897, "generating the": 0.00031379828866509775, "plan determine": 0.0007696350858963753, "learning s performance": 0.002427341734697969, "include such": 0.00052785331295456, "action to train": 0.0008091139115659897, "literature e g": 0.0005456884385180774, "algorithm that lazy": 0.0008091139115659897, "details see": 0.00040276699958546587, "1993 developed": 0.001404529605166758, "separate teacher": 0.0007696350858963753, "corresponding sequence": 0.0005559058853301298, "reinformement learning problems": 0.0008091139115659897, "common": -0.00011288434172167143, "if smoke is": 0.0008091139115659897, "controls only its": 0.0008091139115659897, "of one": 0.00013248506752184532, "or p2 ever": 0.0008091139115659897, "two classes to": 0.0008091139115659897, "strategy to": 0.0003898632748579793, "be found": 0.00012505676244030083, "turns out": 0.00023020870590980126, "learning it passes": 0.0008091139115659897, "and its success": 0.0008091139115659897, "net in which": 0.0007417488271393706, "tended": 0.00034621953936913463, "competition learning to": 0.0007417488271393706, "forth or": 0.0007696350858963753, "and other areas": 0.0007417488271393706, "making when": 0.0007696350858963753, "individual": 4.262179967175568e-05, "nn expects each": 0.0008091139115659897, "random mutation": 0.000702264802583379, "were not": 0.0004995549171964335, "success rate above": 0.0008091139115659897, "be seeded into": 0.0008091139115659897, "the editing": 0.0022236235413205193, "direction when fleeing": 0.0008091139115659897, "much more complicated": 0.0005083144306061808, "must at": 0.000634859264718638, "showed good performance": 0.0007417488271393706, "the game it": 0.0008091139115659897, "earlier draft": 0.0005128077770266814, "dorigo 1994 describe": 0.0008091139115659897, "not one": 0.00042590150453082544, "convergence we considered": 0.0008091139115659897, "system centered": 0.000702264802583379, "it also": 0.00038065417395113867, "continuous state space": 0.0013053152035409873, "000 games 320": 0.0008091139115659897, "called td": 0.0007696350858963753, "correctly labeled": 0.0007696350858963753, "nn failed": 0.0007696350858963753, "0 is given": 0.0005039721952628732, "space but instead": 0.0008091139115659897, "seeded": 0.0004997166844687707, "that accuracy": 0.0005803901647646488, "in solving the": 0.0004747836164770488, "clock heading": 0.0007696350858963753, "plotted against the": 0.0005596382660342995, "the actions taken": 0.0005851984448616567, "optimizing their often": 0.0008091139115659897, "points near the": 0.0006199211760863129, "aircraft": 0.0007604162723975637, "figure compares": 0.0005803901647646488, "99 6 94": 0.0008091139115659897, "implementation of q": 0.0014834976542787413, "popular temporal difference": 0.0008091139115659897, "encapsulate": 0.0003602843725054768, "must have a": 0.0007605640264580702, "obtain such a": 0.0006199211760863129, "different types of": 0.0006839915309017282, "is relatively simple": 0.0006069246369921007, "calculated by running": 0.0008091139115659897, "produce learning curves": 0.0008091139115659897, "we should reasonably": 0.0008091139115659897, "see profound": 0.0007696350858963753, "connectionist approach to": 0.0014834976542787413, "editing gll performs": 0.0008091139115659897, "result all rules": 0.0008091139115659897, "for planning": 0.0005363412876789271, "rather than rule": 0.0007417488271393706, "hypothesis was not": 0.0007417488271393706, "demonstrates that": 0.0006898941963419351, "a closer examination": 0.0006349209434580451, "rl is": 0.000567383102523159, "train a": 0.0023215606590585953, "states to a": 0.0007417488271393706, "homogenous region the": 0.0008091139115659897, "point": -0.0010551627511380338, "simple": -0.0011056551636051762, "train k": 0.000702264802583379, "then to train": 0.0007417488271393706, "reinforcement learning": 0.009275802279029698, "80 85 then": 0.0008091139115659897, "the example generator": 0.0008091139115659897, "this type of": 0.0003097410997719097, "simply": -8.7017281025846e-05, "has failed": 0.0004382027886649359, "nn almost immediately": 0.0008091139115659897, "5 1 bootstrapping": 0.0008091139115659897, "the early 1960s": 0.0008091139115659897, "and pursue a": 0.0007417488271393706, "throughout": 0.00028847877498686613, "zero payoff": 0.0007696350858963753, "step towards a": 0.0005674382257236372, "train a simulated": 0.0008091139115659897, "robot control": 0.0012262939205659443, "other examples": 0.0004050885930083273, "nn on": 0.0035113240129168942, "too strict": 0.0006131469602829721, "in q": 0.0003109518286556765, "create": 7.831222196978301e-05, "algorithms as they": 0.0007417488271393706, "where the goal": 0.0005674382257236372, "it even outperforms": 0.0008091139115659897, "a reward or": 0.0008091139115659897, "the pursuit": 0.0019885232530665498, "occurred prior": 0.0007696350858963753, "in a": 3.590244538749747e-05, "common source of": 0.0008091139115659897, "intuition of the": 0.0007417488271393706, "learning approach had": 0.0016182278231319793, "generated games that": 0.0008091139115659897, "the storage": 0.0003217891594434185, "in an attempt": 0.0004319040237213277, "slowly until": 0.000702264802583379, "a teaching strategy": 0.0008091139115659897, "one surprising": 0.000702264802583379, "agent environments learning": 0.0008091139115659897, "gas": 0.0007032319733126731, "based upon": 0.0003217891594434185, "task several learning": 0.0008091139115659897, "an intermediate": 0.0003217891594434185, "learning techniques such": 0.0008091139115659897, "robot and therefore": 0.0008091139115659897, "prior to play": 0.0008091139115659897, "is intuitive": 0.0005060701527920558, "plan against": 0.0007696350858963753, "examines all": 0.0006131469602829721, "effects on": 0.00036338074496527356, "proportion to": 0.00044153169724958527, "comparator": 0.0008100984898353999, "the relative": 0.0001752961428993088, "was always": 0.00044497617160632185, "can solve": 0.00033865419457809065, "effects of": 0.00044223221420955014, "threshold range": 0.0006628410843555166, "section 3 2": 0.0003141498861200171, "the state based": 0.0007023330300003208, "performance at": 0.0008830633944991705, "p and the": 0.00036983022343051777, "the development": 0.00021905004730177056, "e s strategy": 0.0008091139115659897, "bad actions it": 0.0008091139115659897, "and was": 0.0003238859962113274, "methods can learn": 0.0008091139115659897, "states there is": 0.0006526576017704936, "their study": 0.0004997652289300559, "the pursuer will": 0.0008091139115659897, "by barto": 0.000702264802583379, "selecting actions until": 0.0008091139115659897, "has no known": 0.0007417488271393706, "parameters the": 0.0002882806874477652, "and show that": 0.00035354849163529484, "classical approach to": 0.0006743602501766612, "the first 3": 0.0005954580987137418, "encountered": 0.00018242715422210317, "most effectively at": 0.0008091139115659897, "itself": -2.5355427971723114e-05, "a method to": 0.00040357410968453735, "be able to": 0.00020662323097110736, "2 it also": 0.0005954580987137418, "one and": 0.0009701733465844194, "learning task the": 0.0008091139115659897, "set used": 0.0005060701527920558, "the k nn": 0.0008091139115659897, "this system gll": 0.0008091139115659897, "problems one possible": 0.0008091139115659897, "training set through": 0.0007417488271393706, "primarily of": 0.000567383102523159, "instances produced for": 0.0008091139115659897, "successful after storing": 0.0008091139115659897, "evading": 0.0007021965884209132, "and quickly exceeds": 0.0008091139115659897, "handle several different": 0.0008091139115659897, "algorithms did": 0.0006628410843555166, "frequently improve classification": 0.0008091139115659897, "is random the": 0.0007417488271393706, "step and it": 0.0006526576017704936, "difficult to": 0.00030816804235617184, "about 3 000": 0.0008091139115659897, "are simple structures": 0.0008091139115659897, "development": 6.386469161350763e-05, "first assuming": 0.000702264802583379, "is captured": 0.00037315955974098747, "assignment": 0.0002926282479447407, "limit because": 0.0007696350858963753, "method alone this": 0.0008091139115659897, "hybrid system": 0.0005456354281782176, "ga we show": 0.0008091139115659897, "received is": 0.000567383102523159, "other hand": 9.612216371140011e-05, "purpose": 2.4053868025498347e-05, "evasion tasks": 0.0007696350858963753, "appended to the": 0.0005596382660342995, "chess checkers noughts": 0.0008091139115659897, "halt learning": 0.0007696350858963753, "after only": 0.00105570662590912, "task": 0.0017353896125050906, "pattern recognition": 0.0009442934558349384, "25 this": 0.00048825248710181613, "intelligent agents thus": 0.0008091139115659897, "and applied": 0.000621903657311353, "such approach might": 0.0008091139115659897, "algorithm that": 0.00018648420253057852, "to hit": 0.0005363412876789271, "be to examine": 0.0006526576017704936, "example suppose we": 0.0005456884385180774, "which are analyzed": 0.0008091139115659897, "of both p1": 0.0008091139115659897, "learning stores": 0.0007696350858963753, "showed that at": 0.0006743602501766612, "is related to": 0.00031035974394257536, "like environments an": 0.0008091139115659897, "y": -0.0002787904169347817, "1992 except": 0.0006628410843555166, "steps i e": 0.0006526576017704936, "algorithm in which": 0.0009559858011907364, "they maneuver": 0.0007696350858963753, "and competition learning": 0.0008091139115659897, "results led us": 0.0008091139115659897, "of knowledge required": 0.0008091139115659897, "method similar to": 0.0005128575980484463, "lookup table": 0.0010912708563564353, "memory based control": 0.0008091139115659897, "3 81 7": 0.0007023330300003208, "relatively small set": 0.0006199211760863129, "that neighboring": 0.0005803901647646488, "systems and": 0.00044306727952990617, "has 2": 0.0004382027886649359, "of comparing the": 0.0005954580987137418, "speed to": 0.0005363412876789271, "letting": 0.00021421099229554014, "superficial": 0.00046857120471006095, "achieve some": 0.0005200422895505865, "games at first": 0.0008091139115659897, "state in another": 0.0007417488271393706, "methods k nn": 0.0008091139115659897, "game we next": 0.0008091139115659897, "source": 7.408791773270593e-05, "that rely": 0.0004997652289300559, "determine optimal play": 0.0008091139115659897, "and quickly": 0.0005456354281782176, "valued turn angle": 0.0008091139115659897, "task which": 0.00044497617160632185, "ga we then": 0.0008091139115659897, "what they": 0.00044153169724958527, "reinforcement learning selecting": 0.0008091139115659897, "our success was": 0.0008091139115659897, "that all": 0.00010026029172547316, "produce a game": 0.0008091139115659897, "part by a": 0.0004747836164770488, "of selection is": 0.0008091139115659897, "q learning now": 0.0008091139115659897, "game playing and": 0.0007417488271393706, "chauffeur game even": 0.0008091139115659897, "s performance though": 0.0008091139115659897, "different abilities": 0.000702264802583379, "neighbors if a": 0.0006743602501766612, "an artifact of": 0.0005176213124249083, "provided corrected": 0.0007696350858963753, "examples one": 0.0011908005071032729, "adversely affects": 0.0006628410843555166, "s own": 0.0004642630166224529, "a lazy": 0.008903717747941664, "n state n": 0.0008091139115659897, "difficult delayed": 0.0007696350858963753, "future location": 0.0007696350858963753, "the changing strategy": 0.0008091139115659897, "follows": -0.001430688594452788, "using the profit": 0.0008091139115659897, "figure 1 a": 0.0002964268382825317, "bsed": 0.0006347975979615015, "own k nearest": 0.0008091139115659897, "contains up": 0.000702264802583379, "initially we": 0.0004288371693587632, "gordon and": 0.0006131469602829721, "made the": 0.0006873147925300238, "performer we explored": 0.0008091139115659897, "actually a": 0.00039398316601407357, "describe a lazy": 0.0008091139115659897, "open parking lot": 0.0008091139115659897, "to create": 0.00023020870590980126, "the complexity": 0.00015710943354638437, "often": -0.0001159428988094246, "otherwise the": 0.0003953705007981573, "one of": 0.0001107048248508849, "reaches a performance": 0.0008091139115659897, "back": 5.843582356614891e-05, "and entertainment": 0.000634859264718638, "strongest": 0.0003410923204304051, "threshold range of": 0.0008091139115659897, "them in": 0.00022753861360478008, "accelerate": 0.00034362401526488896, "as 8instance if": 0.0008091139115659897, "combined the": 0.0009659294962378757, "training even": 0.0007696350858963753, "one or": 0.000173566754154994, "even after": 0.00040276699958546587, "game our": 0.0007696350858963753, "scale": 0.00010678299311942778, "are exploring the": 0.0007023330300003208, "more general architecture": 0.0007417488271393706, "affects": 0.00018741611189910064, "decision": 0.0012741602159259424, "q learning with": 0.0008091139115659897, "has to satisfy": 0.0005851984448616567, "task and": 0.0006925063450175328, "pell": 0.0005953424196270563, "the players that": 0.0007417488271393706, "of the experiences": 0.0008091139115659897, "classified are": 0.0015392701717927505, "the children s": 0.0007417488271393706, "a master level": 0.0008091139115659897, "it passes the": 0.0006526576017704936, "been shown": 0.00023479884997171157, "game is updated": 0.0008091139115659897, "game showed good": 0.0008091139115659897, "15 points": 0.000634859264718638, "task in an": 0.0006526576017704936, "not have known": 0.0008091139115659897, "also encouraging it": 0.0008091139115659897, "in direct proportion": 0.0006526576017704936, "than the": 0.0005685290923005282, "broader domain": 0.0007696350858963753, "which explicitly provides": 0.0008091139115659897, "ga q learning": 0.0008091139115659897, "correctly labeled examples": 0.0008091139115659897, "an eager": 0.001269718529437276, "closer examination": 0.0005559058853301298, "kd trees": 0.000702264802583379, "improve until reaching": 0.0008091139115659897, "neighbor percent success": 0.0008091139115659897, "gle achieved better": 0.0008091139115659897, "if evade store": 0.0008091139115659897, "optimize": 0.00017644431332732222, "although all three": 0.0007417488271393706, "the three approaches": 0.0006743602501766612, "constraint": 7.341142338624739e-05, "makes the": 0.00021541844584106192, "while nearest neighbor": 0.0007417488271393706, "one pursuer task": 0.0016182278231319793, "j is a": 0.0003411585969912582, "shifted by a": 0.0007023330300003208, "extensions": 0.00010447367774338842, "appended to": 0.00046861672357587705, "initial states there": 0.0007417488271393706, "of gll outperformed": 0.0008091139115659897, "these observations suggested": 0.0008091139115659897, "consequently": 8.499836270430329e-05, "further in": 0.0003217891594434185, "examines the expected": 0.0008091139115659897, "assist each other": 0.0008091139115659897, "when either": 0.0004149539560409001, "state n high": 0.0008091139115659897, "see this will": 0.0007417488271393706, "neural networks": 0.0010764674004528755, "game pacman and": 0.0008091139115659897, "evades a": 0.0007696350858963753, "applying nearest neighbor": 0.0008091139115659897, "on 100 randomly": 0.0008091139115659897, "98 and": 0.0005954002535516364, "proportional": 0.00011792602781104201, "evades p": 0.0007696350858963753, "3 vector": 0.00052785331295456, "player of the": 0.0007417488271393706, "evasion rate": 0.0007696350858963753, "4 comparing": 0.0006131469602829721, "k nn developed": 0.0008091139115659897, "close enough": 0.00045224640365867626, "task was also": 0.0007417488271393706, "the more interesting": 0.0005524148804057065, "special type of": 0.0005334812968668691, "forward": 0.00011050428679687664, "payoff to": 0.0006628410843555166, "pedestrian the": 0.0015392701717927505, "opponent": 0.00046004841655118944, "e k nn": 0.0016182278231319793, "that operationalizes the": 0.0008091139115659897, "p1 or": 0.000702264802583379, "e succeeds we": 0.0008091139115659897, "but despite this": 0.0007417488271393706, "games are determined": 0.0016182278231319793, "and random mutation": 0.0007417488271393706, "theory to": 0.0003820967919236623, "turn sharply since": 0.0008091139115659897, "lazy learning techniques": 0.0008091139115659897, "based learning learning": 0.0007417488271393706, "ended in evasion": 0.0008091139115659897, "evaluates 50": 0.0007696350858963753, "1990 namely": 0.0007696350858963753, "1 differential": 0.0006628410843555166, "fact at the": 0.0008091139115659897, "space contains": 0.0005559058853301298, "each step one": 0.0006743602501766612, "directed": 9.790175570470561e-05, "path of p": 0.0008091139115659897, "in figure": 0.0002750562790468881, "dynamic programming": 0.00033865419457809065, "actions if": 0.0005456354281782176, "adaptive genetic": 0.0007696350858963753, "actions in": 0.000378426656892181, "find a minimal": 0.0006349209434580451, "game continues until": 0.0016182278231319793, "they can regain": 0.0008091139115659897, "following each": 0.0005200422895505865, "actions it": 0.0005363412876789271, "tasks assume a": 0.0008091139115659897, "still only achieving": 0.0016182278231319793, "have been applied": 0.00045745222770795314, "autonomous": 0.00026096259056477324, "ones for each": 0.0007023330300003208, "classifying each": 0.000634859264718638, "learning method": 0.0009372334471517541, "framework for multi": 0.0006199211760863129, "generated games and": 0.0008091139115659897, "constant": -5.369498036571373e-05, "is captured at": 0.0008091139115659897, "directed toward": 0.000634859264718638, "alone with 21": 0.0008091139115659897, "for the same": 0.000838073184693057, "with delayed": 0.000702264802583379, "evaluation for meta": 0.0008091139115659897, "generation thus we": 0.0008091139115659897, "single": -0.0017909623439039612, "learning proceeds": 0.0006628410843555166, "the game extremely": 0.0008091139115659897, "is a classical": 0.0005456884385180774, "two popular temporal": 0.0008091139115659897, "problem and call": 0.0008091139115659897, "simulator generated actions": 0.0008091139115659897, "we experimented": 0.0008299079120818002, "shift closer to": 0.0008091139115659897, "match all states": 0.0008091139115659897, "memory base": 0.0015392701717927505, "complete game was": 0.0008091139115659897, "by taking a": 0.0004882999224935485, "considered approaches to": 0.0008091139115659897, "each state we": 0.0014046660600006416, "that e had": 0.0008091139115659897, "the ga we": 0.002427341734697969, "to make": 0.0003079097750381065, "steadily until it": 0.0008091139115659897, "ga initially searches": 0.0008091139115659897, "we now see": 0.0007417488271393706, "task furthermore such": 0.0008091139115659897, "combined system also": 0.0008091139115659897, "a game where": 0.0008091139115659897, "provides very": 0.0006628410843555166, "maneuvers grefenstette ramsey": 0.0008091139115659897, "to solve complex": 0.0007417488271393706, "were good and": 0.0008091139115659897, "the averages of": 0.0005851984448616567, "only 10": 0.0009044928073173525, "much harder": 0.00044854462015967935, "because it first": 0.0008091139115659897, "nn developed": 0.0007696350858963753, "examples because": 0.0005456354281782176, "together to learn": 0.0008091139115659897, "itself into a": 0.0007023330300003208, "more difficult to": 0.0003731958134629092, "lined up with": 0.0008091139115659897, "which introduces": 0.0005456354281782176, "determining the": 0.00022237311719812292, "if k nn": 0.0008091139115659897, "agent activities in": 0.0007417488271393706, "s performance was": 0.0007023330300003208, "nn and an": 0.0008091139115659897, "sure that": 0.00028677803128412173, "however because lazy": 0.0008091139115659897, "classifiers which are": 0.0008091139115659897, "addition the three": 0.0008091139115659897, "which interesting": 0.0007696350858963753, "of rules which": 0.0006526576017704936, "lazy methods k": 0.0008091139115659897, "a task": 0.0006275965773301955, "example using": 0.0004004979458675273, "q learning represents": 0.0008091139115659897, "perfect performance": 0.002539437058874552, "1976 modified": 0.0007696350858963753, "and plug itself": 0.0008091139115659897, "during testing the": 0.0006743602501766612, "with all": 0.00022111610710477507, "2 the evasive": 0.0008091139115659897, "as follows first": 0.00035738190863582157, "examples comparable in": 0.0008091139115659897, "play othello a": 0.0008091139115659897, "multi agent activities": 0.0008091139115659897, "a teaching method": 0.0008091139115659897, "closed form": 0.0003573471911393542, "algorithm on": 0.00025524283217824665, "experiments will": 0.0005363412876789271, "the power": 0.00047053594595315013, "33 n": 0.00030909603197861395, "against do our": 0.0008091139115659897, "1 and d": 0.0004882999224935485, "has two": 0.00021502160361016836, "predicted reward for": 0.0008091139115659897, "control tasks more": 0.0008091139115659897, "reward is updated": 0.0008091139115659897, "require similar": 0.000702264802583379, "transmit information in": 0.0008091139115659897, "consistent with the": 0.0003122377618813423, "updated as follows": 0.0006526576017704936, "comparison of pruning": 0.0014046660600006416, "batteries below": 0.0007696350858963753, "used examples": 0.000702264802583379, "success for": 0.0005559058853301298, "reaches a level": 0.0007417488271393706, "player assuming all": 0.0008091139115659897, "upper bounds": 0.0002945105957876159, "research showed that": 0.0007417488271393706, "have a high": 0.00044501940255663815, "by testing the": 0.0006069246369921007, "state is": 0.0010681828546803367, "p players": 0.0007696350858963753, "p for": 0.0002546842039466833, "of examples that": 0.0012698418869160901, "state in": 0.0005633550442978607, "a powerful": 0.00031672395822701763, "zero radius": 0.0007696350858963753, "i following a": 0.0008091139115659897, "the set for": 0.0005674382257236372, "state if": 0.0003982790696131452, "wish to explore": 0.0007417488271393706, "in successful evasion": 0.0016182278231319793, "nn 96": 0.0007696350858963753, "features of the": 0.0003419957654508641, "to decide": 0.00024507456027777314, "was capable": 0.0006628410843555166, "determined by": 0.00042148273758250526, "have had": 0.0004123948992280552, "in the military": 0.0008091139115659897, "1 and 5": 0.0004522903409367932, "improves decision trees": 0.0008091139115659897, "game the": 0.0030768466621600883, "this case obtained": 0.0008091139115659897, "help to": 0.0003530449562101758, "create a": 0.0002487154120616033, "asymptotic properties of": 0.0006069246369921007, "normalized the": 0.000567383102523159, "commonly in the": 0.0008091139115659897, "learning with genetic": 0.0008091139115659897, "and intelligent agents": 0.0008091139115659897, "dec 1998": 0.00048296474811893784, "games a mathematical": 0.0008091139115659897, "calls symmetric chess": 0.0008091139115659897, "a game follows": 0.0008091139115659897, "indicate that": 0.00019361924942928985, "reinforcement learning and": 0.0006743602501766612, "section 5 2": 0.00037434295450873773, "and for the": 0.000312871283472271, "applies a payoff": 0.0008091139115659897, "directly towards p": 0.0008091139115659897, "ga on its": 0.0008091139115659897, "game because the": 0.0008091139115659897, "to perform better": 0.0005279045957013737, "passed by": 0.00048825248710181613, "game typically consisted": 0.0008091139115659897, "than rule": 0.0006628410843555166, "50 to": 0.00052785331295456, "performing the": 0.00028677803128412173, "of multi agent": 0.0005954580987137418, "they were": 0.000541692813051437, "before the ga": 0.0008091139115659897, "constant strategy": 0.0006628410843555166, "solves delayed reinformement": 0.0008091139115659897, "out values": 0.0006628410843555166, "1989 to train": 0.0008091139115659897, "classroom building and": 0.0008091139115659897, "sequence one": 0.0005803901647646488, "focused on": 0.0005267429918024749, "to head": 0.000567383102523159, "rather than producing": 0.0007417488271393706, "demonstrates that the": 0.0004919901420568756, "to date": 0.0002921317927643509, "theory in which": 0.0016182278231319793, "require roughly 5": 0.0008091139115659897, "constraints of": 0.0003147644852783128, "evasion within the": 0.0008091139115659897, "success approximately": 0.0007696350858963753, "work effectively on": 0.0008091139115659897, "extreme": 0.000170715699681252, "directly using": 0.00048296474811893784, "that points": 0.0004642630166224529, "000 test": 0.0006628410843555166, "considered the": 0.00026157905702535613, "33": 9.534311642947061e-05, "also performed better": 0.0008091139115659897, "profound differences in": 0.0008091139115659897, "30": -1.3536233211317276e-05, "the best learning": 0.0007023330300003208, "the resulting action": 0.0016182278231319793, "an adaptation of": 0.0004882999224935485, "wide variety": 0.0006608843682490424, "are identical": 0.00027020377595269354, "approach had no": 0.0008091139115659897, "to continue learning": 0.0008091139115659897, "video game": 0.000702264802583379, "examples our": 0.000567383102523159, "yield excellent performance": 0.0008091139115659897, "direction is": 0.00032932038867923357, "improvement in the": 0.00039332290595165396, "the multiedit": 0.0007696350858963753, "on the evader": 0.0016182278231319793, "that fired in": 0.0008091139115659897, "a rule strength": 0.0008091139115659897, "and generate actions": 0.0008091139115659897, "each other in": 0.0007922932952308791, "car the chauffeur": 0.0008091139115659897, "spatial knowledge base": 0.0008091139115659897, "gll performs": 0.0015392701717927505, "a bootstrapping method": 0.0007417488271393706, "describing the state": 0.0007417488271393706, "current environment where": 0.0008091139115659897, "with the example": 0.0005759152096655707, "non markovian problems": 0.0008091139115659897, "examples gle achieved": 0.0008091139115659897, "the experiment since": 0.0008091139115659897, "space as": 0.00037315955974098747, "when they": 0.0002513894493847149, "as classification problems": 0.0008091139115659897, "learning k nearest": 0.0008091139115659897, "93 3 81": 0.0008091139115659897, "competitive goals": 0.0007696350858963753, "learning at a": 0.0008091139115659897, "up the": 0.00019837578175446472, "the task specifically": 0.0008091139115659897, "then its": 0.0003603193719587997, "and then show": 0.0005524148804057065, "begin with": 0.0002664248079582193, "of the states": 0.0004548376351798251, "different approach to": 0.0005596382660342995, "20 time": 0.0021067944077501365, "appropriate actions in": 0.0008091139115659897, "released the turn": 0.0007417488271393706, "steps they begin": 0.0008091139115659897, "1991 that studies": 0.0008091139115659897, "the predicate": 0.00033865419457809065, "p1 and p": 0.002427341734697969, "predicted are discrete": 0.0008091139115659897, "reward at": 0.000702264802583379, "train": 0.0021017287201076456, "edited the": 0.000702264802583379, "normalized": 0.0003106438475402043, "their effect on": 0.0005176213124249083, "examples is added": 0.0008091139115659897, "successfully evading the": 0.0008091139115659897, "tied to our": 0.0008091139115659897, "utgoff 1992 tesauro": 0.0008091139115659897, "we will see": 0.0003141498861200171, "skalak 1994": 0.0007696350858963753, "a mistake this": 0.0007023330300003208, "markovian e": 0.0007696350858963753, "robot to catch": 0.0008091139115659897, "complexity td gammon": 0.0008091139115659897, "thanks to david": 0.0006743602501766612, "gabriel": 0.0003731233130620422, "the same or": 0.00042987704457580605, "a particular problem": 0.0005524148804057065, "training experiences": 0.0007696350858963753, "a successful evasion": 0.0008091139115659897, "state matcher has": 0.0008091139115659897, "strategy using a": 0.0008091139115659897, "uses a fixed": 0.0005954580987137418, "ishihara": 0.000567327990031413, "in analyzing": 0.00044497617160632185, "agent develops a": 0.0008091139115659897, "parallel network": 0.0013256821687110331, "60 evasion": 0.0007696350858963753, "and to": 0.00028410503769920996, "in non maze": 0.0016182278231319793, "work recently considerable": 0.0008091139115659897, "w sheppard": 0.000702264802583379, "like environments a": 0.0008091139115659897, "large continuous": 0.0015392701717927505, "aim for": 0.0005559058853301298, "capabilities in": 0.00048296474811893784, "effectively": 0.00022796509912279743, "research gordon": 0.0007696350858963753, "deciding how": 0.0005803901647646488, "equations which are": 0.0006349209434580451, "algorithm using": 0.0003128408899145216, "neural network": 0.0003898632748579793, "the size of": 0.0004610509484011014, "varied": 0.00018805333444124348, "teaching markov": 0.0007696350858963753, "continue to": 0.0005720689681691161, "winners": 0.0005278020401703972, "had to develop": 0.0007417488271393706, "at each time": 0.0012298186258164114, "6 discussion and": 0.0006199211760863129, "further they use": 0.0008091139115659897, "the differential equations": 0.0005851984448616567, "hypothesized k nn": 0.0008091139115659897, "2 have identical": 0.0007417488271393706, "it reaches a": 0.0005456884385180774, "time in these": 0.0006743602501766612, "of examples stored": 0.002427341734697969, "where each": 0.00019699847241945838, "simulator determines": 0.0007696350858963753, "task which is": 0.0006526576017704936, "algorithms aha 1992": 0.0008091139115659897, "probably represent": 0.0007696350858963753, "car the typical": 0.0008091139115659897, "q learning because": 0.0008091139115659897, "learning task": 0.0005200422895505865, "forever at a": 0.0008091139115659897, "achieve an objective": 0.0007023330300003208, "common feature of": 0.0006199211760863129, "which a game": 0.0008091139115659897, "to be a": 0.00019352693781326483, "step were": 0.0006628410843555166, "correspond": 7.525622781444759e-05, "the highest fitness": 0.0007417488271393706, "a statistical": 0.00035589291297159965, "of performance above": 0.0008091139115659897, "such points probably": 0.0008091139115659897, "pursuer pursuer evader": 0.0016182278231319793, "lined": 0.00046857120471006095, "non zero": 0.0002627707973273995, "simulation models": 0.0009995304578601118, "performance we considered": 0.0007417488271393706, "the actions were": 0.0007417488271393706, "well on this": 0.0006069246369921007, "s 1968 basically": 0.0008091139115659897, "search space for": 0.0005334812968668691, "1989 using": 0.0006628410843555166, "nn using": 0.0007696350858963753, "averaging the": 0.0009044928073173525, "first algorithm to": 0.0007417488271393706, "but more": 0.0003530449562101758, "gave bag": 0.0007696350858963753, "control prioritized sweeping": 0.0008091139115659897, "method which is": 0.0004882999224935485, "industries": 0.00046857120471006095, "were permitted": 0.000634859264718638, "0 1": 0.00013401152847624946, "are generalized": 0.0004997652289300559, "lb": 0.00038394579071886724, "to aerial": 0.0007696350858963753, "parameters is": 0.0003878648638474452, "learn to play": 0.0013487205003533224, "addition dorigo": 0.0007696350858963753, "nearest sequence": 0.0007696350858963753, "of soccer": 0.0007696350858963753, "reached 60": 0.0007696350858963753, "error back propagation": 0.0008091139115659897, "lazy methods": 0.0038481754294818755, "stored state and": 0.0008091139115659897, "the chauffeur": 0.0007696350858963753, "lazy learning could": 0.0008091139115659897, "with a single": 0.0003167547290380763, "on one and": 0.002023080750529984, "it reached approximately": 0.0008091139115659897, "greater": 3.273697597428264e-05, "were responsible": 0.0006131469602829721, "warfare and": 0.0007696350858963753, "the idea": 0.00036003843117220316, "the profit": 0.0013256821687110331, "learning therefore we": 0.0008091139115659897, "normalized to equalize": 0.0008091139115659897, "very rapidly in": 0.0008091139115659897, "table the": 0.0003197335749799009, "to play differential": 0.0016182278231319793, "and wins": 0.0007696350858963753, "believe it": 0.0004731713358791195, "still requires significantly": 0.0008091139115659897, "results were disappointing": 0.0008091139115659897, "for both variations": 0.0008091139115659897, "resulting set of": 0.0005393947462253054, "idea behind our": 0.0005674382257236372, "learning an empirical": 0.0007023330300003208, "ga representation and": 0.0008091139115659897, "rapidly in": 0.001134766205046318, "low n state": 0.0008091139115659897, "learn essentially e": 0.0008091139115659897, "characterize grefenstette et": 0.0008091139115659897, "and eliminates": 0.0004997652289300559, "algorithm for our": 0.0005851984448616567, "constraints": 2.6344398503953476e-05, "one whitehead": 0.0007696350858963753, "learning represents": 0.0007696350858963753, "of first order": 0.00044270962419637705, "trained ga": 0.0007696350858963753, "require quantization": 0.000702264802583379, "the robot made": 0.0008091139115659897, "we specified a": 0.0008091139115659897, "pruning methods for": 0.0013487205003533224, "to left": 0.00040989971878532225, "well and": 0.0003665369780185166, "2 if": 0.0001655020401378066, "versions of": 0.00019976829929109371, "predicting the": 0.00036338074496527356, "paper demonstrates that": 0.0007417488271393706, "learning sutton": 0.0007696350858963753, "suggested the two": 0.0008091139115659897, "the end of": 0.0006132713944244266, "we then": 0.0003012623688383849, "current implementation takes": 0.0007417488271393706, "a discount": 0.0006131469602829721, "arise in": 0.000310019848849804, "e figure 1": 0.0005456884385180774, "1 shows the": 0.00031479506571990205, "than 90 success": 0.0008091139115659897, "this problem using": 0.0006069246369921007, "control railroad": 0.0007696350858963753, "that escape is": 0.0008091139115659897, "players and": 0.0005803901647646488, "the one": 0.0006324836423027364, "the paths of": 0.0005759152096655707, "algorithm the genetic": 0.0008091139115659897, "instances we": 0.0004997652289300559, "how a": 0.0005676681472954233, "the form of": 0.00024391003976470028, "we selected it": 0.0007417488271393706, "relative to the": 0.0005874806234383738, "method k": 0.0006628410843555166, "for predicting the": 0.0005279045957013737, "approaches": 5.718821030456752e-05, "speed the angle": 0.0008091139115659897, "0 25": 0.00035882246681762515, "methods for complex": 0.0008091139115659897, "initial placements": 0.0007696350858963753, "algorithm classifies": 0.0007696350858963753, "examples stored the": 0.0008091139115659897, "with an": 9.223813900046712e-05, "using plan fitness": 0.0008091139115659897, "in direct": 0.0004074652591731264, "also demonstrate clearly": 0.0008091139115659897, "running gle": 0.0007696350858963753, "performance changed as": 0.0008091139115659897, "predictions are refined": 0.0008091139115659897, "learning algorithm": 0.002757882162098515, "vary continuously": 0.0006628410843555166, "high probability of": 0.0005393947462253054, "is always possible": 0.0004779929005953682, "even after a": 0.0007417488271393706, "more traditional": 0.00044497617160632185, "is performing": 0.0005200422895505865, "the results reveals": 0.0008091139115659897, "with as": 0.00036183856746138145, "thus we were": 0.0007417488271393706, "to k nn": 0.004045569557829949, "addition to the": 0.00028606227330869914, "a combined": 0.0003859053049699601, "distance between p": 0.0005851984448616567, "its parent systems": 0.0008091139115659897, "reaches": 0.0004511189573179961, "strategic": 0.0007266908962938369, "to store with": 0.0014834976542787413, "after only 10": 0.0007417488271393706, "create a system": 0.0007023330300003208, "reached": 0.0005467952048714392, "one is": 0.00018616902889069845, "a plan and": 0.0014834976542787413, "a game is": 0.0008091139115659897, "number of trials": 0.0005524148804057065, "framework for": 0.0003564570650757896, "more quickly than": 0.0005596382660342995, "developed their": 0.000702264802583379, "learning and show": 0.0007417488271393706, "van der": 0.0004123948992280552, "robot shaping developing": 0.0008091139115659897, "found they": 0.0006628410843555166, "then uses a": 0.0006199211760863129, "each rule": 0.0008970892403193587, "the stored state": 0.0008091139115659897, "intermediate": 0.00021568534757906337, "later and": 0.00048825248710181613, "the editing rate": 0.0016182278231319793, "predict by methods": 0.0008091139115659897, "possible however the": 0.0007417488271393706, "which is": 0.00012642443813214296, "classification problems by": 0.0007023330300003208, "pursuer game showed": 0.0008091139115659897, "0 ga": 0.0007696350858963753, "simple multi": 0.000702264802583379, "example set produced": 0.0008091139115659897, "increases so": 0.000567383102523159, "samuel to": 0.0015392701717927505, "bearing heading": 0.0007696350858963753, "task q": 0.0007696350858963753, "explanation": 0.00018741611189910064, "lazy method": 0.0015392701717927505, "task a": 0.00043186206685094484, "must avoid prematurely": 0.0008091139115659897, "feedback on how": 0.0008091139115659897, "work by barto": 0.0008091139115659897, "instead use interpolation": 0.0008091139115659897, "0 which": 0.0002831104418951413, "game where": 0.0017862007606549094, "later used ace": 0.0008091139115659897, "variation on the": 0.0006069246369921007, "a classifier": 0.0004938405038742361, "were encouraging and": 0.0008091139115659897, "we hypothesized": 0.0005803901647646488, "der wal": 0.000702264802583379, "from wilson": 0.0007696350858963753, "truck backer": 0.0007696350858963753, "respectively for": 0.00030027612719626154, "near perfect performance": 0.002427341734697969, "neuronlike": 0.0005953424196270563, "100 games achieving": 0.0008091139115659897, "solutions for": 0.0005938869885403849, "the point the": 0.0005456884385180774, "robot arm": 0.0005559058853301298, "of the learning": 0.0004882999224935485, "still play the": 0.0008091139115659897, "curves": 0.00016096650236250597, "of these parameters": 0.00046866225128631864, "the most popular": 0.0004382453615580345, "possible for lazy": 0.0008091139115659897, "control law": 0.0006628410843555166, "for instance bsed": 0.0008091139115659897, "have": 0, "is an artifact": 0.0005851984448616567, "east then the": 0.0008091139115659897, "after an": 0.0003327228091591544, "nn performed on": 0.0008091139115659897, "and for": 0.0002756653887288935, "payoff function in": 0.0008091139115659897, "90 to": 0.0005559058853301298, "advantage of": 0.0001458326798832132, "42 3 q": 0.0008091139115659897, "general if": 0.0004560919846500759, "1993 and for": 0.0008091139115659897, "used ace": 0.0007696350858963753, "method could produce": 0.0008091139115659897, "of our study": 0.0005279045957013737, "algorithms to these": 0.0008091139115659897, "the task of": 0.00032356501782292976, "to limit examples": 0.0008091139115659897, "to map": 0.0003228323139879973, "approximators in continuous": 0.0008091139115659897, "320": 0.00031473391077755725, "solve difficult": 0.001269718529437276, "from the game": 0.0016182278231319793, "p2 drops": 0.0007696350858963753, "problems this": 0.0004123948992280552, "for complex": 0.00033865419457809065, "learning ebl to": 0.0008091139115659897, "papers from": 0.0006131469602829721, "his algorithm": 0.0004779464664686347, "zhang 1992 skalak": 0.0008091139115659897, "indicates that perhaps": 0.0008091139115659897, "2 also resembles": 0.0008091139115659897, "for the set": 0.0003815128357060037, "fitness values": 0.001269718529437276, "tesauro used": 0.0007696350858963753, "labeled examples because": 0.0008091139115659897, "depends on four": 0.0008091139115659897, "eight": 0.00016959819790576504, "as a": 6.61961310453931e-05, "robot to approach": 0.0008091139115659897, "actions at random": 0.0008091139115659897, "one complication in": 0.0008091139115659897, "fact that gll": 0.0008091139115659897, "as k": 0.0007005481188006801, "editing served to": 0.0008091139115659897, "example if three": 0.0008091139115659897, "the optimal strategies": 0.002225246481418112, "distance between a": 0.0004882999224935485, "studied in": 0.0004714779995535412, "action at": 0.00052785331295456, "limit feedback on": 0.0008091139115659897, "1 tended to": 0.0008091139115659897, "goals more generally": 0.0008091139115659897, "single car the": 0.0008091139115659897, "study one step": 0.0008091139115659897, "selection": 0.000331899183181268, "the reward from": 0.0007417488271393706, "points for editing": 0.0008091139115659897, "provided examples": 0.000702264802583379, "at the": 0.00010843714605082041, "ga transmit information": 0.0008091139115659897, "maximally general as": 0.0008091139115659897, "supported": -3.216993938584577e-05, "more recently systems": 0.0008091139115659897, "as we will": 0.00033085096496788017, "achieve some payoff": 0.0008091139115659897, "ga s": 0.001404529605166758, "we counted one": 0.0008091139115659897, "algorithms ga k": 0.0008091139115659897, "individually we focused": 0.0008091139115659897, "a single car": 0.0007417488271393706, "a formulation similar": 0.0008091139115659897, "players positions develop": 0.0008091139115659897, "the simulator and": 0.0012138492739842013, "ramsey and grefenstette": 0.0016182278231319793, "66 examples": 0.0007696350858963753, "games every": 0.000702264802583379, "knowledge": 0.00012263745496585564, "that both": 0.0003872384988585797, "one classic pursuit": 0.0008091139115659897, "controls": 0.00042685275907454484, "expects each example": 0.0008091139115659897, "examples provided": 0.000634859264718638, "of the ga": 0.0026106304070819745, "through his": 0.000702264802583379, "emitting": 0.000452202474916213, "stored state action": 0.0008091139115659897, "that determining good": 0.0008091139115659897, "e and to": 0.0006743602501766612, "inferior": 0.0003186897732673777, "to hart s": 0.0008091139115659897, "model how actions": 0.0008091139115659897, "diana gordon": 0.000702264802583379, "and p 2": 0.0012778286469368456, "it achieves near": 0.0007417488271393706, "follows a sequence": 0.0008091139115659897, "goals credit": 0.0007696350858963753, "phase approach": 0.000634859264718638, "upper bound don": 0.0008091139115659897, "through his algorithm": 0.0008091139115659897, "classes typically": 0.000702264802583379, "p 2 if": 0.0006069246369921007, "gave bag of": 0.0008091139115659897, "associated actions": 0.0006628410843555166, "while another": 0.0005200422895505865, "and motivate the": 0.0006743602501766612, "maximum turn angle": 0.0008091139115659897, "areas": 0.00013598223773906526, "a markovian decision": 0.0008091139115659897, "ratio of the": 0.00033009897175506186, "a ball in": 0.0007417488271393706, "learning occurs through": 0.0008091139115659897, "midst of": 0.0006628410843555166, "in the graph": 0.0003167547290380763, "several different types": 0.0007023330300003208, "wins the": 0.000567383102523159, "and subramanian": 0.000634859264718638, "95 evasion": 0.0007696350858963753, "solve examples": 0.0007696350858963753, "examples must have": 0.0008091139115659897, "making problems": 0.000702264802583379, "poorer than both": 0.0008091139115659897, "pacman and": 0.0007696350858963753, "the new plan": 0.0008091139115659897, "this choice was": 0.0006199211760863129, "the database": 0.003505928052619408, "used on": 0.0003489161923333023, "least wait until": 0.0008091139115659897, "fixed": -0.00016667787565257316, "payoff or penalty": 0.0008091139115659897, "3 ga": 0.000702264802583379, "solutions for differential": 0.0008091139115659897, "to counter a": 0.0008091139115659897, "cause of": 0.00037664034839981597, "constructing": 0.00010859935643761157, "exists": -3.9384663245086396e-05, "the rule": 0.0005811494962149078, "national": 0.0001400249674400136, "encapsulate some of": 0.0008091139115659897, "players that yield": 0.0008091139115659897, "able to control": 0.0005851984448616567, "using its learned": 0.0008091139115659897, "predict both": 0.0007696350858963753, "stages of this": 0.0005851984448616567, "and approaches": 0.00052785331295456, "that yielded the": 0.0006526576017704936, "by salzberg": 0.000702264802583379, "phases": 0.00015786036938199673, "algo rithms": 0.00037315955974098747, "difference in performance": 0.0005279045957013737, "pattern": 0.00017483689305369712, "backgammon s": 0.0007696350858963753, "discussed in": 0.00013313751781342164, "the radius": 0.0007879663320281471, "ours could": 0.0007696350858963753, "or other source": 0.0008091139115659897, "successful examples have": 0.0008091139115659897, "routing": 0.00018427586060086267, "an action by": 0.0007417488271393706, "based learning tolerating": 0.0008091139115659897, "action would": 0.0005954002535516364, "lazy learning as": 0.0008091139115659897, "the points": 0.0002546842039466833, "stored examples": 0.0007696350858963753, "the task our": 0.0008091139115659897, "encouraging it": 0.000702264802583379, "control task acknowledgments": 0.0008091139115659897, "variety of multi": 0.0007417488271393706, "game i e": 0.0014834976542787413, "and dorigo 1994": 0.0008091139115659897, "lazy learning is": 0.0016182278231319793, "enable k 1": 0.0008091139115659897, "focus on learning": 0.0007023330300003208, "during that": 0.0004050885930083273, "which are simple": 0.0005759152096655707, "problem reinforcement": 0.000702264802583379, "q learning and": 0.0007417488271393706, "the ga transmit": 0.0008091139115659897, "percent evasion": 0.0007696350858963753, "better than the": 0.001833055025520493, "taking": 4.8107736050996695e-05, "smoke bombs": 0.0007696350858963753, "equal": -0.00010557057838725963, "ga performs well": 0.0008091139115659897, "control e": 0.0006628410843555166, "striking result": 0.0007696350858963753, "a single aircraft": 0.0008091139115659897, "supported as": 0.0005200422895505865, "g when": 0.0003681525887744991, "for conjunctive goals": 0.0016182278231319793, "attributes": 0.0010836236737674673, "passing": 0.00012946145470314757, "collected many": 0.0007696350858963753, "otherwise": -0.0001252297502992297, "relevant": 0.00014166806984649107, "1 a game": 0.0008091139115659897, "after any": 0.0004731713358791195, "with careful editing": 0.0008091139115659897, "spatial knowledge": 0.000702264802583379, "nn one": 0.0007696350858963753, "tolerating noisy": 0.0015392701717927505, "of 135 they": 0.0008091139115659897, "q learning to": 0.0029669953085574826, "one possible reason": 0.0007417488271393706, "memory store during": 0.0008091139115659897, "sequential decision": 0.0028369155126157946, "game in this": 0.0006743602501766612, "speeds dropped below": 0.0008091139115659897, "then be": 0.00021661685441970926, "a long series": 0.0007417488271393706, "watkins": 0.0027279121406831334, "evasion which is": 0.0008091139115659897, "game theory in": 0.0008091139115659897, "differential game consists": 0.0008091139115659897, "problems of": 0.0002530247819825898, "evade when": 0.0007696350858963753, "the upper": 0.00018680013899656254, "to play random": 0.0008091139115659897, "passes the resulting": 0.0008091139115659897, "evasion task": 0.0007696350858963753, "high level above": 0.0008091139115659897, "plateau at 90": 0.0008091139115659897, "on the examples": 0.0006069246369921007, "essentially e": 0.0007696350858963753, "be poor": 0.0005363412876789271, "pursuit game in": 0.0008091139115659897, "two phase": 0.00042590150453082544, "game playing case": 0.0008091139115659897, "joint system": 0.0007696350858963753, "when the tasks": 0.0005759152096655707, "two learning algorithms": 0.0013487205003533224, "determine these": 0.000567383102523159, "of performance 4": 0.0008091139115659897, "k nn": 0.04242182939875306, "performer we": 0.000702264802583379, "d 2 respectively": 0.0007023330300003208, "his algorithm that": 0.0008091139115659897, "these actions": 0.0004382027886649359, "calculated by": 0.00034112545549164767, "examples our experiments": 0.0008091139115659897, "solution is relatively": 0.0007417488271393706, "best ever achieved": 0.0008091139115659897, "our case": 0.00028026328662092783, "learning strategies for": 0.0007417488271393706, "of rules in": 0.0005596382660342995, "multi": 0.00018049433881466102, "prioritized sweeping": 0.0023089052576891257, "than the number": 0.00036238524153671306, "john grefenstette simon": 0.0008091139115659897, "socket to": 0.000702264802583379, "grab e": 0.0007696350858963753, "value": -0.0010586658799639336, "maneuvers task when": 0.0008091139115659897, "traditional lazy approach": 0.0008091139115659897, "1963 as": 0.0007696350858963753, "we illustrated": 0.0005456354281782176, "used in conjunction": 0.0004522903409367932, "that the pursuers": 0.0008091139115659897, "can begin with": 0.0007417488271393706, "this task": 0.000607433069723181, "work has": 0.00024254333664610486, "320 generations and": 0.0008091139115659897, "almost": 9.319621554643286e-05, "the graph shows": 0.0005393947462253054, "until almost": 0.0007696350858963753, "noting that": 0.0002609879415061532, "generally strategies": 0.0007696350858963753, "alternation continues": 0.0007696350858963753, "game is intuitive": 0.0008091139115659897, "the two lazy": 0.0008091139115659897, "either method when": 0.0008091139115659897, "of solving": 0.00034112545549164767, "to the classifiers": 0.0008091139115659897, "to control e": 0.0008091139115659897, "to determine these": 0.0006526576017704936, "and constraints of": 0.0006526576017704936, "proceeds as follows": 0.0004259428823122818, "while another agent": 0.0008091139115659897, "same reason": 0.00044153169724958527, "task relative": 0.0007696350858963753, "algorithm the idea": 0.0006526576017704936, "instances the simulator": 0.0008091139115659897, "given generation were": 0.0008091139115659897, "name the difficulty": 0.0008091139115659897, "the next section": 0.0001980492831915353, "problems called delayed": 0.0008091139115659897, "at every time": 0.0005674382257236372, "the difficulty": 0.0011977325785531702, "well we": 0.0003573471911393542, "finding a solution": 0.0005954580987137418, "to recharge its": 0.0008091139115659897, "but the": 0.0002030727471685228, "oracle used": 0.0007696350858963753, "where the lazy": 0.0008091139115659897, "of the rules": 0.000449806936615026, "a combined strategy": 0.0008091139115659897, "fired for": 0.0007696350858963753, "north and p1": 0.0008091139115659897, "determine performance of": 0.0008091139115659897, "results of the": 0.001069950334068168, "80 evasion within": 0.0008091139115659897, "between p1 and": 0.0007023330300003208, "those discussed": 0.0005128077770266814, "however even after": 0.0008091139115659897, "pursuer and": 0.0015392701717927505, "in natural": 0.00039610816435843403, "and much more": 0.0006069246369921007, "idea being": 0.0006628410843555166, "neural": 0.00118809704403119, "the simulated": 0.0003603193719587997, "by encoding them": 0.0007417488271393706, "al 1983": 0.0011607803295292977, "been used": 0.00038524540441563926, "using wilson s": 0.0008091139115659897, "provided by the": 0.0005874806234383738, "sets": -0.0001252297502992297, "position": 0.00017760966040010308, "or better than": 0.0005176213124249083, "table our": 0.0006628410843555166, "updated as": 0.0004349818647972793, "pursuer evader": 0.0023089052576891257, "multiedit": 0.0007021965884209132, "stores": 0.001156512507628938, "time is required": 0.0005524148804057065, "at which point": 0.00048474305809383046, "and pattern": 0.0004382027886649359, "1992 later": 0.0007696350858963753, "remained in": 0.000702264802583379, "k nn the": 0.0008091139115659897, "selects an": 0.00052785331295456, "stored": 0.0012811327089738709, "obtained nearly": 0.000702264802583379, "set of randomly": 0.0006526576017704936, "special issue for": 0.0008091139115659897, "for one generation": 0.0008091139115659897, "or other methods": 0.0008091139115659897, "reward from": 0.000702264802583379, "applicability of lazy": 0.0008091139115659897, "capabilities of": 0.0006925063450175328, "neither the": 0.00039398316601407357, "produce benefits": 0.0007696350858963753, "evasion were": 0.0007696350858963753, "features describing the": 0.0007023330300003208, "finally we": 0.00014845297730283025, "problem previous": 0.0006628410843555166, "lazy test": 0.0007696350858963753, "training since": 0.0007696350858963753, "almost perfect": 0.000634859264718638, "specify two distance": 0.0008091139115659897, "of analyzing a": 0.0007023330300003208, "through 100 generations": 0.0008091139115659897, "nn s performance": 0.0016182278231319793, "continue learning": 0.0007696350858963753, "if the pair": 0.0006199211760863129, "a data": 0.00020153094172163666, "either method could": 0.0016182278231319793, "upper an": 0.0007696350858963753, "more difficult in": 0.0006743602501766612, "learning most": 0.000634859264718638, "showed that examples": 0.0008091139115659897, "normalized the purpose": 0.0008091139115659897, "match": 0.0003407785355716529, "that were": 0.00021423180160118382, "tests": 0.00022796509912279743, "e only": 0.0004642630166224529, "selection is": 0.00039398316601407357, "machine learning an": 0.0007023330300003208, "t 8s2rules": 0.0007696350858963753, "1992 q learning": 0.0008091139115659897, "game that": 0.0019885232530665498, "pattern recognition literature": 0.0008091139115659897, "thus a": 0.00021701898437179995, "actual reward": 0.0015392701717927505, "a single set": 0.0005524148804057065, "this information includes": 0.0007023330300003208, "engagement were then": 0.0008091139115659897, "has only": 0.00026519336172906905, "several methods": 0.00043186206685094484, "one agent trying": 0.0008091139115659897, "watkins 1989 barto": 0.0008091139115659897, "function the": 0.0002476632184695523, "algorithms a parallel": 0.0007417488271393706, "strategy that e": 0.0008091139115659897, "ga is a": 0.0007417488271393706, "like": -0.00045749232193508665, "success": 0.0029933778439949522, "e g in": 0.00037434295450873773, "e it": 0.0002530247819825898, "on genetic algo": 0.0008091139115659897, "players speeds and": 0.0008091139115659897, "oracle used by": 0.0008091139115659897, "perhaps a": 0.00048296474811893784, "we examined": 0.00037315955974098747, "evasion after": 0.0007696350858963753, "clouse utgoff": 0.0007696350858963753, "tic tac toe": 0.0007023330300003208, "stages of learning": 0.0008091139115659897, "of players": 0.0005954002535516364, "continuous state": 0.0024525878411318885, "further gll": 0.0007696350858963753, "prevent the": 0.00033865419457809065, "learn essentially": 0.0007696350858963753, "classical": 0.0001195279098310498, "a method": 0.0005373626256996497, "differential equations model": 0.0008091139115659897, "several steps to": 0.0008091139115659897, "p2 in the": 0.0006743602501766612, "is due": 0.0001896786412995476, "fact at": 0.0006131469602829721, "one for the": 0.0008299885404614837, "e s path": 0.0008091139115659897, "another i e": 0.0006743602501766612, "sejnowski 1989 to": 0.0008091139115659897, "for collecting": 0.0004938405038742361, "al and later": 0.0008091139115659897, "pursuer two pursuers": 0.0032364556462639586, "decision problems when": 0.0008091139115659897, "were passed to": 0.0008091139115659897, "describe an": 0.00031672395822701763, "stuck forever": 0.0007696350858963753, "begins an evasive": 0.0008091139115659897, "illustrate a": 0.0004938405038742361, "indicated the ga": 0.0008091139115659897, "with a stored": 0.0007417488271393706, "direction although all": 0.0008091139115659897, "some state": 0.0008197994375706445, "assuming": 5.640874593278208e-05, "systems this": 0.0003748850085915968, "success while": 0.0006628410843555166, "form of reinforcement": 0.0007023330300003208, "regain": 0.0004997166844687707, "noise": 0.00035880444580774077, "takes over": 0.0004997652289300559, "them the": 0.00027886722524113144, "of co learning": 0.0008091139115659897, "traveling straight": 0.0007696350858963753, "periodically release evader": 0.0008091139115659897, "assume the": 0.00021502160361016836, "is the rule": 0.0006069246369921007, "et al 1975": 0.0007023330300003208, "e figure": 0.0003898632748579793, "although": -0.0001599336068384763, "strategies are complex": 0.0008091139115659897, "theory with applications": 0.0006526576017704936, "tasks in": 0.0006978323846666046, "periodically": 0.00022490585540778116, "noisy": 0.00049950639316368, "identify the strongest": 0.0008091139115659897, "about": -0.0006688979485294913, "competition the": 0.0007696350858963753, "actual": 4.170931452436647e-05, "socket": 0.00039606968857753465, "apprach": 0.0007021965884209132, "factor and": 0.00037315955974098747, "introduces": 0.0001195279098310498, "matcher has": 0.0007696350858963753, "corresponding range to": 0.0008091139115659897, "teach the ga": 0.0008091139115659897, "way around": 0.0005559058853301298, "initial experiments": 0.0005060701527920558, "until termination it": 0.0008091139115659897, "plug itself": 0.0007696350858963753, "and two pursuer": 0.0008091139115659897, "an agent develops": 0.0008091139115659897, "yet are": 0.0005803901647646488, "keeps only points": 0.0008091139115659897, "approach had difficulty": 0.0008091139115659897, "and show": 0.0002513894493847149, "pursuers p1 and": 0.0016182278231319793, "our experiments show": 0.0004601378070916638, "phase of our": 0.0005759152096655707, "play backgammon": 0.0015392701717927505, "different approach": 0.00036338074496527356, "evasion once": 0.0007696350858963753, "q x a": 0.0006526576017704936, "slow to converge": 0.0007417488271393706, "editing was": 0.0007696350858963753, "equations finding a": 0.0008091139115659897, "the end results": 0.0008091139115659897, "asymptotic limit because": 0.0008091139115659897, "popular video game": 0.0008091139115659897, "results of editing": 0.0008091139115659897, "this motivated the": 0.0007023330300003208, "algorithm run": 0.000567383102523159, "forth or makes": 0.0008091139115659897, "1986": 0.00026096259056477324, "1987": 0.0007758876620763826, "1982": 0.0006924390787382693, "1983": 0.000885860216226833, "each algorithm by": 0.0007417488271393706, "1981": 0.00032928840029762313, "learning after an": 0.0008091139115659897, "5a shows a": 0.0008091139115659897, "1988": 0.0007492595897455203, "awarded": 0.0005278020401703972, "reinforcement learning algorithm": 0.0007417488271393706, "a game lasts": 0.0008091139115659897, "starting positions": 0.0005954002535516364, "games and computing": 0.0008091139115659897, "games figure a": 0.0008091139115659897, "maze": 0.001134655980062826, "for e thus": 0.0007023330300003208, "this plateau was": 0.0008091139115659897, "disappointing when": 0.0007696350858963753, "algorithm for k": 0.0005954580987137418, "pit a strategy": 0.0008091139115659897, "was correctly": 0.0006131469602829721, "is much smoother": 0.0008091139115659897, "and associated": 0.0003489161923333023, "but": -0.005670689428847799, "instances in": 0.0007797265497159586, "determine the appropriate": 0.0005759152096655707, "that it provides": 0.0004657382758148953, "a ball": 0.0005060701527920558, "converge and approaches": 0.0008091139115659897, "degrees left": 0.0007696350858963753, "editing": 0.0053151612973609975, "performance the distance": 0.0008091139115659897, "necessary component of": 0.0007417488271393706, "games in a": 0.0008091139115659897, "all points shown": 0.0008091139115659897, "must avoid": 0.0005803901647646488, "exceeds 90": 0.0007696350858963753, "wish": 0.0001195279098310498, "j": -0.00031674685726969573, "variations": 0.00014185549618976322, "a robot to": 0.0021069990900009624, "when using": 0.00026397546369233323, "ga was still": 0.0016182278231319793, "was 95 successful": 0.0008091139115659897, "plan consists": 0.000702264802583379, "1989 the": 0.0004731713358791195, "for collecting examples": 0.0008091139115659897, "modeled as a": 0.00038402039400084893, "by differential equations": 0.0007023330300003208, "to follow": 0.0003238859962113274, "the children": 0.00037315955974098747, "k a": 0.00027817585610585485, "joint system learned": 0.0008091139115659897, "1992 used": 0.000702264802583379, "release evader": 0.0007696350858963753, "time help to": 0.0008091139115659897, "are complex many": 0.0008091139115659897, "game would": 0.0007696350858963753, "recent work in": 0.0005226282087022614, "opponent in such": 0.0008091139115659897, "definition of the": 0.0002748099830244983, "environments a teaching": 0.0008091139115659897, "pit": 0.0006347975979615015, "proceeds": 0.00027374359717739994, "the estimates": 0.0003423836492878316, "examples comparable": 0.0007696350858963753, "which of": 0.0003118921235356357, "highly nonlinear": 0.0006628410843555166, "lazy variant": 0.0015392701717927505, "learning rate": 0.00158355993886368, "the players are": 0.0006743602501766612, "45": 0.00022177516302052797, "42": 0.00010897882090670409, "make the maximum": 0.0008091139115659897, "pursuers for": 0.0007696350858963753, "denoting a": 0.0005363412876789271, "maneuvers q": 0.0007696350858963753, "machine learning v": 0.00042987704457580605, "of markov": 0.0004349818647972793, "to 1": 0.00014797318092092765, "the general": 0.0004497047941742727, "to escape from": 0.0012398423521726258, "ga throughout its": 0.0008091139115659897, "85": 0.0006396945918343108, "basically zigzags back": 0.0008091139115659897, "improving the averaging": 0.0008091139115659897, "highly trained ga": 0.0008091139115659897, "pursuer game": 0.006157080687171002, "nn still requires": 0.0008091139115659897, "a common feature": 0.0006349209434580451, "neighbors k nn": 0.0008091139115659897, "experiments demonstrate that": 0.001104829760811413, "variation": 0.00011832515194928532, "single constant strategy": 0.0008091139115659897, "s actions were": 0.0008091139115659897, "strategy for": 0.0007742354695790322, "determine these examples": 0.0008091139115659897, "control problems": 0.00361797122926941, "the class was": 0.0007023330300003208, "complicated task": 0.0007696350858963753, "0 is": 0.00013599544759312972, "strategies in differential": 0.0008091139115659897, "reaches some asymptotic": 0.0008091139115659897, "apply reinforcement throughout": 0.0008091139115659897, "ga to jump": 0.0008091139115659897, "how performance changed": 0.0008091139115659897, "are within d": 0.0008091139115659897, "in time": 0.00018743431824375768, "locates all of": 0.0008091139115659897, "task we now": 0.0007417488271393706, "value state": 0.0006628410843555166, "experiment with": 0.00036338074496527356, "2 respectively": 0.0003228323139879973, "strategies in pursuit": 0.0008091139115659897, "q value for": 0.0008091139115659897, "limited": 6.594547764683087e-05, "comparison with": 0.0002708464065257185, "learning experiments were": 0.0008091139115659897, "material is": 0.00043186206685094484, "minimum radius": 0.000634859264718638, "example in a": 0.00046289837369057756, "simon kasif and": 0.0008091139115659897, "by grefenstette et": 0.0016182278231319793, "rate above": 0.0007696350858963753, "that at least": 0.000701529560067623, "develop a method": 0.0006199211760863129, "minimal computational": 0.000634859264718638, "has both": 0.00046861672357587705, "set of pairs": 0.000471675475395776, "we store each": 0.0008091139115659897, "fitness rather than": 0.0008091139115659897, "resulting action": 0.0015392701717927505, "for a limited": 0.0005674382257236372, "commonly in": 0.000634859264718638, "speed and the": 0.0006069246369921007, "between 1 and": 0.0004259428823122818, "1990 clouse": 0.0007696350858963753, "the reinforcement": 0.0005803901647646488, "our success": 0.000702264802583379, "the five nearest": 0.0008091139115659897, "editing would frequently": 0.0008091139115659897, "under": -0.00013377958970589826, "to work together": 0.0006349209434580451, "in more of": 0.0008091139115659897, "1989 wilson s": 0.0008091139115659897, "compilation that operationalizes": 0.0008091139115659897, "must learn": 0.001134766205046318, "was to": 0.00027020377595269354, "adds additional": 0.000567383102523159, "sequential behavior on": 0.0008091139115659897, "2 reducing": 0.0005803901647646488, "a lazy technique": 0.0008091139115659897, "each attribute": 0.0004779464664686347, "expected payoff": 0.0013256821687110331, "is calculated by": 0.00046866225128631864, "not know": 0.00027020377595269354, "general as": 0.0004288371693587632, "and eager": 0.0006628410843555166, "of this work": 0.0002579122500997948, "the evasive maneuvers": 0.008091139115659897, "we formulate": 0.000378426656892181, "every": -0.00033151286039062995, "is computed": 0.00019328620393072667, "to the table": 0.0005954580987137418, "examples gle": 0.0007696350858963753, "is a variation": 0.0005176213124249083, "examples are provided": 0.0006526576017704936, "training is very": 0.0008091139115659897, "two versions of": 0.0004601378070916638, "curvature is": 0.0005803901647646488, "examples gll": 0.0015392701717927505, "be converted into": 0.000471675475395776, "000 games where": 0.0008091139115659897, "teacher and": 0.000634859264718638, "by initializing the": 0.0007023330300003208, "neighboring states": 0.000702264802583379, "the ga instead": 0.0008091139115659897, "step however": 0.0005456354281782176, "example when": 0.00029694349427019246, "between classes": 0.0005128077770266814, "two versions": 0.00039398316601407357, "develop continuously in": 0.0008091139115659897, "games where performance": 0.0008091139115659897, "updated using the": 0.0005954580987137418, "their own likewise": 0.0008091139115659897, "against the": 0.0002530247819825898, "suggested the": 0.0004938405038742361, "both lazy learning": 0.0008091139115659897, "resulting system": 0.00044854462015967935, "in random": 0.00042590150453082544, "lazy approach to": 0.0008091139115659897, "consistent": 6.417794121484131e-05, "standard q learning": 0.0016182278231319793, "estimates": 0.00011127165817290848, "direct": 1.070971211947868e-05, "traditional eager": 0.0007696350858963753, "the problems": 0.00023433161380612713, "unable to match": 0.0008091139115659897, "success approximately equal": 0.0008091139115659897, "uses a separate": 0.0007023330300003208, "competition initially": 0.0007696350858963753, "even though the": 0.00031035974394257536, "to k": 0.0013574640874433747, "estimated": 0.00012114439617845291, "have known closed": 0.0008091139115659897, "actions to predict": 0.0008091139115659897, "and we would": 0.0005226282087022614, "dynamics of the": 0.0004919901420568756, "bsed learning ctr": 0.0008091139115659897, "are stored since": 0.0008091139115659897, "straight ahead": 0.000702264802583379, "hide": 0.0002657815520222347, "has additional": 0.0005456354281782176, "selected": 0.00025114334378458837, "nonlinear thus": 0.0007696350858963753, "to escape": 0.0021453651507157083, "goals credit assignment": 0.0008091139115659897, "complicated planning tasks": 0.0008091139115659897, "format amenable to": 0.0008091139115659897, "profit sharing plan": 0.0008091139115659897, "intuitive the": 0.0005954002535516364, "which is similar": 0.0004548376351798251, "problems are": 0.00025807848985967736, "clause in the": 0.0006069246369921007, "explanation based": 0.0005803901647646488, "k nn failed": 0.0008091139115659897, "action to the": 0.0006743602501766612, "the basic game": 0.0008091139115659897, "many successful": 0.0006628410843555166, "examples and mutate": 0.0008091139115659897, "any state action": 0.0008091139115659897, "game for": 0.0005954002535516364, "pursuer problems": 0.0007696350858963753, "its changes of": 0.0008091139115659897, "interesting differences": 0.0007696350858963753, "with a method": 0.0005851984448616567, "with less": 0.00035882246681762515, "applications to": 0.00024055787488784733, "lower limits": 0.0005954002535516364, "because the ga": 0.0008091139115659897, "represented": -5.631003093080095e-07, "path": 9.392919185154878e-05, "to identify": 0.00019597523926923044, "logarithmic": 0.00021342637953727242, "playing arena while": 0.0008091139115659897, "1 a": 9.558837313491353e-05, "a classroom": 0.000702264802583379, "8 results": 0.00052785331295456, "to provide good": 0.0005851984448616567, "changed": 9.93440056234479e-05, "learning algorithms as": 0.0008091139115659897, "lazy learner in": 0.0008091139115659897, "limit examples": 0.0007696350858963753, "700 games to": 0.0008091139115659897, "4 3 performance": 0.0006743602501766612, "connectionist approach": 0.0013256821687110331, "e but": 0.00048296474811893784, "are updated based": 0.0007417488271393706, "changes": 9.580437439691832e-06, "two genetic operators": 0.0008091139115659897, "probability of being": 0.0005226282087022614, "for robot control": 0.0007417488271393706, "on genetic": 0.0009659294962378757, "the search": 0.0004577321498458149, "database given": 0.0006131469602829721, "quite well for": 0.0007023330300003208, "possibly different": 0.0004938405038742361, "in the performance": 0.0008638080474426554, "vector of three": 0.0008091139115659897, "question of": 0.0005619362024632697, "tac toe": 0.0006628410843555166, "such a teacher": 0.0008091139115659897, "sweeping training agents": 0.0008091139115659897, "difficult for the": 0.0005393947462253054, "of self": 0.00035027405940034004, "one is learning": 0.0008091139115659897, "learn better than": 0.0008091139115659897, "step in the": 0.00035449346454352723, "one algorithm to": 0.0007417488271393706, "the lazy learner": 0.0016182278231319793, "would": -0.0021705444922222655, "method genetic": 0.0007696350858963753, "generating a random": 0.0006526576017704936, "angle and speed": 0.0008091139115659897, "al 1983 demonstrated": 0.0008091139115659897, "noting": 0.00017127786952990064, "the ga then": 0.0008091139115659897, "to q": 0.0003072722989859923, "attributes in instance": 0.0008091139115659897, "examples was": 0.000567383102523159, "k nn it": 0.0008091139115659897, "k nn is": 0.002427341734697969, "learning methods should": 0.0008091139115659897, "an agent to": 0.0005851984448616567, "real euclidean": 0.0006131469602829721, "plan is": 0.0004779464664686347, "we wish": 0.00024507456027777314, "figure 3 shows": 0.00032641850536544673, "is no": 7.228784639209104e-05, "size of": 0.00025552855412633025, "excellent": 0.0004463937473028437, "pursuer task relative": 0.0008091139115659897, "plan in": 0.0005363412876789271, "trials 5": 0.0007696350858963753, "programming robots using": 0.0008091139115659897, "must": -0.0016697063703960766, "figure 1": 0.0001043703050907286, "ga so that": 0.0008091139115659897, "the combined use": 0.0007023330300003208, "tomek devijver 1986": 0.0008091139115659897, "they anticipate": 0.000702264802583379, "good examples for": 0.0008091139115659897, "the changing": 0.00046009310747955083, "call a set": 0.0006349209434580451, "was given": 0.0003489161923333023, "learning also": 0.000702264802583379, "characterizing these delayed": 0.0008091139115659897, "players that": 0.0005803901647646488, "the variance": 0.0003374403959319754, "pursuers e": 0.0007696350858963753, "being that": 0.0004349818647972793, "correct because": 0.0005954002535516364, "where q": 0.0003462531725087664, "action prioritized": 0.0007696350858963753, "learns the": 0.0005200422895505865, "perfect performance with": 0.0008091139115659897, "related research gordon": 0.0008091139115659897, "evader b two": 0.0008091139115659897, "improve until": 0.001404529605166758, "lasts for": 0.0005954002535516364, "e at": 0.0003748850085915968, "in the early": 0.001752981446232138, "4 the": 8.945603531807077e-05, "control action": 0.0006628410843555166, "to accomplish we": 0.0007417488271393706, "outcome of": 0.00035165014402826746, "where the behaviors": 0.0008091139115659897, "figure 3": 0.00014425339947978373, "teacher to": 0.000634859264718638, "problems in": 0.000357645532212096, "end": -0.00019907598507042207, "and genetic": 0.0011607803295292977, "conclusions this study": 0.0008091139115659897, "p and e": 0.0005524148804057065, "used to accelerate": 0.0006526576017704936, "a discount factor": 0.0007023330300003208, "the question of": 0.0006790087439311421, "set of tests": 0.0006069246369921007, "1990 studied the": 0.0008091139115659897, "widespread": 0.00029210341667957533, "a success rate": 0.0007023330300003208, "problems is": 0.0003315762308313901, "game to": 0.001269718529437276, "size are": 0.0004074652591731264, "these problems we": 0.0005128575980484463, "little has": 0.0011908005071032729, "outperformed the": 0.0005456354281782176, "have to": 0.0001076644253353967, "ball in": 0.0005559058853301298, "method alone": 0.001404529605166758, "completely surprising": 0.0007696350858963753, "nn alone with": 0.0008091139115659897, "state we must": 0.0008091139115659897, "efficient memory": 0.0005559058853301298, "difficulty achieving": 0.0007696350858963753, "classes and eliminates": 0.0008091139115659897, "on 100": 0.0010912708563564353, "parallel": -3.8984107909111434e-05, "as chess but": 0.0008091139115659897, "the large continuous": 0.0008091139115659897, "arithmetic mean": 0.0005060701527920558, "form of the": 0.0002916385948209471, "speed of": 0.0011295664551273514, "the early": 0.0011910677408124614, "bootstrap": 0.0004098599033682474, "problem could be": 0.0005334812968668691, "missile we initially": 0.0008091139115659897, "kd trees in": 0.0008091139115659897, "100 games": 0.0015392701717927505, "complexity": -4.81077360509967e-05, "algorithms": -0.0037159967416739966, "now achieving 91": 0.0008091139115659897, "by the previous": 0.00045745222770795314, "we began by": 0.0013053152035409873, "by letting the": 0.0005851984448616567, "first order": 0.0002371636759458836, "been using neural": 0.0008091139115659897, "particular we began": 0.0008091139115659897, "know the": 0.0002541283390836954, "embedded linear programming": 0.0008091139115659897, "temporal difference methods": 0.0007023330300003208, "comments and ideas": 0.0007417488271393706, "no turn of": 0.0008091139115659897, "were good": 0.000702264802583379, "decision problems to": 0.0007023330300003208, "over": -0.0006002982387050222, "behavior on the": 0.0005954580987137418, "able to find": 0.00044501940255663815, "expects": 0.00032491886531992714, "single set": 0.0005060701527920558, "a reinforcement connectionist": 0.0016182278231319793, "evades the": 0.0007696350858963753, "the angle defined": 0.0007417488271393706, "foundation under grant": 0.0004382453615580345, "it evaluates": 0.0005200422895505865, "by solving a": 0.00045745222770795314, "p2 run out": 0.0008091139115659897, "are summarized": 0.0003063720986511328, "known editing algorithm": 0.0008091139115659897, "e escapes and": 0.0008091139115659897, "same payoff": 0.0007696350858963753, "match would be": 0.0008091139115659897, "is determined as": 0.0005176213124249083, "approach to": 0.000763285919457377, "probability of": 0.0006403413378675597, "the difficulty of": 0.0007894497301830917, "markovian problems can": 0.0008091139115659897, "associated with each": 0.000977093330659494, "provide examplars to": 0.0008091139115659897, "scale up the": 0.0006526576017704936, "x a is": 0.0005524148804057065, "general and pursuit": 0.0008091139115659897, "rate our": 0.0006131469602829721, "to assist": 0.00042590150453082544, "gll init": 0.0007696350858963753, "continuously in time": 0.0007417488271393706, "work supported in": 0.0005851984448616567, "is passed": 0.0003423836492878316, "and needed an": 0.0008091139115659897, "permitted to": 0.0004004979458675273, "these delayed reinforcement": 0.0008091139115659897, "data selecting typical": 0.0008091139115659897, "pursuit game studied": 0.0008091139115659897, "most striking difference": 0.0007023330300003208, "turn angle": 0.005387445601274626, "that point": 0.0006109589850943084, "and subramanian 1993a": 0.0008091139115659897, "ebl to incorporate": 0.0008091139115659897, "aircraft used by": 0.0008091139115659897, "navigating a": 0.000702264802583379, "each time step": 0.0012398424170280884, "robot control prioritized": 0.0008091139115659897, "of escape": 0.000634859264718638, "developing autonomous": 0.0007696350858963753, "5a shows": 0.000702264802583379, "routing are using": 0.0008091139115659897, "to represent": 0.00018062149021171034, "train on its": 0.0007417488271393706, "task was": 0.0009201862149591017, "complete lookup": 0.0007696350858963753, "comments and": 0.0003374403959319754, "of updating mccallum": 0.0008091139115659897, "algorithm was a": 0.0007417488271393706, "strategy of the": 0.0005524148804057065, "stores up to": 0.0008091139115659897, "monitoring and": 0.00044497617160632185, "two pursuers one": 0.0008091139115659897, "state the actions": 0.0007417488271393706, "fitness": 0.0038327412130901265, "robot to navigate": 0.0016182278231319793, "problem of determining": 0.00042987704457580605, "several robot": 0.000702264802583379, "the optimal strategy": 0.0016181842386759166, "30 000 games": 0.0008091139115659897, "learn rapidly in": 0.0008091139115659897, "diana": 0.0004882050609253128, "with the": 1.900669787064707e-05, "is related": 0.0002627707973273995, "pedestrian that is": 0.0008091139115659897, "and 30 000": 0.0008091139115659897, "action comparator selects": 0.0008091139115659897, "learning solutions to": 0.0008091139115659897, "tasks the stored": 0.0008091139115659897, "are normalized": 0.0004074652591731264, "combining": 0.00024796738709223666, "control problems that": 0.0007417488271393706, "capable of": 0.0005279509273846665, "information since our": 0.0008091139115659897, "simulated aircraft used": 0.0008091139115659897, "of whether it": 0.0005954580987137418, "the ga with": 0.0007417488271393706, "one of those": 0.0004919901420568756, "yield this value": 0.0008091139115659897, "around 95 evasion": 0.0008091139115659897, "we hypothesized k": 0.0008091139115659897, "they have": 0.00038657240786145334, "game we can": 0.0008091139115659897, "method to": 0.0002069735289986681, "might be": 0.00048451944950885433, "back propagation algorithm": 0.0007023330300003208, "with lazy": 0.001904577794155914, "mistake this": 0.0006628410843555166, "relatively simple": 0.00037664034839981597, "quickly than": 0.0005128077770266814, "bad examples if": 0.0008091139115659897, "to the direction": 0.0005334812968668691, "which is consistent": 0.0004958241803403253, "perception": 0.0005522017294221014, "further gll remained": 0.0008091139115659897, "which makes the": 0.00046866225128631864, "more details of": 0.0006199211760863129, "are directed toward": 0.0008091139115659897, "requirements without": 0.0006628410843555166, "ever pass": 0.0007696350858963753, "problems learning": 0.0006628410843555166, "figure 5a shows": 0.0007417488271393706, "also has eight": 0.0008091139115659897, "ga then": 0.0007696350858963753, "players friedman 1971": 0.0008091139115659897, "game our experiments": 0.0008091139115659897, "backgammon an experiment": 0.0008091139115659897, "credit assignment problem": 0.0007417488271393706, "every action taken": 0.0008091139115659897, "the ga recognizing": 0.0008091139115659897, "formulation of the": 0.0003720615030496811, "bounds shift": 0.0007696350858963753, "colombetti": 0.0014043931768418264, "during the lazy": 0.0008091139115659897, "performance after 15": 0.0008091139115659897, "for memory based": 0.0008091139115659897, "selection for plans": 0.0008091139115659897, "enough to hit": 0.0007417488271393706, "already": -3.442327537533579e-05, "best performance of": 0.0012398423521726258, "taken in these": 0.0008091139115659897, "the ga": 0.029599898402997087, "state variables correspond": 0.0008091139115659897, "games which": 0.0005954002535516364, "before the": 0.00029119338343628926, "best performance on": 0.0006743602501766612, "primary": 0.00011515664523045955, "labeled with its": 0.0008091139115659897, "game then e": 0.0008091139115659897, "paper describes": 0.0003436573962650119, "learned very rapidly": 0.0008091139115659897, "of rules a": 0.0006743602501766612, "classifies each": 0.000634859264718638, "database for": 0.0008699637295945586, "based control": 0.0004642630166224529, "produce better": 0.0004938405038742361, "environment rather": 0.0007696350858963753, "lazy variant of": 0.0016182278231319793, "brings to": 0.000567383102523159, "level for": 0.0003859053049699601, "performance though": 0.0006628410843555166, "usually occurred after": 0.0008091139115659897, "actions were correct": 0.0008091139115659897, "to improve until": 0.0014834976542787413, "rl problems": 0.0007696350858963753, "approach k nearest": 0.0016182278231319793, "some goal or": 0.0008091139115659897, "too": -6.194610874384444e-06, "car i": 0.000702264802583379, "measure p1 and": 0.0008091139115659897, "to 50 of": 0.0006199211760863129, "rule discovery": 0.0013256821687110331, "70 scaled linearly": 0.0008091139115659897, "of the tests": 0.0005524148804057065, "important for": 0.0005207998951859358, "toe": 0.0005127579656835996, "fails to evade": 0.0008091139115659897, "selected the": 0.0003697942966553643, "system of first": 0.0008091139115659897, "centered": 0.00044809657392201705, "ga instead of": 0.0008091139115659897, "reinforcement tasks": 0.0007696350858963753, "took": 0.0003799680027415508, "assuming optimal play": 0.0008091139115659897, "task a closer": 0.0008091139115659897, "or penalty": 0.001404529605166758, "store almost": 0.0007696350858963753, "of this task": 0.0005851984448616567, "the more striking": 0.0008091139115659897, "most common": 0.0003128408899145216, "demonstrate significant": 0.0006628410843555166, "we decided to": 0.00048474305809383046, "action regardless of": 0.0008091139115659897, "will learn": 0.0006628410843555166, "neighbor techniques to": 0.0008091139115659897, "to match its": 0.0007023330300003208, "of self learning": 0.0007417488271393706, "the most likely": 0.00046289837369057756, "game typically gas": 0.0008091139115659897, "co learning": 0.0007696350858963753, "already exists": 0.00046861672357587705, "that knew the": 0.0008091139115659897, "examples stored here": 0.0008091139115659897, "classes": 0.00020993024821000397, "was still": 0.0014488942443568135, "way that pruning": 0.0008091139115659897, "with performance was": 0.0008091139115659897, "task at": 0.0009659294962378757, "smoother indicating": 0.0007696350858963753, "a small set": 0.0004051279487445566, "learning tolerating": 0.0007696350858963753, "steps and all": 0.0008091139115659897, "made a mistake": 0.0006349209434580451, "generations for the": 0.0007023330300003208, "fashion": 0.00011515664523045955, "are identical to": 0.0004259428823122818, "surface for": 0.0005363412876789271, "ran": 0.000381268033325017, "pursuers in our": 0.0008091139115659897, "dogfighting": 0.0007021965884209132, "show that it": 0.0006873815675025808, "watkins 1990 millan": 0.0008091139115659897, "such simple games": 0.0008091139115659897, "outperforms": 0.00023018634469504555, "action can be": 0.0005759152096655707, "t k a": 0.0007417488271393706, "task as": 0.00044153169724958527, "nature these": 0.0007696350858963753, "examples is difficult": 0.0008091139115659897, "of this paper": 0.00015285645804524235, "examples are used": 0.0007023330300003208, "variable as follows": 0.0007023330300003208, "and therefore provided": 0.0007417488271393706, "relatively": 0.00013537045455171693, "they found": 0.00048296474811893784, "escape because of": 0.0008091139115659897, "1991 has applied": 0.0008091139115659897, "1968": 0.00044493294905444163, "continuously they addressed": 0.0008091139115659897, "will be selected": 0.0005456884385180774, "respect to": 8.739178576602872e-05, "possible to design": 0.0005393947462253054, "1963": 0.0013144806721272996, "brings to the": 0.0006526576017704936, "that was": 0.00023668683372858498, "of soccer he": 0.0008091139115659897, "x a": 0.00024405533553294298, "playing at": 0.0007696350858963753, "and attempted": 0.0005954002535516364, "a location where": 0.0007417488271393706, "capable of solving": 0.0006743602501766612, "counter a": 0.000567383102523159, "though": 6.66083034389534e-05, "of curvature": 0.00316711987772736, "the tasks we": 0.0007417488271393706, "for evasive": 0.0023089052576891257, "1992 salzberg 1991": 0.0008091139115659897, "smoke is released": 0.0008091139115659897, "object of analyzing": 0.0008091139115659897, "can think of": 0.0004360863081445778, "game s characteristics": 0.0008091139115659897, "sharing rate": 0.0007696350858963753, "smoke 4": 0.0007696350858963753, "games require the": 0.0008091139115659897, "ahead but they": 0.0008091139115659897, "trying to pursue": 0.0008091139115659897, "than the ga": 0.004045569557829949, "the rule of": 0.0005674382257236372, "single set of": 0.0005759152096655707, "over later the": 0.0008091139115659897, "highly trained": 0.000702264802583379, "now see": 0.0005200422895505865, "simulator passes": 0.000702264802583379, "always superb exceeding": 0.0008091139115659897, "a wide": 0.0004139470579973362, "is to determine": 0.0003436907837512904, "has a": 9.296488111969191e-05, "consists of 20": 0.0006743602501766612, "to perform": 0.0010408541382258838, "the car i": 0.0008091139115659897, "another possible": 0.00042590150453082544, "best performance": 0.0014235716518863986, "solutions dependent on": 0.0008091139115659897, "and intelligent": 0.0005128077770266814, "random": 0.0004588403828452303, "component of": 0.00020011885135250967, "of differential games": 0.0016182278231319793, "action for example": 0.0007023330300003208, "maneuvers game": 0.0023089052576891257, "shows how well": 0.0007417488271393706, "any state": 0.0003878648638474452, "the future": 0.00023202315752870006, "solutions": 0.00019445752159466873, "such an environment": 0.0005596382660342995, "3 q": 0.0005060701527920558, "the chromosome corresponding": 0.0008091139115659897, "take this study": 0.0008091139115659897, "added to the": 0.00026501519119001733, "of traditional game": 0.0008091139115659897, "pursuer problem the": 0.0008091139115659897, "1992 salzberg": 0.0007696350858963753, "randomly evaded": 0.0007696350858963753, "15 points whereas": 0.0008091139115659897, "the current": 0.0005003932202174613, "catching q": 0.0007696350858963753, "a threshold range": 0.0008091139115659897, "computed as follows": 0.0004360863081445778, "binary attributes": 0.000634859264718638, "the mean strength": 0.0008091139115659897, "this approach": 0.00038396615743658104, "developing strategies": 0.000702264802583379, "and ideas": 0.0005456354281782176, "s game called": 0.0008091139115659897, "prioritized sweeping reinforcement": 0.0008091139115659897, "discrete classes": 0.0007696350858963753, "method clouse and": 0.0008091139115659897, "they begin the": 0.0007417488271393706, "and the range": 0.0005674382257236372, "complex domains": 0.0006131469602829721, "mistake this approach": 0.0008091139115659897, "here has": 0.0004997652289300559, "135 they can": 0.0008091139115659897, "arithmetic mean of": 0.0006069246369921007, "though is the": 0.0008091139115659897, "ebl to": 0.0007696350858963753, "as evasive maneuvers": 0.0008091139115659897, "described further": 0.000702264802583379, "has also": 0.00025981503993729386, "despite": 0.00015431877434841996, "several algorithms": 0.0004288371693587632, "mean payoff for": 0.0008091139115659897, "the problem": 0.0003589598831892163, "pairs in the": 0.0016181842386759166, "to these": 0.00019462362878394347, "through 500": 0.0007696350858963753, "maneuvers lazy": 0.0007696350858963753, "competing control laws": 0.0008091139115659897, "locations on": 0.0005363412876789271, "that a combined": 0.0007023330300003208, "have the correct": 0.0005759152096655707, "algorithms using local": 0.0008091139115659897, "learning phase": 0.000567383102523159, "other areas": 0.00046861672357587705, "study whether": 0.000702264802583379, "twice": 0.00012400968436223982, "to store almost": 0.0008091139115659897, "decreases with as": 0.0008091139115659897, "in neural networks": 0.0006349209434580451, "evasion while": 0.0007696350858963753, "strategy the player": 0.0008091139115659897, "the selected action": 0.0008091139115659897, "the question": 0.0004481401038009682, "opponents finally tesauro": 0.0008091139115659897, "difficult learning": 0.0006628410843555166, "resulting strategies": 0.0007696350858963753, "learning proceeds as": 0.0008091139115659897, "nn was used": 0.0008091139115659897, "1960s": 0.0005455824281366266, "teacher is": 0.0013256821687110331, "produce by": 0.0007696350858963753, "its strategy to": 0.0008091139115659897, "a range": 0.000541692813051437, "each other": 0.00032459326552842805, "car the": 0.0026513643374220662, "learning approach using": 0.0008091139115659897, "irrelevant and": 0.0005559058853301298, "information in order": 0.0005596382660342995, "embedded in": 0.0003238859962113274, "games the": 0.003971681717662112, "all the examples": 0.0005334812968668691, "both benefit": 0.0007696350858963753, "might escape because": 0.0008091139115659897, "of the game": 0.006076563684462772, "this study one": 0.0008091139115659897, "pursuers as": 0.0007696350858963753, "games stored where": 0.0008091139115659897, "the corresponding range": 0.0007417488271393706, "additional information about": 0.0005524148804057065, "combining different types": 0.0008091139115659897, "classifier systems and": 0.0016182278231319793, "to be more": 0.0003167547290380763, "to it": 0.00021905004730177056, "problems frequently modeled": 0.0008091139115659897, "monitor the performance": 0.0007023330300003208, "approach": -0.00624812897090657, "space in the": 0.00042031844251562157, "discovery": 0.0004300014351749534, "that poor examples": 0.0008091139115659897, "with only 10": 0.0008091139115659897, "achieving 91 evasion": 0.0008091139115659897, "delayed reinforcement": 0.004617810515378251, "or loses": 0.0007696350858963753, "optimal control theory": 0.0007023330300003208, "actions taken by": 0.0011703968897233135, "twice as many": 0.0005176213124249083, "however": -0.001962484213688086, "problem requires rules": 0.0008091139115659897, "law to": 0.0005456354281782176, "a system": 0.0005986367595764342, "the learning process": 0.0005128575980484463, "it could get": 0.0008091139115659897, "on 10 000": 0.0014834976542787413, "level of": 0.0005105170394252058, "samuel for": 0.0007696350858963753, "regain speed": 0.0007696350858963753, "play othello": 0.0007696350858963753, "to the differential": 0.0006526576017704936, "improve": 8.631151291999155e-05, "faced": 0.0002890118751735629, "et al against": 0.0008091139115659897, "been shown to": 0.0003378762358657853, "three fold": 0.000567383102523159, "examples one of": 0.0007417488271393706, "achieved 98": 0.0007696350858963753, "simulator the": 0.00045224640365867626, "approach the examples": 0.0007417488271393706, "players": 0.006285892406614418, "games": 0.022372082291442063, "ga with lazy": 0.0008091139115659897, "and p s": 0.0005334812968668691, "the 85": 0.000702264802583379, "variance": 0.00019260399189191792, "are three": 0.000259233183784521, "1 bootstrapping": 0.0007696350858963753, "players must learn": 0.0008091139115659897, "olsder": 0.0007021965884209132, "learning with a": 0.0006199211760863129, "solve k nn": 0.0008091139115659897, "other hand if": 0.00031098203868469185, "temporally successive actions": 0.0008091139115659897, "are three fold": 0.0007417488271393706, "solve our difficult": 0.0008091139115659897, "database using the": 0.0006743602501766612, "on their own": 0.0010913768770361549, "loses at": 0.000702264802583379, "ball in their": 0.0008091139115659897, "k 0": 0.00025981503993729386, "k 1": 0.0003717092273294047, "of being": 0.00028026328662092783, "examples this": 0.0009558929329372694, "and then": 0.000518493642243392, "base by": 0.0006131469602829721, "developed their prioritized": 0.0008091139115659897, "algorithm for": 0.00026423339016708067, "essentially e just": 0.0008091139115659897, "small memory requirements": 0.0007417488271393706, "updated based on": 0.0006199211760863129, "to adapt q": 0.0008091139115659897, "s direction when": 0.0008091139115659897, "ga achieved above": 0.0008091139115659897, "the pursuers speeds": 0.0008091139115659897, "zigzags": 0.0007021965884209132, "was only around": 0.0008091139115659897, "been": -0.004179948911084608, "quickly": 0.0002538468641389411, "at 80": 0.0006628410843555166, "real euclidean n": 0.0008091139115659897, "to find a": 0.0002545233354905152, "game the rules": 0.0008091139115659897, "to theoretical": 0.0007696350858963753, "expected": 4.50802367982074e-05, "k nn from": 0.0008091139115659897, "had difficulty": 0.0006628410843555166, "history information": 0.0005200422895505865, "skalak": 0.0006347975979615015, "of e and": 0.0004882999224935485, "assigned we do": 0.0008091139115659897, "simple games as": 0.0008091139115659897, "2060100 percent": 0.0007696350858963753, "the details": 0.0002134471126225199, "using these": 0.00027612768624444016, "a special": 0.00016496272185669375, "which examples": 0.0013256821687110331, "learning and teaching": 0.0008091139115659897, "quickly exceeds": 0.0007696350858963753, "that the problem": 0.0003554472439844678, "between p and": 0.0005039721952628732, "sequence of moves": 0.0006526576017704936, "catch": 0.0006924390787382693, "maximally": 0.0007205687450109536, "could produce by": 0.0008091139115659897, "pairs learning": 0.0007696350858963753, "increases so does": 0.0006526576017704936, "planning game": 0.0007696350858963753, "good ones": 0.000702264802583379, "eventually achieved": 0.0007696350858963753, "additional complexity td": 0.0008091139115659897, "experiments reported here": 0.0006069246369921007, "the formative stages": 0.0008091139115659897, "n": -0.002049299516841237, "randomly if": 0.000702264802583379, "since our implementation": 0.0007023330300003208, "literature the most": 0.0007417488271393706, "the expected payoff": 0.0007417488271393706, "gll performed better": 0.0008091139115659897, "based on": 0.00010316155400187935, "stored here": 0.0007696350858963753, "erratically": 0.0006347975979615015, "procedure": -1.1839710306851567e-05, "1 e": 0.0002921317927643509, "temporal differences": 0.0013256821687110331, "on an": 0.00013621739730095125, "escape from two": 0.0008091139115659897, "s q value": 0.0008091139115659897, "were then": 0.0004004979458675273, "we took combined": 0.0008091139115659897, "201 233": 0.000702264802583379, "the game i": 0.0014834976542787413, "action or": 0.0005060701527920558, "gle achieved 86": 0.0008091139115659897, "graph are": 0.00037315955974098747, "rithms lamarkian": 0.0007696350858963753, "first order differential": 0.0007417488271393706, "a difficult class": 0.0008091139115659897, "learning algorithms and": 0.0006349209434580451, "move is": 0.0004779464664686347, "question is": 0.00027345521625013827, "has eight": 0.0005363412876789271, "nn after": 0.0007696350858963753, "instance database": 0.0007696350858963753, "performance though much": 0.0008091139115659897, "suggest": 0.00011012176867211072, "information must": 0.00048296474811893784, "gordon john grefenstette": 0.0008091139115659897, "the effects on": 0.0005954580987137418, "how a lazy": 0.0008091139115659897, "classified are deleted": 0.0008091139115659897, "complex": 3.54832707327821e-05, "was stored in": 0.0007023330300003208, "evading the pursuers": 0.0008091139115659897, "several": -0.0010914112101107192, "bounds followed by": 0.0007417488271393706, "a combining": 0.0005954002535516364, "we next set": 0.0008091139115659897, "agent is": 0.0008830633944991705, "resulting action to": 0.0008091139115659897, "makes sense": 0.00036183856746138145, "task in fact": 0.0008091139115659897, "follow the": 0.00025636849908832897, "a combining different": 0.0008091139115659897, "games one exception": 0.0008091139115659897, "can capture in": 0.0008091139115659897, "for delayed": 0.000702264802583379, "is somewhat inflated": 0.0008091139115659897, "much smoother": 0.0006628410843555166, "the ga experiments": 0.0008091139115659897, "700 examples are": 0.0008091139115659897, "players this means": 0.0008091139115659897, "also gave": 0.00052785331295456, "a game clock": 0.0008091139115659897, "neighbor our bootstrapping": 0.0008091139115659897, "make a long": 0.0008091139115659897, "reached 60 evasion": 0.0008091139115659897, "one possible future": 0.0008091139115659897, "learning rather": 0.000702264802583379, "of tomek devijver": 0.0008091139115659897, "holland 1975": 0.0006628410843555166, "not storing many": 0.0008091139115659897, "tasks we designed": 0.0008091139115659897, "time and then": 0.0005456884385180774, "action asymptotic": 0.0007696350858963753, "the key idea": 0.00041851198115822714, "each generation thus": 0.0008091139115659897, "tracking ramsey and": 0.0008091139115659897, "away indicates that": 0.0008091139115659897, "10 000 games": 0.0007417488271393706, "several agents": 0.000634859264718638, "in overall": 0.00048825248710181613, "to demonstrate": 0.0005071504162048275, "one evader": 0.0015392701717927505, "the game s": 0.0008091139115659897, "the database i": 0.0008091139115659897, "ga to generate": 0.0008091139115659897, "plan grefenstette": 0.0007696350858963753, "be modeled": 0.00029776693520311534, "98 100 evasion": 0.0008091139115659897, "actions correspond to": 0.0007023330300003208, "known as editing": 0.0008091139115659897, "anonymous reviewers of": 0.0006743602501766612, "rules a plan": 0.0008091139115659897, "simultaneous learning by": 0.0008091139115659897, "even when achieved": 0.0008091139115659897, "action pairs": 0.0049158536180836515, "a limited time": 0.0006743602501766612, "be unable to": 0.0005393947462253054, "one example": 0.0003697942966553643, "in rule": 0.0009659294962378757, "and action prioritized": 0.0008091139115659897, "decision problems": 0.002174909323986396, "the early phases": 0.0006349209434580451, "the feature": 0.00036183856746138145, "task as a": 0.0006526576017704936, "of the database": 0.0004404523980181757, "are used to": 0.0002129474767449426, "5a": 0.00038020813619878184, "games differential": 0.0007696350858963753, "then show how": 0.0004882999224935485, "5b": 0.00036975837685967165, "the game k": 0.0008091139115659897, "remained in the": 0.0008091139115659897, "sweeping reinforcement learning": 0.0008091139115659897, "frame of": 0.00042590150453082544, "therefore modified the": 0.0008091139115659897, "5 2": 0.0002323042745963919, "approach discussed": 0.0005803901647646488, "limit feedback": 0.0007696350858963753, "is a": 5.068395099954657e-06, "the game e": 0.0016182278231319793, "k nn one": 0.0008091139115659897, "perform as well": 0.0004779929005953682, "good function approximators": 0.0008091139115659897, "machine learning and": 0.0005393947462253054, "better for": 0.00040276699958546587, "performed moderately": 0.0007696350858963753, "fleeing two pursuers": 0.0008091139115659897, "of rule": 0.00040989971878532225, "rules we can": 0.0006743602501766612, "rules in which": 0.0006199211760863129, "a j": 0.00026397546369233323, "in particular we": 0.0005060987284035323, "of characterizing these": 0.0008091139115659897, "algorithm in": 0.0004948881655700813, "learning initially we": 0.0008091139115659897, "determine the reward": 0.0008091139115659897, "moves where": 0.000702264802583379, "50": 0.00043173463727981667, "52": 0.0001342177283211427, "tasks they have": 0.0008091139115659897, "two players called": 0.0007417488271393706, "are markov": 0.000634859264718638, "algorithm is": 0.00011793748361323856, "assume that": 0.0001168770090966306, "the next phase": 0.0005524148804057065, "these states": 0.00043186206685094484, "discounted reward": 0.0007696350858963753, "a q": 0.00035165014402826746, "actual surface": 0.0005954002535516364, "extended it": 0.000702264802583379, "on the homicidal": 0.0008091139115659897, "car and the": 0.002225246481418112, "envision": 0.00034888230052248793, "system can produce": 0.0008091139115659897, "first and to": 0.0007417488271393706, "with the question": 0.0006069246369921007, "successfully": 0.0004146464772121431, "after an additional": 0.0007417488271393706, "or perhaps a": 0.0006526576017704936, "al 1990 and": 0.0006743602501766612, "learning to learn": 0.0008091139115659897, "games where e": 0.0008091139115659897, "escape": 0.0024053681068542227, "lookup table our": 0.0008091139115659897, "machine learning algorithms": 0.0005674382257236372, "metagamer": 0.0014043931768418264, "averaging process might": 0.0008091139115659897, "learner needs to": 0.0007023330300003208, "own thus": 0.000702264802583379, "resulted in a": 0.00046289837369057756, "do run": 0.0006131469602829721, "plan can be": 0.0006349209434580451, "used for future": 0.0007417488271393706, "database full": 0.0007696350858963753, "salzberg 1993 a": 0.0008091139115659897, "payoff the q": 0.0008091139115659897, "bounds shift closer": 0.0008091139115659897, "genetic algorithm this": 0.0007023330300003208, "nn rather": 0.0007696350858963753, "successive actions": 0.0007696350858963753, "a continuous": 0.0002831104418951413, "stored instances we": 0.0008091139115659897, "start the learning": 0.0008091139115659897, "eager learning": 0.0023089052576891257, "initially figure": 0.000702264802583379, "defense mechanisms": 0.000702264802583379, "reward or": 0.000702264802583379, "applied q": 0.000702264802583379, "deleted": 0.0004348026843046688, "and different": 0.0003338822091906335, "experiences for": 0.0007696350858963753, "one complication": 0.000702264802583379, "operators to": 0.00044497617160632185, "in order to": 0.00022671104020418245, "is the angle": 0.0005226282087022614, "discount": 0.00041491364968285823, "numerous important control": 0.0008091139115659897, "is awarded immediately": 0.0008091139115659897, "almost all": 0.0002727971730761859, "applied a": 0.0009659294962378757, "by wilson 1972": 0.0008091139115659897, "changed as editing": 0.0008091139115659897, "space is reduced": 0.0007023330300003208, "permitted": 0.00023384353125882718, "plug": 0.0004004590436872584, "rules within": 0.000634859264718638, "of solutions": 0.0006542249523968281, "neighbor applications": 0.0007696350858963753, "future direction is": 0.0007417488271393706, "in contrast a": 0.0005083144306061808, "that still play": 0.0008091139115659897, "get stuck": 0.00052785331295456, "plus": 0.00022408435804161908, "algo": 0.00021902876997808896, "rules using": 0.0015384233310800442, "steadily": 0.00043182011813148384, "population are": 0.000702264802583379, "prioritized sweeping algorithm": 0.0008091139115659897, "of running": 0.0003839830887362287, "wilson in": 0.0007696350858963753, "e at the": 0.0005524148804057065, "aha": 0.0014991500534063125, "state information since": 0.0008091139115659897, "fixed playing": 0.0007696350858963753, "presence": 6.764544207817014e-05, "which examples were": 0.0008091139115659897, "the primary cause": 0.0006743602501766612, "using neural network": 0.0007417488271393706, "the focus": 0.0003037165348615905, "genetic operators or": 0.0008091139115659897, "it has": 8.653713361660332e-05, "1968 basically": 0.0007696350858963753, "is the predicted": 0.0006526576017704936, "examples to": 0.0014858519175779664, "called the": 0.00014279274345842474, "and determined": 0.0005954002535516364, "accounted for the": 0.0006199211760863129, "comparable in": 0.00048825248710181613, "for this problem": 0.0003386870959862882, "rely": 0.000148919836752868, "possible to use": 0.0004020439867656976, "were normalized to": 0.0007417488271393706, "stuck": 0.0003207251598139373, "anderson": 0.00032708070228134765, "applied samuel": 0.0007696350858963753, "our lazy": 0.000634859264718638, "control of": 0.0005647832275636757, "sharp turns into": 0.0008091139115659897, "pedestrian the radius": 0.0008091139115659897, "successful at": 0.0005456354281782176, "head": 0.00017644431332732222, "variable as": 0.0004349818647972793, "level above 70": 0.0008091139115659897, "attempted": 0.00024556375149618344, "differences": 0.0004716943051154901, "games such as": 0.0012698418869160901, "of moves": 0.00048296474811893784, "control tasks tolerating": 0.0008091139115659897, "simply as": 0.0003898632748579793, "advice with": 0.000702264802583379, "e can adjust": 0.0008091139115659897, "game then": 0.001404529605166758, "removed": 0.00010225925052666218, "performance is": 0.0002508495615030361, "of relevant": 0.0003839830887362287, "applied to state": 0.0007417488271393706, "therefore had to": 0.0007023330300003208, "are difficult to": 0.00041851198115822714, "evader figure": 0.0007696350858963753, "versions": 9.363335634015079e-05, "truly combined learning": 0.0008091139115659897, "were edited when": 0.0008091139115659897, "randomly until e": 0.0008091139115659897, "prematurely": 0.00041491364968285823, "better solutions": 0.0005200422895505865, "examples from the": 0.0005524148804057065, "stored where": 0.0007696350858963753, "and teaching markov": 0.0008091139115659897, "pairs for that": 0.0008091139115659897, "able to work": 0.0006526576017704936, "points shown": 0.0005803901647646488, "in each": 9.276369913012809e-05, "the range difference": 0.0008091139115659897, "multiple solutions": 0.0005128077770266814, "games optimal strategies": 0.0008091139115659897, "different ones": 0.000702264802583379, "of the implementation": 0.0004051279487445566, "plotted against": 0.0004779464664686347, "reinforcement problems": 0.0023089052576891257, "an attempt to": 0.0003892305354108736, "difficult reinforcement": 0.0007696350858963753, "we then selected": 0.0007417488271393706, "systems based": 0.0008460997951443425, "to develop a": 0.00035738190863582157, "its poor performance": 0.0007417488271393706, "payoff at": 0.000702264802583379, "performance and": 0.0002445638107444049, "of learning it": 0.0008091139115659897, "lazy technique to": 0.0008091139115659897, "different abilities different": 0.0008091139115659897, "nn": 0.02233556099221778, "no": -0.002517871286220458, "extreme for example": 0.0008091139115659897, "but were": 0.00048825248710181613, "whereas": 5.157586547466611e-05, "most effectively": 0.000702264802583379, "when": -0.007205687450109536, "examples have been": 0.0005674382257236372, "actions possibly different": 0.0008091139115659897, "the methods of": 0.0004404523980181757, "setting": 3.587762054065548e-05, "1991 has": 0.000634859264718638, "papers": 0.0001498870374366185, "watkins 1989 the": 0.0008091139115659897, "performed better": 0.0014992956867901676, "they make the": 0.0006526576017704936, "nn was": 0.0015392701717927505, "tic": 0.00041491364968285823, "this paper": 4.9059413006071216e-05, "set for": 0.00025807848985967736, "e just": 0.0005954002535516364, "000 random games": 0.0008091139115659897, "with the earlier": 0.0005596382660342995, "distance between the": 0.0003634160486420408, "play for": 0.0006628410843555166, "rule form": 0.000702264802583379, "or through": 0.0004997652289300559, "consider two classes": 0.0006743602501766612, "is to guide": 0.0007417488271393706, "examples these examples": 0.0008091139115659897, "algorithm this": 0.0005874235532398661, "performance plotted": 0.0007696350858963753, "smith and": 0.0005363412876789271, "to improve": 0.0008141292437015604, "follows where lb": 0.0008091139115659897, "order to know": 0.0006349209434580451, "run beginning": 0.0007696350858963753, "genetic algorithm run": 0.0008091139115659897, "typical instances in": 0.0016182278231319793, "than k nn": 0.0008091139115659897, "and action are": 0.0007417488271393706, "faster": 7.996680341923815e-05, "population for": 0.000634859264718638, "learning algorithms take": 0.0008091139115659897, "and p2 are": 0.0008091139115659897, "how to escape": 0.0008091139115659897, "limits of the": 0.0005334812968668691, "the communication or": 0.0007417488271393706, "highly dynamic environment": 0.0007417488271393706, "robot arm to": 0.0007417488271393706, "skills that": 0.0007696350858963753, "common source": 0.0006628410843555166, "high success": 0.0006628410843555166, "classes typically classification": 0.0008091139115659897, "a game before": 0.0008091139115659897, "of p to": 0.0010787894924506108, "neighbors": 0.0015730989913525465, "angle defined by": 0.0007417488271393706, "probably represent noise": 0.0008091139115659897, "k nn table": 0.0008091139115659897, "alternation continues until": 0.0008091139115659897, "the value state": 0.0008091139115659897, "shaping genetic": 0.0007696350858963753, "focus": 8.760929839591855e-05, "learning depending on": 0.0008091139115659897, "bombs which will": 0.0008091139115659897, "decreased very": 0.0007696350858963753, "from smoke 4": 0.0008091139115659897, "and one": 0.0004884775462209363, "important for solving": 0.0007417488271393706, "takes a long": 0.0007417488271393706, "previous work recently": 0.0008091139115659897, "widrow": 0.0019043927938845048, "environments a": 0.00044854462015967935, "recharge": 0.0007021965884209132, "steps to accomplish": 0.0008091139115659897, "game the corresponding": 0.0008091139115659897, "the outcome of": 0.00040670626310009803, "0 01 regardless": 0.0008091139115659897, "based method": 0.0007604901422511093, "fold first": 0.0005559058853301298, "selection goldberg": 0.0007696350858963753, "e while e": 0.0008091139115659897, "environment": 0.0003022220143379173, "data and less": 0.0008091139115659897, "rather than constructing": 0.0007417488271393706, "as the severity": 0.0008091139115659897, "speeds with the": 0.0008091139115659897, "difference between p1": 0.0007417488271393706, "when only a": 0.0005128575980484463, "to the more": 0.0004259428823122818, "the pedestrian the": 0.0016182278231319793, "so it": 0.0002311124137898519, "finds in": 0.0005456354281782176, "rather than all": 0.0006199211760863129, "problems we are": 0.0006349209434580451, "advantage": 8.16974432922393e-06, "task specifically predictions": 0.0008091139115659897, "as strength r": 0.0008091139115659897, "nos iri 9116843": 0.0008091139115659897, "performance but": 0.00044153169724958527, "traffic control railroad": 0.0008091139115659897, "a master": 0.00048825248710181613, "and an adaptation": 0.0007023330300003208, "thus we should": 0.0006526576017704936, "entertainment industries but": 0.0008091139115659897, "can be modeled": 0.00036764690895931803, "differs from wilson": 0.0008091139115659897, "and othello pell": 0.0008091139115659897, "time help": 0.0007696350858963753, "on which one": 0.0006743602501766612, "in a similar": 0.0006194821995438194, "pedestrian isaacs": 0.0007696350858963753, "research gordon and": 0.0008091139115659897, "around obstacles considerable": 0.0008091139115659897, "their prioritized sweeping": 0.0008091139115659897, "size to a": 0.0007417488271393706, "approaches to reinforcement": 0.002427341734697969, "distinguishes it": 0.000702264802583379, "level": -0.0007438429958231343, "rules with": 0.00044854462015967935, "table 1": 0.0002615155356483293, "task the key": 0.0008091139115659897, "a single pursuer": 0.0016182278231319793, "during the game": 0.0007417488271393706, "problem and because": 0.0008091139115659897, "illustrate a common": 0.0008091139115659897, "methods usually assume": 0.0008091139115659897, "the problem of": 0.0003400054394831129, "direction much": 0.0007696350858963753, "addressed the problem": 0.0005279045957013737, "classifying the": 0.001040084579101173, "for reducing": 0.0003315762308313901, "by storing examples": 0.0007417488271393706, "as it is": 0.00029697234334182074, "against one pursuer": 0.0016182278231319793, "attempts to evade": 0.0008091139115659897, "the difficulty here": 0.0007417488271393706, "the players this": 0.0008091139115659897, "ritter method": 0.0007696350858963753, "slowed": 0.00043182011813148384, "al and the": 0.0007417488271393706, "lose speed as": 0.0008091139115659897, "of the sequence": 0.000356410000254863, "we used a": 0.0003411585969912582, "more generally": 0.00028456257763219726, "applying three learning": 0.0008091139115659897, "experiments reported": 0.00042027761111456123, "two pursuers as": 0.0008091139115659897, "rules are maximally": 0.0008091139115659897, "eliminates examples": 0.0007696350858963753, "1993b use an": 0.0008091139115659897, "the frequency with": 0.0005456884385180774, "different defense": 0.0007696350858963753, "control tasks": 0.004213588815500273, "one classic": 0.0007696350858963753, "one whitehead 1992": 0.0008091139115659897, "the antecedent": 0.0004997652289300559, "a location": 0.0004050885930083273, "is challenging": 0.0005456354281782176, "until inside s": 0.0008091139115659897, "are averaging": 0.0007696350858963753, "michael littman": 0.0006628410843555166, "and the variables": 0.0005334812968668691, "one way of": 0.00046866225128631864, "2 reaching": 0.0007696350858963753, "when action": 0.0007696350858963753, "cause problems": 0.00048825248710181613, "gll outperformed the": 0.0008091139115659897, "applying learning algorithms": 0.0007417488271393706, "logarithmic scale": 0.0004938405038742361, "children s game": 0.0008091139115659897, "the correct": 0.0012351944066423257, "work by grefenstette": 0.0008091139115659897, "is outside": 0.00043186206685094484, "another i": 0.0006131469602829721, "our approach stores": 0.0007417488271393706, "k nn figure": 0.0008091139115659897, "shifting it": 0.000702264802583379, "field being an": 0.0008091139115659897, "algorithms on": 0.0003072722989859923, "of perception": 0.0011607803295292977, "trained a": 0.0006628410843555166, "game follows": 0.0007696350858963753, "left with the": 0.0005334812968668691, "people learn": 0.0007696350858963753, "4 4 3": 0.0005226282087022614, "methods for learning": 0.0007417488271393706, "state depends only": 0.0007023330300003208, "control problems learning": 0.0008091139115659897, "a truly combined": 0.0008091139115659897, "environments an empirical": 0.0008091139115659897, "strategy prior to": 0.0008091139115659897, "the communication": 0.0002503122400467382, "then is how": 0.0007417488271393706, "the homicidal": 0.003078540343585501, "considerable research has": 0.0006743602501766612, "differences between": 0.00027345521625013827, "to solve yet": 0.0008091139115659897, "we were able": 0.0004005368556067546, "solve the evasion": 0.0008091139115659897, "their multistrategy apprach": 0.0008091139115659897, "whether it is": 0.0003766769402922088, "described below determine": 0.0008091139115659897, "one step": 0.00028239161378183786, "example to be": 0.0007417488271393706, "example can be": 0.0004882999224935485, "in other": 0.00011051502162170635, "maneuvers task as": 0.0008091139115659897, "additional complexity": 0.0004779464664686347, "the evader have": 0.0008091139115659897, "teacher or": 0.0007696350858963753, "there is no": 0.0001412703825159515, "affecting performance": 0.000567383102523159, "and fitness": 0.0006628410843555166, "to believe": 0.00042027761111456123, "even the basic": 0.0007417488271393706, "below a": 0.0003197335749799009, "reviewers of": 0.0005803901647646488, "complete lookup table": 0.0008091139115659897, "follows first assuming": 0.0008091139115659897, "some intuition": 0.0005456354281782176, "sutton 1988": 0.001404529605166758, "prey": 0.0005278020401703972, "our experiments will": 0.0008091139115659897, "memory": 0.0004535097152756728, "this has": 0.00025193193052089276, "and evaluation for": 0.0007417488271393706, "a player learning": 0.0008091139115659897, "d 1 respectively": 0.0007023330300003208, "approach robot": 0.0007696350858963753, "find any editing": 0.0008091139115659897, "would be too": 0.0005128575980484463, "strategy against itself": 0.0008091139115659897, "comparator examines": 0.0007696350858963753, "ase barto sutton": 0.0008091139115659897, "fired in a": 0.0008091139115659897, "use of both": 0.0005596382660342995, "is the set": 0.0004545354434331391, "performance was only": 0.0008091139115659897, "85 degrees": 0.0007696350858963753, "a range around": 0.0008091139115659897, "of the players": 0.0029772904935687094, "editing occurred": 0.0007696350858963753, "for all actions": 0.0008091139115659897, "to games in": 0.0008091139115659897, "modified": 0.00012263745496585564, "domain of": 0.00025524283217824665, "in complex": 0.0004349818647972793, "are determined by": 0.0007680407880016979, "a second": 0.0007046767295146618, "task relative to": 0.0008091139115659897, "reinforcement and": 0.0006628410843555166, "q table": 0.0006131469602829721, "teacher are": 0.001404529605166758, "al demonstrated that": 0.0008091139115659897, "given that poor": 0.0008091139115659897, "all other": 0.00017704790440011743, "can then": 0.0002029591594968731, "e example": 0.000634859264718638, "placements": 0.00044493294905444163, "with these": 0.00023156689856445445, "throughout its learning": 0.0008091139115659897, "performer": 0.000452202474916213, "figure": -0.0028834866818457394, "the improved efficiency": 0.0008091139115659897, "learning approaches": 0.0005559058853301298, "optimal strategies": 0.002977001267758182, "maximally general": 0.0007696350858963753, "an environment one": 0.0007417488271393706, "distance between": 0.0007246389378337016, "not completely": 0.00034757605337154215, "performed": -0.00022878151105861974, "learning sequential decision": 0.0016182278231319793, "application of": 0.00014095124829550685, "conversely": 0.00018427586060086267, "the actual surface": 0.0006526576017704936, "are shown in": 0.00023388896864953132, "to editing and": 0.0008091139115659897, "effects of perceptual": 0.0008091139115659897, "requirements": 0.00014122291822754542, "plan is a": 0.0006526576017704936, "the approach discussed": 0.0008091139115659897, "learning these results": 0.0008091139115659897, "earlier k": 0.0007696350858963753, "of games stored": 0.0008091139115659897, "1": 0, "notoriously slow": 0.000702264802583379, "helpful comments and": 0.0004747836164770488, "then the bearing": 0.0008091139115659897, "to the": 0.0, "optimize competing control": 0.0008091139115659897, "task both": 0.0007696350858963753, "must adapt": 0.0005803901647646488, "maneuvers task the": 0.0008091139115659897, "and action asymptotic": 0.0008091139115659897, "random action regardless": 0.0008091139115659897, "use samuel": 0.0007696350858963753, "lined up": 0.000702264802583379, "and different sensing": 0.0008091139115659897, "used in": 7.93637742339966e-05, "these examples": 0.0013497615837279016, "maneuvers grefenstette et": 0.0008091139115659897, "achieved 86 evasion": 0.0008091139115659897, "used it": 0.00036494662878843966, "demonstrate clearly the": 0.0008091139115659897, "effect from": 0.0005954002535516364, "rule that fired": 0.0016182278231319793, "t care": 0.0004288371693587632, "be in the": 0.0003403281695183581, "reinforcement learning has": 0.0007417488271393706, "it reached 93": 0.0008091139115659897, "techniques the combined": 0.0008091139115659897, "the primary": 0.0002357389997767706, "classroom": 0.0002657815520222347, "two players in": 0.0008091139115659897, "not usually applied": 0.0008091139115659897, "sweeping reinforcement": 0.0007696350858963753, "succeeded": 0.00038020813619878184, "clear that": 0.00038524540441563926, "to each": 0.00012034599086620945, "learning could": 0.000634859264718638, "solve difficult problems": 0.0008091139115659897, "lazy technique": 0.0007696350858963753, "tests for": 0.00035445902764197844, "both future reinforcement": 0.0008091139115659897, "representation": 2.5340880120736154e-06, "type this motivated": 0.0008091139115659897, "similar to stepwise": 0.0008091139115659897, "were successful": 0.0005559058853301298, "in the most": 0.0004240325865444586, "been generated another": 0.0008091139115659897, "be generated by": 0.00040993954193880374, "nearest neighbor algorithm": 0.0006349209434580451, "ga for one": 0.0008091139115659897, "corresponding state": 0.0005200422895505865, "13 features": 0.0006628410843555166, "is higher": 0.0003374403959319754, "bounds of": 0.000335054731187079, "teach the": 0.0006131469602829721, "generalized or specialized": 0.0008091139115659897, "it improves somewhat": 0.0008091139115659897, "for state x": 0.0008091139115659897, "during training": 0.0010912708563564353, "activities in": 0.00048825248710181613, "above and we": 0.0007417488271393706, "classified are discarded": 0.0008091139115659897, "dependent on having": 0.0008091139115659897, "a non": 0.00013621739730095125, "and because": 0.0003128408899145216, "allowed to": 0.00021782729572560684, "certain performance": 0.0006131469602829721, "be applied in": 0.0004339731734948358, "pairs our implementation": 0.0007417488271393706, "that are incorrectly": 0.0008091139115659897, "low level of": 0.0005954580987137418, "al against one": 0.0008091139115659897, "to counter": 0.0005456354281782176, "for learning to": 0.0006743602501766612, "in instance based": 0.002427341734697969, "out to improve": 0.0008091139115659897, "e successfully": 0.0007696350858963753, "following rule": 0.00042027761111456123, "random actions with": 0.0008091139115659897, "performance at regular": 0.0008091139115659897, "least wait": 0.0007696350858963753, "learning rule": 0.000634859264718638, "that gll outperformed": 0.0008091139115659897, "reward so it": 0.0008091139115659897, "simple games": 0.0013256821687110331, "training the": 0.0004560919846500759, "that a small": 0.0005279045957013737, "used alone previous": 0.0008091139115659897, "at least wait": 0.0008091139115659897, "a small": 0.0005458972063088678, "how increasing": 0.0006628410843555166, "for conjunctive": 0.0011908005071032729, "exploring the": 0.0007463191194819749, "sheppard salzberg 1993": 0.0016182278231319793, "term": -3.660574929421074e-06, "a temporal difference": 0.0007417488271393706, "state spaces": 0.0004938405038742361, "name": 9.187953736685217e-05, "then tried": 0.000702264802583379, "until the": 0.0001729951419732728, "is how": 0.0002921317927643509, "responsible for": 0.00026767013033800354, "assignment problem and": 0.0006743602501766612, "aha 1992 salzberg": 0.0008091139115659897, "involves solving a": 0.0007023330300003208, "pursuit games in": 0.0008091139115659897, "known optimal strategy": 0.0008091139115659897, "remainder of the": 0.0006528370107308935, "escape second we": 0.0008091139115659897, "95 evasion neither": 0.0008091139115659897, "laws in complex": 0.0008091139115659897, "algorithms ga": 0.000702264802583379, "is the size": 0.00036873270276064425, "individually": 0.00046955208579092735, "gammon is currently": 0.0008091139115659897, "a form suitable": 0.0007023330300003208, "rules using simulation": 0.0016182278231319793, "that has two": 0.0006526576017704936, "developed an environment": 0.0007417488271393706, "match would": 0.0007696350858963753, "space has 2": 0.0008091139115659897, "linear programming": 0.0003228323139879973, "reached a successful": 0.0008091139115659897, "plus lazy learning": 0.0008091139115659897, "be added": 0.0002609879415061532, "use of": 0.00017994374727564754, "catching": 0.00046004841655118944, "in which players": 0.0007417488271393706, "begun": 0.00033862129956161867, "passed by the": 0.0008091139115659897, "to approach and": 0.0008091139115659897, "that engagement were": 0.0008091139115659897, "and p2 individually": 0.0008091139115659897, "from a fixed": 0.0005226282087022614, "important control": 0.0007696350858963753, "or teaching phase": 0.0008091139115659897, "plan fitness a": 0.0008091139115659897, "another plateau at": 0.0008091139115659897, "profit": 0.0004911275029923669, "chosen set of": 0.0006526576017704936, "work has been": 0.0003386870959862882, "and its performance": 0.0005128575980484463, "noting that all": 0.0007417488271393706, "in the midst": 0.0007023330300003208, "we deleted it": 0.0008091139115659897, "process of": 0.0002069735289986681, "sampling idea of": 0.0008091139115659897, "developed a lazy": 0.0008091139115659897, "time t k": 0.0006349209434580451, "helpful comments": 0.00030818023003300325, "strategy combining eager": 0.0008091139115659897, "level of performance": 0.0010352426248498167, "capable of learning": 0.0006349209434580451, "maneuver": 0.0005953424196270563, "ones in general": 0.0008091139115659897, "theory": -0.0003202779445215926, "tomek 1976": 0.0007696350858963753, "an action": 0.001109382889966093, "penalty typically an": 0.0008091139115659897, "which naturally causes": 0.0007417488271393706, "littman 1994 observed": 0.0008091139115659897, "for each of": 0.0004715238052466873, "adaptive control of": 0.0012698418869160901, "by salzberg et": 0.0008091139115659897, "murthy for helpful": 0.0008091139115659897, "3 the": 6.029067413866265e-05, "operators mutation": 0.000702264802583379, "the strategy": 0.00031872073205630987, "smoke it was": 0.0008091139115659897, "approach and pursue": 0.0008091139115659897, "figure 7 we": 0.0005128575980484463, "the severity": 0.0005363412876789271, "algorithm s performance": 0.0005279045957013737, "which are": 0.00013372058494506966, "continuous state spaces": 0.0007417488271393706, "the game well": 0.0008091139115659897, "actions with probability": 0.0008091139115659897, "application in the": 0.0004998137828238603, "an environment": 0.0010467485769999067, "turn": 0.0004772240007685337, "time the": 0.00013183520442615413, "agent reinforcement": 0.000634859264718638, "its own teacher": 0.0007417488271393706, "attributes which is": 0.0007417488271393706, "ga throughout": 0.0015392701717927505, "states and selects": 0.0008091139115659897, "be quite fast": 0.0008091139115659897, "therefore had": 0.0006628410843555166, "combined use": 0.000634859264718638, "features of": 0.00022886607492290744, "95 4 4": 0.0008091139115659897, "to recharge": 0.0007696350858963753, "use the general": 0.0006526576017704936, "space is": 0.0002386061189975044, "vary continuously they": 0.0008091139115659897, "was the storage": 0.0008091139115659897, "examples a": 0.0004642630166224529, "less time": 0.00042590150453082544, "often the": 0.0002945105957876159, "action pair": 0.0021067944077501365, "frequently to escape": 0.0008091139115659897, "simplified": 0.0001355392982704429, "we can begin": 0.0006526576017704936, "space in": 0.0005391297575283002, "have been": 0.00018086237940563072, "system that outperformed": 0.0008091139115659897, "1986 we": 0.0006628410843555166, "performance against do": 0.0008091139115659897, "we were generating": 0.0008091139115659897, "all states and": 0.0006349209434580451, "given": -0.002958067014877373, "first learner with": 0.0008091139115659897, "when faced": 0.0006131469602829721, "for memory": 0.0003820967919236623, "examples that was": 0.0008091139115659897, "that arise in": 0.0004657382758148953, "different learning": 0.0005803901647646488, "and random": 0.0003665369780185166, "even better these": 0.0008091139115659897, "gray applied what": 0.0008091139115659897, "out peak performance": 0.0008091139115659897, "are ace ase": 0.0008091139115659897, "learning methods on": 0.0008091139115659897, "is used": 0.00013277257007387425, "at an intermediate": 0.0006526576017704936, "instead the": 0.0003028459277060942, "thus we counted": 0.0008091139115659897, "reward is": 0.0011908005071032729, "gives": -6.574906844955463e-05, "exploring": 0.0004300014351749534, "fewest time": 0.0007696350858963753, "zhang 1992": 0.0007696350858963753, "a helpful teacher": 0.002225246481418112, "we designed": 0.00046009310747955083, "we could": 0.00020011885135250967, "continues until the": 0.0005759152096655707, "with uniform": 0.000391902140873557, "if it collected": 0.0008091139115659897, "examples decreases": 0.0007696350858963753, "released": 0.00027884013760390546, "training agents": 0.0015392701717927505, "known to": 0.00020959779892486697, "action taken by": 0.0006526576017704936, "examples a common": 0.0008091139115659897, "salzberg 1991": 0.0006628410843555166, "salzberg 1993": 0.0023089052576891257, "game change": 0.0007696350858963753, "specify": 8.230188056213731e-05, "population": 0.0019815805946653805, "wide": 0.00013149813689910926, "complex sequential decision": 0.0008091139115659897, "into the sensor": 0.0007023330300003208, "determined that yielded": 0.0008091139115659897, "beginning of": 0.00021383882269906333, "require": -0.0002629962737982185, "training even when": 0.0008091139115659897, "learn how": 0.0005363412876789271, "computing the value": 0.0005954580987137418, "and appropriate": 0.0005128077770266814, "r": 0, "a genetic algorithm": 0.004419319043245652, "train the": 0.0004779464664686347, "selecting actions": 0.0007696350858963753, "compares the": 0.00029776693520311534, "outcome": 0.00022839973357585987, "primarily of storing": 0.0008091139115659897, "hidden state in": 0.0007417488271393706, "and": 0, "game continues": 0.001404529605166758, "considered how": 0.0006131469602829721, "for example standard": 0.0007417488271393706, "the examples": 0.0013705861848009619, "rule differential": 0.0007696350858963753, "states which naturally": 0.0008091139115659897, "takes only the": 0.0008091139115659897, "and 5 and": 0.0006069246369921007, "by successfully": 0.000702264802583379, "after 16 000": 0.0008091139115659897, "correct control": 0.000702264802583379, "found that the": 0.0003489500907295262, "any": -0.002869019323577732, "highest expected reward": 0.0008091139115659897, "is a special": 0.0003378762358657853, "a point": 0.00020623389645783668, "characteristics metagamer": 0.0007696350858963753, "play random games": 0.0008091139115659897, "thus it is": 0.0003354811312356286, "performance was always": 0.0008091139115659897, "pursuers one": 0.0007696350858963753, "decision rules": 0.0010726825753578542, "learning algorithms reinforcement": 0.0008091139115659897, "the truck backer": 0.0008091139115659897, "ideas": 0.00011050428679687664, "one algorithm": 0.0009765049742036323, "do our": 0.0006628410843555166, "learning sequential": 0.001404529605166758, "can work": 0.0008764055773298718, "train a robot": 0.0008091139115659897, "and catching q": 0.0008091139115659897, "maneuvers problem requires": 0.0008091139115659897, "achieve a": 0.00027748884847682954, "is adjusted": 0.0004779464664686347, "strengths": 0.0003019530704824289, "examples continue": 0.000702264802583379, "additional 5": 0.0006628410843555166, "of three algorithms": 0.0007023330300003208, "or p2": 0.000702264802583379, "sure": 0.00017644431332732222, "multiple": -5.248256205250101e-05, "attempt to improve": 0.0006069246369921007, "performance on": 0.0017527907565861053, "learn in a": 0.0007023330300003208, "games in these": 0.0008091139115659897, "best plan determine": 0.0008091139115659897, "k nn alone": 0.0016182278231319793, "performance of": 0.002028754098576598, "for complex control": 0.0008091139115659897, "the most common": 0.0003634160486420408, "hidden state is": 0.0008091139115659897, "turn increases": 0.0006131469602829721, "of the experiments": 0.00042031844251562157, "studied here has": 0.0008091139115659897, "arbitrarily sharp turns": 0.0008091139115659897, "games optimal": 0.0007696350858963753, "ga at the": 0.0008091139115659897, "attributes in": 0.0008637241337018897, "roughly 5": 0.0005954002535516364, "with a set": 0.0007680407880016979, "considered": -0.0004283864538377573, "sutton 1988 tesauro": 0.0008091139115659897, "to using reinforcement": 0.0008091139115659897, "later": -0.00017530747069844675, "iri 9116843 and": 0.0008091139115659897, "memory size our": 0.0008091139115659897, "uses a ga": 0.0007417488271393706, "differential games are": 0.0016182278231319793, "e just keeps": 0.0008091139115659897, "game are then": 0.0008091139115659897, "batteries below we": 0.0008091139115659897, "turn 90": 0.0007696350858963753, "takes only": 0.00044854462015967935, "of storing": 0.00042590150453082544, "hypothesis that two": 0.0008091139115659897, "but a game": 0.0008091139115659897, "it stores in": 0.0008091139115659897, "1990 can": 0.0007696350858963753, "editing occurred prior": 0.0008091139115659897, "throw away": 0.0005363412876789271, "toward achieving": 0.000702264802583379, "be successful": 0.00043186206685094484, "the speed of": 0.001497371818034951, "spaces": 0.0003017210354456585, "anonymous reviewers": 0.0003530449562101758, "one pursuer in": 0.0008091139115659897, "the poor performance": 0.0010913768770361549, "teaching phase": 0.0007696350858963753, "artificial systems": 0.0005803901647646488, "focused on translating": 0.0008091139115659897, "ramsey schultz": 0.0007696350858963753, "actual reward fl": 0.0008091139115659897, "emitting smoke it": 0.0008091139115659897, "at time t": 0.0006790087439311421, "learning algorithms can": 0.0007417488271393706, "in a lazy": 0.0013487205003533224, "the most frequently": 0.0005176213124249083, "the solution": 0.00045335868247714875, "and distance": 0.0004642630166224529, "systems practical issues": 0.0008091139115659897, "explicitly": 7.701122342656559e-05, "had great": 0.0007696350858963753, "are represented": 0.0002508495615030361, "problems when the": 0.0006349209434580451, "however our hypothesis": 0.0007417488271393706, "to demonstrate the": 0.0003507647800338115, "speed of e": 0.0008091139115659897, "differential games require": 0.0008091139115659897, "of delayed": 0.0005363412876789271, "game earlier": 0.0007696350858963753, "sharply otherwise the": 0.0008091139115659897, "k nn finally": 0.0008091139115659897, "therefore provided corrected": 0.0008091139115659897, "the beginning of": 0.00026022991695183543, "learning selecting": 0.0007696350858963753, "the distance between": 0.0009685910347398554, "however even": 0.0003859053049699601, "15 000": 0.0005954002535516364, "car the driver": 0.0008091139115659897, "experiments in": 0.0002747832868924773, "p we": 0.00025193193052089276, "building and": 0.0004560919846500759, "ga was capable": 0.0008091139115659897, "learned excellent strategies": 0.0008091139115659897, "reported here": 0.0003748850085915968, "within d 1": 0.0008091139115659897, "david aha": 0.000702264802583379, "success rate": 0.0021453651507157083, "outperform": 0.0005468573086117383, "actions to": 0.00042027761111456123, "until almost all": 0.0008091139115659897, "editing then proceeds": 0.0008091139115659897, "methods should be": 0.0005954580987137418, "predicted": 0.0004988963073324921, "solve examples of": 0.0008091139115659897, "a process": 0.0002695648787641501, "points probably": 0.000702264802583379, "called delayed": 0.0006628410843555166, "reveals": 0.0002126468044753682, "learning as a": 0.0013053152035409873, "strategies for differential": 0.0008091139115659897, "success rate continued": 0.0008091139115659897, "the payoff": 0.0030657348014148603, "addition we found": 0.0007023330300003208, "single pedestrian": 0.0007696350858963753, "are encoded using": 0.0005954580987137418, "sutton watkins": 0.0007696350858963753, "decreased very slowly": 0.0008091139115659897, "analyzing this": 0.0006628410843555166, "parking": 0.001134655980062826, "in addition to": 0.00020564087741339372, "below to": 0.00042590150453082544, "type of problem": 0.0006349209434580451, "fails": 0.00011792602781104201, "s samuel": 0.0007696350858963753, "rules are": 0.000620039697699608, "ways": 2.2625697686291662e-05, "require the players": 0.0008091139115659897, "information about its": 0.0005759152096655707, "the ga by": 0.0008091139115659897, "rather than": 0.0005768213399478365, "easy to solve": 0.0005524148804057065, "compilation that": 0.0007696350858963753, "outside": 0.00011437308048377166, "so we": 0.00016685948096700342, "can then be": 0.0002942722465015078, "learning algorithm lies": 0.0008091139115659897, "small well": 0.000702264802583379, "position and": 0.0003238859962113274, "from the distance": 0.0006743602501766612, "planning for conjunctive": 0.0016182278231319793, "guide a": 0.0005456354281782176, "same or perhaps": 0.0008091139115659897, "information with": 0.00039610816435843403, "has additional information": 0.0008091139115659897, "201 233 nov": 0.0007417488271393706, "littman expanded": 0.0007696350858963753, "originated": 0.00032280095582248115, "population do": 0.0007696350858963753, "training we hypothesize": 0.0008091139115659897, "each move is": 0.0008091139115659897, "nn using the": 0.0008091139115659897, "colombetti 1994": 0.0007696350858963753, "do not require": 0.0003593539089640634, "only plans": 0.0007696350858963753, "east then": 0.0007696350858963753, "problem such": 0.0004779464664686347, "it first": 0.0004382027886649359, "other topics programming": 0.0008091139115659897, "some asymptotic limit": 0.0008091139115659897, "much better than": 0.00041851198115822714, "memory base by": 0.0008091139115659897, "same reactive": 0.0007696350858963753, "nn classifier in": 0.0008091139115659897, "many valuable comments": 0.0006349209434580451, "predict by the": 0.0007023330300003208, "pedestrian able to": 0.0008091139115659897, "two learners": 0.0006628410843555166, "the second algorithm": 0.0005039721952628732, "region": 9.363335634015079e-05, "correct in": 0.00044497617160632185, "games his metagamer": 0.0008091139115659897, "propagation": 0.00016307535687015102, "system strength and": 0.0008091139115659897, "memory algorithm which": 0.0008091139115659897, "the error back": 0.0007417488271393706, "respectively noting that": 0.0008091139115659897, "information in": 0.00043646699559801873, "and was used": 0.0006526576017704936, "one approach": 0.0003449470981709676, "memory size are": 0.0008091139115659897, "together to outperform": 0.0008091139115659897, "examples if it": 0.0016182278231319793, "of running gle": 0.0008091139115659897, "1983 barto et": 0.0008091139115659897, "which is sufficient": 0.0012698418869160901, "learning phase of": 0.0008091139115659897, "abilities further they": 0.0008091139115659897, "for this phase": 0.0006349209434580451, "the first set": 0.00041851198115822714, "robotics": 0.0003573124803874222, "early stages these": 0.0008091139115659897, "sampling": 0.0003576107924809437, "60": 0.00012195824896711308, "pole": 0.0007532075272321914, "strategy combining": 0.000702264802583379, "66": 0.00016467783894012493, "a performer": 0.000702264802583379, "co learning at": 0.0008091139115659897, "chess like": 0.0007696350858963753, "are used": 9.014831665410398e-05, "should reasonably expect": 0.0008091139115659897, "evade when using": 0.0008091139115659897, "effectively on control": 0.0008091139115659897, "knowledge of": 0.0002240700519004841, "figure a lazy": 0.0008091139115659897, "it was": 0.0003167776273160597, "y is the": 0.0007533538805844176, "pursuer s direction": 0.0008091139115659897, "includes a second": 0.0008091139115659897, "approaches lazy": 0.0007696350858963753, "assist each": 0.0007696350858963753, "mean of": 0.0003315762308313901, "a common": 0.0003655024589591071, "ga to achieve": 0.0008091139115659897, "backgammon an": 0.0007696350858963753, "500": 0.0005454498815643297, "direction": 0.00026994420815126363, "algorithm gll": 0.0015392701717927505, "system gll": 0.0007696350858963753, "given generation": 0.000702264802583379, "for analyzing learning": 0.0007417488271393706, "possible however": 0.00044497617160632185, "generation as 50": 0.0008091139115659897, "system gle": 0.0007696350858963753, "distance is": 0.00035445902764197844, "s algorithm": 0.00028677803128412173, "two of the": 0.00035836314958925027, "determined that": 0.00041758029726340933, "until play": 0.0007696350858963753, "careful": 0.00016414165496572494, "irrelevant": 0.00047523881761247605, "results of ga": 0.0008091139115659897, "which resulted": 0.0005363412876789271, "case": -0.0014790335074386866, "examples with bad": 0.0008091139115659897, "single pursuer is": 0.0008091139115659897, "iri 9223591 r": 0.0008091139115659897, "logarithmic scale is": 0.0008091139115659897, "would frequently": 0.0007696350858963753, "during the formative": 0.0008091139115659897, "harder to": 0.00036183856746138145, "measures the position": 0.0008091139115659897, "the table the": 0.00046289837369057756, "thus it": 0.00022931191401334662, "the formative": 0.0007696350858963753, "learning algorithms have": 0.0007023330300003208, "for e to": 0.0007023330300003208, "level with strategic": 0.0008091139115659897, "more of": 0.0003177175902857743, "ga transmit": 0.0007696350858963753, "ga through 5": 0.0008091139115659897, "games includes": 0.0007696350858963753, "and oe is": 0.0005176213124249083, "actions in performing": 0.0008091139115659897, "attributes to": 0.0004560919846500759, "same in addition": 0.0007023330300003208, "learning s asymptotic": 0.0008091139115659897, "50 ga": 0.0007696350858963753, "memory our strategy": 0.0008091139115659897, "expect the surface": 0.0008091139115659897, "thus basically zigzags": 0.0008091139115659897, "systems for intelligent": 0.0008091139115659897, "1993 used": 0.000702264802583379, "table are the": 0.0006526576017704936, "is to use": 0.0002788943181416697, "problems with large": 0.0006069246369921007, "the details of": 0.00029588410531796453, "ga s 90": 0.0008091139115659897, "approach that is": 0.0005226282087022614, "the set with": 0.0005851984448616567, "pruning": 0.0008163498667446772, "e k": 0.0006847672985756632, "rate on its": 0.0008091139115659897, "head directly towards": 0.0008091139115659897, "problems that": 0.00030112584215908326, "of how": 0.0002084662442079054, "to achieve similar": 0.0006526576017704936, "be applied": 0.00029403625017513366, "plan fitness is": 0.0008091139115659897, "to generate": 0.0003353606405107819, "maneuver in": 0.0007696350858963753, "pairs without": 0.000702264802583379, "a highly trained": 0.0008091139115659897, "to david": 0.0005363412876789271, "might enable": 0.0007696350858963753, "also generate": 0.0005363412876789271, "time step and": 0.0005226282087022614, "in learning": 0.0008576743387175264, "pursuit games possible": 0.0008091139115659897, "hart s 1968": 0.0008091139115659897, "binary attributes booker": 0.0008091139115659897, "sections discuss the": 0.0006743602501766612, "speeds different defense": 0.0008091139115659897, "moore and atkeson": 0.0008091139115659897, "examples next we": 0.0008091139115659897, "1994 in": 0.0004779464664686347, "separate reinforcement": 0.0007696350858963753, "state action": 0.006348592647186379, "driver": 0.00030024696001537796, "values to determine": 0.0007023330300003208, "escape depends": 0.0007696350858963753, "g if e": 0.0007417488271393706, "1992 except that": 0.0007417488271393706, "changing": 9.398582090934488e-05, "initial states": 0.00042304989757217126, "grefenstette 1994 have": 0.0008091139115659897, "many games do": 0.0008091139115659897, "empirical comparison": 0.0009765049742036323, "reference the search": 0.0008091139115659897, "provided corrected actions": 0.0008091139115659897, "computing the": 0.00031832382407851693, "level greater": 0.0006131469602829721, "that yielded": 0.0005954002535516364, "require quantization of": 0.0007417488271393706, "communication or teaching": 0.0008091139115659897, "without": -0.00037996800274155075, "we see": 0.0001758775423056482, "bound is": 0.000259233183784521, "termination": 0.0003786744830852467, "model": -0.00012400968436223982, "reward": 0.004405049480559842, "or specialized by": 0.0008091139115659897, "researchers": 0.00015233275537100346, "in addition": 0.0004275784066274623, "database evasion": 0.0007696350858963753, "1 we": 9.755222500456918e-05, "to store": 0.000996980764572016, "early phases of": 0.0006199211760863129, "approach stores": 0.0013256821687110331, "speeds of": 0.0005060701527920558, "generating bad": 0.0007696350858963753, "a game contains": 0.0008091139115659897, "q learning k": 0.0016182278231319793, "actions": 0.004827536567130536, "94 5 did": 0.0008091139115659897, "against each other": 0.0006199211760863129, "1992 skalak 1994": 0.0008091139115659897, "power of": 0.00042455900560917727, "data but the": 0.0006199211760863129, "bad examples in": 0.0008091139115659897, "the strengths of": 0.0005334812968668691, "of hidden": 0.00044854462015967935, "nearly perfectly": 0.0007696350858963753, "the nearest neighbor": 0.0005524148804057065, "resulting action is": 0.0008091139115659897, "called the pursuer": 0.0008091139115659897, "captured": 0.0001718423499250408, "must learn in": 0.0008091139115659897, "strength plan fitness": 0.0008091139115659897, "expects each": 0.0007696350858963753, "warfare and other": 0.0008091139115659897, "possibility of escape": 0.0008091139115659897, "to pursue": 0.00048296474811893784, "study aha": 0.0007696350858963753, "the pursuer relative": 0.0008091139115659897, "taken by the": 0.00040670626310009803, "4 4 2": 0.0004522903409367932, "suitable for samuel": 0.0008091139115659897, "except": -1.551813690984632e-05, "11 examples gle": 0.0008091139115659897, "at convergence we": 0.0008091139115659897, "continued to improve": 0.0016182278231319793, "between taking": 0.0007696350858963753, "isaacs 1963": 0.0023089052576891257, "fired are updated": 0.0008091139115659897, "is adjusted by": 0.0007023330300003208, "demonstrated that": 0.0006873147925300238, "point was correctly": 0.0008091139115659897, "to the sharpness": 0.0008091139115659897, "of members of": 0.0006743602501766612, "using hill": 0.0007696350858963753, "9 42 3": 0.0008091139115659897, "be associated with": 0.00040830984894046896, "facing e g": 0.0008091139115659897, "not completely surprising": 0.0008091139115659897, "more formal": 0.00042304989757217126, "dropped below the": 0.0008091139115659897, "the beginning": 0.00039744494010191835, "2060100": 0.0004882050609253128, "ae is": 0.0006847672985756632, "playing has begun": 0.0008091139115659897, "learning slowed": 0.0007696350858963753, "more general": 0.00017185904337267295, "used nearest neighbor": 0.0008091139115659897, "theory is the": 0.0005954580987137418, "the playing field": 0.0008091139115659897, "used the": 0.0003007751872021741, "clock the angle": 0.0008091139115659897, "rule strength plan": 0.0008091139115659897, "neighbors and": 0.0008764055773298718, "in the": 0.0, "combined system": 0.0011908005071032729, "actions at every": 0.0008091139115659897, "teach a robot": 0.0016182278231319793, "perfect performance the": 0.0008091139115659897, "and two player": 0.002427341734697969, "using k nearest": 0.0014834976542787413, "all 20": 0.000702264802583379, "for game playing": 0.0008091139115659897, "is sufficient to": 0.0006134022182469986, "is within": 0.0003157396500417892, "two pursuer task": 0.005663797380961928, "were passed": 0.001404529605166758, "mutate those directly": 0.0008091139115659897, "randomly generated": 0.001129921045199448, "all of": 0.0008628252004377143, "uses euclidean distance": 0.0008091139115659897, "13 features describing": 0.0008091139115659897, "to examine": 0.0002747832868924773, "randomly evaded p": 0.0008091139115659897, "games stored": 0.0007696350858963753, "p 1 e": 0.0007023330300003208, "defined by": 0.00012841175229188933, "reduced": -3.942232162707948e-06, "anderson 1983": 0.000702264802583379, "improved efficiency provided": 0.0008091139115659897, "we therefore had": 0.0007417488271393706, "be close": 0.000391902140873557, "interest probability of": 0.0008091139115659897, "simulator": 0.0013860756584005158, "in a new": 0.00041851198115822714, "near the": 0.00028456257763219726, "within a plan": 0.0008091139115659897, "competition": 0.0011298112908482872, "out to": 0.00022886607492290744, "should expand the": 0.0008091139115659897, "this task known": 0.0008091139115659897, "than d 1": 0.0007417488271393706, "used nearest": 0.0007696350858963753, "r is": 0.00015736440764536582, "respect": -4.055921844324362e-05, "50 evasion": 0.0007696350858963753, "not to": 0.0001980300438984334, "plan and": 0.0009876810077484722, "provided": -0.0002646051482419554, "develop pursuit": 0.0007696350858963753, "eager approach": 0.0007696350858963753, "well we considered": 0.0008091139115659897, "the task several": 0.0008091139115659897, "single missile": 0.0007696350858963753, "the state that": 0.0005524148804057065, "and entertainment industries": 0.0008091139115659897, "plans during": 0.0007696350858963753, "rules are stored": 0.0008091139115659897, "by methods of": 0.0007417488271393706, "provides": -8.82017160806518e-05, "encoding them in": 0.0007417488271393706, "against do": 0.0007696350858963753, "than the car": 0.0007417488271393706, "teacher prototype": 0.0007696350858963753, "conditions can": 0.0003878648638474452, "communicate": 0.000170715699681252, "using a declarative": 0.0006743602501766612, "nn on one": 0.0008091139115659897, "its previous": 0.00048296474811893784, "several goals simultaneously": 0.0007417488271393706, "h t j": 0.0008091139115659897, "sampling and": 0.0004382027886649359, "assume that at": 0.00048474305809383046, "optimal strategies in": 0.0006526576017704936, "can outperform either": 0.0008091139115659897, "for their": 0.00017385346182484084, "for that engagement": 0.0008091139115659897, "successful a": 0.0006628410843555166, "chauffeur game in": 0.0008091139115659897, "on": 0, "algorithms a": 0.0003128408899145216, "complication in": 0.0005954002535516364, "adaptive ga": 0.0006628410843555166, "on this": 0.0005967021770470903, "other recent work": 0.0007417488271393706, "of": 0, "oe": 7.115488900151588e-05, "discussed": -4.9824007551155044e-05, "when read": 0.000634859264718638, "memory based method": 0.0008091139115659897, "it to": 0.0004360832006979072, "surface for extensions": 0.0008091139115659897, "equalize": 0.0005127579656835996, "and 85 degrees": 0.0008091139115659897, "two pursuer game": 0.004045569557829949, "future reinforcement and": 0.0008091139115659897, "in the range": 0.00030374604195717594, "or": -0.014043931768418264, "storing approximately 1": 0.0008091139115659897, "the data and": 0.00037786441809092093, "and catching": 0.0006628410843555166, "directly on the": 0.0004601378070916638, "more difficult": 0.001014300832409655, "game that involved": 0.0008091139115659897, "communication": 4.647792550976728e-05, "by hidden state": 0.0008091139115659897, "problems as classification": 0.0008091139115659897, "use an": 0.00025357520810241374, "the data": 0.00023190969933386255, "determine": -0.0006589379027295507, "determining optimal": 0.0006131469602829721, "to differential": 0.0005456354281782176, "q value is": 0.0007023330300003208, "had considerable difficulty": 0.0008091139115659897, "problem was": 0.0003327228091591544, "theoretically": 0.00021985083825553804, "class was actually": 0.0008091139115659897, "with a high": 0.0004339731734948358, "or conversely": 0.0006131469602829721, "when history is": 0.0008091139115659897, "antecedant compares a": 0.0008091139115659897, "there": -0.001175592220928333, "the games involves": 0.0016182278231319793, "agent environments": 0.001404529605166758, "examples it could": 0.0008091139115659897, "strict": 0.000170715699681252, "that lazy": 0.0013256821687110331, "time we": 0.00021112298341276222, "problems we": 0.0008581034522536741, "we specify two": 0.0008091139115659897, "is significant": 0.0003489161923333023, "and beyond": 0.00044153169724958527, "fired are": 0.0015392701717927505, "equations which": 0.0004123948992280552, "for classification and": 0.0006526576017704936, "of 20": 0.0006925063450175328, "permit the ga": 0.0008091139115659897, "that ended": 0.000702264802583379, "when e was": 0.0008091139115659897, "key idea": 0.00036338074496527356, "environment for": 0.0006145445979719846, "considered to": 0.00025981503993729386, "start a": 0.0008637241337018897, "the population they": 0.0008091139115659897, "mingers": 0.000567327990031413, "et al 1983": 0.0012398423521726258, "the sharpness": 0.0005559058853301298, "likely reason for": 0.0008091139115659897, "our current implementation": 0.0004601378070916638, "track lin": 0.0007696350858963753, "part because": 0.0005363412876789271, "applying": -6.757487591717434e-06, "one class": 0.000391902140873557, "can also interpret": 0.0008091139115659897, "but steadily": 0.0007696350858963753, "ways for": 0.00042304989757217126, "learning problems better": 0.0008091139115659897, "by averaging": 0.0008764055773298718, "was motivated by": 0.0005226282087022614, "awarded immediately": 0.0007696350858963753, "start the": 0.00035882246681762515, "been done to": 0.0011518304193311414, "the q learning": 0.0007023330300003208, "player must": 0.0007696350858963753, "parent systems this": 0.0008091139115659897, "they tackle increasingly": 0.0008091139115659897, "be poor whenever": 0.0008091139115659897, "space or": 0.00046009310747955083, "the ga nor": 0.0008091139115659897, "would be associated": 0.0007023330300003208, "correspond to features": 0.0007417488271393706, "three algorithms": 0.0012608328333436837, "a fixed control": 0.0008091139115659897, "applied to": 0.0005896255556703788, "the one pursuer": 0.004854683469395938, "that generation": 0.0006628410843555166, "be sure that": 0.0004882999224935485, "successive actions two": 0.0008091139115659897, "incorrect": 0.0001806039456279112, "i e 25": 0.0007417488271393706, "were generating": 0.0007696350858963753, "standard q": 0.001404529605166758, "rewards associated with": 0.0007417488271393706, "s troubles we": 0.0008091139115659897, "be appended to": 0.0006526576017704936, "games will": 0.000702264802583379, "evasion was still": 0.0008091139115659897, "in classifying": 0.0005803901647646488, "8instance if e": 0.0008091139115659897, "we explored": 0.0004997652289300559, "originated in": 0.0006131469602829721, "5": -0.011937342003155526, "evasion strategies": 0.0007696350858963753, "learning to evade": 0.0008091139115659897, "and depends on": 0.0005176213124249083, "watkins q": 0.0007696350858963753, "of percent": 0.000702264802583379, "has 2 9": 0.0008091139115659897, "regain speed by": 0.0008091139115659897, "a ga based": 0.0007417488271393706, "information must be": 0.0005393947462253054, "pursuers figure 3": 0.0008091139115659897, "separate": 0.00010982298378825846, "good performance after": 0.0008091139115659897, "clouse and": 0.0015392701717927505, "includes": 4.485470300503035e-05, "16 000 games": 0.0008091139115659897, "the parking lot": 0.0008091139115659897, "wide variety of": 0.0007418794663306229, "included": 6.543418526746033e-05, "its memory requirements": 0.0007023330300003208, "gle on": 0.0007696350858963753, "in the next": 0.00017804833516313513, "1987 nguyen": 0.0007696350858963753, "differential games machine": 0.0007417488271393706, "version includes a": 0.0008091139115659897, "the adaptive": 0.0007497700171831936, "early work": 0.0004123948992280552, "simplified game": 0.0007696350858963753, "1988 temporal": 0.0007696350858963753, "calls": 0.00012400968436223982, "systems to": 0.00034112545549164767, "curve": 0.000148919836752868, "phase of the": 0.00038529791840416234, "many of": 0.00019563598729230164, "updates the": 0.00032932038867923357, "booker": 0.0006347975979615015, "pair in": 0.0004004979458675273, "was having difficulty": 0.0008091139115659897, "nearest neighbors if": 0.0008091139115659897, "are much": 0.00028903995093373133, "same pursuit": 0.0007696350858963753, "all": -0.01334173517999735, "pursuer has": 0.0007696350858963753, "move is determined": 0.0008091139115659897, "and receiving": 0.00042590150453082544, "the bounds": 0.0008603340938523651, "achieve alone": 0.000702264802583379, "a roll": 0.0005803901647646488, "network learning algorithms": 0.0008091139115659897, "actions later": 0.0007696350858963753, "homogenous region": 0.0007696350858963753, "neural network learning": 0.0007023330300003208, "reinforcement connectionist approach": 0.0016182278231319793, "are markov decision": 0.0008091139115659897, "driver of": 0.0005954002535516364, "2 3": 7.19656479487812e-05, "and led to": 0.0007023330300003208, "over time": 0.0002953154240675878, "plans that achieved": 0.0008091139115659897, "can be added": 0.0003975888325128001, "2 9": 0.0002741172369601924, "follow": 0.00010254824470536034, "of memory": 0.0002466206804679992, "decisions": 0.00016254520394587348, "base and": 0.00044153169724958527, "atkeson 1990 watkins": 0.0008091139115659897, "formulation similar": 0.000634859264718638, "game 3 2": 0.0007417488271393706, "uniform probability following": 0.0008091139115659897, "has failed to": 0.0005954580987137418, "construct an initial": 0.0007417488271393706, "then e": 0.0006797648562020925, "pursuer relative": 0.0007696350858963753, "init": 0.0003054498199398159, "program": 1.774308975473892e-05, "in another": 0.00029943314463829254, "problems with respect": 0.0006349209434580451, "high degree of": 0.0004278905317797242, "stochastic": 0.0003786744830852467, "provides the": 0.00022622594443259307, "trials the first": 0.0008091139115659897, "they were able": 0.0006199211760863129, "explore the effects": 0.0007023330300003208, "activities": 0.0002320006200680367, "system also": 0.0004731713358791195, "action pair in": 0.0008091139115659897, "2 k": 0.0002621733301065935, "apply the actual": 0.0008091139115659897, "with each of": 0.0004601378070916638, "where lb": 0.0007696350858963753, "1982 to determine": 0.0008091139115659897, "are building an": 0.0008091139115659897, "and p": 0.000652364794629184, "after about": 0.0005559058853301298, "fixed solution": 0.0007696350858963753, "following rule for": 0.0006526576017704936, "and q": 0.0006646009192948592, "schultz 1990": 0.0007696350858963753, "consists primarily": 0.0006628410843555166, "in which fitness": 0.0008091139115659897, "e evades": 0.0023089052576891257, "includes numerous": 0.000702264802583379, "conjunction with lazy": 0.0016182278231319793, "results for the": 0.0002836198770817394, "as chess": 0.001404529605166758, "determined by solving": 0.0006069246369921007, "the history": 0.0003423836492878316, "action by averaging": 0.0008091139115659897, "what it": 0.0007146943822787083, "game we ran": 0.0008091139115659897, "edited when read": 0.0008091139115659897, "currently playing": 0.0007696350858963753, "problem could": 0.00046861672357587705, "the actual reward": 0.0016182278231319793, "features that": 0.00035589291297159965, "its success rate": 0.0008091139115659897, "demonstrating how": 0.0005803901647646488, "hill climbing to": 0.0006743602501766612, "bag of smoke": 0.0008091139115659897, "simulation a single": 0.0007023330300003208, "they anticipate the": 0.0008091139115659897, "and h": 0.0002270994318821418, "ten": 0.0005584528363479892, "learn in": 0.000634859264718638, "eventually reached almost": 0.0008091139115659897, "around 45 from": 0.0008091139115659897, "a mapping": 0.0002809681012316349, "handle several": 0.0006628410843555166, "smoke 4 the": 0.0008091139115659897, "examples used by": 0.0008091139115659897, "translating": 0.00025300020453897806, "rate": 0.0005640153458794819, "design": -4.4397268621774376e-05, "learning therefore": 0.000702264802583379, "studies the": 0.0003982790696131452, "of its own": 0.00048474305809383046, "represent the": 0.0001615064831696181, "behaviors and strategies": 0.0008091139115659897, "and atkeson": 0.0007696350858963753, "what": -0.0002383577910736765, "nonlinear": 0.00016959819790576504, "lazy learner needs": 0.0008091139115659897, "be unable": 0.0004938405038742361, "for that action": 0.0007417488271393706, "interactions in nature": 0.0008091139115659897, "learning to perform": 0.0008091139115659897, "plan can": 0.0005803901647646488, "operators mutation and": 0.0008091139115659897, "was clear that": 0.0006526576017704936, "but a": 0.0002603999475929679, "version": -0.0002454801982311501, "distance parameters": 0.0007696350858963753, "denoting a position": 0.0008091139115659897, "whenever a new": 0.0005596382660342995, "state 1": 0.00044497617160632185, "typically classification": 0.0007696350858963753, "time and": 0.0002782623104149078, "the position": 0.0002530247819825898, "lies in": 0.00025750558543057484, "strategic games": 0.0007696350858963753, "condensed": 0.00043182011813148384, "the pedestrian able": 0.0008091139115659897, "q learning performed": 0.0008091139115659897, "to update": 0.00028603448408455804, "call a co": 0.0008091139115659897, "in gabriel": 0.0007696350858963753, "multistrategy apprach": 0.0007696350858963753, "region the": 0.0003697942966553643, "stored games one": 0.0016182278231319793, "noughts and crosses": 0.0008091139115659897, "a more": 0.0002751414981438882, "of the results": 0.0003055091709200821, "directions": 9.646940000726047e-05, "and with": 0.00018935563451343574, "previous turn a": 0.0008091139115659897, "algorithm can develop": 0.0008091139115659897, "equations": 0.0002451198677483408, "are incorrectly classified": 0.0008091139115659897, "own for a": 0.0008091139115659897, "state i": 0.0007463191194819749, "a mapping from": 0.0004259428823122818, "each example this": 0.0008091139115659897, "state n": 0.0005803901647646488, "evade p even": 0.0008091139115659897, "analyzed to": 0.0005200422895505865, "e from": 0.000378426656892181, "captured at": 0.0006131469602829721, "highlight the fact": 0.0007023330300003208, "control problems for": 0.0005954580987137418, "space and time": 0.0004339731734948358, "state x": 0.0008899523432126437, "state y": 0.0011118117706602597, "whether it": 0.00027956301522652775, "generally strategies for": 0.0008091139115659897, "k nn were": 0.0008091139115659897, "of temporally": 0.0006628410843555166, "produced by": 0.00021541844584106192, "examples provided by": 0.0007023330300003208, "corresponding state action": 0.0008091139115659897, "problem in which": 0.0004601378070916638, "the problem while": 0.0006743602501766612, "reached a": 0.00044497617160632185, "a markov": 0.0007679661774724574, "combined the results": 0.0008091139115659897, "an approach similar": 0.0005759152096655707, "simple structures in": 0.0008091139115659897, "be found in": 0.00020736515911366914, "the second threshold": 0.0008091139115659897, "p and": 0.000326182397314592, "such an architecture": 0.0006069246369921007, "state and action": 0.0013053152035409873, "winners of the": 0.0008091139115659897, "two people learn": 0.0008091139115659897, "mutation using": 0.0007696350858963753, "algorithm k nn": 0.0008091139115659897, "taking an action": 0.0008091139115659897, "of reference the": 0.0006526576017704936, "the antecedant": 0.0007696350858963753, "grant nos": 0.0006628410843555166, "to games": 0.0007696350858963753, "upper and": 0.0003128408899145216, "net in": 0.00052785331295456, "that involved one": 0.0008091139115659897, "algorithms using": 0.00037664034839981597, "see this": 0.0002831104418951413, "the chauffeur is": 0.0008091139115659897, "for deriving": 0.00040989971878532225, "architecture in which": 0.0006199211760863129, "form into": 0.0005803901647646488, "as binary": 0.0005363412876789271, "and pole": 0.001404529605166758, "of problem we": 0.0008091139115659897, "where q x": 0.0008091139115659897, "lazy learner by": 0.0008091139115659897, "those points": 0.00046861672357587705, "much greater": 0.00042027761111456123, "i are": 0.00018807160268822633, "a plan fitness": 0.0008091139115659897, "operators": 0.0005333705118606369, "theory differential game": 0.0008091139115659897, "converted into a": 0.0004747836164770488, "threshold then e": 0.0008091139115659897, "also thanks": 0.0005803901647646488, "basically": 0.00041764397055689856, "known": -0.0007844704003780189, "pursuer game 4": 0.0008091139115659897, "rely on determining": 0.0008091139115659897, "term game to": 0.0008091139115659897, "because k": 0.0005803901647646488, "control problems in": 0.0006349209434580451, "bootstrapping method": 0.000702264802583379, "reward for": 0.0018394408808489165, "q learning experiments": 0.0008091139115659897, "the ga q": 0.0007417488271393706, "base guarantees": 0.0007696350858963753, "features describing": 0.0006628410843555166, "be close enough": 0.0006743602501766612, "with the general": 0.0005393947462253054, "v": -0.00026827203982513663, "the graph": 0.0003673491594640934, "we will focus": 0.0004601378070916638, "quite fast": 0.0005456354281782176, "field of": 0.00028167752214893036, "a target": 0.00031872073205630987, "game over time": 0.0008091139115659897, "the result was": 0.0005456884385180774, "2 have": 0.00035165014402826746, "challenging": 0.00022663986328578232, "on the payoff": 0.0007417488271393706, "state x with": 0.0008091139115659897, "apply these": 0.00046861672357587705, "though the solution": 0.0008091139115659897, "end of a": 0.00040993954193880374, "selected with uniform": 0.0008091139115659897, "arise": 0.00011281589316285373, "course the ga": 0.0008091139115659897, "database that are": 0.0006743602501766612, "for even simple": 0.0008091139115659897, "left the": 0.0003898632748579793, "found that k": 0.0007417488271393706, "is updated as": 0.0005674382257236372, "that yield this": 0.0008091139115659897, "values to": 0.00027817585610585485, "goal": 2.198428165130429e-05, "further and": 0.0004731713358791195, "rather": -0.00023090028980819562, "the anonymous": 0.0002721430567364954, "rate above 95": 0.0008091139115659897, "this plateau": 0.0007696350858963753, "outside the bounds": 0.0006743602501766612, "strategy the": 0.0003898632748579793, "e are": 0.0003054794925471542, "used in q": 0.0008091139115659897, "perfect performance after": 0.0008091139115659897, "car having": 0.0007696350858963753, "erratically but steadily": 0.0008091139115659897, "from smoke": 0.0007696350858963753, "heading is the": 0.0008091139115659897, "states will": 0.0005954002535516364, "although the car": 0.0007417488271393706, "of bad": 0.00048825248710181613, "the pursuer attempts": 0.0008091139115659897, "pursuer problem while": 0.0008091139115659897, "in differential games": 0.002225246481418112, "examples were": 0.0015384233310800442, "learner that": 0.0005954002535516364, "was only": 0.0003982790696131452, "lethal envelope": 0.0007696350858963753, "which resulted in": 0.0005954580987137418, "end of": 0.0004353774116899911, "parking lot and": 0.0008091139115659897, "games suggest solution": 0.0008091139115659897, "2 9 theta": 0.0008091139115659897, "game typically": 0.0015392701717927505, "determine the correct": 0.0006526576017704936, "the state space": 0.002335383212465242, "500 generations i": 0.0008091139115659897, "size to": 0.00033865419457809065, "individually speed": 0.0007696350858963753, "the resulting strategies": 0.0008091139115659897, "correspond to classes": 0.0008091139115659897, "domains and then": 0.0008091139115659897, "replayed with the": 0.0008091139115659897, "indicating that k": 0.0008091139115659897, "size of memory": 0.0006069246369921007, "p even": 0.0005954002535516364, "had widespread": 0.0007696350858963753, "each attribute in": 0.0006526576017704936, "specifying": 0.000145582549251732, "50 games": 0.0007696350858963753, "successful after": 0.000702264802583379, "be used to": 0.00027113126895836196, "similar game 3": 0.0008091139115659897, "times steps": 0.000702264802583379, "and colombetti 1994": 0.0008091139115659897, "question is related": 0.0007417488271393706, "a neural net": 0.0006526576017704936, "developed": -0.00014033526150547648, "to be good": 0.0005759152096655707, "accumulate as the": 0.0008091139115659897, "each example in": 0.0007023330300003208, "set used for": 0.0006526576017704936, "advantage of the": 0.00029216017436279294, "problems so we": 0.0007417488271393706, "and the new": 0.00038275883369467365, "which examples to": 0.0007417488271393706, "robots using reinforcement": 0.0007417488271393706, "require roughly": 0.0007696350858963753, "shown in": 0.00011472567058477988, "teaching strategy for": 0.0008091139115659897, "specifically tied": 0.0007696350858963753, "in conjunction": 0.0005563517122117097, "could get stuck": 0.0008091139115659897, "own after any": 0.0008091139115659897, "applied in many": 0.0006743602501766612, "assignment in rule": 0.0016182278231319793, "examples evaluate lazy": 0.0008091139115659897, "the value": 0.00028357433909900027, "the heart of": 0.0004360863081445778, "1 respectively noting": 0.0008091139115659897, "the system begins": 0.0007417488271393706, "of the pursuer": 0.0016182278231319793, "also has a": 0.00044270962419637705, "soccer": 0.0005278020401703972, "might": -8.042484846461443e-05, "our type of": 0.0007417488271393706, "searches a wide": 0.0008091139115659897, "range around each": 0.0008091139115659897, "types of opponents": 0.0008091139115659897, "database any state": 0.0008091139115659897, "difficult delayed reinforcement": 0.0008091139115659897, "linearly from": 0.0006131469602829721, "predator": 0.0005953424196270563, "neighbor is": 0.0005456354281782176, "framework": 1.7467819870314086e-05, "at convergence algorithm": 0.0008091139115659897, "ga recognizing the": 0.0008091139115659897, "accumulate": 0.00034362401526488896, "current implementation": 0.00035027405940034004, "learn to solve": 0.0007417488271393706, "1 to perform": 0.0007023330300003208, "task both pursuers": 0.0008091139115659897, "poor performance": 0.0015359323549449149, "attribute bounds followed": 0.0008091139115659897, "actions are": 0.0003859053049699601, "directed toward achieving": 0.0008091139115659897, "how to": 0.0007016606602668115, "reinforcement learning assume": 0.0008091139115659897, "the memory base": 0.0008091139115659897, "ga and then": 0.0016182278231319793, "action with": 0.0005559058853301298, "control strategy": 0.0005456354281782176, "in learning strategies": 0.0008091139115659897, "examples the": 0.00032932038867923357, "path of": 0.00028167752214893036, "of this": 5.748820872836259e-05, "forward selection": 0.000702264802583379, "comparator selects an": 0.0008091139115659897, "points for": 0.00032075631632839377, "be added at": 0.0007417488271393706, "formulate": 0.00018933724154262334, "improvement in": 0.00026337149590123743, "generation": 0.00028961817092102403, "7 we": 0.00022535886933316643, "learning s": 0.002809059210333516, "memory even": 0.000634859264718638, "achieved at least": 0.0008091139115659897, "goal is": 0.00018616902889069845, "expect": 8.330950921753584e-05, "evasive maneuvers": 0.010774891202549252, "relative frame": 0.0007696350858963753, "inflated": 0.00046857120471006095, "which an agent": 0.002225246481418112, "nn the ga": 0.0008091139115659897, "difficult in this": 0.0006526576017704936, "early stages of": 0.0004601378070916638, "science foundation": 0.0002664248079582193, "and mutate": 0.0007696350858963753, "we do": 0.0002141987109862114, "discrete": 0.00013847052678092888, "a result of": 0.00028123137983766567, "values with k": 0.0008091139115659897, "only 20 rules": 0.0008091139115659897, "methods for delayed": 0.0008091139115659897, "we edited": 0.0007696350858963753, "and generate": 0.00042590150453082544, "scale up": 0.0004731713358791195, "game clock": 0.0007696350858963753, "system learned": 0.0007696350858963753, "hill": 0.0005749976229874555, "making problems in": 0.0008091139115659897, "corresponding to this": 0.0004813101872060044, "during each generation": 0.0008091139115659897, "after 5 700": 0.0008091139115659897, "resulting algorithm was": 0.0008091139115659897, "solution is highly": 0.0007417488271393706, "degrees is": 0.0005954002535516364, "believe it might": 0.0008091139115659897, "ending when": 0.000702264802583379, "algorithms planning": 0.0007696350858963753, "modified this approach": 0.0008091139115659897, "observed after": 0.0006628410843555166, "if three": 0.000567383102523159, "without explicitly": 0.0005128077770266814, "these observations": 0.0003603193719587997, "on control tasks": 0.0008091139115659897, "how to provide": 0.0006349209434580451, "and control": 0.0002708464065257185, "degree of accuracy": 0.0005954580987137418, "approach to robot": 0.0014046660600006416, "algorithms are": 0.00020959779892486697, "teach": 0.0014057136141301832, "to developing strategies": 0.0008091139115659897, "anderson 1983 barto": 0.0007417488271393706, "generate": 7.114859141990202e-05, "that genetic": 0.0015392701717927505, "for robot": 0.0005803901647646488, "ub i": 0.0006628410843555166, "is grefenstette": 0.0007696350858963753, "of task": 0.0003982790696131452, "any number": 0.0003304421841245212, "however the results": 0.0004958241803403253, "well when": 0.00044854462015967935, "of tests during": 0.0008091139115659897, "specified a": 0.00052785331295456, "were stopped": 0.0005954002535516364, "paper describes how": 0.0006349209434580451, "that genetic algorithms": 0.0016182278231319793, "a backgammon": 0.0007696350858963753, "approaches to developing": 0.0008091139115659897, "problems the": 0.0009782552429776195, "agent takes": 0.0006628410843555166, "relatively small": 0.000536596201670834, "since the": 4.4105142172639904e-05, "considering a": 0.00037664034839981597, "for learning evasion": 0.0008091139115659897, "still an enormous": 0.0008091139115659897, "for instance": 0.00031780750354604116, "demonstrate that k": 0.0008091139115659897, "least": -0.0005178458188125903, "setting the": 0.00027612768624444016, "stepwise forward": 0.0007696350858963753, "e because": 0.000567383102523159, "adds additional examples": 0.0008091139115659897, "of one or": 0.00040357410968453735, "assume a small": 0.0007417488271393706, "algorithms in search": 0.0011909161974274836, "reinforcement connectionist": 0.0015392701717927505, "passes": 0.0003436846998500816, "case we": 0.00015333731949816723, "instances indicated": 0.0007696350858963753, "as they": 0.00044223221420955014, "first see": 0.000702264802583379, "paths of either": 0.0008091139115659897, "facing north and": 0.0008091139115659897, "moore and": 0.0006628410843555166, "extremely well again": 0.0008091139115659897, "each rule that": 0.0008091139115659897, "particular game these": 0.0008091139115659897, "crossing the": 0.0004938405038742361, "difficult than": 0.00046009310747955083, "great difficulty solving": 0.0008091139115659897, "and salzberg": 0.000634859264718638, "passed": 0.0004972691273577931, "first set": 0.0007060899124203516, "for the remainder": 0.0004601378070916638, "store": 0.0006554334943810556, "jth dimension of": 0.0008091139115659897, "first state to": 0.0008091139115659897, "have numeric": 0.000702264802583379, "were correct in": 0.0008091139115659897, "later and its": 0.0008091139115659897, "with e and": 0.0007023330300003208, "determines the": 0.00021782729572560684, "performs quite well": 0.0005954580987137418, "rules that fired": 0.0016182278231319793, "any given time": 0.0004473842663752093, "problems apply zero": 0.0008091139115659897, "generating them": 0.000634859264718638, "for a time": 0.0005393947462253054, "a dynamic environment": 0.0006349209434580451, "identify the": 0.00024006682541839522, "yielded the": 0.0004997652289300559, "beginning exceeding the": 0.0008091139115659897, "was the": 0.00048111574977569466, "difficult task furthermore": 0.0008091139115659897, "capture e while": 0.0008091139115659897, "a declarative formulation": 0.0008091139115659897, "prematurely converging": 0.0007696350858963753, "would consider": 0.0005128077770266814, "significantly more difficult": 0.0006349209434580451, "game that ended": 0.0008091139115659897, "of control problems": 0.0008091139115659897, "applying three": 0.000702264802583379, "fitness is calculated": 0.0008091139115659897, "is a learning": 0.0006199211760863129, "to left the": 0.0007417488271393706, "s direction and": 0.0008091139115659897, "highest fitness is": 0.0008091139115659897, "bounds only the": 0.0008091139115659897, "is random": 0.0004642630166224529, "actions are directed": 0.0008091139115659897, "in dasarathy 1991": 0.0008091139115659897, "as a bootstrapping": 0.0008091139115659897, "obstacles": 0.00034888230052248793, "immediately reaches": 0.0007696350858963753, "decided to": 0.000391902140873557, "1 comparing learning": 0.0008091139115659897, "state variable as": 0.0007417488271393706, "population are dependent": 0.0008091139115659897, "was performing nearly": 0.0008091139115659897, "rule would": 0.0005954002535516364, "d 1 and": 0.000471675475395776, "formulation has both": 0.0008091139115659897, "with all of": 0.0005524148804057065, "pursuer and then": 0.0008091139115659897, "non markovian": 0.0011908005071032729, "differential equations for": 0.0005954580987137418, "circle centered on": 0.0008091139115659897, "also thanks to": 0.0007417488271393706, "games to": 0.0013256821687110331, "wilson": 0.0014660054984837723, "experiments also demonstrate": 0.0007023330300003208, "children s": 0.0005363412876789271, "gll zhang 1992": 0.0008091139115659897, "algorithms to solve": 0.0005524148804057065, "this will": 0.00021227950280458863, "learning to": 0.0063377306297349445, "laws for the": 0.0007417488271393706, "game studied in": 0.0007417488271393706, "algorithms to markov": 0.0008091139115659897, "player of": 0.000702264802583379, "this task a": 0.0008091139115659897, "in the two": 0.0006471300356458595, "a strategy": 0.0006822509109832953, "emitting smoke": 0.0007696350858963753, "nn were able": 0.0008091139115659897, "learning tr": 0.0006628410843555166, "finding": 0.00010239860714071547, "task we": 0.0008247897984561104, "set for this": 0.0005954580987137418, "1993a 1993b": 0.0007696350858963753, "al which indicated": 0.0008091139115659897, "we then tried": 0.0007417488271393706, "examples consisted of": 0.0008091139115659897, "added": 4.06912284077621e-05, "turns learning depending": 0.0008091139115659897, "fleeing two": 0.0007696350858963753, "it substantially more": 0.0008091139115659897, "measures": 0.00011088758151026398, "later the": 0.0003603193719587997, "effect on this": 0.0008091139115659897, "this demonstrates": 0.00048296474811893784, "see figure": 0.0001815300489040021, "evaluate performance against": 0.0008091139115659897, "70": 0.0002755326682929171, "nn alone": 0.0015392701717927505, "the ratio of": 0.00029862579311609863, "attempts to prevent": 0.0007417488271393706, "learning curves": 0.0005803901647646488, "strategy against": 0.0006628410843555166, "the mapping": 0.0002627707973273995, "97 98 and": 0.0008091139115659897, "is rarely used": 0.0007417488271393706, "a stored state": 0.0016182278231319793, "evader figure 5": 0.0008091139115659897, "stores complete": 0.0015392701717927505, "each move": 0.0005456354281782176, "traditional": 0.0005960640337406875, "were disappointing when": 0.0008091139115659897, "was always superb": 0.0008091139115659897, "considered approaches": 0.0007696350858963753, "ga if perf": 0.0008091139115659897, "players must": 0.0006628410843555166, "3 vector within": 0.0008091139115659897, "experimented with": 0.0007089180552839569, "which uses a": 0.000471675475395776, "well even when": 0.0007417488271393706, "are the": 0.0001305386013446306, "set of relevant": 0.0006069246369921007, "expected reward": 0.0006628410843555166, "to develop pursuit": 0.0008091139115659897, "the original work": 0.0006743602501766612, "to the state": 0.0012298186258164114, "change the": 0.00020188646752198293, "database of instances": 0.0008091139115659897, "decreases with": 0.00041758029726340933, "than producing rules": 0.0008091139115659897, "values where for": 0.0008091139115659897, "learning curve is": 0.0008091139115659897, "and games are": 0.0008091139115659897, "all actions associated": 0.0008091139115659897, "i e it": 0.0003141498861200171, "at random for": 0.0007417488271393706, "sheppard": 0.0019043927938845048, "penalty": 0.000371045860088017, "of an agent": 0.0005176213124249083, "in continuous": 0.00048296474811893784, "or conversely for": 0.0008091139115659897, "examples was to": 0.0008091139115659897, "the actions at": 0.0007417488271393706, "its previous turn": 0.0008091139115659897, "even outperforms its": 0.0008091139115659897, "e the complete": 0.0007417488271393706, "his": 0.00016864276445969448, "hit": 0.00024975319658184, "even simple": 0.000567383102523159, "all states which": 0.0006526576017704936, "in differential": 0.0019990609157202236, "backgammon program called": 0.0008091139115659897, "playing has": 0.0007696350858963753, "with almost every": 0.0008091139115659897, "our study": 0.0003177175902857743, "although the": 0.00014536106689930242, "speeds of p1": 0.0008091139115659897, "solution strategies for": 0.0008091139115659897, "the simulator": 0.002511757267723376, "would require roughly": 0.0008091139115659897, "td methods": 0.000702264802583379, "y state": 0.0007696350858963753, "solutions and": 0.00036494662878843966, "as a framework": 0.0011909161974274836, "5 theta": 0.00042304989757217126, "and the pedestrian": 0.002427341734697969, "in the population": 0.0012138492739842013, "develop continuously": 0.0007696350858963753, "the range 80": 0.0008091139115659897, "into a chromosome": 0.0008091139115659897, "of which were": 0.0005674382257236372, "as strength": 0.0007696350858963753, "the arithmetic": 0.000378426656892181, "90 the": 0.0005363412876789271, "respect to the": 0.00019667558190001054, "nn second": 0.0007696350858963753, "for helpful comments": 0.0004779929005953682, "similar fashion": 0.00041758029726340933, "simplified game of": 0.0008091139115659897, "the multiedit algorithm": 0.0008091139115659897, "states were passed": 0.0008091139115659897, "evader b": 0.0007696350858963753, "evader a": 0.0007696350858963753, "pole problem": 0.0007696350858963753, "v 33 n": 0.0003507647800338115, "evader e": 0.0023089052576891257, "achieved": 0.00017187935237956205, "and it can": 0.00040357410968453735, "in a differential": 0.0006349209434580451, "strategic games such": 0.0008091139115659897, "comparison of": 0.00035586480186055116, "achieves": 0.00013377958970589826, "first however": 0.0005456354281782176, "e the expected": 0.0007023330300003208, "defense": 0.00033862129956161867, "and competition the": 0.0008091139115659897, "are": 0, "learning algorithms the": 0.0005851984448616567, "simulated robot": 0.000702264802583379, "performance 4": 0.0005954002535516364, "how to solve": 0.0005083144306061808, "arm": 0.00033620802548856775, "many ways": 0.0003820967919236623, "demonstrates that genetic": 0.0008091139115659897, "learns": 0.0009217273567057226, "examples must": 0.0007696350858963753, "similar actions we": 0.0008091139115659897, "action pairs without": 0.0008091139115659897, "state in memory": 0.0007023330300003208, "states and apply": 0.0007417488271393706, "examples consisted": 0.0007696350858963753, "editing gll": 0.0007696350858963753, "aim for a": 0.0007023330300003208, "storing examples in": 0.002427341734697969, "the evader has": 0.0008091139115659897, "1 state": 0.00052785331295456, "convergence we": 0.0004642630166224529, "numerous": 0.00019870316723696684, "torras 1992 moore": 0.0008091139115659897, "well on problems": 0.0008091139115659897, "recently": 0.00016776253867960048, "actions through": 0.000702264802583379, "fact the lazy": 0.0008091139115659897, "initially": 0.00044630579749388075, "be quite": 0.0002945105957876159, "meant that the": 0.0007023330300003208, "figure 5b for": 0.0007417488271393706, "result of using": 0.0006199211760863129, "from ga": 0.000702264802583379, "games increased this": 0.0008091139115659897, "head directly": 0.0007696350858963753, "performance q": 0.0007696350858963753, "generalized or": 0.000634859264718638, "our extended": 0.00052785331295456, "c": -0.0002830829420950543, "ga teaching k": 0.0008091139115659897, "instance based": 0.0020512311081067255, "that neighboring states": 0.0008091139115659897, "evader from achieving": 0.0008091139115659897, "determined the outcome": 0.0008091139115659897, "of performance": 0.000851502220943135, "reduction in": 0.0002386061189975044, "expected payoff and": 0.0008091139115659897, "quantization": 0.00034888230052248793, "5 000": 0.0032180477260735627, "reduction is": 0.0003315762308313901, "for example if": 0.00024391003976470028, "context": -7.6057164073587004e-06, "plus editing gll": 0.0008091139115659897, "how well k": 0.0008091139115659897, "finds": 0.00014843855739245598, "complicated task which": 0.0008091139115659897, "arbitrarily": 0.0002390558196620996, "stores the": 0.0003217891594434185, "a pursuit": 0.001904577794155914, "in a data": 0.000449806936615026, "either method alone": 0.0016182278231319793, "the expected discounted": 0.0007023330300003208, "points that": 0.0007060899124203516, "markovian problems the": 0.0008091139115659897, "as the": 5.182931765974132e-05, "a form": 0.0008429043036949046, "similar to grefenstette": 0.0008091139115659897, "extension of": 0.00018935563451343574, "the earlier k": 0.0008091139115659897, "e while": 0.00048296474811893784, "this study considered": 0.0007417488271393706, "interesting examples": 0.000634859264718638, "than the homicidal": 0.0008091139115659897, "accuracy decreased": 0.0007696350858963753, "complication": 0.0003207251598139373, "learning and gas": 0.0008091139115659897, "in multi agent": 0.0011348764514472745, "about each": 0.0004560919846500759, "of perceptual": 0.001134766205046318, "a lazy learning": 0.0032364556462639586, "games includes numerous": 0.0008091139115659897, "due": -0.00011127165817290851, "were real valued": 0.0008091139115659897, "strategy": 0.0007800008576929878, "based reasoning papers": 0.0008091139115659897, "only 5": 0.0004731713358791195, "reduction": 6.652509986502366e-05, "study they provided": 0.0008091139115659897, "accuracy decreases": 0.000634859264718638, "action pairs in": 0.0007417488271393706, "this suggests": 0.00030198240340165204, "well with": 0.0003338822091906335, "we cannot": 0.00022153363976495309, "1989 barto": 0.0007696350858963753, "that p": 0.00020771762406971897, "of training on": 0.0008091139115659897, "dt where a": 0.0007417488271393706, "on neural networks": 0.0007417488271393706, "the terms have": 0.0008091139115659897, "we studied": 0.0003748850085915968, "this family": 0.00048825248710181613, "same control": 0.0005363412876789271, "of perception and": 0.0016182278231319793, "the simulator generated": 0.0008091139115659897, "only its": 0.0004382027886649359, "they addressed the": 0.0007417488271393706, "method which differs": 0.0008091139115659897, "thanks to diana": 0.0008091139115659897, "trying to": 0.0005027788987694298, "discussed in this": 0.0004005368556067546, "the ability of": 0.0018275474766626283, "to play the": 0.0012698418869160901, "a complete game": 0.0008091139115659897, "successful a lazy": 0.0008091139115659897, "different ones for": 0.0008091139115659897, "p2": 0.0017340712510413776, "p1": 0.0026334591343441845, "storing approximately": 0.0007696350858963753, "a differential": 0.001808985614634705, "mccallum showed": 0.0007696350858963753, "also wins by": 0.0008091139115659897, "the pursuer s": 0.0007417488271393706, "depends on": 0.00023349058399633546, "and r is": 0.00041328080567602945, "of state": 0.0003054794925471542, "alone if we": 0.0007417488271393706, "behavior": -1.0981724788263222e-05, "evaluates": 0.00018741611189910064, "both variations": 0.000702264802583379, "optimal strategy prior": 0.0008091139115659897, "where e is": 0.0004360863081445778, "such a small": 0.0005456884385180774, "21 examples comparable": 0.0008091139115659897, "follows instance": 0.000702264802583379, "the two pursuer": 0.012136708673489845, "one pursuer two": 0.0032364556462639586, "chapman 1987 as": 0.0008091139115659897, "is much": 0.00035409580880023487, "performance with only": 0.0007023330300003208, "table this permits": 0.0008091139115659897, "working together can": 0.0007417488271393706, "and selected an": 0.0008091139115659897, "disappointing": 0.0004098599033682474, "nearest neighbor techniques": 0.0007417488271393706, "alone previous": 0.0007696350858963753, "well initially": 0.000702264802583379, "versions of the": 0.00031479506571990205, "periodically release": 0.0007696350858963753, "numeric values": 0.000567383102523159, "this difficult": 0.0006131469602829721, "20 rules with": 0.0008091139115659897, "terms have": 0.0005200422895505865, "whitehead": 0.0005455824281366266, "c is": 0.0001375555909253381, "rule differential games": 0.0008091139115659897, "being predicted": 0.0005954002535516364, "e the pursuer": 0.0008091139115659897, "teacher is probably": 0.0008091139115659897, "because of this": 0.00040830984894046896, "play differential games": 0.0016182278231319793, "decision problem van": 0.0008091139115659897, "cause problems for": 0.0006349209434580451, "scaled linearly from": 0.0008091139115659897, "solutions to the": 0.00037093973316531143, "the predicted reward": 0.0016182278231319793, "9": -0.0006373795465347554, "randomly selecting": 0.000567383102523159, "rules and": 0.00032932038867923357, "states in": 0.0002961263574580495, "higher": -3.326254993251183e-05, "examination of": 0.0003462531725087664, "using rule compilation": 0.0008091139115659897, "applying nearest": 0.0007696350858963753, "literature": 0.00012772938322701526, "to study": 0.0004658821202250575, "method to solve": 0.0005083144306061808, "speed of the": 0.0008370239623164543, "class of delayed": 0.0008091139115659897, "two particularly": 0.0006628410843555166, "usually": -4.4854703005030336e-05, "together to produce": 0.0007023330300003208, "rule compilation that": 0.0008091139115659897, "decide which of": 0.0005954580987137418, "lazy q learning": 0.004045569557829949, "complex many games": 0.0008091139115659897, "both k nn": 0.0008091139115659897, "learning strategy": 0.000567383102523159, "a low level": 0.0004919901420568756, "to escape depends": 0.0008091139115659897, "lower": -0.0001878446254488446, "relevant attributes however": 0.0008091139115659897, "to learn several": 0.0008091139115659897, "competitive games in": 0.0008091139115659897, "is described": 0.00018839142079640303, "as ours": 0.0005060701527920558, "and sensing": 0.0006628410843555166, "our definition of": 0.0004404523980181757, "analysis": -0.00015381975734280533, "3 shows how": 0.0005524148804057065, "fired are generalized": 0.0008091139115659897, "to encapsulate": 0.0005363412876789271, "20 times steps": 0.0008091139115659897, "distributions of": 0.0003374403959319754, "that averaging": 0.000702264802583379, "and later we": 0.0007417488271393706, "and ship routing": 0.0008091139115659897, "trials on random": 0.0008091139115659897, "issues of": 0.0003489161923333023, "evades the pursuers": 0.0008091139115659897, "the field of": 0.00038402039400084893, "had to represent": 0.0008091139115659897, "abilities": 0.0010548479599690097, "a payoff": 0.0005803901647646488, "implemented the": 0.00031672395822701763, "some of e": 0.0008091139115659897, "determined in part": 0.0007417488271393706, "approximately 97 success": 0.0008091139115659897, "payoff function the": 0.0008091139115659897, "competitive": 0.00048106901682282664, "make the": 0.00015408402117808592, "performing considerably": 0.0007696350858963753, "of expected": 0.00046009310747955083, "intervals": 0.0001513496472119038, "learner with k": 0.0008091139115659897, "with k": 0.0013574640874433747, "wilson 1972": 0.0007696350858963753, "too strict a": 0.0007417488271393706, "that examples could": 0.0008091139115659897, "with e": 0.00035165014402826746, "adaptation of": 0.00035027405940034004, "a plateau": 0.0006628410843555166, "with a": 9.016923214251898e-05, "show the results": 0.0004522903409367932, "variety of": 0.0003517550846112964, "for lazy": 0.002269532410092636, "k nn to": 0.0032364556462639586, "solutions we": 0.00042027761111456123, "traditional lazy method": 0.0008091139115659897, "the ga system": 0.0008091139115659897, "one rule": 0.00046009310747955083, "recognition a": 0.00046009310747955083, "in the database": 0.0024695773194404465, "plateau": 0.0019116001654504613, "operators to evolve": 0.0008091139115659897, "set through": 0.0006131469602829721, "which different": 0.0005200422895505865, "winners of": 0.000702264802583379, "steps our": 0.0005803901647646488, "to diana gordon": 0.0008091139115659897, "both variations of": 0.0008091139115659897, "plan with the": 0.0007417488271393706, "noncooperative": 0.0007021965884209132, "task the experiments": 0.0008091139115659897, "samuel system": 0.0007696350858963753, "with 1": 0.0002741172369601924, "i e a": 0.00025945200309779564, "speed by traveling": 0.0008091139115659897, "robot and": 0.0010912708563564353, "to these problems": 0.0005456884385180774, "table the result": 0.0007417488271393706, "results for each": 0.0004958241803403253, "6 using this": 0.0008091139115659897, "points whereas for": 0.0008091139115659897, "learning could perform": 0.0008091139115659897, "using samuel for": 0.0008091139115659897, "i e k": 0.0010352426248498167, "this makes sense": 0.0005954580987137418, "routing are": 0.00052785331295456, "next phase": 0.0005128077770266814, "eventual payoff": 0.0007696350858963753, "selecting typical instances": 0.0016182278231319793, "that simply": 0.00044153169724958527, "learning the task": 0.0016182278231319793, "p uses a": 0.0007417488271393706, "another study aha": 0.0008091139115659897, "upper bounds respectively": 0.0006743602501766612, "the first threshold": 0.0008091139115659897, "sequences non": 0.000702264802583379, "to evolve a": 0.0006743602501766612, "must perform a": 0.0006349209434580451, "use rules": 0.000634859264718638, "demonstrate the": 0.00024055787488784733, "ones in": 0.0003338822091906335, "are correctly": 0.0004560919846500759, "a chromosome for": 0.0008091139115659897, "followed by each": 0.0007417488271393706, "until play ended": 0.0008091139115659897, "combined use of": 0.0006743602501766612, "the theoretically minimal": 0.0008091139115659897, "for k": 0.0019483929005349623, "to compare": 0.00020660315877070218, "actions when the": 0.0006743602501766612, "we use": 0.00010709681599616145, "learning these": 0.0005954002535516364, "pursuers in": 0.0015392701717927505, "for e": 0.0009137830433055614, "this figure compares": 0.0007417488271393706, "pursuers is": 0.0007696350858963753, "plan are selected": 0.0008091139115659897, "in these": 0.00045778312588702077, "teaching strategy": 0.0007696350858963753, "robot path": 0.0015392701717927505, "possible future direction": 0.0008091139115659897, "p players at": 0.0008091139115659897, "communicate what it": 0.0008091139115659897, "problem is the": 0.00038790254623973576, "makes a series": 0.0008091139115659897, "noncooperative game": 0.0007696350858963753, "population may": 0.0007696350858963753, "only controls": 0.0007696350858963753, "700 examples next": 0.0008091139115659897, "between taking an": 0.0008091139115659897, "circle centered": 0.0005456354281782176, "or loses at": 0.0008091139115659897, "to successfully evade": 0.0008091139115659897, "lower and": 0.0007206387439175994, "80 success": 0.0007696350858963753, "to machine learning": 0.0007023330300003208, "adapt its strategy": 0.0008091139115659897, "tends": 0.00015633199732239923, "of ritter": 0.0007696350858963753, "difficult to characterize": 0.0006349209434580451, "prob": 0.00021033758092698209, "in gabriel dynamic": 0.0008091139115659897, "tackle increasingly difficult": 0.0008091139115659897, "fitness values of": 0.0007417488271393706, "time and where": 0.0008091139115659897, "bootstrapping idea": 0.0007696350858963753, "this game we": 0.0008091139115659897, "threshold was set": 0.0019047628303741355, "maneuver in direct": 0.0008091139115659897, "of updating": 0.00044854462015967935, "task known": 0.0007696350858963753, "by running": 0.0003327228091591544, "be percent": 0.0007696350858963753, "aerial dogfighting and": 0.0008091139115659897, "othello": 0.0014043931768418264, "particular problem": 0.00042590150453082544, "vector in real": 0.0008091139115659897, "atkeson 1993 but": 0.0008091139115659897, "was that": 0.0015209802845022186, "1989 namely": 0.0007696350858963753, "space for": 0.0002721430567364954, "rules within a": 0.0007417488271393706, "algorithms reinforcement learning": 0.0008091139115659897, "genetic algorithm for": 0.0006526576017704936, "we do not": 0.0003396336218421593, "and colombetti and": 0.0008091139115659897, "be converted": 0.0003748850085915968, "range": -0.00012641215795359683, "typically consisted": 0.0007696350858963753, "murthy for": 0.0007696350858963753, "samuel then": 0.0007696350858963753, "location where they": 0.0008091139115659897, "for some": 0.00031904544783679337, "store each": 0.0005803901647646488, "examples thus it": 0.0008091139115659897, "train k nn": 0.0008091139115659897, "and novel": 0.0005559058853301298, "ctr john w": 0.0008091139115659897, "motivated the second": 0.0008091139115659897, "producing rules": 0.0007696350858963753, "learning approach that": 0.0007417488271393706, "substantially more difficult": 0.0007417488271393706, "achieving around 95": 0.0008091139115659897, "can be found": 0.00019286222308448407, "pit a": 0.000702264802583379, "that ended in": 0.0008091139115659897, "also pit": 0.0007696350858963753, "the initial placements": 0.0008091139115659897, "strategies are": 0.0007922163287168681, "approach uses": 0.0009044928073173525, "1963 this sequence": 0.0008091139115659897, "navigate around obstacles": 0.0008091139115659897, "converging on": 0.000702264802583379, "question": 0.00012167765532973086, "the ga throughout": 0.0016182278231319793, "long": -5.211539321897609e-05, "are modeled": 0.0007298932575768793, "genetic algorithm is": 0.0007023330300003208, "fashion to": 0.00048296474811893784, "is complex": 0.0004779464664686347, "of ga if": 0.0008091139115659897, "learning also learned": 0.0008091139115659897, "more recently michael": 0.0008091139115659897, "about which": 0.0004288371693587632, "sections": 3.326254993251183e-05, "uses and refines": 0.0007417488271393706, "produce agents that": 0.0008091139115659897, "both k": 0.0005128077770266814, "and actions": 0.0004349818647972793, "the turn increases": 0.0008091139115659897, "to continue": 0.00033988242810104627, "learning by a": 0.0008091139115659897, "task q learning": 0.0008091139115659897, "stochastic component each": 0.0008091139115659897, "tasks pursuer": 0.0007696350858963753, "stages of": 0.0006394671499598017, "necessary component": 0.000702264802583379, "learning tolerating noisy": 0.0008091139115659897, "oe is": 0.0002882806874477652, "linearly from no": 0.0008091139115659897, "both q": 0.0005559058853301298, "that one": 0.00020082290713615512, "learning in classifier": 0.0008091139115659897, "salzberg 1993 4": 0.0008091139115659897, "parameters one": 0.0005363412876789271, "and machine learning": 0.0005393947462253054, "strict a": 0.0006131469602829721, "solve difficult learning": 0.0007023330300003208, "is the actual": 0.0004882999224935485, "which point the": 0.0005393947462253054, "coverage of": 0.00039398316601407357, "chromosome corresponding to": 0.0008091139115659897, "a is applied": 0.0006349209434580451, "games which in": 0.0008091139115659897, "and much": 0.0004149539560409001, "it toward": 0.0006628410843555166, "at random": 0.0009592007249397027, "highlight": 0.00027884013760390546, "reduce its memory": 0.0008091139115659897, "called": -0.0009092175723087346, "graph shows how": 0.0007417488271393706, "more recently": 0.0009413948659952932, "cannot be sure": 0.0005954580987137418, "associated": -0.0002950115325469697, "below determine the": 0.0008091139115659897, "e the radius": 0.0008091139115659897, "init population do": 0.0008091139115659897, "cover two players": 0.0008091139115659897, "which indicated the": 0.0008091139115659897, "the experiences of": 0.0007023330300003208, "100 evasion while": 0.0008091139115659897, "a small memory": 0.0007023330300003208, "being predicted are": 0.0008091139115659897, "pursuer the capabilities": 0.0008091139115659897, "has yielded performance": 0.0008091139115659897, "millan": 0.001269595195923003, "performance threshold": 0.0007696350858963753, "lazy learning method": 0.0008091139115659897, "step further": 0.0004779464664686347, "adapt q learning": 0.0008091139115659897, "all rules will": 0.0008091139115659897, "back propagation": 0.0005559058853301298, "evaluate lazy test": 0.0008091139115659897, "angle at each": 0.0016182278231319793, "single pursuer which": 0.0008091139115659897, "strategy prior": 0.0007696350858963753, "because lazy": 0.0007696350858963753, "1988 tesauro 1992": 0.0008091139115659897, "will become important": 0.0007417488271393706, "game we selected": 0.0008091139115659897, "we begin": 0.0002186410781136593, "evader additional capabilities": 0.0008091139115659897, "in classifier": 0.0006628410843555166, "predator prey interactions": 0.0008091139115659897, "that reinforcement": 0.0007696350858963753, "which locates": 0.000702264802583379, "encouraging and": 0.000567383102523159, "collecting examples was": 0.0008091139115659897, "they found they": 0.0008091139115659897, "values described below": 0.0007417488271393706, "the current turn": 0.0008091139115659897, "plan in the": 0.0006526576017704936, "task is": 0.0005378593376444504, "ga as the": 0.0007417488271393706, "turn angle of": 0.0008091139115659897, "storage of": 0.0003982790696131452, "problems": -0.003615564397304429, "of the competition": 0.0008091139115659897, "differential games third": 0.0008091139115659897, "nn s poor": 0.0008091139115659897, "to evade when": 0.0008091139115659897, "generated": -0.0002699442081512637, "the instance": 0.00035445902764197844, "assume the tasks": 0.0008091139115659897, "k nn classifier": 0.0008091139115659897, "the knowledge": 0.0003072722989859923, "problem van der": 0.0008091139115659897, "bad examples finally": 0.0008091139115659897, "almost immediately and": 0.0008091139115659897, "task specifically": 0.000702264802583379, "control a": 0.0004050885930083273, "experiments applying": 0.000702264802583379, "letting the state": 0.0007417488271393706, "approach must": 0.0005803901647646488, "are modeled by": 0.0005226282087022614, "identifying differences between": 0.0008091139115659897, "attributes in a": 0.0006349209434580451, "the strength for": 0.0008091139115659897, "reward for each": 0.0008091139115659897, "task and the": 0.0005176213124249083, "is known to": 0.00032356501782292976, "general and": 0.0003315762308313901, "third traditional": 0.000702264802583379, "using this": 0.00037486863648751535, "be used": 0.00015111170752098434, "are building": 0.000567383102523159, "because the": 0.00018728490451172576, "lot with a": 0.0008091139115659897, "intervals we estimated": 0.0008091139115659897, "once": -5.827896435123235e-05, "problems so": 0.0005363412876789271, "form dt where": 0.0008091139115659897, "a long": 0.0005267429918024749, "delayed reinforcement problems": 0.002427341734697969, "a sample game": 0.0016182278231319793, "95 successful": 0.0007696350858963753, "96 9 42": 0.0008091139115659897, "be associated": 0.00036494662878843966, "extended version": 0.0004288371693587632, "the reward": 0.0017021493075694769, "second lazy": 0.0007696350858963753, "only around": 0.000634859264718638, "nn second details": 0.0008091139115659897, "action would have": 0.0007023330300003208, "in the antecedent": 0.0006199211760863129, "a performance": 0.0002809681012316349, "are refined through": 0.0008091139115659897, "very high": 0.0002898046105948889, "bounds respectively": 0.000634859264718638, "that can": 8.636658066988502e-05, "issues": 0.00010239860714071547, "lazy and eager": 0.0007417488271393706, "simon": 0.000280236063377934, "rule strength": 0.0023089052576891257, "intelligent agents": 0.0005128077770266814, "approach might be": 0.0006349209434580451, "deterministic": 0.00011872516938489912, "these experiments the": 0.0004958241803403253, "ritter et al": 0.0014834976542787413, "learning rl": 0.0006628410843555166, "second phase": 0.00034757605337154215, "for the single": 0.00046289837369057756, "algorithm takes": 0.0003878648638474452, "agents thus": 0.000702264802583379, "include": -7.759690855244181e-05, "lazy learning these": 0.0008091139115659897, "generation select": 0.0007696350858963753, "two pursuer evasion": 0.0016182278231319793, "the jth dimension": 0.0008091139115659897, "j is the": 0.00030374604195717594, "ga surpassing": 0.0007696350858963753, "up to 50": 0.0005851984448616567, "have different": 0.00028167752214893036, "been studied": 0.0005116085074838764, "93 3": 0.0005803901647646488, "will become": 0.00032821057342992757, "as binary attributes": 0.0008091139115659897, "the attribute bounds": 0.0008091139115659897, "performance jumped": 0.0007696350858963753, "the examples were": 0.0007417488271393706, "5 sample": 0.0006628410843555166, "environment for analyzing": 0.0008091139115659897, "games where": 0.001269718529437276, "the threshold": 0.0006456646279759946, "the same system": 0.0005456884385180774, "neighbors finally we": 0.0008091139115659897, "successful examples": 0.000702264802583379, "a population may": 0.0008091139115659897, "by considering": 0.0002240700519004841, "approach using k": 0.0008091139115659897, "will take": 0.0003462531725087664, "the pedestrian": 0.0053027286748441324, "p1 and p2": 0.0027284421925903874, "and speed": 0.000391902140873557, "set with its": 0.0007417488271393706, "concluded": 0.00027746189472758456, "slowed consider ably": 0.0008091139115659897, "simple structures": 0.0006628410843555166, "learning tr on": 0.0008091139115659897, "equations learning": 0.0007696350858963753, "maximally gen eral": 0.0008091139115659897, "a set of": 0.0009747681157878259, "further in section": 0.0005226282087022614, "fold": 0.0002445400551532689, "rate ae is": 0.0007417488271393706, "we use a": 0.00023265689064774458, "traveling": 0.0006181320161608259, "pole prob": 0.0007696350858963753, "states and perceptions": 0.0008091139115659897, "machine learning": 0.0015409011501650162, "a three": 0.0002921317927643509, "a method for": 0.00030201174202046106, "memory requirements b": 0.0008091139115659897, "novel attributes": 0.0007696350858963753, "game lasts for": 0.0008091139115659897, "checkers": 0.00035442459743045417, "achieving 100 success": 0.0008091139115659897, "for a location": 0.0008091139115659897, "predicting the rewards": 0.0008091139115659897, "the pursuers is": 0.0008091139115659897, "memory requirements": 0.0011143889381834747, "expected discounted": 0.0006628410843555166, "networks": 0.00021732615270870343, "playing field being": 0.0008091139115659897, "aliasing in": 0.0005456354281782176, "in part": 0.0007811905545680066, "lazy learning both": 0.0008091139115659897, "flattened out": 0.000634859264718638, "some payoff isaacs": 0.0008091139115659897, "two pursuers p1": 0.0008091139115659897, "were stopped was": 0.0008091139115659897, "of accuracy": 0.0003462531725087664, "would have": 0.00035883930149511285, "wait until we": 0.0008091139115659897, "degree": 9.594103050662592e-05, "approach must have": 0.0007417488271393706, "problem has": 0.0002905747481074539, "genetic algorithm in": 0.0014834976542787413, "considered the algorithms": 0.0008091139115659897, "if we halt": 0.0008091139115659897, "the algorithm s": 0.0004779929005953682, "north and": 0.0005559058853301298, "evasion instead": 0.0007696350858963753, "alone this": 0.0011118117706602597, "explore": 0.0003304321450368394, "gas we": 0.0007696350858963753, "approximately 1 500": 0.0008091139115659897, "bad actions later": 0.0008091139115659897, "the start of": 0.0003411585969912582, "first minimal": 0.0007696350858963753, "abilities one": 0.0007696350858963753, "performance between": 0.00048296474811893784, "selected the set": 0.0007417488271393706, "the rules that": 0.0010558091914027474, "difficulty by adding": 0.0008091139115659897, "control laws": 0.0011908005071032729, "up to fifty": 0.0008091139115659897, "popular approaches to": 0.0006743602501766612, "learning performed": 0.000702264802583379, "do not have": 0.000530846874987798, "industries but": 0.0007696350858963753, "order differential": 0.0005456354281782176, "suggests": 0.00010447367774338842, "approach that": 0.0005938869885403849, "nonlinear thus we": 0.0008091139115659897, "tree induction efficient": 0.0008091139115659897, "dimension of the": 0.0003634160486420408, "binary emitting smoke": 0.0008091139115659897, "are using differential": 0.0008091139115659897, "games in fact": 0.0008091139115659897, "perform the task": 0.0006743602501766612, "amount of": 0.00012014402828336187, "q learning given": 0.0008091139115659897, "second phase of": 0.0005039721952628732, "twice as": 0.00034757605337154215, "and upper bound": 0.0005456884385180774, "apply one": 0.00052785331295456, "our experiments ae": 0.0008091139115659897, "expand the": 0.0003859053049699601, "the angle between": 0.0004522903409367932, "of discrete": 0.0003177175902857743, "scaled": 0.0001818166271881099, "in many ways": 0.0005039721952628732, "however determining relevant": 0.0008091139115659897, "an open": 0.00025636849908832897, "because only": 0.00041758029726340933, "apply": -0.00013028848304744023, "to markovian": 0.000702264802583379, "that two learning": 0.0008091139115659897, "near perfect": 0.0018394408808489165, "use genetic operators": 0.0008091139115659897, "learning depending": 0.0007696350858963753, "problems to date": 0.0008091139115659897, "use": -0.0061478985505237106, "value for": 0.0002033187844386837, "from": 0, "other in the": 0.0004779929005953682, "air traffic": 0.0005456354281782176, "to find any": 0.0011348764514472745, "solutions and for": 0.0007023330300003208, "examples include": 0.0003878648638474452, "tree induction learning": 0.0008091139115659897, "few": -2.0345614203881056e-05, "e fails to": 0.0007417488271393706, "examination": 0.0002541036544465819, "network that": 0.000783804281747114, "rate if the": 0.0006069246369921007, "000 games of": 0.0008091139115659897, "ga evades": 0.0007696350858963753, "classification problems": 0.0004938405038742361, "next section": 0.0001486934483179834, "describe an approach": 0.0006199211760863129, "learned excellent": 0.0007696350858963753, "8s2rules strength": 0.0007696350858963753, "performance threshold our": 0.0008091139115659897, "000 games": 0.009129442433583925, "friedman 1971": 0.0007696350858963753, "if e fails": 0.0008091139115659897, "escape is always": 0.0008091139115659897, "evader pursuer": 0.0015392701717927505, "outperformed both": 0.000702264802583379, "s characteristics metagamer": 0.0008091139115659897, "result was that": 0.0006349209434580451, "dorigo 1994": 0.0007696350858963753, "as k nn": 0.0008091139115659897, "iri 9223591": 0.0007696350858963753, "no improvement": 0.00048825248710181613, "its class name": 0.0008091139115659897, "that two": 0.0002695648787641501, "times steps i": 0.0008091139115659897, "to solve difficult": 0.0008091139115659897, "neighbor algorithms to": 0.0008091139115659897, "with k nn": 0.0029669953085574826, "percent success examples": 0.0008091139115659897, "on one": 0.0007086358426673296, "variable to a": 0.0005596382660342995, "interesting differences k": 0.0008091139115659897, "environments learning": 0.0007696350858963753, "this is": 1.67955276994053e-05, "of other": 0.00018711684273839185, "50 evasion were": 0.0008091139115659897, "dropped": 0.00023477604289546367, "1 of": 0.0003618473061430687, "expected rewards associated": 0.0008091139115659897, "itself into": 0.000634859264718638, "aircraft used": 0.0007696350858963753, "uses euclidean": 0.0007696350858963753, "superior to": 0.00035589291297159965, "steps since it": 0.0007417488271393706, "our approach": 0.0003342651151289631, "algorithm adds": 0.000567383102523159, "of curvature our": 0.0008091139115659897, "tag": 0.00025082519534844617, "something": 0.00020365966709578537, "algorithm performed even": 0.0008091139115659897, "tac": 0.000567327990031413, "tr on": 0.0005060701527920558, "game theory differential": 0.0008091139115659897, "method our": 0.0004779464664686347, "9223591": 0.0007021965884209132, "individually speed bearing": 0.0008091139115659897, "affects two": 0.0007696350858963753, "are normalized the": 0.0007417488271393706, "of comparing": 0.0004560919846500759, "neural net in": 0.0008091139115659897, "these examples one": 0.0008091139115659897, "deal with issues": 0.0007417488271393706, "approach by taking": 0.0008091139115659897, "learner by": 0.0007696350858963753, "excellent strategies": 0.0007696350858963753, "point the simulator": 0.0008091139115659897, "to predict": 0.0008407898598627835, "search optimization": 0.0006131469602829721, "instead": -0.00026730610353706703, "applied samuel to": 0.0008091139115659897, "potential effect": 0.0007696350858963753, "nature these examples": 0.0008091139115659897, "each 3 vector": 0.0008091139115659897, "more striking": 0.000634859264718638, "below we": 0.0002546842039466833, "the simulator passes": 0.0008091139115659897, "other words the": 0.00030374604195717594, "strength s t": 0.0008091139115659897, "initially implemented": 0.000702264802583379, "needs to": 0.00015458393483475883, "and feature": 0.0004731713358791195, "a simulated": 0.0004288371693587632, "pursuer p and": 0.0008091139115659897, "call this system": 0.0007417488271393706, "producing rules we": 0.0008091139115659897, "store during": 0.000634859264718638, "state that follows": 0.0007417488271393706, "and classifying the": 0.0007023330300003208, "any given": 0.0002430451200871382, "of the playing": 0.0008091139115659897, "robotics planning": 0.0007696350858963753, "for nearby": 0.000634859264718638, "chapman": 0.00043816022404243314, "theta 10 22": 0.0008091139115659897, "k nn expects": 0.0008091139115659897, "and fi": 0.0002898046105948889, "if evade": 0.0007696350858963753, "of two": 8.113945228978329e-05, "we show the": 0.00032216701795198684, "given in figure": 0.00031942590101071355, "database evasion usually": 0.0008091139115659897, "000 examples": 0.0019885232530665498, "that k nn": 0.0032364556462639586, "lazy approach are": 0.0008091139115659897, "neighbors 4": 0.000702264802583379, "those discussed in": 0.0005759152096655707, "by successfully evading": 0.0008091139115659897, "135": 0.0002682720398251367, "values described": 0.000702264802583379, "r learning to": 0.0008091139115659897, "attempted to": 0.0003697942966553643, "superior": 0.00020957743974090145, "3 2 also": 0.0006199211760863129, "tasks pursuer evader": 0.0008091139115659897, "to play and": 0.0007023330300003208, "sharply otherwise": 0.0007696350858963753, "is updated": 0.0008407898598627835, "component each move": 0.0008091139115659897, "and to store": 0.0007023330300003208, "however determining": 0.0006131469602829721, "n each clause": 0.0008091139115659897, "very slowly until": 0.0008091139115659897, "apply reinforcement": 0.0007696350858963753, "quantization of": 0.0005559058853301298, "in general and": 0.0004747836164770488, "each set": 0.00032821057342992757, "22 games": 0.0007696350858963753, "and control problems": 0.0007417488271393706, "can capture": 0.0004349818647972793, "methods specifically": 0.0005954002535516364, "material": 0.0002206785921423253, "this additional": 0.0004050885930083273, "1990 we call": 0.0008091139115659897, "i e the": 0.0013423049874737112, "range difference": 0.0006628410843555166, "provide examplars": 0.0007696350858963753, "a formulation": 0.0004938405038742361, "was about": 0.00044497617160632185, "possibly different ones": 0.0008091139115659897, "the sequence": 0.00016362339426920716, "fifty plans": 0.0007696350858963753, "is awarded": 0.0007696350858963753, "learning rate 0": 0.0008091139115659897, "gll outperformed": 0.0015392701717927505, "variables were permitted": 0.0008091139115659897, "slowly being outperformed": 0.0008091139115659897, "control strategy they": 0.0008091139115659897, "turns into the": 0.0006199211760863129, "measures the": 0.0003037165348615905, "profound": 0.00044493294905444163, "its genetic algorithm": 0.0008091139115659897, "is an estimate": 0.0010452564174045229, "to theoretical work": 0.0008091139115659897, "fitness proportional": 0.0007696350858963753, "supported in": 0.0002240700519004841, "nn after reaching": 0.0008091139115659897, "learning for robot": 0.0007417488271393706, "to the one": 0.00028313794703862665, "action comparator examines": 0.0008091139115659897, "are learning": 0.0006628410843555166, "of delayed reinforcement": 0.0008091139115659897, "this probability": 0.0003839830887362287, "pursuers speeds": 0.0007696350858963753, "sharp turns i": 0.0008091139115659897, "and the evader": 0.002427341734697969, "turn randomly": 0.0007696350858963753, "rule watkins": 0.000702264802583379, "traditional eager approaches": 0.0008091139115659897, "related": -0.00017067516345630073, "with no": 0.0001949601876710967, "0 1 for": 0.0004813101872060044, "two pursuers in": 0.0008091139115659897, "range to": 0.0005559058853301298, "with no reduction": 0.0007417488271393706, "our": -0.00956069319802133, "80": 0.0006430558777283486, "81": 0.0001912873267246254, "86": 0.00020151136610806482, "and dorigo": 0.0007696350858963753, "out": -0.0007302742229324322, "of each algorithm": 0.0006199211760863129, "that the class": 0.0004339731734948358, "escaping from a": 0.0008091139115659897, "than the rules": 0.0007417488271393706, "an empirical": 0.0006724813721400439, "finally we experimented": 0.0008091139115659897, "artificial systems practical": 0.0008091139115659897, "the following": 2.1986417291643452e-05, "and appropriate actions": 0.0008091139115659897, "intuitively optimal": 0.0007696350858963753, "in random games": 0.0008091139115659897, "performs": 0.00016199615996282966, "angle which is": 0.0007023330300003208, "smith and gray": 0.0008091139115659897, "environment where we": 0.0008091139115659897, "solve the pursuit": 0.0008091139115659897, "induction": 0.00022408435804161908, "rule watkins 1989": 0.0007417488271393706, "occurred the": 0.0005200422895505865, "p 2 it": 0.0007417488271393706, "k nn performed": 0.0016182278231319793, "shows how": 0.00048811067106588595, "of members": 0.0005456354281782176, "at regular": 0.0004560919846500759, "the problem much": 0.0007417488271393706, "well with two": 0.0008091139115659897, "than both": 0.0004382027886649359, "turns learning": 0.0007696350858963753, "learning it might": 0.0008091139115659897, "turn of": 0.0005803901647646488, "reveals some interesting": 0.0008091139115659897, "striking result though": 0.0008091139115659897, "corrected actions when": 0.0008091139115659897, "teaching a robot": 0.0008091139115659897, "after 15 000": 0.0008091139115659897, "g": -0.0006522040264570033, "study they": 0.0006131469602829721, "was replayed with": 0.0008091139115659897, "a small number": 0.000602879758470108, "low 1 state": 0.0008091139115659897, "value differential": 0.0007696350858963753, "fitness determined by": 0.0008091139115659897, "may contain up": 0.0007417488271393706, "database for the": 0.0012138492739842013, "that perhaps it": 0.0008091139115659897, "we have": 3.188957008316522e-05, "the editing approach": 0.0008091139115659897, "this means that": 0.00022380728235843543, "to accumulate as": 0.0008091139115659897, "competition the condensed": 0.0008091139115659897, "is zero": 0.000259233183784521, "the mapping between": 0.0005596382660342995, "which indicated": 0.0006628410843555166, "its learned": 0.000702264802583379, "intuitively": 0.00012608584047358245, "at first and": 0.0007417488271393706, "confirms in": 0.0007696350858963753, "3 1": 5.6443547934645344e-05, "3 2": 0.00012399573781399732, "5 degrees": 0.0005954002535516364, "evasion strategies in": 0.0008091139115659897, "itself and study": 0.0008091139115659897, "algorithms to dynamic": 0.0008091139115659897, "strategic guidance from": 0.0008091139115659897, "game before": 0.0007696350858963753, "factor up to": 0.0007417488271393706, "game play occurs": 0.0008091139115659897, "fact it achieves": 0.0008091139115659897, "toe and go": 0.0008091139115659897, "learning on": 0.0009876810077484722, "chess and othello": 0.0008091139115659897, "al demonstrated": 0.0007696350858963753, "of editing": 0.000567383102523159, "practical issues": 0.0009372334471517541, "was given the": 0.0006743602501766612, "to map this": 0.0007417488271393706, "their": -0.0033460816512468658, "generating ten": 0.0007696350858963753, "ase barto": 0.0007696350858963753, "and artificial": 0.00042304989757217126, "as stated": 0.00029943314463829254, "learning or": 0.0005803901647646488, "under grant": 0.0003109518286556765, "ga through": 0.0007696350858963753, "learn several robot": 0.0008091139115659897, "a lazy approach": 0.002427341734697969, "to warfare and": 0.0008091139115659897, "the on": 0.00033865419457809065, "throughout the": 0.00021462605873503448, "it finds": 0.0004123948992280552, "with 21 examples": 0.0008091139115659897, "on problems of": 0.0006349209434580451, "evade in a": 0.0008091139115659897, "a is the": 0.0005961435801289452, "lazy learning phase": 0.0008091139115659897, "3 p": 0.00011243955592491191, "that determining": 0.0005128077770266814, "and continued": 0.0005456354281782176, "general problem": 0.0003665369780185166, "until the combined": 0.0008091139115659897, "by grefenstette": 0.0013256821687110331, "is applied to": 0.0003025866997388251, "holland": 0.0010556040803407945, "that lazy methods": 0.0016182278231319793, "1987 atkeson 1990": 0.0008091139115659897, "own likewise machine": 0.0008091139115659897, "reinforcement throughout a": 0.0008091139115659897, "to cover two": 0.0008091139115659897, "some initial": 0.00042027761111456123, "reducing memory": 0.0010121403055841115, "e loses": 0.0007696350858963753, "unlike the single": 0.0008091139115659897, "apparent plateau between": 0.0008091139115659897, "it collected": 0.0007696350858963753, "could have been": 0.0004548376351798251, "problems one way": 0.0007417488271393706, "pursuers figure": 0.0023089052576891257, "nearby neighbors": 0.0007696350858963753, "the pursuers in": 0.0008091139115659897, "neighbor to perform": 0.0008091139115659897, "actions distance": 0.0007696350858963753, "much more": 0.0003839252355208861, "for example when": 0.0003489500907295262, "in a format": 0.0006349209434580451, "space but": 0.0004731713358791195, "have used a": 0.0004382453615580345, "90 success after": 0.0016182278231319793, "space to": 0.00030112584215908326, "evasive maneuvers task": 0.004854683469395938, "often competing goals": 0.0008091139115659897, "having a": 0.0005006244800934764, "shaping developing autonomous": 0.0008091139115659897, "for game": 0.000702264802583379, "other topics": 0.000634859264718638, "2 to throw": 0.0008091139115659897, "a minimum": 0.0002435491125668703, "the oracle used": 0.0008091139115659897, "angle": 0.0020732487447858152, "evaluates 50 plans": 0.0008091139115659897, "game at random": 0.0008091139115659897, "applied q learning": 0.0008091139115659897, "through a process": 0.0006349209434580451, "rule is": 0.0003072722989859923, "because of one": 0.0008091139115659897, "1 performance of": 0.0005393947462253054, "which": -0.03791861577472931, "generation were passed": 0.0008091139115659897, "as it": 0.00015014439872232055, "if perf evaluate": 0.0008091139115659897, "testing the results": 0.0007417488271393706, "to cancel out": 0.0007417488271393706, "of niches in": 0.0008091139115659897, "to the next": 0.00029974251586906684, "field being": 0.000702264802583379, "of its": 0.00040403034539503803, "in the set": 0.0002991826910604989, "is currently playing": 0.0008091139115659897, "when faced with": 0.0006526576017704936, "making when several": 0.0008091139115659897, "93 evasion after": 0.0008091139115659897, "is used on": 0.0005674382257236372, "and attempted to": 0.0006526576017704936, "examples and": 0.0014352898672705006, "is clear": 0.00019295402328989292, "in the 85": 0.0008091139115659897, "race track lin": 0.0008091139115659897, "same point in": 0.0006199211760863129, "learning initially": 0.0007696350858963753, "information includes 13": 0.0008091139115659897, "it achieves": 0.00040989971878532225, "with 1 700": 0.0008091139115659897, "performance will continue": 0.0008091139115659897, "class": -0.00035586438280176956, "step thus": 0.0005200422895505865, "converged to": 0.0005128077770266814, "we concluded": 0.000567383102523159, "neighboring": 0.0002174013421523344, "in continuous state": 0.0008091139115659897, "rules will match": 0.0008091139115659897, "the basic": 0.00012443499567340823, "we will": 0.00019396410310090566, "surprising result": 0.00052785331295456, "line performance": 0.0005803901647646488, "within a threshold": 0.0007023330300003208, "recently moore and": 0.0008091139115659897, "clear that a": 0.0004998137828238603, "first and": 0.00022279508543139435, "using edited data": 0.0008091139115659897, "rules by encoding": 0.0008091139115659897, "the prior": 0.0003748850085915968, "we found that": 0.0009706950534687893, "that objective": 0.0006628410843555166, "programming to determine": 0.0008091139115659897, "respectively of": 0.0003898632748579793, "20 examples": 0.0006628410843555166, "around in": 0.0005456354281782176, "planning": 0.0015517753241527652, "pedestrian that": 0.0007696350858963753, "are summarized in": 0.00036873270276064425, "time than": 0.0003859053049699601, "database is not": 0.0006349209434580451, "learning is not": 0.0007417488271393706, "nearer": 0.00047790004136261533, "immediately reaches a": 0.0008091139115659897, "even further this": 0.0007417488271393706, "where we hypothesized": 0.0008091139115659897, "their many valuable": 0.0007023330300003208, "but they have": 0.0005674382257236372, "the advice": 0.000567383102523159, "high degree": 0.00036494662878843966, "eager approach is": 0.0008091139115659897, "from the": 6.757883790599505e-06, "is much faster": 0.0004958241803403253, "provided an": 0.0004779464664686347, "differential game": 0.008427177631000546, "and ub i": 0.0007417488271393706, "their own after": 0.0008091139115659897, "local": -4.126061338107221e-05, "set the idea": 0.0008091139115659897, "the game if": 0.0006526576017704936, "methods for": 0.0007151223525901587, "guide a search": 0.0007023330300003208, "by examining the": 0.00039472486509154587, "are discrete sutton": 0.0008091139115659897, "of actions": 0.002327189183084671, "game would require": 0.0008091139115659897, "great difficulty": 0.0006628410843555166, "two evasion": 0.0007696350858963753, "sweeping algorithm": 0.0007696350858963753, "instance based learning": 0.0024796847043452516, "effectively on": 0.0006628410843555166, "been used for": 0.0004020439867656976, "or performing some": 0.0007417488271393706, "ones": 0.00010588624219505315, "t a teaching": 0.0008091139115659897, "words": 2.3196665182963486e-05, "examples figure 8": 0.0007417488271393706, "regardless of what": 0.0006349209434580451, "of training": 0.001169589824573938, "work effectively": 0.0005803901647646488, "space and the": 0.0004382453615580345, "for p is": 0.0005456884385180774, "to learn how": 0.0006199211760863129, "approximately 1": 0.00041758029726340933, "classification accuracy": 0.0004779464664686347, "differential": 0.00561734646562627, "paper also": 0.00040989971878532225, "difference learning": 0.003809155588311828, "the game in": 0.0007023330300003208, "because of the": 0.0008284694138972057, "of teaching a": 0.0008091139115659897, "is the homicidal": 0.0008091139115659897, "genetic operators": 0.0017862007606549094, "well for the": 0.0005226282087022614, "and othello": 0.0007696350858963753, "then selected the": 0.0008091139115659897, "more details": 0.0005522553724888803, "generations": 0.0011092751305790151, "low level": 0.00029135044701075676, "second details of": 0.0007417488271393706, "rules with the": 0.0006349209434580451, "two people": 0.000567383102523159, "the original": 8.704954580888244e-05, "actions taken in": 0.0007417488271393706, "ebl": 0.0007021965884209132, "generate good examples": 0.0008091139115659897, "for analyzing": 0.00036183856746138145, "a markov decision": 0.0014046660600006416, "test games": 0.0007696350858963753, "we have the": 0.0002345099318084397, "mean strength of": 0.0008091139115659897, "e y is": 0.0006199211760863129, "the algorithms and": 0.0005176213124249083, "can regain": 0.000702264802583379, "pursuer which gives": 0.0008091139115659897, "reduce the effects": 0.0006199211760863129, "one agent": 0.0005200422895505865, "maneuvering and": 0.000702264802583379, "closer": 0.0003106438475402043, "4 4 results": 0.0006349209434580451, "lazy learning plus": 0.0008091139115659897, "first used": 0.00044497617160632185, "improve rapidly": 0.0007696350858963753, "correctly classified are": 0.0008091139115659897, "range measurement": 0.0007696350858963753, "suppose we have": 0.0004319040237213277, "a co adaptive": 0.0014834976542787413, "either p1": 0.0007696350858963753, "and neural networks": 0.0005456884385180774, "gives some": 0.0004349818647972793, "chromosome corresponding": 0.0007696350858963753, "superb": 0.000567327990031413, "we call this": 0.00032427110244429073, "any editing": 0.0007696350858963753, "previous work": 0.0004372821562273186, "first uses": 0.0005456354281782176, "closed": 0.00010596383576229036, "van der wal": 0.0007417488271393706, "theta": 0.00011903409790647318, "is learning": 0.0013256821687110331, "well on a": 0.0005596382660342995, "of 20 rules": 0.0008091139115659897, "gives some intuition": 0.0008091139115659897, "mean payoff": 0.000702264802583379, "control problems widrow": 0.0008091139115659897, "ability": 0.0005878853021602391, "same control strategy": 0.0008091139115659897, "rapidly passing": 0.0007696350858963753, "laws for": 0.0005456354281782176, "failed to produce": 0.0007417488271393706, "lethal envelope of": 0.0008091139115659897, "games for": 0.0006131469602829721, "two popular": 0.0005363412876789271, "both the feature": 0.0007417488271393706, "formulate markov": 0.0007696350858963753, "sense since editing": 0.0008091139115659897, "hypothesis": 0.0004976916349536917, "through learning differential": 0.0008091139115659897, "rule will": 0.0005559058853301298, "explored several algorithms": 0.0008091139115659897, "training but the": 0.0008091139115659897, "is rarely": 0.00046009310747955083, "500 games": 0.0015392701717927505, "some initial states": 0.0007417488271393706, "until it reached": 0.0008091139115659897, "results reveals some": 0.0008091139115659897, "being good": 0.000702264802583379, "of characterizing": 0.0005456354281782176, "multistrategy apprach a": 0.0008091139115659897, "algorithm applied to": 0.0005176213124249083, "than the pedestrian": 0.0008091139115659897, "table 1 comparing": 0.0007023330300003208, "learning with delayed": 0.0008091139115659897, "it as the": 0.0004747836164770488, "pursuer evader pursuer": 0.0008091139115659897, "1990 and": 0.0004560919846500759, "the ga because": 0.0008091139115659897, "off the": 0.00031379828866509775, "avoid prematurely": 0.0007696350858963753, "state that": 0.0003177175902857743, "for their many": 0.0005851984448616567, "threshold thus a": 0.0008091139115659897, "see section": 0.00021581659514866702, "50 ga 90": 0.0008091139115659897, "to be close": 0.0005279045957013737, "stored state": 0.0023089052576891257, "wall": 0.00032280095582248115, "of nearest neighbor": 0.0005954580987137418, "to state": 0.00028456257763219726, "data but": 0.0004123948992280552, "environments": 0.0005766973363691479, "n space": 0.0004779464664686347, "how to determine": 0.0005128575980484463, "to guide": 0.000335054731187079, "the attribute": 0.0003982790696131452, "sequences": 0.0001474706456244279, "curvature intuitively": 0.000702264802583379, "table": -0.00029215692701324076, "method could achieve": 0.0008091139115659897, "direction and the": 0.0005596382660342995, "best learning agent": 0.0008091139115659897, "had widespread application": 0.0008091139115659897, "using reinforcement learning": 0.0013053152035409873, "examples and games": 0.0008091139115659897, "point the": 0.0007276300099383145, "many ways for": 0.0007023330300003208, "for editing": 0.0006131469602829721, "checked for nearby": 0.0008091139115659897, "td gammon is": 0.0007417488271393706, "be the same": 0.0003331401991494251, "fifty plans all": 0.0008091139115659897, "are incorrectly": 0.000634859264718638, "following a game": 0.0008091139115659897, "to warfare": 0.0007696350858963753, "scaling up": 0.00046009310747955083, "to construct an": 0.00041159621990674106, "against a": 0.00036183856746138145, "1990 namely evades": 0.0008091139115659897, "1993 developed their": 0.0008091139115659897, "and where": 0.0002658073710966492, "which was binary": 0.0008091139115659897, "one of the": 0.00011583469617764312, "since our lazy": 0.0008091139115659897, "adopted in": 0.00042027761111456123, "sufficient": 5.7860018244934214e-05, "nor k": 0.0007696350858963753, "reward for that": 0.0008091139115659897, "more recently moore": 0.0008091139115659897, "beyond what": 0.0005456354281782176, "three algorithms did": 0.0008091139115659897, "games to be": 0.0007417488271393706, "knowledge required for": 0.0008091139115659897, "techniques the": 0.0003304421841245212, "than constructing a": 0.0008091139115659897, "throughout the remainder": 0.0005674382257236372, "inside s": 0.000634859264718638, "dorigo": 0.001269595195923003, "plans is": 0.000567383102523159, "to train": 0.002669857029637931, "shows that assuming": 0.0007417488271393706, "of either p1": 0.0008091139115659897, "unlike": 9.682657545975398e-05, "control problems one": 0.0008091139115659897, "will grab": 0.0007696350858963753, "a lookup": 0.0004997652289300559, "will": -0.005497984244238223, "examples required": 0.0006628410843555166, "of its poor": 0.0007417488271393706, "results were": 0.0002985967834217994, "point in": 0.00019000245717040344, "additional capabilities": 0.0007696350858963753, "many of the": 0.0002841039625067904, "represent the pursuit": 0.0008091139115659897, "achieved by": 0.00019428795643586087, "research has been": 0.0004339731734948358, "given the task": 0.0006526576017704936, "stochastic dynamic": 0.000634859264718638, "we adopted": 0.00046861672357587705, "chauffeur game is": 0.0008091139115659897, "can yield excellent": 0.0008091139115659897, "games one pursuer": 0.002427341734697969, "of either": 0.0003338822091906335, "thus": -0.0019421606871436045, "range of": 0.00014917554426177257, "that learns": 0.001134766205046318, "be seeded": 0.0007696350858963753, "in that averaging": 0.0008091139115659897, "speed and turn": 0.0008091139115659897, "two dimensional simulation": 0.0008091139115659897, "combining the": 0.00028456257763219726, "for nearest neighbor": 0.0005954580987137418, "game and": 0.0011908005071032729, "a high": 0.0006965630989859717, "1989 the original": 0.0008091139115659897, "range still": 0.0007696350858963753, "follows where c": 0.0008091139115659897, "it is clear": 0.00025051539973936805, "perhaps": 0.00025807154885296526, "rule for": 0.0003128408899145216, "evasion tactics while": 0.0008091139115659897, "ga was": 0.003078540343585501, "pedestrian isaacs 1963": 0.0008091139115659897, "follows where q": 0.0008091139115659897, "examples stores up": 0.0008091139115659897, "to monitor": 0.0003982790696131452, "tasks assume": 0.0007696350858963753, "frequently modeled as": 0.0008091139115659897, "teacher are encoded": 0.0008091139115659897, "work by salzberg": 0.0008091139115659897, "least 50": 0.000567383102523159, "typical formulation has": 0.0008091139115659897, "and has": 0.00017616918237866545, "difficult": 0.00014794038740081032, "s characteristics": 0.0005803901647646488, "nn and": 0.004167801774861455, "use interpolation": 0.000702264802583379, "included in the": 0.00030491819601586613, "and continued to": 0.0007417488271393706, "consisted of a": 0.0005759152096655707, "decision problem": 0.0012152657790249818, "has been used": 0.00030030530004452694, "of examples can": 0.0007417488271393706, "declarative formulation of": 0.0008091139115659897, "the bearing": 0.0007696350858963753, "quickly than the": 0.0006743602501766612, "randomly generated games": 0.002427341734697969, "performance we": 0.0003147644852783128, "markov decision problems": 0.0032632880088524683, "k nn second": 0.0008091139115659897, "representation and": 0.0003037165348615905, "e is caught": 0.0008091139115659897, "will be quite": 0.0005851984448616567, "performance the resulting": 0.0007417488271393706, "have good examples": 0.0008091139115659897, "games table 1": 0.0008091139115659897, "and upper": 0.0007033002880565349, "deleted it with": 0.0008091139115659897, "task is presence": 0.0008091139115659897, "to solve a": 0.0004259428823122818, "that averaging control": 0.0008091139115659897, "gabriel dynamic noncooperative": 0.0008091139115659897, "the purpose of": 0.00026022991695183543, "is to turn": 0.0006743602501766612, "y is": 0.0004066375688773674, "each plan is": 0.0008091139115659897, "solving this type": 0.0008091139115659897, "resulting strategies are": 0.0008091139115659897, "of this credit": 0.0008091139115659897, "more complex": 0.00019941872258974786, "task when": 0.0004997652289300559, "sensing": 0.0007088491948609083, "techniques such": 0.0003374403959319754, "task several": 0.000702264802583379, "ga initially": 0.0007696350858963753, "well again": 0.0005954002535516364, "its success": 0.0005363412876789271, "and the arithmetic": 0.0006743602501766612, "neighbor to": 0.0005456354281782176, "a traditional": 0.0007033002880565349, "learning algorithm embedded": 0.0008091139115659897, "obtain": -6.828031506640576e-05, "toward achieving some": 0.0008091139115659897, "this approach the": 0.0004339731734948358, "batteries": 0.0004997166844687707, "depending on which": 0.0004882999224935485, "k nn did": 0.0008091139115659897, "about its": 0.0004074652591731264, "metagamer has been": 0.0008091139115659897, "is significant information": 0.0008091139115659897, "nn to": 0.0026513643374220662, "began by": 0.001134766205046318, "set of examples": 0.00365839746091583, "experiments ae": 0.000702264802583379, "ga q": 0.000702264802583379, "genetic algorithms can": 0.0008091139115659897, "tree induction": 0.00105570662590912, "dasarathy 1991 algorithms": 0.0008091139115659897, "which is substantially": 0.0007023330300003208, "examined several": 0.0006628410843555166, "smith": 0.0002425197773127735, "close to it": 0.0006199211760863129, "capabilities": 0.0005546937395548991, "for the initial": 0.00040993954193880374, "games every action": 0.0008091139115659897, "significant improvement in": 0.00046866225128631864, "stored for k": 0.0008091139115659897, "different machine learning": 0.0008091139115659897, "control task": 0.0006628410843555166, "received is an": 0.0008091139115659897, "maneuvers task at": 0.0008091139115659897, "game well with": 0.0008091139115659897, "80 this plateau": 0.0008091139115659897, "shows the": 0.00010560049215727939, "ga k": 0.0007696350858963753, "of the car": 0.002697441000706645, "we varied": 0.0004560919846500759, "watkins 1989": 0.0019885232530665498, "identical": 9.176480678741031e-05, "play occurs": 0.0007696350858963753, "difference learning a": 0.0016182278231319793, "operators or other": 0.0008091139115659897, "be assigned we": 0.0008091139115659897, "of a classroom": 0.0008091139115659897, "a game that": 0.0008091139115659897, "of randomly generated": 0.0011909161974274836, "a markovian": 0.0005803901647646488, "5 2 to": 0.0005596382660342995, "4 4 4": 0.0004958241803403253, "4 4 1": 0.00048474305809383046, "know": 5.6313816169504e-06, "atkeson": 0.0028366399501570656, "labeled with": 0.0003423836492878316, "values were": 0.0004560919846500759, "database the": 0.0003859053049699601, "pursuer is shifted": 0.0008091139115659897, "aircraft attempts": 0.0007696350858963753, "ga 0": 0.000702264802583379, "several steps": 0.0004731713358791195, "a traditional lazy": 0.0016182278231319793, "pair already exists": 0.0008091139115659897, "helpful": 0.00043743616389715136, "space in other": 0.0006349209434580451, "the ten": 0.00044497617160632185, "frequently used examples": 0.0008091139115659897, "less than": 0.00010135358510674161, "loses": 0.0006541614045626953, "updated 4": 0.000702264802583379, "minimum threshold then": 0.0008091139115659897, "decision problems as": 0.0008091139115659897, "specifically we": 0.0002882806874477652, "addition to": 0.00015838881365802984, "bootstrapping nearest neighbor": 0.0008091139115659897, "this has been": 0.00042987704457580605, "was because only": 0.0008091139115659897, "the more complex": 0.00048474305809383046, "000 games the": 0.002427341734697969, "tesauro 1992 and": 0.0008091139115659897, "ga k nn": 0.0008091139115659897, "because": -0.0028512353393409955, "in this": 4.505277940905082e-06, "explicitly generating": 0.0007696350858963753, "sequence": -0.0004662317148098588, "important for our": 0.0006349209434580451, "sharp turns": 0.0013256821687110331, "algorithm learns the": 0.0008091139115659897, "at time": 0.0005150111708611497, "is very difficult": 0.0004548376351798251, "will match": 0.000567383102523159, "gave": 0.0005472814626663096, "performance of ga": 0.0008091139115659897, "could achieve": 0.0005456354281782176, "was that we": 0.0006743602501766612, "and very good": 0.0007023330300003208, "backgammon classifier": 0.0007696350858963753, "modify the upper": 0.0008091139115659897, "subramanian": 0.00043816022404243314, "are then": 0.00020224300789959939, "ga using hill": 0.0008091139115659897, "car having a": 0.0008091139115659897, "using the": 0.00014605303414517412, "neighbor algorithms": 0.0012262939205659443, "e but they": 0.0008091139115659897, "has to": 0.00015609398501714912, "to solve examples": 0.0008091139115659897, "temporal difference": 0.005078874117749104, "little has been": 0.0012698418869160901, "we were not": 0.0005279045957013737, "corresponding action": 0.000634859264718638, "problems apply": 0.0007696350858963753, "is released the": 0.0006743602501766612, "ga gle": 0.0007696350858963753, "it has learned": 0.0007417488271393706, "transmit examples to": 0.0008091139115659897, "problem since": 0.00037315955974098747, "80 evasion": 0.0015392701717927505, "learning strategy combining": 0.0007417488271393706, "similar coverage of": 0.0007417488271393706, "colearning": 0.0006347975979615015, "this paper to": 0.0004020439867656976, "percent success stored": 0.0016182278231319793, "received from the": 0.000471675475395776, "problems better": 0.000702264802583379, "randomly until": 0.0007696350858963753, "compared with all": 0.0007023330300003208, "to chess checkers": 0.0008091139115659897, "curve is": 0.00036494662878843966, "at a low": 0.0005954580987137418, "a known editing": 0.0008091139115659897, "this study": 0.0011324417675805652, "pedestrian can change": 0.0008091139115659897, "the ga during": 0.0016182278231319793, "learning to work": 0.0007417488271393706, "where each set": 0.0008091139115659897, "each 3": 0.0005803901647646488, "become important": 0.0005559058853301298, "until we": 0.00038024507112555464, "only a": 0.00011833664652398412, "generated actions": 0.0007696350858963753, "rare": 0.0002476391618188996, "as editing": 0.0015392701717927505, "extension": 4.946867687267703e-05, "tended to": 0.0004288371693587632, "editing procedure": 0.0007696350858963753, "same way that": 0.0005083144306061808, "strategies for solving": 0.0007417488271393706, "sejnowski 1989": 0.0007696350858963753, "learning to play": 0.0013487205003533224, "strategies we will": 0.0008091139115659897, "bad examples this": 0.0008091139115659897, "on this task": 0.0006349209434580451, "be applied to": 0.00023895233700511577, "comparator examines the": 0.0008091139115659897, "converging": 0.00030368703349832073, "many bad": 0.0013256821687110331, "own": 0.0006511963311569414, "game clock the": 0.0008091139115659897, "1972 showed": 0.0007696350858963753, "of markov games": 0.0008091139115659897, "led us": 0.00044497617160632185, "algorithms to": 0.0020509479927066318, "tag the": 0.0004997652289300559, "computational time": 0.0004938405038742361, "97 98": 0.0007696350858963753, "neighbor rules using": 0.0008091139115659897, "2 and": 6.230925841856971e-05, "in q learning": 0.0008091139115659897, "small set of": 0.0007981040490153399, "nn did": 0.0007696350858963753, "to explore our": 0.0008091139115659897, "only points near": 0.0008091139115659897, "the same reason": 0.0004882999224935485, "500 games for": 0.0008091139115659897, "significantly": 0.00011727441287072071, "first uses a": 0.0007023330300003208, "van": 0.00017940222290387038, "state space in": 0.0010558091914027474, "well when faced": 0.0008091139115659897, "atkeson 1992 as": 0.0008091139115659897, "eager learning algorithm": 0.0008091139115659897, "in this case": 0.0001263891321455263, "10 33 points": 0.0008091139115659897, "made the decisions": 0.0008091139115659897, "performance plotted against": 0.0008091139115659897, "achieved 50 80": 0.0008091139115659897, "k nn rather": 0.0008091139115659897, "stored as a": 0.0005226282087022614, "one generation": 0.0013256821687110331, "to features of": 0.0007023330300003208, "would assist each": 0.0008091139115659897, "researchers atkeson": 0.0007696350858963753, "task requires several": 0.0008091139115659897, "action taken": 0.0005803901647646488, "in memory our": 0.0008091139115659897, "estimates of": 0.0002921317927643509, "a single plan": 0.0007023330300003208, "agent tasks they": 0.0008091139115659897, "potential effect from": 0.0008091139115659897, "where they": 0.00032932038867923357, "irrelevant attributes": 0.000567383102523159, "follows a": 0.00028026328662092783, "compares a": 0.0005803901647646488, "plans or control": 0.0008091139115659897, "p2 in": 0.0005559058853301298, "of the form": 0.0001985105227131167, "comparing two lazy": 0.0008091139115659897, "in speed": 0.00048296474811893784, "reinforcement problems apply": 0.0008091139115659897, "values that": 0.00029943314463829254, "made": -0.00021250210476973663, "tactics": 0.0005127579656835996, "recently systems": 0.0007696350858963753, "used to show": 0.0004601378070916638, "whether": -0.0001141011769338299, "apply these algorithms": 0.0008091139115659897, "in the experiments": 0.00036445739219780933, "were permitted to": 0.0008091139115659897, "each generation": 0.0005363412876789271, "to 50 to": 0.0008091139115659897, "t each of": 0.0006743602501766612, "markov decision problem": 0.0014834976542787413, "below": -0.00031775881156665266, "how performance": 0.0005954002535516364, "difficult than the": 0.0007417488271393706, "demonstrate": 0.0004058726524690209, "and the consequent": 0.0006199211760863129, "then select": 0.0005456354281782176, "simulator determines the": 0.0008091139115659897, "is relatively": 0.0005207998951859358, "result in": 0.00013555246509561008, "isaacs": 0.0017860272588811692, "pursue and capture": 0.0008091139115659897, "overall accuracy": 0.0005803901647646488, "decision tree": 0.0007797265497159586, "gray applied": 0.0007696350858963753, "on having": 0.000567383102523159, "which were": 0.0003028459277060942, "which is known": 0.00046289837369057756, "imado ishihara 1993": 0.0008091139115659897, "phases of the": 0.0004404523980181757, "control variables were": 0.0008091139115659897, "this special": 0.00040989971878532225, "50 of": 0.0003714629793944916, "result is": 0.0001566008237783972, "we hypothesize this": 0.0008091139115659897, "algorithms in the": 0.00042031844251562157, "occurs through a": 0.0008091139115659897, "control law to": 0.0008091139115659897, "if three instances": 0.0008091139115659897, "design a": 0.00029943314463829254, "percent": 0.0010710549614777007, "two dimensional": 0.00023386624774719507, "characterize grefenstette": 0.0007696350858963753, "other": -0.005858460731103754, "next phase of": 0.0006526576017704936, "like games his": 0.0008091139115659897, "problems we conducted": 0.0008091139115659897, "the solution is": 0.000712820000509726, "time step were": 0.0008091139115659897, "military and": 0.0007696350858963753, "range measurement the": 0.0008091139115659897, "e was given": 0.0008091139115659897, "to produce better": 0.0006526576017704936, "to replicate those": 0.0008091139115659897, "and applied a": 0.0008091139115659897, "generations and": 0.0005954002535516364, "differential game theory": 0.004045569557829949, "explored several": 0.0007696350858963753, "game earlier research": 0.0008091139115659897, "that pruning": 0.0006628410843555166, "more complex task": 0.0007417488271393706, "algorithm can be": 0.0002845902238556143, "solutions for the": 0.0004548376351798251, "and applied q": 0.0008091139115659897, "a simplified": 0.00032495042922757434, "for the evasive": 0.0016182278231319793, "of lazy q": 0.0008091139115659897, "95 with": 0.0006628410843555166, "time such": 0.0004288371693587632, "in temporal difference": 0.0014046660600006416, "a fixed solution": 0.0008091139115659897, "by hidden": 0.0007696350858963753, "25 000": 0.0005954002535516364, "because it did": 0.0008091139115659897, "ace ase": 0.0015392701717927505, "learning curves we": 0.0007023330300003208, "will grab e": 0.0008091139115659897, "wal 1981": 0.0007696350858963753, "learning both in": 0.0008091139115659897, "the standard ga": 0.0008091139115659897, "metagamer focused": 0.0007696350858963753, "using all other": 0.0008091139115659897, "game guarantees that": 0.0008091139115659897, "new plan": 0.0006628410843555166, "the results of": 0.0017258577330448207, "perf evaluate": 0.0007696350858963753, "minimal number": 0.0004074652591731264, "method of": 0.0001896786412995476, "incorrectly classified are": 0.0008091139115659897, "mean strength": 0.0007696350858963753}