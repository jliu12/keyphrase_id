cube
bys
processors
pipesort
partitioning
subtrees
processor
sunfire
oversampling
disk
sorts
group
pc
parallelization
sort
lattice
dehne
attribute
cluster
bottom
sequential
parallel
attributes
arraycube
gure
speedup
top
load
asl
sd
tree
xes
buys
subcube
skew
subproblems
balancing
runtime
ned
pt
ef
curve
coarse
cubes
iceberg
hash
external
subcubes
pipehash
shared
slowest
memory
tasks
eavis
chaplin
rau
array
orders
spanning
ts
sorting
running
child
parent
suf
balance
ad
les
steiner
pi
grained
bene
seconds
aggregates
tunable
sorted
disks
mmst
cgm
rpp
mhz
loads
balanced
platform
optimum
chunks
assigned
abc
modi
pipe
ab
rolap
heap
todd
buffer
binomial
icts
pipes
rows
took
pre
overlap
parallelized
leda
olap
cient
aimed
fabric
parallelize
striped
andrew
code
computations
dimension
ram
reuse
front
sharing
frank
zipf
partitions
ratio
weights
rp
newer
dimensions
sparse
ed
cuts
subtree
scan
weight
ported
resorting
pentium
considerably
vertices
communication
balances
inter
partition
parallelizing
cant
multidimensional
grows
interconnection
ying
machines
blocks
create
sizes
mpi
linux
augmented
ancestor
max
overlapping
scans
gb
library
edges
packing
shifting
assigns
cardinality
output
oneachprocessor
khoimanhnguyen
partitioncube
neat
sivagnanasundaram
selectednodesintheoriginallattice
theauthorswouldliketothankstevenblimkie
cuboid
byaddingthese
oroverlap
pehle
aspanningtree
tobedrawnfromthenon
sdisk
recurse
skiplist
suganthan
ofthelatticewithpositiveweightsassignedtothenodes
sarawagi
amongthe
subtreespersubset
data cube
cube construction
group bys
pc cluster
parallel top
cluster running
construction method
parallel bottom
oversampling ratio
sort orders
external memory
shared disk
attribute sorts
sunfire 6800
cube parallelization
single attribute
cube computation
data set
partial data
theoretical optimum
running time
fixed parameters
max tree
optimum curve
sequential pipesort
arraycube method
optimal speedup
experiments per
detailed group
processor pi
point 5
different group
parameters data
pre xes
processors 8
dimensional data
partitioning strategies
per data
data cubes
less detailed
data size
dehne et
contain a1
detailed ones
rows number
k partitioning
runtime curve
group buys
pipesort 1
end machine
sd 2
cube algorithms
tree partitioning
partitioning strategy
min max
disk array
parallel method
de ned
spanning tree
load balancing
coarse grained
ef cient
iceberg cube
d dimensional
parallel data
good load
coarse tasks
storage estimation
multidimensional aggregates
p subproblems
dimensional partial
slowest processor
sequential top
existing sequential
subcube computations
p subtrees
loads assigned
binomial heap
sequential methods
cube algorithm
comparison tests
overlapping sort
augmented lattice
data point
based data
input data
load balance
partitioning problem
front end
data sets
parallel setting
dehne todd
sequential external
times observed
rau chaplin
inter processor
todd eavis
eavis andrew
independent subproblems
experimental performance
frank dehne
different partitioning
andrew rau
tree partition
weighted tree
pre x
individual processors
tree k
suf cient
processor communication
average time
relation r
set r
sequential data
shared nothing
running times
data cube construction
top down data
pc cluster running
cluster running time
cube construction method
number of processors
bottom up data
single attribute sorts
data cube parallelization
shows the pc
bottom up methods
group by computations
data point 5
fixed parameters data
theoretical optimum curve
min max tree
experiments per data
per data point
time in seconds
data set r
top down method
partial data cube
observed in 22
data cube computation
less detailed ones
orders between different
number of subtrees
front end machine
top down cube
dehne et al
shown in gure
based data cube
parallel data cube
input data set
tree k partitioning
obtain good load
max tree k
xes and sort
bottom up cube
bottom up method
processors 8 dimensions
partition the lattice
dimensional partial data
les each took
speedup of p
shared disk array
sequential data cube
sharing of pre
eavis andrew rau
inter processor communication
andrew rau chaplin
sequential external memory
frank dehne todd
number of single
amount of buffer
todd eavis andrew
dehne todd eavis
number of tasks
iceberg cube computation
end of algorithm
method in section
ratio of 2
parallel databases v
distributed and parallel
vertices and edges
modi ed min
one person year
partitions the bottom
buys from less
cost to build
use of existing
overhead by partitioning
implemented our parallel
machines with faster
via an interconnection
pipesort pipe hash
processed ef ciently
generating partial data
asl and pt
