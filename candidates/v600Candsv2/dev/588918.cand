conn
lagrangian
lagrange
phi
multipliers
penalty
sufficiently
multiplier
iterates
executed
deduce
criticality
augmented
active
converges
normals
ff
subsequence
subproblem
hessian
cone
dominant
fx
tends
moreau
kv
gammar
inequality
inner
xx
stopping
lsnno
converge
convergent
iteration
infinitely
ae
degeneracy
convergence
powell
lancelot
orthonormal
away
estimates
neighbourhood
orthogonal
violation
nonlinear
squares
minimization
null
disaggregated
mately
linearly
kp
packages
package
gammag
constrained
gradient
updates
weakly
gammak
fletcher
minos
th
limit
isolated
strongly
approxi
algorithmic
subvector
harwell
tolerance
tucker
ds
bertsekas
subspace
convex
kuhn
equality
rank
fr
badly
jsj
spanned
ensures
identification
conditioning
gradients
page
critical
differentiable
projection
subroutines
indexed
min
tangent
inequalities
imply
aim
selon
gruver
avriel
tuyttens
ecomposition
orthogonale
polaires
outwards
othogonal
mutuellement
lcong
hilbertien
jd
ik
columns
ill
behaved
nonsingular
stationary
schwarz
globally
orthogonality
stays
infinite
multiplying
norms
boundedness
subroutine
ad
covers
norm
arioli
thatb
imsl
imate
deux
dunn
hestenes
sachs
hereon
inexactness
release
onto
projected
appealing
specifically
flexible
jacobian
enforced
firstly
criterion
minimized
emphasis
update
et
cauchy
fij
catalogue
calculable
espace
burke
contractive
polarity
forsgren
nato
fortran
trust
iterations
perturbations
submatrix
minimizer
relaxed
kg
choices
nonzero
decomposition
carpenter
nocedal
nag
encompass
x phi
conn et
step 3a
phi k
k sufficiently
sufficiently large
augmented lagrangian
ff k
penalty parameters
limit point
linear inequality
fx k
step 3b
inner iteration
multiplier estimates
penalty parameter
x k
algorithm 3
k g
k 2
k tends
linear constraints
r x
lagrange multiplier
d k
th subset
executed infinitely
active constraints
al 5
lagrange multipliers
strongly active
k j
k converges
dominant constraints
r xx
gammar x
bounded away
corresponding lagrange
inequality constraints
global convergence
moreau decomposition
maximum penalty
k increases
iteration k
k k
infinitely often
k 7
constraints active
large k
c x
point x
lemma 4
k converge
single limit
ae k
let fx
et al
hence step
weakly active
general constraints
j x
j th
local convergence
constraints 1
theorem 5
general equality
non degeneracy
assume furthermore
ae v
matrix whose
linearly constrained
non positive
lemma 5
j converges
cone n
inequality 5
k max
hold let
convergent subsequence
large enough
k 1
null space
algorithms 3
w k
large scale
whose columns
ff min
algorithm 7
complete sequence
subspace orthogonal
lagrangian 1
assume as1
v converges
iteration stopping
powell 23
xx phi
lagrangian algorithms
positive constants
convergence theory
convergence analysis
k 2 k
conn et al
x phi k
k sufficiently large
algorithm 3 1
active at x
r x phi
tends to zero
linear inequality constraints
converges to zero
fx k g
lagrange multiplier estimates
constraints at x
j th subset
sequence of iterates
away from zero
executed infinitely often
et al 5
corresponding lagrange multipliers
gammar x phi
j x z
limit point x
sufficiently large k
j 2 z
x with corresponding
ff k tends
algorithm 7 1
maximum penalty parameter
theorem 4 6
zero as k
let fx k
converge to zero
single limit point
algorithms 3 1
g k 2
hence step 3a
lemma 5 3
subsequence of iterates
part of 4
strongly active constraints
must be executed
matrix whose columns
c i x
assume that as1
weakly active constraints
k j converges
obtain from 5
step 3b must
constraints 1 3
inequality constraints active
k k 7
fr x phi
phi k k
ae v converges
equality and linear
r xx phi
kp t k
augmented lagrangian algorithms
penalty parameter ff
matrix r xx
inner iteration stopping
ae b k
phi k g
augmented lagrangian 1
assumptions are sufficient
hold let fx
combination of general
problem 1 1
k large enough
iterates fx k
form an orthonormal
k g k
