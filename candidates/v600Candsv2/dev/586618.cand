deepest
regression
rdepth
dr
dataset
rousseeuw
depth
medsweep
fit
hubert
mse
breakdown
michaelis
woolf
confidence
bias
hormone
menten
tilting
med
hyperplane
estimator
receptor
bootstrap
intercept
ir
observations
enzyme
semiparametric
windmill
reciprocal
mcd
fits
assays
ellipsoid
median
cressie
spending
slope
slopes
squared
dimensions
covariance
expenditures
keightley
kinetics
samples
vertical
mother
educational
univariate
outliers
linearity
newborn
surely
outlier
plot
ng
estimators
passed
passes
stock
residuals
km
salary
leverage
maximal
sweep
sweeping
tangent
squares
gaussian
robust
tilt
aelst
yohai
dasl
struyf
equivariance
outlying
fwo
scatchard
affine
double
determinant
logarithm
bivariate
gammaff
dissociation
estimates
ae
velocity
pg
polynomial
statis
belgium
inflation
intercepts
region
kd
leroy
gammav
pollard
yielding
animals
proces
regressors
weight
break
residual
jjx
animal
ellipse
equals
monotone
mller
sphere
van
ties
ave
gammau
versus
wind
resolves
cancer
sample
pass
fitted
ls
yielded
hypothesis
max
nonparametric
distributions
concentration
coefficients
uia
lineweaver
dualization
parametrizations
zamar
katina
catalyzed
newborns
explodes
portnoy
wellmann
bootstrapped
gasko
regresssion
estrogen
driessen
keightly
rouseeuw
halfline
interscience
kjh
trimmed
outlyingness
equivariant
receptors
disproportionally
benderly
amenta
daniels
glivenko
gammakm
haldane
maxrdepth
assay
backtransforming
attractions
convf
hpn
backtransform
ik
simulating
distribution
invariant
lim
origin
steady
planes
species
deepest regression
regression depth
z n
dataset z
breakdown value
medsweep algorithm
rdepth z
hubert 16
ir p
confidence region
p value
polynomial regression
dr z
michaelis menten
regression line
double reciprocal
rdepth k
regression dr
gamma gamma
corresponding p
z ng
deepest polynomial
ae ir
mean squared
squared error
reciprocal equation
semiparametric model
woolf equation
standard gaussian
n m
n ae
simple regression
higher dimensions
linear regression
windmill data
educational spending
hormone receptor
maximal rdepth
m observations
spending data
rdepth 0
confidence ellipsoid
around u
observations passed
maximal regression
dr fit
f rdepth
stock return
tilting j
general position
original data
n time
polynomial fit
maximal depth
j around
value f
approximate algorithm
v max
expression 16
average salary
depth estimators
leverage points
bootstrap samples
rdepth dr
f 41
converges almost
deepest fit
p observations
sweep x
univariate median
minimum covariance
tangent hyperplane
return dataset
menten model
becomes vertical
covariance determinant
determinant estimator
menten equation
rdepth j
region r
regression estimator
dr k
n pg
confidence regions
model h
compute f
definition 1
almost surely
fast algorithm
p gamma1
x values
p relative
f n
must add
theorem 1
least squares
dataset z n
z n m
rdepth z n
rousseeuw and hubert
dr z n
passed when tilting
corresponding p value
ae ir p
deepest regression dr
deepest regression line
z n ae
mean squared error
dataset z ng
p value f
double reciprocal equation
deepest polynomial regression
number of observations
compute f n
tilting j around
bias and mean
r 0 95
educational spending data
n ae ir
maximal regression depth
gamma gamma gamma
f n k
f rdepth z
passes through p
region r 0
confidence region r
least m observations
around u v
holds that rdepth
value f 41
deepest regression estimator
surely to 1
pg is bounded
minimum covariance determinant
rdepth j z
michaelis menten equation
algorithm of rousseeuw
stock return dataset
cressie and keightley
ir p relative
add at least
semiparametric model h
michaelis menten model
covariance determinant estimator
j around u
h on ir
j z n
z n pg
converges almost surely
test for linearity
regression dr z
max and km
k z n
data i e
n and p
let us consider
log n time
hubert 16 introduced
successively sweep x
generated 50 points
z n relative
deepest linear regression
