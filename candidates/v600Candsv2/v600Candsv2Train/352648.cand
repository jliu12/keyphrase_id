pol
datasets
dataset
training
mda
lda
attributes
qda
categorical
ind
ocu
sas
uci
loh
tae
ibo
ocm
ftl
ftu
rates
statlog
splits
quest
smo
cart
median
imo
dec
discriminant
ten
records
dna
attribute
learning
univariate
pda
trees
thy
validation
classification
ocl
rbf
statistical
bcw
lmt
lvq
stat
fold
provost
cmc
veh
neural
logistic
statistically
mining
bld
vot
ranks
se
ib
regression
plurality
rank
wisc
decision
tree
breast
wolberg
classifier
cross
mml
polyclass
statlib
contraceptive
fda
brodley
fastest
multivariate
alexe
lmdt
noise
http
marks
categories
pruning
thirty
smoking
foster
rate
sixteen
seg
buntine
hammer
estimated
hastie
sparcstation
patient
nn
twenty
cal
im
opt
adult
leaves
www
holte
needle
edu
wav
tibshirani
significance
error
mean
genetic
archive
ripley
bayes
quinlan
bos
minutes
spline
spec
penalized
tanner
utgoff
seven
ppp
plot
accuracy
shih
slowest
sample
comprehensibility
silhouette
pid
vanichse
muata
kweku
treeprogs
osei
indonesia
aspiration
velayathan
molyneaux
takul
sarle
splus
semesters
kooperberg
html
sixty
breiman
radial
versus
murthy
forty
numerical
log
cancer
error rates
mean error
error rate
training time
numerical attributes
median training
training times
cross validation
decision tree
ten fold
categorical attributes
mean rank
noise attributes
uci dataset
fold cross
tree algorithms
using ten
test set
categorical attribute
discriminant analysis
training set
machine learning
data mining
statlog project
statistical algorithms
statistically significantly
plurality rule
combination splits
univariate splits
x marks
mean ranks
se dec
decision trees
dec f90
www stat
stat wisc
classification accuracy
estimated using
logistic regression
foster provost
significantly different
wisc edu
neural networks
dec 3000
ten minutes
median sec
ind cart
ibo im
shih 1997
style ss5
pda mda
dec sas
spline based
fastest algorithm
l hammer
http www
peter l
class attribute
time versus
discriminant anal
smo thy
plus using
ocl ocm
ocu ocl
pol log
wolberg tanner
ftu c4r
spec newsletter
mda pol
use version
ib ibo
solid vertical
fine needle
sec ftu
quest linear
dec c
knowledge discovery
sample size
tree algorithm
statistically significant
three classes
hidden units
linear discriminant
dataset gives
sparcstation 5
thirty three
rate within
function network
model selection
radial basis
linear combination
lowest mean
continuous attribute
logical analysis
thirty two
neural network
standard error
log scale
vertical line
six numerical
mean error rate
rates are estimated
ten fold cross
median training time
fold cross validation
estimated using ten
mean error rates
terms of mean
decision tree algorithms
using ten fold
obtained from http
different from pol
statistically significantly different
linear combination splits
stat wisc edu
http www stat
www stat wisc
records the error
number of leaves
statlib s archive
se dec f90
style ss5 c
loh and shih
addition of noise
training time versus
pol in terms
rank of error
less than ten
peter l hammer
number of datasets
analysis of variance
radial basis function
set of size
ocu ocl ocm
sec ftu c4r
ib ibo im
lowest mean error
issue 2 june
six numerical attributes
training time less
uci dataset gives
trees are denoted
solid vertical line
software is obtained
error rate within
median sec ftu
ftu c4r ib
trees and rules
brodley and utgoff
se and 1
basis function network
neural network algorithms
half of table
n 4 p
computers and industrial
industrial engineering v
algorithm is described
number of categories
last three columns
estimate the error
analysis of data
machine learning v
computers and operations
stat cmu edu
test set statlog
national indonesia contraceptive
rules statistical algorithms
independent noise attributes
classifier is constructed
clark and pregibon
