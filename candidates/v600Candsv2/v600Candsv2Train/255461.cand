pruning
rep
tdp
fossil
learning
theories
overfitting
cutoff
training
post
foil
grow
clause
conquer
learned
krk
growing
literals
noise
clauses
stnd
noisy
accuracy
quinlan
furnkranz
pruned
literal
predictive
rule
dev
bratko
stopping
pre
cohen
separateandconquer
pruningset
lymphography
endgame
domains
covered
rules
brunk
mushroom
niblett
dzeroski
cameron
correlation
pazzani
holte
secs
datasets
phase
criterion
chess
dolsak
splitratio
muggleton
growingset
pagallo
king
climbing
frnkranz
classification
rook
negative
heuristic
concept
prolog
prune
learn
relational
decision
votes
austrian
cover
separate
learns
haussler
illegal
propositional
overly
hill
learner
euthyroid
elc
jones
clark
explanations
faster
exit
cpu
log
prunes
luaces
ranilla
overfits
bahamonde
incremental
johannes
regularities
instances
avoidance
hepatitis
bias
sick
sparcstations
stop
white
asymptotic
setup
background
olshen
michie
growth
deliberately
artificial
accuracies
top
generalize
relations
merits
induction
michalski
covers
widmer
breast
deleting
mesh
tries
incompatibility
commonly
greedy
breiman
cart
domain
significance
sizes
confirms
tree
cancer
intermediate
oscar
aq
differences
inductive
uci
inefficiency
heuristics
prematurely
learnable
disjuncts
unseen
glass
costs
tested
caught
undone
fastest
entirely
slower
deletion
fires
greedily
wherever
mere
post pruning
pre pruning
pruning set
pruning phase
rule learning
reduced error
training set
error pruning
specific theory
rep grow
krk domain
final theory
cohen 1993
positive examples
pruning algorithm
pruning algorithms
pruning methods
conquer rule
concept description
dev range
accuracy stnd
starting theory
stnd dev
range time
predictive accuracy
negative examples
noisy domains
learning algorithms
cutoff parameter
initial rule
set sizes
time fossil
growing phase
decision tree
incremental reduced
run times
conquer learning
pruning approaches
training examples
stopping criterion
tree learning
cpu secs
run time
empty theory
cameron jones
rule growth
overfitting theory
quinlan 1990
furnkranz 1994
jones 1994
algorithm foil
return theory
positive 99
pazzani 1991
overly specific
theory figure
growing set
background knowledge
learning algorithm
pruning tdp
bratko 1992
initial top
foil quinlan
initial theory
simpler theory
subsequent clauses
integrating pre
foil 6
intermediate theory
rep 97
overfitting phase
pruning heuristics
rule growing
overfitting avoidance
maximum correlation
noise handling
learning decision
asymptotic complexity
training instances
holte 1993
machine learning
data sets
noisy examples
hill climbing
conquer strategy
search heuristic
grow fossil
initial overfitting
pruning sets
artificial noise
growth rep
pruning rep
domain initial
quinlan 1994
fossil foil
subsequent post
haussler 1990
krk endgame
pruning decisions
examples growingset
pruning time
growingset pruningset
mesh design
examples splitratio
negative cover
grow algorithm
pruning criterion
separate and conquer
reduced error pruning
post pruning algorithms
post pruning phase
pre and post
accuracy stnd dev
conquer rule learning
stnd dev range
dev range time
training set sizes
range time fossil
faster than rep
rep and grow
top down search
top down pruning
pruning i rep
incremental reduced error
decision tree learning
rule learning algorithms
complete and consistent
return theory figure
post pruning methods
post pruning algorithm
brunk and pazzani
grow i rep
initial rule growth
cameron jones 1994
rule learning algorithm
general to specific
foil quinlan 1990
initial rule growing
domain with 10
rule growing phase
post pruning approaches
good starting theory
dzeroski and bratko
growing and pruning
number of finite
terms of accuracy
positive and negative
generate all theories
growth rep grow
positive 99 67
clark and niblett
loop exit loop
pre pruning algorithm
learned by fossil
pagallo and haussler
error pruning rep
conquer learning strategy
overfitting the noise
learning and pruning
domain initial rule
rep grow fossil
pruning and learning
pre pruning heuristics
foil 6 1
examples growingset pruningset
grow fossil foil
rule growth rep
integration of pruning
fossil foil 6
subsequent post pruning
rule learning systems
average run time
increasing training set
avoidance as bias
rules and conditions
p n p
description length principle
inductive logic programming
needed to encode
