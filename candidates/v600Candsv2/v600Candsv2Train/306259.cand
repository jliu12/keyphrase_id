elevator
car
cars
rl
passenger
agents
reinforcement
passengers
floor
agent
learning
lobby
floors
traffic
hall
reinforcements
decentralized
omniscient
waiting
peak
arrival
training
buttons
annealing
rld
button
policies
avgwait
squaredwait
systemtime
esa
actions
team
online
barto
trained
secs
wait
controller
arrivals
hours
event
decisions
units
queue
games
dlb
decelerate
zoning
fim
learned
doors
simulated
collective
squared
neural
controllers
stop
supervisory
receding
crites
learn
dp
huff
action
calls
profile
hour
fuzzy
strakosch
cassandras
siikonen
policy
greedy
exploration
upward
reward
mahadevan
bao
percent
elapsed
sridhar
prisoner
bradtke
weights
temperature
footprints
rewards
travel
gammon
hitachi
simulator
heavy
registered
face
td
annealed
elevators
tesauro
moving
stopped
discount
stochasticity
activation
incomplete
networks
pushed
testbed
decision
instability
unsophisticated
events
pure
schedule
horizon
train
trip
group
capacity
gammafi
payoffs
network
ascending
stationarity
feedforward
thathachar
whiteson
fstop
feudal
hajime
tobita
inept
pepyne
contg
ujihara
interfloor
intervisit
ghavamzadeh
play
opponent
activations
sutton
voting
objectives
situations
minute
longest
controlling
tendency
rlr
pct
lqf
experiences
dilemma
discrete
supervised
stopping
averaged
evenly
probabilities
contingencies
wanting
shimon
unanimous
equilibrium
highest
beam
someone
gradual
ai
centralized
observable
shaft
vantage
rls
markey
fujita
emerges
multi
sequential
service
unstable
waited
rush
ishii
critic
conveying
pas
poisson
rlc
round
lewis
serviced
reinforcement learning
multi agent
agent rl
hall calls
elevator group
group control
elevator system
hall call
peak traffic
online reinforcements
elevator control
elevator time
rl agents
simulated elevator
next floor
q learning
waiting times
learning rate
elevator systems
value estimates
squared wait
incomplete state
omniscient reinforcements
avgwait squaredwait
squaredwait systemtime
wait times
input units
moving cars
wait time
discrete event
q values
average squared
rl algorithms
passenger arrival
passenger arrivals
real elevator
elevator car
state information
q value
zero sum
passengers per
algorithm avgwait
car arrival
systemtime percent
reinforcement signal
percent 60
one elevator
control policies
average wait
traffic profile
state space
arrival event
rl algorithm
agent reinforcement
immediate call
causes activation
upward moving
making car
hall button
bao et
car causes
controlling one
peak profile
call buttons
decentralized rl
global reinforcement
hall buttons
waiting passengers
receding horizon
group supervisory
sum games
heavy traffic
real system
sridhar mahadevan
optimal policy
decision point
existing controller
annealing schedule
call information
arrival rates
learning agents
non greedy
decentralized control
agent systems
waiting time
average waiting
travel time
supervisory control
learning algorithm
event dynamic
arrival patterns
discount factor
elevator cars
highest floor
gradual annealing
floor traffic
original decentralized
unsophisticated agents
rld 14
sequential multi
rl controllers
similar policies
hierarchical reinforcement
car whose
another car
multi agent rl
elevator group control
simulated elevator time
q value estimates
incomplete state information
avgwait squaredwait systemtime
hours of simulated
real elevator system
average squared wait
one elevator car
levels of incomplete
systemtime percent 60
squaredwait systemtime percent
algorithm avgwait squaredwait
percent 60 secs
agent reinforcement learning
multi agent reinforcement
zero sum games
squared wait times
decision making car
group control system
upward moving cars
decision is required
controlling one elevator
group supervisory control
car causes activation
hall call information
car arrival event
bao et al
global reinforcement signal
pure up traffic
amount of time
responsible for controlling
average wait time
wants to get
state transition probabilities
multi agent systems
event dynamic systems
discrete event dynamic
peak traffic profile
omniscient and online
elevator control strategies
time t x
relatively unsophisticated agents
original decentralized algorithm
temperature and learning
inter floor traffic
downward moving cars
store the q
areas of state
motion between floors
visited during control
sequential multi agent
heuristic elevator control
important in multi
elevator control algorithms
pure down traffic
nine down hall
rld 14 7
time t y
hierarchical reinforcement learning
immediate call allocation
floor or continue
car whose decision
hall call buttons
team of rl
averaged over hours
problem of elevator
amount of exploration
time the time
non zero sum
andrew g barto
stochasticity and non
past the next
prisoner s dilemma
open and close
