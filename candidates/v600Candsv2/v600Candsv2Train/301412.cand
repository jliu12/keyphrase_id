plna
llna
kax
squares
concave
sla
bk
signal
recovered
norm
combinatorial
ax
residual
ls
corrupted
verbar
polyhedral
kx
parsimonious
sampled
minimization
noise
nonzero
parametrically
suppression
averages
vertex
learning
olvi
thetar
smooth
curve
linearization
mangasarian
supergradient
minimizing
fung
dayton
displays
min
dashed
wisc
glenn
rtsch
terminating
measuring
shall
nonzeros
gammay
parsimony
kristin
justifiable
singular
razor
averaged
nondifferentiable
recovery
occam
cplex
gunnar
coefficient
thetan
misclassification
observed
bennett
matlab
finitely
training
marked
wi
plotted
orders
differentiable
solutions
curves
successive
madison
solves
strictly
magnitude
termination
mining
smoothing
street
wisconsin
componentwise
indebted
infinity
exampleindicate
supergradients
parametricly
breneman
nonzeroelements
stepless
federalist
solutionx
corruptionp
minghu
paulb
jbrosen
solutionto
amaldi
gracious
efined
byorders
nonconcavity
proposedlinear
lengthy
massive
residuals
solving
classifiers
ff
jxj
discrepancy
ayhan
demiriz
embrechts
musicant
toc
jinbo
west
nonnegative
average
signals
vectors
kann
disputed
tenfold
objective
deviation
distances
discontinuous
plot
jolla
curt
commands
ucsd
edu
seconds
straight
prime
approximation
smallness
mathworks
sabbatical
kpk
columns
testing
uncorrupted
combinatorially
mika
multiobjective
identifications
circles
solved
search
interfaced
xc
schlkopf
comparative
nonpositive
smola
svms
closer
hospitality
vapnik
unsatisfied
suppressing
concavity
underestimate
acceptably
kxk
wolfe
cardinality
material
theoretically
prescribe
approximability
novel
ensembles
bradley
least squares
true system
gamma bk
true signal
plna llna
bk 1
combinatorial search
concave minimization
kax gamma
solution x
signal g
llna solutions
squares solution
observed system
average kax
recovered signal
least norm
plna solution
observed signal
curve marked
ax b
total least
nonzero elements
sla 3
kax c
llna solution
signal recovered
algorithm 4
system residual
noise vectors
polyhedral set
concave function
machine learning
set residual
solution 25
linearization algorithm
norm approximation
average kx
ls gamma
smooth problem
llna figure
kax ls
successive linearization
coefficient vector
vertex solution
solution 27
problem 14
problem 2
solutions obtained
c gamma
strictly less
dashed curves
minimization problem
vectors p
true solution
vector x
problem min
kx gamma
residual kax
marked llna
algorithm sla
suppression parameter
squares plna
error kax
plna problem
marked plna
observed actual
llna compared
average true
finitely terminating
signal recovery
gamma x
finite termination
r n
testing set
x ls
solutions solve
system training
search 32
observed linear
system testing
smooth approximation
mean 0
step function
b replaced
finite value
b min
b p
parameter l
l mangasarian
real space
problem 6
support vector
smoothing parameter
linear system
value decomposition
normal distribution
also plotted
objective function
approximation problem
p verbar
madison wi
successive linear
average llna
corrupted b
signal sampled
recovery solid
elements sampled
wi 53706
error verbar
street madison
average plna
nondifferentiable concave
recovered signals
justifiable fast
possibly noise
west dayton
plna and llna
gamma bk 1
kax gamma bk
least squares solution
algorithm 4 1
true signal g
measuring how well
ax b p
recovered signal g
kax c gamma
true system residual
sla 3 1
concave minimization problem
gamma x k
true solution x
coefficient vector x
averaged over 5
plna solution 25
average kax c
averages of kax
c gamma bk
comparison of plna
squares solution 27
noise vectors p
signal the observed
successive linearization algorithm
solved by algorithm
replaced by b
number of nonzero
minimization problem min
total least squares
system training set
versus where x
observed linear system
linearization algorithm sla
tested the average
system also plotted
kax ls gamma
well the plna
plna llna figure
curve marked plna
set residual kax
average true system
curve marked llna
solution 27 solved
squares plna llna
system testing set
suppression parameter l
norm approximation problem
least norm approximation
g t 18
solution x c
kx gamma x
combinatorial search 32
mean 0 standard
obtained by least
minimizing a concave
marked llna compared
smooth problem 7
total least norm
displays the true
obtained by combinatorial
computed for values
distribution with mean
x k 1
solutions were computed
solution of 26
orders of magnitude
singular value decomposition
vector in r
support vector machine
min c 0
well the least
llna and least
west dayton street
training set residual
average plna kax
true linear system
madison wi 53706
noise vector p
given is computed
true system testing
vector x determined
justifiable fast finite
testing set residual
noise corrupted b
