redistribution
caterpillar
schedule
circulant
dpt
msec
cyclic
transfer
reorganizations
array
superblock
communication
ibm
destination
bipartite
message
processors
kx
processor
contention
reorganization
0data
blocks
tavg
index
block
row
messages
msecs
send
matching
unpack
transferred
layout
mpi
transmission
mbytes
shuffled
tmin
unpacking
matrix
secs
scheduling
ts
median
pack
sized
generalized
minyi
reorganizing
reorganized
subsection
robin
tmax
packing
tmed
rows
hsien
interprocessor
minimizes
column
folded
bandwidth
supercomputing
redis
atmost
indices
submatrix
utilized
ching
hpc
receive
sizes
costs
kq
guo
submatrices
hsu
sender
node
experimental
reorganize
multiphase
formalism
reports
measuring
ffg
moved
theoretically
round
tribution
diagonalization
hpf
parallelizing
ownership
rearranged
distribution
sending
source
rearrangement
converted
sent
shifted
packed
entries
reditribution
inturn
mhpcc
manash
redistri
kirtania
multicomputers
entry
incurred
supercomputer
memory
partitioned
abstractrun
wtime
jeannot
daming
dunn
th
slices
half
transferring
sp
art
unpacks
assistance
variance
os
ikuo
roumeliotis
realignment
souravlas
redistributions
varied
onto
qt
woei
relocates
unpacked
manos
avoids
distinct
negligible
computes
acknowledgment
latencies
circularly
nakata
minimized
location
platforms
events
barrier
measured
formulae
packs
multipro
collections
received
incur
overheads
dominates
jih
stavros
scenario
gerard
schemes
theta
conversion
interference
emmanuel
schedules
fashion
caterpillar algorithm
redistribution time
data transfer
communication step
algorithm caterpillar
transfer time
generalized circulant
total array
array size50
time msec
circulant matrix
transfer cost
total redistribution
communication schedule
schedule computation
ibm sp2
algorithm total
index computation
cyclic x
communication case
matching scheme
destination processor
bipartite matching
node contention
data redistribution
communication steps
cyclic kx
distribution table
table d
destination processors
block cyclic
send communication
array redistribution
message sizes
q processors
different message
p processors
schedule table
computation time
column reorganizations
sized messages
source processor
transmission cost
0data transfer
source processors
computation cost
communication scheduling
redistribution problem
equal sized
block matrix
initial distribution
block index
index set
final layout
theta p
cyclic redistribution
final distribution
initial layout
step therefore
network bandwidth
experimental results
message packing
column reorganization
communication cases
matrix formalism
processor table
distributed memory
largest message
block messages
array size
message size
cyclic distribution
computation costs
local block
median time
scheme 5
row 0
processor indices
communication events
fully utilized
array elements
processor index
minimum time
processor sets
d f
first superblock
processor ts
node time
row reorganization
row reorganizations
time tmax
maximum time
table based
supercomputing v
one block
processor point
scheme minimizes
cost schedule
packing unpacking
free communication
folded onto
total transmission
redistribution parameters
global block
round robin
proposed algorithm
set computation
processor set
algorithm caterpillar algorithm
data transfer time
generalized circulant matrix
total array size50
algorithm total array
caterpillar algorithm total
data transfer cost
total redistribution time
bipartite matching scheme
schedule and index
schedule computation time
array size50 0150
transfer time msec
redistribution time msec
distribution table d
number of communication
different message sizes
processors to cyclic
send communication schedule
communication schedule table
kx on q
initial distribution table
equal sized messages
x on p
case with different
0data transfer time
array size50 0data
redistribution from cyclic
matching scheme 5
bandwidth is fully
schedule computation cost
final distribution table
communication step therefore
index computation costs
start up cost
index computation cost
destination processor table
table based framework
destination processor index
table d f
communication with different
circulant matrix formalism
problem from cyclic
block cyclic distribution
block cyclic redistribution
l s theta
messages are transferred
minimizes the number
framework for redistribution
kx on p
within a superblock
therefore the redistribution
range of 100
minimize the transmission
index set computation
global block index
location in d
x to cyclic
journal of supercomputing
start up time
using our algorithm
entry of d
time data redistribution
