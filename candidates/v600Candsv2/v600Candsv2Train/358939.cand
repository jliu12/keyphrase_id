prefetching
prefetch
cache
prefetched
rpt
prefetches
aaaa
stride
fetch
miss
fetched
instruction
memory
referencing
processor
instructions
multiprocessors
tagged
stream
strides
issued
pollution
hardware
loop
multiprocessor
block
array
misses
obl
ld
blocks
engine
compiler
latency
demand
sequential
caches
buffers
locality
references
policy
referenced
gornish
rac
accesses
unnecessary
microprocessor
prediction
baer
buffer
tag
initiated
hierarchies
steady
patterns
dram
word
dahlgren
evicted
pc
replacement
cached
access
reference
fetches
overhead
pd
memories
prefetcher
mechanisms
initiating
placed
brought
spatial
latencies
patel
lockup
bandwidth
palacharla
kessler
addresses
directives
strided
secondary
register
shared
requests
scalar
mowry
spectable
weidong
stenstr
turnoff
nproc
benefit
effective
accessed
schemes
iteration
benchmark
processors
hierarchy
transient
stalled
uniprocessors
irregular
powerpc
epilog
compile
hit
initiates
chen
utilization
sigarch
contention
tentative
superscalar
hp
lilja
comparatively
policies
displaced
kenneth
diverse
tolerating
chip
lookahead
hide
software
coherence
necessitated
kadayif
polluting
stalls
ross
speeding
looping
timely
requested
hirzel
binding
seattle
transfers
prolog
entries
stall
anticipates
interconnection
caching
opportunities
ismail
hsin
entry
fetching
counter
sharing
bus
preloading
exceptions
fu
mechanism
microarchitectures
address
strategies
load
despite
loops
vectorized
hsien
speedups
architecture
shi
news
loads
programmable
iterations
traffic
programs
displace
bodies
tend
mahmut
ratios
blocking
dsm
initiate
programmer
prematurely
predictable
registers
kandemir
cycles
primary
spill
aaaa aaaa
data prefetching
software prefetching
sequential prefetching
demand fetched
prefetched data
fetch instructions
prefetch engine
fetched prefetched
cache blocks
prefetched block
referencing patterns
cache block
cache miss
block b
prefetched demand
hardware prefetching
main memory
cache pollution
stream buffers
prefetch distance
prefetch address
tagged prefetch
prefetching techniques
unnecessary prefetches
processor cache
previous address
prefetched prefetched
fetch instruction
spatial locality
instruction overhead
prefetching schemes
memory system
memory multiprocessors
data prefetch
access patterns
prefetching mechanisms
prefetch efficiency
dram performance
prefetch mechanisms
shared memory
memory access
memory hierarchies
prefetch mechanism
benchmark programs
main loop
average memory
memory latencies
explicit fetch
rpt prefetching
tagged prefetching
vector prefetching
tag previous
stride state
address stride
prefetching opportunities
pd field
array referencing
memory latency
based prefetching
cache utilization
primary cache
memory instruction
software controlled
prefetch hardware
prefetch operations
stride information
demand fetch
large cache
array references
local memory
cache replacement
memory accesses
memory requests
stream buffer
hardware data
prefetching strategies
prefetching scheme
cache misses
cache memories
actual use
reference prediction
memory bandwidth
hardware based
prefetch cache
general applications
reference stream
access pattern
programmable prefetch
vector references
fetch policy
ld b
place prefetched
la pc
k 20
rpt entry
stride array
prefetch case
rpt entries
product calculation
referencing pattern
looping structures
ld c
infer prefetching
six benchmark
program counter
processor systems
effective address
memory reference
loop iteration
large stride
prefetch strategy
prefetched blocks
j 30
multiprocessor applications
adaptive prefetching
prefetch policy
large strides
register space
overlapping computation
memory fetch
state ld
word cache
multiprocessor systems
memory multiprocessor
run time
miss ratios
b 1
aaaa aaaa aaaa
demand fetched prefetched
prefetch on miss
prefetched demand fetched
fetched prefetched demand
shared memory multiprocessors
prefetching in shared
block b 1
address stride state
prefetch is issued
tag previous address
previous address stride
single processor systems
fu and patel
reference prediction table
memory access patterns
hardware data prefetching
chen and baer
given in figure
degree of prefetching
array referencing patterns
six benchmark programs
computation with memory
k j 30
programmable prefetch engine
gap between microprocessor
initiates a prefetch
ld c k
place prefetched data
state ld b
average memory latency
stride state ld
data from main
prefetching in multiprocessors
fetched prefetched prefetched
j 10 000
load or store
adaptive sequential prefetching
actual memory reference
latency of main
poor cache utilization
palacharla and kessler
large cache blocks
prefetching in multiprocessor
kenneth a ross
one loop iteration
cache block size
b i k
c k j
main memory access
computer architecture news
acm sigarch computer
architecture news v
sigarch computer architecture
shi hsien hsin
prefetched prefetched demand
cache line turnoff
memory accesses prefetching
stall cycles prefetching
data prefetching techniques
performance has necessitated
fetch data prefetching
weidong shi hsien
benefit of prefetching
provides optimal performance
hardware based stride
infer prefetching opportunities
cache blocks may
effectiveness of hardware
use of increasingly
useful and introduce
misses and issues
word cache blocks
data prefetching anticipates
connected via pointers
