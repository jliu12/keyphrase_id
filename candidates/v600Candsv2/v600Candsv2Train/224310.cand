iwarp
lap
cm
gigabit
hippi
nectar
bandwidth
fem
elapsed
testbed
ana
sec
cray
chemical
psc
pipelining
heterogeneous
stochastic
sparse
gen
solver
matching
network
dense
mb
sonet
paragon
supercomputer
phase
incidence
ts
alpha
dhsc
pittsburgh
cmu
nodes
steenkiste
sustainable
throughput
dt
generation
plant
transfer
bw
testbeds
statistical
distributing
uncertainty
supercomputing
hemy
npasses
checksumming
outboard
apost
bottleneck
sensitivity
materials
communications
mbyte
unweighted
nrows
initialization
bipartite
format
indices
bursts
stream
streams
burst
production
assignment
percent
communication
mimd
raw
matrix
samples
thinking
neuroscience
mpp
inversely
execution
pipeline
overlapped
pipelined
speed
conversion
manifold
atm
sends
dedicated
sent
suited
metropolitan
campus
idle
kbyte
networks
resources
bayesian
rpc
versus
sustained
pvm
floating
expertise
requirements
hide
locates
deployment
intel
center
slowest
multicomputer
simd
bandwidths
transferred
workstations
estimated
serial
across
host
datalink
initialmatching
gbs
mummert
mahdavi
tsrange
cnri
measurements
traffic
national
weighted
tradeoff
primal
lab
cpu
link
km
tasks
machines
architecture
agency
spawar
jamshid
mcrae
intensive
phases
int
insignificant
buffering
inference
converted
utilization
influences
runs
mode
initiatives
industry
assignments
subsystem
augmenting
optimization
dod
warfare
nsec
impact
conceptualization
climate
connecting
peter
seconds
latencies
matroids
predicts
planning
networking
transmit
terminal
c 90
cm 2
network bandwidth
lap solution
initial matching
cost matrix
iwarp nodes
lap solver
data generation
execution time
size 4k
nectar testbed
performance model
mb sec
linear assignment
elapsed time
reduced cost
analysis phase
chemical process
optimization application
sparse approach
stochastic lap
iwarp system
nodes bandwidth
assignment problem
bandwidth time
bandwidth mb
process optimization
lap problem
heterogeneous computing
application performance
high speed
lap application
phase size
pittsburgh supercomputer
plant data
iwarp c
solution phase
estimated execution
communication requirements
problem size
gigabit network
element indices
dense method
application across
n ts
dense approach
supercomputer center
elapsed times
time sec
distributed computing
cray c
nectar gigabit
probability manifold
lap initial
initial reduced
fem running
gigabit testbed
raw materials
statistical reduction
sustainable network
intel iwarp
atm sonet
hippi based
lap size
lap initialization
phase figure
weighted matching
incidence matrix
sparse method
production data
zero element
dedicated mode
traffic models
samples n
peter steenkiste
cost data
distributed memory
model analysis
application components
systems connected
stochastic linear
bandwidth requirements
overall application
time phase
speed networks
network performance
thinking machines
file server
bipartite matching
bayesian inference
solver phase
computing operations
existing separately
application depend
pittsburgh supercomputing
matrix transferred
center psc
alpha file
transfer requirements
matrix unweighted
model ana
nodes cm
developed application
generation computations
neuroscience application
michael hemy
p iwarp
cray floating
sparse transfer
sample generation
solver initialization
computing gigabit
separately developed
int lap
generation and analysis
cm 2 nodes
reduced cost matrix
degree of pipelining
linear assignment problem
nodes bandwidth time
number of cm
network bandwidth mb
chemical process optimization
process optimization application
number of iwarp
c 90 cm
application performance model
bandwidth mb sec
execution time sec
estimated execution time
bound by communications
iwarp c 90
lap solution phase
zero element indices
phase size 4k
pittsburgh supercomputer center
percent of elapsed
c 90 using
number of nodes
dense and sparse
cray c 90
impact of network
nectar gigabit testbed
ana on c
iwarp to c
initial reduced cost
time phase figure
approach the cm
lap initial matching
lap on cm
bandwidth time phase
stochastic linear assignment
use the model
distributed memory systems
size of 4k
overall application performance
architecture and applications
high speed networks
communications versus effective
sec for lap
predicts an execution
cm 2 computes
sparse incidence matrix
data generation bottleneck
supercomputer center psc
lap solver running
sizes lap size
sustainable network bandwidth
output c 90
lower data transfer
samples n ts
lap solver initialization
gigabit i o
npasses n nrows
based distributed supercomputing
o for distributed
initial matching model
solver phase size
matrix unweighted bipartite
occurred for repeated
area network man
cm 2 idle
