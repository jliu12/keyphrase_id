preemption
cache
preemptions
refill
priority
preempted
invocations
tasks
response
phasing
delay
task
jk
schedulability
blocks
worst
scenarios
lee
prediction
infeasible
scenario
wcet
fig
preempt
cycles
preemptive
overestimation
dc
scheduling
executes
invocation
reloading
overlapped
constraint
fft
widening
costs
fir
mapping
deadline
safe
counted
schedulers
lms
scheduler
mappings
maximizex
pc
bounding
gap
execute
dma
busquets
lud
mataix
staschulat
memory
objective
multiplied
block
regions
constraints
proportionally
displaced
increasingly
tighter
resumes
predictability
explained
queue
trend
misses
reloaded
disjoint
multitasking
extendible
rectify
unpredictability
doubly
instruction
ifip
execution
rolf
reload
inequalities
pessimistic
interactions
lowest
sensitive
newport
lock
sram
utilization
eliminate
ernst
subsets
multiprogramming
conflict
readers
partitioning
codesign
target
intervals
referenced
subsumes
iv
classified
beach
interference
jaudelice
hyojun
axil
sunghwan
berkelaar
caterina
scoglio
jaeyu
bumsoo
arex
shinhan
summation
advanced
interrupt
predictions
mapped
vii
analyzing
stringent
cpu
kim
highest
ada
dsp
involved
theta
tue
diffserv
noh
doolittle
hemendra
basumallick
uhl
hyperperiod
multiplying
drawback
continues
filter
accounting
ftp
negi
abstractcache
abhik
fpa
roychoudhury
nilsen
xip
chanik
groups
microarchitecture
associates
jumps
priorities
os
percentage
layland
akyildiz
tulika
mpls
supersparc
tech
calculating
lp
cooley
preempting
overlooks
bumps
categorizes
threads
oliveira
ql
suffers
busy
vi
caching
unschedulable
qs
subsection
earliest
bae
preemption delay
related preemption
cache related
case response
priority task
preemption cost
cache blocks
cache refill
refill time
useful cache
response time
cache mapping
preemption scenarios
higher priority
lee et
proposed technique
worst case
task set
priority tasks
e theta
preemption costs
r 4
real time
lower priority
time prediction
j h
blocks used
execution point
preempted task
case preemption
preemption scenario
cache regions
fixed priority
d r
theta d
cache block
sensitive preemption
scenario sensitive
previous techniques
schedulability analysis
task j
cost table
infeasible task
tasks 1
linear programming
main memory
regions used
time increases
cache partitioning
four tasks
infeasible preemption
task phasing
many infeasible
response times
time systems
function value
g j
target machine
cache memory
memory blocks
delay due
u u
objective function
et al
r k
widening speed
advanced constraints
unit cycles
maximum objective
cache mappings
memory continues
memory block
speed gap
task sets
accurate prediction
block c
mapping 2
mapping 1
technique explained
task preemption
delay takes
time needed
task 4
eliminate many
task k
priority schedulers
lowest priority
maximum number
preemptive scheduling
following constraint
time equation
priority preemptive
hard real
current trend
four invocations
three preemption
tighter prediction
possible preemption
refill times
proportionally large
delay becomes
doubly counted
preempt preempt
free real
time r
fig 3
highest priority
two constraints
total number
technique takes
n jk
analyzed independently
task interactions
include 2
mapping 3
cache related preemption
related preemption delay
worst case response
case response time
cache refill time
useful cache blocks
number of preemptions
al s technique
lee et al
higher priority task
e theta d
response time prediction
d r 4
higher priority tasks
cache blocks used
theta d r
lower priority task
worst case preemption
refill time increases
preemption cost table
scenario sensitive preemption
related by dc
number of useful
number of invocations
objective function value
g j h
r 4 e
preemptions of j
tasks that execute
sensitive preemption cost
u u u
real time systems
tasks 1 2
cache mapping 1
prediction of cache
priority task j
cache regions used
cache mapping 2
example in fig
pc i r
task is preempted
cache block c
j during r
response time r
j and k
processor and main
set of useful
trend of widening
n 0 jk
main memory continues
account the relationship
task is involved
phasing of tasks
maximum objective function
priority task 4
widening speed gap
indicates that accurate
many infeasible task
tasks to eliminate
jk and n
m 0 jk
constraint of lee
eliminate many infeasible
used to bound
set of tasks
delay in fixed
response time equation
priority task k
fixed priority schedulers
r i cannot
give the worst
case response times
preemption delay takes
lower priority tasks
priority preemptive scheduling
highest priority task
hard real time
fixed priority preemptive
linear programming problem
lowest priority task
becomes increasingly important
bound the number
analysis of cache
cannot be larger
infeasible preemption scenario
proportionally large percentage
