multiplication
processor
multiplications
matrices
sup
elementary
matrix
cache
replication
tradeo
ik
communication
nb
kung
2d
3d
na
jk
lpram
cannon
strassen
bounds
bisection
toledo
conventional
snir
tiskin
univac
transferred
wp
asymptotically
sivan
memory
processors
misses
asymptotic
nc
loomis
berntsen
nanbnc
aggarwal
rows
ij
hong
irony
live
chandra
lemma
cut
whitney
unied
memories
dror
degenerates
dag
algebra
multipli
begins
phase
tradeoff
cations
reside
geijn
multiplicands
dekel
phipac
nassimi
lblas
resides
row
constants
cuts
underlies
send
sent
blocked
mnr
ncn
compulsory
watts
mul
rst
replicate
slow
subroutines
summa
prams
prefetch
sa
received
specic
broadcasts
inequality
pebble
receive
phases
bulk
mn
alexander
subroutine
nan
sahni
caches
sb
multiply
private
across
kalman
regime
cross
evenly
analyzes
fa
contributes
mc
blue
israel
columns
cm
sc
dense
ma
cient
hypercubes
dene
unlikely
involving
ibm
provable
fb
acyclic
synchronous
sgi
sp
cellular
arithmetic
accesses
hey
mccoll
humanities
compres
matri
tflops
rutledge
paterson
mckeller
organiza
bining
gustavson
zubair
nbn
tiplicands
coman
jerrell
feel
amount
perhaps
product
column
dierent
saves
specically
factorization
store
fc
subsets
red
products
contributions
workstations
tiplications
claries
partnership
worksta
johnsson
forbid
tiprocessors
computers
square
clusters
concrete
decompose
statement
mb
rigorous
academy
herbert
vb
rubinstein
isoperimetric
capacity
storage
matrix multiplication
communication lower
elementary multiplications
lower bounds
c ik
3d algorithms
2d algorithms
multiplication algorithms
distributed memory
processor must
per processor
b jk
memory parallel
ij b
m words
local memory
conventional matrix
parallel computer
memory per
must send
memory communication
multiplications involving
must perform
parallel matrix
slow memory
processor distributed
least words
asymptotic notation
involving rows
conventional multiplication
sup 2
p processor
exactly m
must cross
communication across
cache misses
linear algebra
g n
asymptotically optimal
lemma 2
multiplication algorithm
words must
sup words
aggarwal chandra
communication tradeo
input replication
n matrices
lower bound
two n
sivan toledo
input matrices
theorem statement
bounds also
phase begins
local memories
extra memory
computation begins
one processor
least n
irony sivan
p words
multipli cations
loomis whitney
least wp
whitney inequality
words per
output combining
lpram model
kung 17
discrete loomis
communication per
alexander tiskin
communication necessary
dror irony
nanbnc 1
concrete constants
fast cache
words proof
algorithms must
capacity cache
argument shows
n n
statement holds
synchronous parallel
basic lemma
bulk synchronous
least proof
element c
f n
communication network
n elements
m r
another processor
amount of communication
communication lower bounds
matrix multiplication algorithms
bounds for matrix
consider the conventional
ij b jk
number of words
distributed memory parallel
elements of c
number of elementary
memory parallel computer
conventional matrix multiplication
processor must send
hong and kung
memory per processor
n i sup
processor distributed memory
p processor distributed
elementary multiplications involving
lemma 2 2
send or receive
words of local
words of memory
multiplications involving rows
two n n
words that must
receive at least
parallel matrix multiplication
n n matrices
n 2 elements
elements of b
multiplication of two
least one processor
column of b
sup i p
exactly m words
algorithms are asymptotically
one processor must
chandra and snir
c is m
matrix multiplication algorithm
memory communication tradeo
theorem statement holds
n 1 2
must be transferred
sup 2 sup
amount of memory
row of c
bounds the number
p 2 3
state and prove
sent and received
communication e cient
strassen s algorithm
multiplication algorithms must
nanbnc 1 2
element c ik
dror irony sivan
loomis whitney inequality
algorithms must perform
irony sivan toledo
processor at least
communication lower bound
words per processor
communication that must
communication per processor
b is n
cannon s algorithm
toledo and alexander
discrete loomis whitney
data that must
capacity cache misses
n 2 2p
lemma 3 1
required to store
c 2 g
cache the number
p i sup
bulk synchronous parallel
n c 2
