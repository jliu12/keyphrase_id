load
balancing
transfer
particles
diffusion
percent
deltal
tasks
pic
particle
dsmc
locality
eff
balance
gde
computers
ogde
imbalance
diffusive
ffit
reactor
hb
diff
grid
transferred
neighbors
timestep
agde
paragon
plasma
routines
task
remapping
gec
lavg
errmax
thruster
cells
processors
transfers
workload
intel
vectors
concurrent
phases
balanced
efficiency
movement
hawk
scplib
transferring
pde
exchange
solver
field
cray
partition
repartitioning
dhb
partitions
metric
cell
err
library
mapped
const
underloaded
torus
mesh
metrics
disturbance
ode
facilities
comprised
calculate
calculated
phase
knapsack
loads
termination
runtime
move
kwok
scalable
dist
ffl
lowest
ideal
timestepping
changxun
rarefied
propulsion
ffil
powerchallenge
backflow
macroparticles
addendum
exchanges
quantities
heat
initiated
idle
ion
simulations
push
communication
workstations
fromone
bisection
options
meshes
mapping
silicon
scatter
exceeds
costly
synchronization
utilization
randal
million
neighboring
send
poor
selection
simulation
max
diffuse
tori
receive
overloaded
fairly
prediction
lap
physics
min
strategies
undertaken
unstructured
conducted
spectral
gradient
electromagnetic
zhong
balances
laboratory
irregular
accuracy
hl
cheung
color
adjusting
grids
heterogeneous
gather
institute
center
timing
unnecessary
potentials
efficacy
exhausted
distance
moved
iterative
outgoing
rigorous
continuum
cur
burns
asynchronous
converged
norm
closest
dimensional
exposing
extremal
communicating
location
scalar
preserve
thread
multicomputers
parametric
neighbor
remedy
threads
bars
adaptive
granularity
speedup
scalability
destinations
dramatically
converges
expect
evolves
dynamic
rel
load balancing
transfer vectors
transfer vector
load balance
dynamic load
work transfer
task selection
eff min
two computers
vector algorithms
load imbalance
total load
hb method
diffusion algorithm
balancing framework
pic code
balancing algorithm
communication locality
one would
neighbors j
intel paragon
lowest cost
timestep size
task movement
computer must
diff 1
phase two
field solve
balancing steps
scalable concurrent
total work
average distance
one computer
transfer cost
balancing would
ogde diff
ffl max
imbalance exists
particle push
field solver
processors ogde
global norm
load prediction
cost metric
grid cells
cray t3d
overall efficiency
phase one
load evaluation
balancing problem
achieve load
algorithms transferred
programming library
task mapping
would expect
concurrent programming
c l
load distribution
subset sum
hb algorithm
task transfer
processors percent
dimensional exchange
static mapping
ion thruster
balancing system
computer 2
gec reactor
communication list
global load
new load
particles contained
hierarchical balancing
every computer
gradient model
tasks transferred
gde algorithm
sum problem
dsmc code
diffusion algorithms
gde method
lavg eff
various transfer
j 2
percent utilization
varying numbers
diff 2
ideal location
based load
communicating tasks
computer 1
termination condition
phase 1
computing v
prediction model
gather scatter
two large
balancing strategies
local load
l max
dynamic load balancing
transfer vector algorithms
load balancing framework
j 2 n
load balancing algorithm
neighbors j 2
total work transfer
amount of work
computer to another
load balancing steps
cost of load
parallel and distributed
scalable concurrent programming
ogde diff 1
diff 1 diff
load imbalance exists
work transfer vectors
task s state
load balancing would
processors ogde diff
number of processors
one would expect
load balancing problem
achieve load balance
number of tasks
set of tasks
distributed computing v
journal of parallel
percent more work
scatter to obtain
load prediction model
concurrent programming library
authors of 24
based load balancing
tasks to computers
deltal i j
c l n
determine which tasks
mapping of tasks
satisfy its transfer
n i receive
computer 1 computer
lavg eff min
subset sum problem
computer 2 phase
load balancing system
processors percent utilization
various transfer vector
set of computers
two large scale
number of load
number of particles
applied to two
phase 2 phase
load balancing strategies
d dimensional mesh
computing v 64
numbers of processors
maintain an efficiency
case a task
computation this fact
balance the computation
cannot be divided
termination condition based
purpose load balancing
reduced the transfer
