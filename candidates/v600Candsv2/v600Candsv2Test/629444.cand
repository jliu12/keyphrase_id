supernode
supernodes
hyperplanes
grain
schedule
tiling
ct
shape
dependence
startup
parallelepiped
koziris
nectarios
transformation
partitioning
athanasaki
phases
transferred
dependences
lengths
loops
communication
georgios
matrix
hyperplane
tile
processors
running
sotiropoulos
goumas
processor
nested
index
vectors
iteration
tiled
volume
maria
iterations
loop
nests
cone
fronts
aristidis
tsoukalas
luce
transmission
square
discusses
message
transformations
tsanakas
drosinos
panayiotis
cutting
smps
extreme
nikolaos
nonlinear
pipelined
penalty
theta
hypercube
systolic
hd
comm
grouping
scheduling
doubly
oe
wave
closed
comp
jingling
rajopadhye
disp
rashmi
hyperrectangular
dharma
balev
papakonstantinou
hodzic
multicom
wentong
hyperrectangles
andonov
campbell
lsgp
yanev
edin
planes
vector
hyper
affine
boothe
weijia
startups
dimensionalities
clare
abstractwith
nitions
professorship
convex
sides
minimized
media
multiprocessors
bajaj
crete
triolet
hal
sliced
supercomputing
spaces
schedules
messages
ramanujam
dencies
defi
respected
sadayappan
irigoin
gt
peizong
transputer
xue
doacross
rectangular
multidimensional
side
henry
zvi
supercompilers
pen
dell
mapped
families
uniform
depen
jersey
oblique
kedem
island
greece
grouped
sizes
columns
shang
puters
nicosia
collinear
thirteenth
reasonably
transmitted
transformed
phase
interdependent
assistant
meir
lemmas
neighboring
subtasks
equidistant
alternates
analytical
formulation
modeled
ave
integral
rank
cai
cyprus
baltimore
minimizing
approximated
dependencies
initiation
orthogonal
normal
bg
supernode size
supernode transformation
total running
grain size
optimal supernode
linear schedule
index space
running time
optimal grain
length vector
side lengths
supernode index
iteration index
relative side
supernode shape
dependence matrix
supernode relative
dependence vectors
different supernode
parameter model
relative length
parameter communication
optimal linear
one parameter
partitioning hyperplanes
supernode sizes
two parameter
supernode transformations
schedule vector
optimal relative
size g
computation phases
parallelepiped supernode
communication model
h r
communication time
algorithm j
communication phases
nectarios koziris
nested loops
side length
j d
startup penalty
two supernode
transformation h
matrix h
matrix d
vector r
closed form
supernode partitioning
one supernode
maria athanasaki
square supernode
startup cost
communication startup
communication cost
g o
r g
index set
bounded loop
resulting supernode
n partitioning
nonlinear program
supernode grain
memory parallel
communication phase
iteration space
consider algorithm
transformed algorithm
optimal shape
supernode side
hyperplane matrix
dimensional algorithm
convex cone
constant bounded
ct ct
l processors
space j
g r
distributed memory
single processor
processors time
tile size
form expression
theta theta
v g
communication volume
schedule length
computation time
loop nests
set j
scheduling length
dependences 12
size shape
independent supernodes
components depend
four iterations
affine function
g ct
wave fronts
changes lemma
schedule wave
containing four
loops onto
normal vectors
nested loop
real positive
optimal tile
startup time
sotiropoulos georgios
athanasaki aristidis
tiled nested
parallelepiped supernodes
georgios goumas
tsoukalas nectarios
drosinos maria
athanasaki nectarios
uniform dependence
square containing
parameters h
extreme vectors
supernode volume
aristidis sotiropoulos
constant communication
algorithm problems
total running time
optimal grain size
optimal supernode size
size and shape
iteration index space
optimal linear schedule
parameter communication model
relative length vector
supernode index space
j s d
h r g
side length vector
amount of data
find the optimal
transformation h r
relative side length
supernode transformation h
length vector r
different supernode sizes
one parameter model
optimal relative length
grain size g
one parameter communication
find an optimal
linear schedule vector
communication startup cost
relative side lengths
dependence matrix d
supernode relative side
algorithm j d
distributed memory parallel
h and r
number of communication
problem of finding
square supernode shape
two parameter model
two parameter communication
two supernode transformations
v g r
l processors time
supernode index set
constant bounded loop
model with constant
optimal supernode shape
optimal supernode relative
index set j
closed form expression
finding an optimal
time for different
number of phases
memory parallel computer
d 2 d
g g o
linear schedule wave
set with g
model communication cost
supernode transformation applied
square containing four
bounded loop iteration
shape the total
supernode grain size
schedule wave fronts
supernode size changes
supernode size g
components of dependence
vectors d 2
shape or close
change as supernode
changes lemma 3
cost is modeled
size and supernode
algorithm in example
h g r
n partitioning hyperplanes
close to square
constant communication time
supernode the supernode
supernode relative length
