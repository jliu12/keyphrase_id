classiers
mdts
meta
mdt
classier
cdp
stacking
attributes
bla
odts
scann
bagging
predictions
voting
learning
boosting
classication
vote
predicted
trees
induced
expertise
base
cml
odt
ordinary
diversity
signicantly
ltree
tac
toe
decision
hypothyroid
hepatitis
soya
diabetes
echocardiogram
ionosphere
ensembles
wine
waveform
glass
combiner
tic
correlation
classifiers
inducing
dierent
training
breast
entropy
plurality
german
bridges
australian
combining
accuracy
chess
improvement
condence
conf
iris
td
heart
prediction
leaf
insignificant
distributions
car
nn
siers
induce
clas
bayes
probability
cdps
weka
impurity
outperform
domains
comprehensible
certainty
propositional
signicant
areas
balance
knn
combine
nearest
stratied
classi
errors
correlated
frameworks
stacked
naive
modication
mining
cascading
dependence
cd
worse
pruning
dierence
brazdil
lml
gama
maxprob
aml
accuracies
uci
ensemble
info
classied
appendix
image
discriminant
regression
weight
arbiters
classications
losses
rst
ve
leaves
neighbor
density
error
ect
condent
expressive
na
validation
attribute
pavel
dierences
twenty
repository
species
predicting
votes
comprehensibility
induces
classify
identifying
concise
vs
post
ilp
asterisk
predicts
select
slope
fold
endfor
settings
cv
suite
dened
paired
renement
constructing
calculate
bernard
signicance
cn
conquer
unseen
tree
art
wins
neural
pred
cross
calculated
split
expressiveness
avg
returned
enko
domingo
ibl
base level
level classiers
meta level
level attributes
meta decision
decision trees
class probability
level classier
combining classiers
error correlation
relative improvement
data set
induced using
ordinary decision
mdts induced
classier c
level learning
learning algorithms
accuracy improvement
level data
multiple classiers
class value
tic tac
tac toe
distributions predicted
select best
combining multiple
probability distributions
predicted class
relative areas
cdp bla
class values
signicantly worse
ordinary attributes
bridges td
insignificant significant
breast w
using cdp
probability distribution
signicantly better
k nn
plurality vote
mdt leaves
balance breast
chess diabetes
trees mdts
distribution properties
diabetes echocardiogram
short line
decision tree
line density
voting schemes
class distribution
example x
learning algorithm
image ionosphere
hypothyroid image
iris soya
soya tic
trees induced
ionosphere iris
classiers c
w bridges
level classifiers
toe vote
wine insignificant
td car
echocardiogram german
constructing ensembles
vote waveform
glass heart
classication errors
given example
waveform wine
german glass
car chess
hepatitis hypothyroid
australian balance
classifiers australian
classiers induced
heart hepatitis
attributes used
data sets
voting scheme
set m
improvement achieved
see table
dierent learning
attributes bla
significant figure
original base
conf 1
tree induced
mdt induced
classication error
mdt cdp
density 5
c 1
naive bayes
trees vs
machine learning
table 6
set l
relative accuracy
c j
conf 2
distribution predicted
using class
error c
cdp set
inducing meta
stacking framework
learning mdts
odts induced
current subset
values predicted
combine classiers
using bla
maximum probability
base level classiers
meta level attributes
meta decision trees
base level classier
class probability distributions
level data set
meta level data
ordinary decision trees
areas of expertise
class probability distribution
tic tac toe
base level attributes
combining multiple classiers
meta level learning
data set m
mdts induced using
set of meta
probability distributions predicted
balance breast w
decision trees mdts
short line density
tac toe vote
soya tic tac
toe vote waveform
bridges td car
hepatitis hypothyroid image
w bridges td
breast w bridges
wine insignificant significant
german glass heart
image ionosphere iris
glass heart hepatitis
level learning algorithms
ionosphere iris soya
australian balance breast
echocardiogram german glass
car chess diabetes
heart hepatitis hypothyroid
boosting and bagging
level classier c
hypothyroid image ionosphere
diabetes echocardiogram german
waveform wine insignificant
induced using cdp
vote waveform wine
td car chess
level classifiers australian
base level classifiers
classifiers australian balance
iris soya tic
chess diabetes echocardiogram
correlation between base
meta decision tree
ensembles of classiers
see table 6
set of base
decision trees induced
class distribution properties
decision tree induced
decision trees vs
original base level
used to induce
insignificant significant figure
line density 5
achieved with mdts
dierent learning algorithms
shows that mdts
examples in l
sets of meta
diversity of errors
relative accuracy improvement
single data set
level attributes bla
class values predicted
boosting of decision
two base level
used for classication
classiers with mdts
certainty and condence
domains and signicantly
area of expertise
induced with mlc4
highest class probability
bagging of decision
base level learning
level classiers induced
level classiers c
method for combining
accuracy of mdts
ect the certainty
level attributes used
base level predictions
density 5 0
bagging and boosting
one data sets
linear regression line
twenty one data
degree of error
side of figure
used to classify
