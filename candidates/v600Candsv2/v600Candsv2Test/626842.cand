ring
hot
request
processor
latency
utilization
contention
outstanding
spot
transaction
topologies
banks
station
traffic
hector
cache
rings
locality
saturation
cluster
packet
theta
cycle
branching
efficiency
cycles
memory
workload
blocking
packets
topology
utilizations
reads
prefetching
block
slotted
module
processors
rate
spots
localities
multiprocessors
simulator
word
exposed
ml
queue
tradeoff
misses
levels
speeds
remote
hierarchy
retries
stall
doubtful
target
transfers
memories
rates
favorite
hit
plots
unidirectional
miss
page
sci
synchronization
mode
batch
probabilities
coherence
modules
dram
multiprocessor
clusters
hierarchical
saturate
bank
strobe
tango
multicomputer
versus
interfaces
questionable
inter
shared
communication
simulating
interconnection
prototype
degradation
multithreaded
crossbar
multithreading
network
interface
stations
root
response
validated
fetched
hiding
accesses
sibai
halfwidths
cyberplus
fadi
teraflop
ultracomputers
favoritism
rxmy
ratio
consistency
synthetic
factors
compensate
batches
significance
prohibitively
agarwal
writes
controller
limiting
migrations
drop
offered
ranges
coherent
loads
mem
cause
connections
bottleneck
ksr
alpha
hardware
addressing
hierarchies
near
disadvantage
subtransaction
replications
realism
hide
increased
traverse
saturates
distributing
workloads
load
simulation
contexts
varied
transactions
advantageous
standards
requesting
realistic
causes
tend
traversed
bandwidth
concurrency
caches
access
examine
sensitive
patterns
committee
improvement
congested
percentage
scalable
ends
chose
completes
extent
transfer
percent
read
varying
substantially
queues
dec
retry
sharply
imposes
request rate
ring utilization
theta theta
transaction latency
maximum ring
outstanding transactions
hot spot
communication locality
processor efficiency
memory banks
cycle time
ring cycle
target memory
processor cycles
memory cycle
blocking reads
request rates
multiple outstanding
inter ring
branching factors
page mode
cluster 1
non blocking
ring based
memory utilization
mean remote
memory saturation
spot memory
multiple memory
block size
branching factor
ring interface
mode access
root ring
spot traffic
memory queue
base system
cluster 2
first word
contention free
theta figure
workload model
ring levels
hierarchical ring
ring hierarchy
ring utilizations
l request
versus request
traffic patterns
rate b
hot spots
u l
shared memory
ring topology
ring cycles
source processor
favorite memory
processor module
e request
response packet
cache miss
processor cycle
hit ratio
cache misses
memory contention
workload parameters
remote transaction
processing module
memory latency
cache hit
traffic pattern
memory probabilities
request packet
plots efficiency
larger branching
ring saturation
ring contention
communication localities
locality model
r u
cache coherence
memory access
one memory
maximum number
processor stall
memory bank
hot memory
hardware contexts
best topologies
reads block
scalable coherent
target station
stall ends
ring interfaces
large branching
b 33
multiple hardware
coherent interface
level workload
three traffic
per processing
l e
system performance
x r
limiting factor
memory module
overall system
block transfers
ring connections
local ring
processor modules
station controller
efficiency versus
banks per
increasing efficiency
maximum transaction
synthetic workload
cycle times
memory multiprocessors
per processor
software cache
rate 0
memory consistency
level 1
experiments indicate
c l
maximum ring utilization
theta theta theta
number of outstanding
non blocking reads
multiple outstanding transactions
multiple memory banks
memory cycle time
hot spot memory
hot spot traffic
ring cycle time
x r u
page mode access
request rate b
theta theta figure
r u l
versus request rate
u l request
l request rate
cache hit ratio
mean remote transaction
m a x
remote transaction latency
e request rate
c l e
number of levels
cluster 1 probabilities
cluster 2 size
inter ring interface
maximum ring utilizations
one memory bank
overall system performance
scalable coherent interface
hierarchical ring based
cycles between cache
per processing module
three traffic patterns
processor stall ends
multiple hardware contexts
ring and memory
favorite memory probabilities
b 33 theta
inter ring connections
rate b 33
memory and maximum
memory banks per
request rate 0
maximum transaction latency
larger branching factors
system and workload
level 1 ring
rate for different
memory and ring
number of processor
shared memory multiprocessors
number of memory
rate of 0
processor cycle time
reaches the processor
software cache coherence
f c e
somewhat larger branching
higher request rates
u l topologies
level workload model
l e request
one outstanding transaction
different t values
utilization and maximum
outstanding transactions per
per memory module
increasing the block
synthetic workload model
concurrency and contention
page mode dram
adaptive maximum number
efficiency versus request
l a y
y c l
number of ring
plots efficiency versus
f f c
communication locality model
effect on efficiency
source processor module
access strobe line
transactions and non
mode dram access
take prohibitively long
increase in ring
communication locality changes
memory bank per
use of page
large branching factors
would take prohibitively
low level workload
transactions per processor
degree of communication
near the hot
ring based systems
simple node interfaces
exposed transaction latency
increase in order
c e request
tradeoff between concurrency
shared memory multiprocessor
