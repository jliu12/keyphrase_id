decoupled
ep
caches
cache
ap
uniprocessors
strcpy
latency
saxpy
locality
architectures
slip
instruction
queues
zs
uniprocessor
queue
instructions
deap
processor
eod
memories
memory
execute
astronautics
livermore
interleaved
bandwidth
pipe
sensitivity
benchmarks
convolution
fetch
architecture
insensitivity
r2000
unequal
unbalance
llls
noninterleaved
operands
benchmark
traces
lawrence
fetched
cycles
correlation
decoupling
speedup
loops
processors
mips
bottleneck
tokens
access
pipelined
wm
studies
bus
spatial
streams
token
parallelism
computers
temporal
effects
load
string
cray
block
ahead
unrolling
simulation
cycle
fom
uniproc
handcoded
slow
miss
trace
exhibit
significance
simulations
fig
dae
3100
chip
sma
furnishes
contentions
slower
instr
deposited
hide
cached
register
vlsi
limitations
count
deposit
linpack
flushed
bytes
organizations
grain
alleviate
concluded
exhibits
module
calculation
speed
compiler
increments
interleaving
simulators
width
peak
20000
bits
capturing
array
waiting
hides
organization
dec
architectural
delay
benefit
demand
past
bottlenecks
evident
stand
read
microprocessor
ibm
loaded
6000
routine
attained
offs
assembly
12022
strcmp
porpodas
6001
interlocks
lll3
5cycles
heel
unrealistically
30580
11083
6600
20065
25435
24497
tripling
parcerisa
19524
15cycles
nonpipelined
crago
milidonis
12253
lll1
noncached
1938
espasa
alachiotis
31560
whereupon
wulf
lll11
furnishing
gaudiot
1094
goutis
2251
1070
5926
sdp
kakarountas
mask
baseline
rs
busy
conduct
accessing
consume
superior
ratio
strong
controller
computations
buffering
achilles
fifos
3975
writeback
decoupled architectures
the ep
the ap
memory latency
decoupled architecture
the decoupled
of decoupled
in decoupled
execute processor
a decoupled
with caches
access processor
memory access
the memory
decoupled systems
decoupled system
the execute
access time
decoupled computers
latency effects
and decoupled
zs 1
the access
uniprocessors with
the cache
temporal locality
execution time
cache based
to memory
with cache
the uniprocessor
spatial locality
data memory
ap and
data cache
address calculation
astronautics zs
access execute
the queues
without caches
read queue
lawrence livermore
main memory
and execute
data caches
memory speed
from caches
the astronautics
livermore loops
decoupled access
of memory
block size
uniprocessor with
the benchmarks
instructions are
memory bandwidth
architecture performance
caches and
locality and
sensitivity of
uniprocessors and
architectures can
saxpy unequal
cray 1
that decoupled
write queue
instruction streams
memory unit
the lawrence
strong temporal
in saxpy
the queue
cache in
a bottleneck
cache memories
bandwidth requirement
caches in
memory module
total bandwidth
access and
in fig
an access
effects in
architectures with
slow memory
and ep
memories the
performed simulations
two processors
performance advantage
larger block
memory cycle
simulation study
latency and
memory is
total execution
execute architectures
ap has
the deap
latency sensitivity
structured memory
the slip
the strcpy
certain latency
calculation instructions
cached uniprocessors
memory path
its section
the zs
once memory
eod token
data operands
execute processors
pipelined memory
to uniprocessors
ep stand
wm architecture
ap instructions
cache organizations
the llls
cache decoupled
the saxpy
deap architecture
alone execution
data fetch
both uniprocessors
the wm
the eod
ap ep
complete its
tokens to
the sensitivity
in execution
memory system
the bus
data elements
a cache
the data
on chip
this benchmark
bus width
demand by
by capturing
caches can
ep can
mips r2000
interleaved memories
15 cycles
limitations associated
single processors
that caches
significance of
the performance
the speedup
the read
and cache
of demand
pipe a
convolution and
ep and
ap can
24 8
computer program
interleaved memory
single cycle
insensitivity to
performance to
sensitivity to
section of
cache is
the mips
caches is
a miss
grain parallelism
32 bits
instruction caches
and correlation
the pipe
a data
benefit from
simulation results
increase in
queue and
the code
systems we
of cache
are fetched
queues in
bandwidth requirements
not benefit
time the
the significance
the effects
be concluded
in problems
96 1
processor would
system with
the write
the total
a decoupled architecture
the execute processor
the decoupled system
in decoupled architectures
a data cache
the memory latency
the access processor
access and execute
of memory latency
memory access time
latency effects in
astronautics zs 1
memory latency effects
in a decoupled
effects in decoupled
to memory access
the main memory
the astronautics zs
the ap and
the read queue
memory latency and
decoupled access execute
lawrence livermore loops
benefit from caches
decoupled architectures with
effects of memory
simulation study of
the data memory
uniprocessor with cache
to memory latency
ap and ep
data cache in
of decoupled computers
decoupled architectures can
as the memory
the access and
performance of decoupled
and decoupled systems
by the execute
and decoupled architectures
by the ap
to the ep
uniprocessors and decoupled
uniprocessors with caches
and the astronautics
cache based systems
the uniprocessor with
decoupled architecture performance
caches and decoupled
the write queue
for the decoupled
cache in a
strong temporal locality
the total bandwidth
and without caches
the two processors
to complete its
in execution time
the total execution
total execution time
a simulation study
the memory access
effect of memory
demand by the
the address calculation
structured memory access
decoupled systems with
stand alone execution
time the ep
data caches in
its section of
and execute processors
do not benefit
the zs 1
study of decoupled
complete its section
of demand by
ep stand alone
the ap has
decoupled system the
ahead of demand
of decoupled systems
with cache decoupled
fine grain parallelism
the ap can
we performed simulations
the lawrence livermore
the deap architecture
associated with caches
an access processor
the ep can
sensitivity to memory
memory latency sensitivity
the decoupled architecture
in saxpy unequal
address calculation instructions
of the wm
access execute architectures
alone execution time
significance of a
of the decoupled
of decoupled architectures
in problems with
uniprocessors with and
convolution and correlation
between the access
the wm architecture
section of the
with and without
and the ep
of the pipe
spatial locality and
a computer program
limitations associated with
reported in 24
0 96 1
the time the
of the cache
performance evaluation of
execution time the
the sensitivity of
of the code
in fig 2
beyond a certain
memory cycle time
evident in the
the significance of
token to the
the memory system
not benefit from
the execution time
of the memory
access time of
increase in execution
the cache is
be concluded that
the performance of
can reduce the
can be observed
when the memory
main memory is
of a computer
of a data
the effects of
of the string
execute processor would
other decoupled architectures
that decoupled architectures
the cray 1
choice for cpu
instruction buffering techniques
can run ahead
performed simulations to
of performance to
correlation and strcpy
than spatial locality
a certain latency
without caches and
decoupled architecture is
total memory access
unequal increments the
also once memory
memory poses a
saxpy do not
the access process
decoupled architectures and
eod token to
that temporal locality
for microprocessor cache
of each benchmark
caches can reduce
on chip instruction
data memory unit
the fast memory
of instruction buffering
these benchmarks the
uniprocessors without caches
buffering techniques memory
decoupled architectures exhibit
architecture a simulation
if the ap
the slip that
different instruction streams
access related instructions
register and cache
decoupled architecture the
a miss and
zs 1 central
performed simulations with
the data fetch
computations the access
limitations of decoupled
offs for microprocessor
in speed up
of memory speed
decoupled architecture in
only spatial locality
from caches if
requirement but not
6000 and the
