seller
sellers
myopic
price
profit
pricing
shopbot
kephart
agent
prices
learning
agents
opponent
players
wars
policies
fl
discount
war
reward
economies
tesauro
player
profits
simultaneous
policy
sairamesh
myoptimal
consumers
lookahead
convergence
undercutting
economy
rewards
diamonds
nash
learner
economic
vs
myopically
crites
games
game
dynamics
consumer
buyers
foresight
stationary
quality
alternately
payoffs
reinforcement
instantaneous
asymmetric
equilibrium
buyer
lookup
undercut
unending
greenwald
rl
anticipate
dashed
amplitude
plot
filtering
approximators
trajectory
action
profitability
opponents
hanson
sandholm
converged
differentiation
markov
landscape
asymmetries
competing
cyclic
curve
discounting
infinitely
1998
competition
regime
minimax
baseline
curves
monotonically
symmetric
products
barto
priced
littman
prisoner
pfig
abandon
watkins
discounted
abandons
multiagent
cumulative
alternating
economically
wellman
allowable
equilibria
landscapes
markets
charging
deterministic
discretized
corresponded
persist
payoff
iterated
1999
compete
observable
markovian
immediate
dilemma
circle
chess
adjusting
instantaneously
arrows
self
actions
strategic
consequences
td
asymmetry
filled
optimize
infeasible
autonomous
turns
history
tables
implied
pq
competitive
perfect
leading
cross
training
evolves
consistently
plots
offering
amongst
discretization
yielded
symmetry
adjust
tirole
scissors
useable
fudenberg
fluctua
infintely
damp
subgame
substitutability
kreps
welfare
hashimoto
montonically
hunters
pricebots
differen
tesfatsion
rampant
microeconomic
leigh
undercuts
yoshitsugu
collusive
deltaq
utilites
shopbots
gammon
bargain
charge
deterministically
extent
terminating
simplifying
despite
phenomena
simultaneously
problematic
realistic
adaptive
hu
circles
unpredictable
ordinary
q learning
seller 1
seller 2
the sellers
simultaneous q
the q
and kephart
price quality
vs myopic
discount parameter
price war
q functions
profit functions
price wars
myopic vs
the price
q function
shopbot model
both sellers
q derived
quality model
q learner
kephart 1999
agent q
the shopbot
both players
multi agent
of seller
of fl
average profit
tesauro and
for seller
expected profit
the myopic
two player
learning in
and seller
agent economies
the consumers
information filtering
parameter fl
two sellers
pricing policies
seller s
other seller
cyclic price
asymmetric solution
derived price
price pair
myopic opponent
profit for
immediate reward
in tesauro
the discount
state action
the seller
expected reward
a myopic
take turns
price curves
cross plot
kephart 1998
time step
state space
dashed line
plot of
single agent
filtering model
sellers in
each seller
zero sum
vs q
non stationary
current price
the state
by seller
2 open
of price
their prices
s price
than seller
setting prices
action pair
fl dashed
alternately take
myopic optimal
exact convergence
pricing algorithms
vs discount
approximate convergence
alternating turn
quality seller
curves at
indicates baseline
price curve
sairamesh and
economic models
the players
the agents
of q
and policies
learning is
lookup tables
longer term
profit per
b cross
the prices
of sellers
state s
for both
an agent
of simultaneous
learning by
a average
a seller
other agents
policies and
p 2
obtained at
reinforcement learning
diamonds and
price competition
arbitrary sum
high prices
derived policies
deterministic policy
cumulative profit
future rewards
derived policy
stationary environment
solid diamonds
open diamonds
self consistently
sairamesh 1998
two seller
and crites
defined order
that seller
model myopic
optimal pricing
minimum price
fixed strategy
myoptimal pricing
unending cyclic
instantaneous profits
expected profits
sellers alternately
optimal policies
myopic policy
function approximators
fully observable
competing sellers
reward or
term consequences
no convergence
and sairamesh
sandholm and
pricing policy
and shopbot
kephart hanson
war regime
diamonds vs
self consistent
wars when
optimal price
theoretical guarantees
s current
also found
three models
price and
per time
convergence to
each agent
software agents
history dependent
nash equilibrium
q table
sum games
prices are
two competing
1 solid
agent systems
step for
hanson and
and arrows
exact or
prices of
p 1
of theoretical
lookup table
full knowledge
good approximate
adjusting their
the profit
in agent
two step
arrows indicate
that simultaneous
learning rate
optimal policy
simultaneous q learning
myopic vs myopic
q learning in
price quality model
agent q learning
the price quality
and kephart 1999
tesauro and kephart
for both sellers
discount parameter fl
the shopbot model
for seller 1
the price war
the other seller
the q functions
in the shopbot
the two sellers
q learning is
the discount parameter
in tesauro and
and seller 2
q derived price
the q learner
the q function
single agent q
for both players
cross plot of
and kephart 1998
the information filtering
cyclic price wars
plot of q
q learning by
of q learning
of the discount
of q derived
the q derived
in the price
seller 2 s
the state space
of the q
information filtering model
learning in the
of seller 2
q functions and
alternately take turns
derived price curves
seller 2 open
price curves at
of simultaneous q
vs discount parameter
functions and policies
model a average
multi agent q
state action pair
profit for both
q s a
b cross plot
profit per time
by seller 1
a average profit
seller 1 s
fl dashed line
average profit per
sairamesh and kephart
time step for
in the information
values of fl
other seller s
s q function
value of fl
per time step
at each time
each time step
well defined order
the myopic opponent
arrows indicate a
solid diamonds and
the sellers alternately
seller 1 as
that the sellers
price wars when
price for seller
a myopic opponent
the q table
than seller 1
model myopic vs
expected profit for
against a myopic
parameter fl dashed
case the seller
term consequences of
that simultaneous q
sellers alternately take
that seller 2
line and arrows
the myopic optimal
hanson and sairamesh
step for seller
price war regime
longer term consequences
sandholm and crites
line indicates baseline
kephart hanson and
q derived policy
good approximate convergence
lack of theoretical
agent s current
more interesting and
optimal price for
q derived policies
in two player
seller 1 solid
information filtering and
filtering and shopbot
in agent economies
diamonds vs discount
when the sellers
diamonds and seller
2 open diamonds
and sairamesh 1998
of theoretical guarantees
1 solid diamonds
myopic optimal price
open diamonds vs
unending cyclic price
adjusting their prices
the immediate reward
and arrows indicate
as a function
state s 0
of p 2
a function of
multi agent systems
of the myopic
despite the lack
dashed line indicates
dashed line and
number of sellers
function of fl
of the sellers
all three models
in all three
for small values
the current price
each value of
is obtained at
full knowledge of
of multi agent
the extent that
the more interesting
small values of
the other agents
a plot of
to the extent
and multi agent
in our model
p 2 is
plot of the
in a well
in which both
autonomous agents and
very good approximate
price of approximately
assumptions of knowledge
or identical products
profit landscape for
turns setting prices
discount parameter in
current q function
symmetric solution in
sellers as a
vs q shopbot
vs myopic pricing
basis of price
the sellers products
if so whether
of single agent
prices in a
we study simultaneous
price dynamics trajectory
the asymmetric solution
current price pair
non stationary environment
random entry in
of pricing policies
step lookahead calculation
were generally set
two player alternating
state space transitions
have full knowledge
very high prices
generally set to
stationary environment for
myopic 2 average
whether such solutions
the profit functions
each seller s
profits for both
the policies implied
vs myopic expected
