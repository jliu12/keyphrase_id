cherno
silvey
nuisance
asymptotic
snr
distances
sensor
lrt
leibler
kullback
ali
target
sec
tank
coe
recognition
targets
likelihood
detection
quantizers
gaussian
compressed
truck
cients
sensors
noise
miss
compression
image
hypothesis
coder
coders
transform
quantization
hypotheses
orientation
concave
lindeberg
mixture
imagery
quantized
lossy
favorable
detector
convex
imaging
theoretic
wavelet
thermodynamic
bounds
distributions
priors
tractable
radar
statistical
noisy
probability
distance
prior
ji
composite
scene
dissimilarity
inequality
multisensor
unquantized
ratios
intractable
pdf
variability
ln
tightness
attractive
unknown
ary
t62
testing
remote
fig
di
modeled
figs
additivity
monte
ch
ratio
expressions
involving
additive
orthonormal
corrupted
infrared
variate
tight
entropy
carlo
images
spikes
tance
degradations
measures
classification
bit
db
analytically
equality
cient
central
integrals
minimax
rigid
clean
exp
template
angles
zone
clutter
strengthened
pixel
bayesian
realizations
identically
multiplicative
signal
error
erent
rates
alarm
proposition
convexity
invertible
worst
simplifies
jensen
deformations
asymptotically
expectation
optimality
nonlinear
simulations
qualified
orientations
formulated
evaluated
approximations
conditioned
covariance
energy
probabilities
flir
vasudevan
cher
deadzone
advantageously
is2
imagers
analytics
lavanya
calumet
kassam
dwelled
lanterman
shaikin
quantizer
urbashi
decompressed
unbeatable
noncoherent
civilian
tanks
category
estimation
dead
ds
quantities
exponent
approximation
templates
mass
conditional
ects
decreasing
dr
statistically
1264
marginals
hyperspectral
thermo
marcum
curran
trucks
bhattacharyya
reemphasize
1274
usion
neyman
systematic
poisson
scalar
coherent
i d
p e
d i
in sec
target recognition
ali silvey
the cherno
cherno distances
of error
kullback leibler
nuisance parameters
likelihood ratio
p miss
detection problem
probability of
leibler distances
bounds on
hypothesis testing
sec 2
sensor noise
and kullback
coe cients
target detection
sensor data
the asymptotic
cherno distance
cherno and
error p
leibler and
asymptotic approximation
d p
information theoretic
sec 5
log likelihood
sec 6
c d
d gaussian
recognition performance
compressed data
i i
on p
upper bound
transform coe
hypotheses h
likelihood ratios
on target
composite hypothesis
the lrt
and cherno
l ji
silvey distances
theoretic distances
data i
h i
the likelihood
the probability
recognition problems
asymptotic expressions
distances in
the target
ji i
image data
h 0
the lindeberg
truck imagery
least favorable
noisy sensor
nuisance parameter
cherno bound
average approximation
the ali
silvey class
testing problem
target is
p f
decreasing and
detection performance
the tank
bit rates
known target
detection problems
l c
the kullback
problems involving
h 1
cients c
m ary
the mixture
independent components
hypothesis test
to p
bound on
is convex
the transform
hypothesis h
is concave
distances are
the sensor
bit rate
scalar quantizers
at orientation
ary hypothesis
binary detection
involving nuisance
of cherno
error rule
approximation 35
lossy compression
expression 21
optimal lrt
bound 14
gaussian sensor
silvey distance
binary hypothesis
on cherno
asymptotic expression
snr 8
distances provide
miss p
ratio is
cients are
the compressed
the prior
the log
noise and
performance measures
parameters such
distance d
and h
performance bounds
limit theorem
central limit
p i
sensors are
average distance
image t
under hypotheses
theoretic bounds
automatic target
ratios l
under hypothesis
tank and
mixture distribution
of miss
minimum probability
and truck
and 15
statistical models
system parameters
proposition 7
modeled as
detection algorithm
of targets
cherno bounds
carlo simulations
see sec
of asymptotic
on detection
dissimilarity between
under some
gaussian noise
p 0
d are
the detection
d s
expressions for
coe cient
d where
possible targets
35 is
under h
gaussian data
provide upper
random with
11 and
data are
the inequality
upper bounds
lower bounds
d d
d h
these distances
sec 3
compression algorithm
an upper
the average
are tight
as target
prior distribution
some conditions
distances that
are modeled
in fig
the optimal
e is
a target
a known
corrupted by
targets are
convex function
i d i
d i d
probability of error
i i d
on p e
data i d
kullback leibler distances
to p e
and kullback leibler
l c d
the likelihood ratio
p e is
the probability of
cherno and kullback
error p e
of error p
kullback leibler and
i d gaussian
i d is
likelihood ratio is
p e in
d p i
in sec 6
l ji i
ali silvey distances
11 and 15
and cherno distances
information theoretic distances
leibler and cherno
ji i d
composite hypothesis testing
in sec 5
the log likelihood
in sec 2
hypothesis testing problem
bounds on p
transform coe cients
ali silvey class
the ali silvey
sensor data i
d s p
decreasing and c
the asymptotic approximation
i d h
the cherno bound
sec 2 4
cients c d
the kullback leibler
upper bound on
log likelihood ratio
bound on p
d p 0
i d p
coe cients c
h 0 and
the sensor data
and p e
parameters such as
proposition 7 1
c d d
0 and h
ratio is the
coe cients are
ali silvey distance
tank and truck
the asymptotic expression
probability of miss
on target recognition
detection problem in
involving nuisance parameters
in the ali
theoretic bounds on
target recognition performance
d gaussian sensor
under hypothesis h
log likelihood ratios
i d are
asymptotic expressions for
of error rule
bounds on target
target recognition problems
a known target
is the likelihood
of miss p
sensor noise and
the minimum probability
approximation to p
under hypotheses h
nuisance parameters in
noisy sensor data
the cherno distance
likelihood ratios l
distances in 11
gaussian sensor noise
as random with
i d the
the average approximation
binary detection problem
for the tank
and truck imagery
d h i
c is concave
the cherno and
m ary hypothesis
and p miss
sensor data are
image t i
asymptotic expression 21
the optimal lrt
asymptotic approximation 35
leibler distances in
miss p miss
central limit theorem
an upper bound
and h 1
and c is
lower bounds on
of the compressed
p e and
modeled as random
the compressed data
hypothesis h i
testing problem the
i d where
see sec 2
as in sec
distance d p
such as target
and the asymptotic
discussed in sec
sec 5 1
minimum probability of
automatic target recognition
information theoretic bounds
d are independent
probability of false
dissimilarity between two
sec 2 2
d where the
provide upper bounds
monte carlo simulations
between two distributions
c d are
of error is
of error for
under some conditions
s p 0
the data i
h i the
in 11 and
the central limit
p f and
upper bounds on
p i i
h i and
the upper bound
the average distance
d i i
are modeled as
problem in which
optimal lrt detector
miss and p
simple hypothesis testing
illustrate the theory
p i d
the target recognition
of ali silvey
from i d
corrupted by i
along with noisy
the projected image
expectation under hypothesis
with noisy sensor
known target is
bounds on ali
lrt in 4
convex decreasing and
nuisance parameter we
d gaussian noise
cherno distances in
is the mixture
asymptotic approximation to
the mixture distribution
erent noise realizations
j i d
with prior under
for the cherno
on detection performance
upper bound 42
presence of nuisance
bounds on detection
from 44 l
mixture distribution i
exp snr 8
whether a known
with nuisance parameter
classification of multiple
of nuisance parameters
sec 6 3
worst where worst
