kernel
gsk
lsk
documents
svm
document
reuters
lsi
corpus
semantic
training
baseline
text
generalised
vsm
feature
latent
classifier
864
learning
matrix
gram
generalisation
retrieval
kernels
dimensionality
categorization
medline1033
alch
846
margin
eigenvalue
conducting
buc
acq
inner
bvsm
wheat
gvsm
siolas
category
money
schmidt
f1
regression
dimension
ionosphere
joachims
micro
datasets
products
bag
dimensions
crude
singular
query23
modeapte
earn
eigenvalues
pca
indexed
gaussian
classification
similarity
752
medline
svd
averaged
co
decomposition
bias
indexing
ridge
grain
eigenvectors
norm
vectors
spaces
polynomial
informative
ship
soft
rank
fx
splits
query20
orthogonalisation
yaoyong
kermit
reuters21578
9603
hypernym
newfeat
tfidf
feat
corn
ff
experiments
categories
500
rise
diagonal
vector
multilingual
3299
wordnet
husband
spouse
kms
equalization
machines
word
principal
projection
entries
ir
synonymous
wife
815
shawe
855
statistical
565
748
756
punctuation
857
features
learnt
mapped
incorporating
occurrence
mapping
correlations
metric
proximity
conducted
onto
reminiscent
corpora
improvements
extraction
sparse
split
frequency
recipes
nr
sv
lewis
approaching
preprocessed
impressive
ordinal
dual
extract
trade
relevant
tuned
subspace
orthogonal
approximation
substantial
extracting
fed
classifiers
1000
weight
demonstrate
sought
dictionary
conjunctions
extracts
avg
external
2pr
krieging
grauman
25431
hff
2877
maillet
eigensubspaces
gvsms
satarupa
zilan
haixian
smola
generalistion
solias
spi
kevyn
21578
isometrically
neurocolt2
97dimension
kristen
pun
recode
remultiplying
dulong
feature space
the feature
gsk algorithm
an svm
svm with
the lsk
a kernel
kernel matrix
the kernel
latent semantic
svm classifier
the corpus
linear kernel
semantic kernel
the gsk
864 0
0 864
kernel for
baseline method
support vector
relevant documents
the documents
generalisation performance
document matrix
lsk and
vector space
space model
inner products
the baseline
the gram
information retrieval
gsk lsk
of svm
eigenvalue decomposition
with gsk
text categorization
by document
for text
vector machines
term by
generalised version
kernel k
a document
documents in
baseline figure
money fx
f1 numbers
co occurrence
by conducting
a semantic
the generalised
gram matrix
the polynomial
gram schmidt
classifier with
text data
semantic indexing
alch e
the vsm
term term
non text
products between
vsm matrix
d alch
kernel defined
e buc
generalised gsk
0 846
basic vector
defined feature
gsk is
reduced feature
kernel methods
training set
the document
experiments on
matrix p
statistical learning
of documents
kernel function
semantic information
indexed by
documents are
first k
siolas and
lsk step
term similarity
new kernel
846 2
the lsi
reuters categories
some datasets
polynomial mapping
semantic network
low rank
two documents
feature spaces
we selected
the training
text classification
dimensionality of
bag of
averaged f1
rank approximation
th feature
kernel based
micro averaged
dimension of
the dimension
the matrix
and linear
feature vector
of experiments
a generalised
ridge regression
a feature
documents that
matrix d
test set
of dimensions
the dimensionality
inner product
each document
optimal value
document is
the latent
documents by
documents into
the term
semantic proximity
ionosphere data
of gsk
buc 23
k training
cross language
conducting preliminary
the gvsm
any kernel
0 752
a svm
gaussian construction
752 0
the reuters
in intervals
on reuters
joachims 10
same documents
conducting experiments
polynomial kernel
indexing lsi
lsk method
similarity matrix
reuters and
occurrence information
and svm
end for
by term
a training
results demonstrate
e ff
the semantic
representation is
training data
of words
t do
vector d
j th
semantic kernels
splits of
soft margin
different terms
kernel that
enough positive
feature map
co occur
documents we
matrix is
machine learning
a vector
set we
documents the
term matrix
component analysis
approximation strategy
new space
original feature
gaussian kernel
on text
document it
100 random
preliminary experiments
performance of
these results
onto the
demonstrate that
singular value
space in
vector machine
categorization with
document by
the feature space
the baseline method
0 864 0
generalisation performance of
the gsk algorithm
vector space model
in the feature
with gsk lsk
svm with gsk
performance of svm
linear kernel for
by document matrix
gsk lsk and
of svm with
lsk and linear
in the corpus
the term by
generalised version of
the kernel matrix
term by document
and linear kernel
svm classifier with
support vector machines
a feature space
latent semantic indexing
documents in the
an svm classifier
reduced feature space
d alch e
an svm with
alch e buc
a semantic kernel
a semantic network
defined feature space
basic vector space
kernel defined feature
and d alch
the gram matrix
of the feature
the first k
feature space in
for text categorization
the new kernel
as the j
inner products between
the polynomial mapping
a kernel k
the generalised version
to t do
siolas and d
of the gsk
generalised gsk algorithm
non text data
0 846 2
micro averaged f1
the vsm matrix
the basic vector
th feature of
feature space we
to the baseline
dimension of the
number of dimensions
low rank approximation
onto the first
the latent semantic
j th feature
bag of words
in a feature
the dimension of
the dimensionality of
value of c
the documents are
of the kernel
results demonstrate that
the j th
by conducting preliminary
semantic indexing lsi
the lsk step
with a semantic
by term matrix
864 0 752
of the lsk
eigenvalue decomposition of
we selected randomly
the eigenvalue decomposition
experiments on one
f1 numbers for
a svm classifier
conducting experiments on
the lsk method
e buc 23
a generalised version
vsm matrix p
the polynomial or
version of gsk
the reduced feature
with linear kernel
conducting preliminary experiments
original feature space
joachims 10 and
of an svm
0 752 0
of gsk algorithm
co occurrence information
the same documents
by conducting experiments
term similarity matrix
set of experiments
demonstrate that the
of the term
a document is
number of documents
j as the
into a new
term by term
space model for
documents into a
the document by
feature space of
statistical learning theory
of inner products
results are averaged
projection onto the
the inner products
relevant documents in
in information retrieval
in the kernel
singular vectors of
to the kernel
the original feature
document is represented
inner product between
a new example
text categorization with
feature space the
of the corpus
a singular value
the norm of
optimal value of
rise to the
for each category
do end for
a vector is
are averaged over
space in order
for text classification
split of the
feature space and
support vector machine
the proposed method
dimensionality of the
the training set
the parameter c
these results show
the optimal value
training set and
often in the
indexed by the
the feature vector
we focused on
gives rise to
comparable to the
to n do
data set we
of these experiments
an inner product
averaged over 100
svm with linear
on some datasets
view the lsk
set and test
acq money fx
by placing more
the documents into
yaoyong li john
feature extraction process
set we selected
indexing lsi 4
return feat i
polynomial or gaussian
gsk algorithm this
term term correlations
the generalised gsk
ff which satisfies
husband and wife
and svm classifier
756 0 846
retrieval using the
the new feature
feat i j
data matrix d
text and non
k training set
matrix d the
748 0 846
towards relevant documents
documents that share
on a semantic
approximate dimension equalization
latent semantic kernel
