pol
datasets
dataset
training
c4t
mda
lda
ss5
c4r
ic0
attributes
qda
categorical
fm2
ind
ocu
fm1
sas
uci
ss20
ql0
qu0
loh
tae
st0
ibo
ocm
ftl
ftu
rates
statlog
splits
quest
smo
cart
median
ic1
imo
dec
discriminant
st1
ten
records
dna
attribute
learning
univariate
pda
trees
thy
validation
classification
ocl
9m
rbf
statistical
bcw
lmt
lvq
qu1
ql1
stat
fold
provost
cmc
veh
neural
oc1
logistic
statistically
mining
bld
cal5
vot
c4
ranks
se
ib
t1
regression
plurality
rank
f90
wisc
decision
tree
breast
wolberg
classifier
cross
34s
mml
polyclass
statlib
contraceptive
10min
1min
fda
brodley
fastest
multivariate
alexe
lmdt
noise
http
marks
categories
pruning
thirty
3000
smoking
foster
rate
sixteen
seg
buntine
20s
hammer
estimated
hastie
3h
lvq1
olvq1
sparcstation
patient
nn
twenty
7m
cal
im
opt
adult
leaves
www
holte
needle
edu
wav
tibshirani
significance
error
mean
genetic
1994
4m
archive
ripley
bayes
quinlan
bos
minutes
spline
spec
penalized
tanner
utgoff
1m
1997
seven
ppp
plot
accuracy
shih
slowest
sample
5s
comprehensibility
silhouette
pid
vanichse
muata
5min
kweku
treeprogs
osei
46s
indonesia
aspiration
velayathan
molyneaux
takul
52s
sarle
splus
semesters
kooperberg
56s
1hr
47s
36s
html
sixty
breiman
radial
versus
murthy
forty
numerical
log
cancer
error rates
mean error
error rate
training time
numerical attributes
median training
training times
cross validation
decision tree
ten fold
categorical attributes
mean rank
noise attributes
uci dataset
ss5 c
fold cross
rates are
tree algorithms
from pol
this uci
the datasets
are estimated
the algorithms
using ten
the training
test set
of pol
loh and
0 se
categorical attribute
discriminant analysis
training set
s plus
each dataset
machine learning
data mining
statlog project
statistical algorithms
the statlog
1 se
statistically significantly
of mean
not statistically
other algorithms
plurality rule
fm1 and
ss20 s
combination splits
univariate splits
x marks
mean ranks
se dec
decision trees
each algorithm
pol is
c4 5
the error
from http
dec f90
www stat
stat wisc
classification accuracy
the mean
attributes and
estimated using
and st1
datasets are
logistic regression
attributes the
foster provost
rates of
significantly different
algorithms are
wisc edu
neural networks
the dataset
dec 3000
ten minutes
ic0 and
median sec
statlib s
ind cart
ibo im
shih 1997
5 9m
style ss5
pda mda
the statlib
dec sas
and shih
3 2m
s archive
each categorical
dataset is
spline based
of leaves
dataset the
fastest algorithm
records the
denoted by
l hammer
st0 and
the plurality
pol in
than ten
the fastest
of categories
with univariate
of noise
http www
peter l
attribute into
of error
mining and
class attribute
datasets is
estimated from
time versus
validation the
most accurate
c4t and
3000 equivalent
c4r ib
and imo
discriminant anal
smo thy
plus using
ocl ocm
and ic1
ocu ocl
pol log
wolberg tanner
ftu c4r
spec newsletter
in loh
and fm2
mda pol
the sas
use version
have median
tae and
ib ibo
solid vertical
ql0 and
fine needle
and quest
sec ftu
quest linear
a patient
of datasets
dec c
are denoted
the test
knowledge discovery
sample size
algorithms that
the dna
tree algorithm
statistically significant
three classes
hidden units
linear discriminant
dataset gives
dataset was
from uci
sparcstation 5
thirty three
rate within
pol and
function network
attributes are
records in
model selection
radial basis
algorithm is
linear combination
different from
trees a
and utgoff
and ripley
lowest mean
brodley and
continuous attribute
logical analysis
thirty two
to predict
the trees
the classifier
neural network
of training
standard error
trees with
computers and
log scale
vertical line
and neural
and lda
splits each
six numerical
lda and
mean error rate
rates are estimated
error rates are
the error rates
ten fold cross
median training time
fold cross validation
estimated using ten
this uci dataset
mean error rates
the mean error
numerical attributes and
terms of mean
decision tree algorithms
using ten fold
error rates of
obtained from http
of noise attributes
different from pol
are estimated using
not statistically significantly
the statlog project
of the algorithms
statistically significantly different
for each dataset
linear combination splits
significantly different from
the test set
the training set
of the datasets
stat wisc edu
are three classes
http www stat
www stat wisc
records the error
mean rank of
number of leaves
is to predict
for each algorithm
of error rates
are estimated from
are not statistically
are two classes
statlib s archive
the plurality rule
and shih 1997
se dec f90
from pol in
style ss5 c
than ten minutes
loh and shih
at the 10
that of pol
addition of noise
the statlib s
training time versus
pol in terms
rank of error
each categorical attribute
error rate and
less than ten
rates of the
decision trees a
the fastest algorithm
the training times
peter l hammer
the class attribute
st0 and st1
error rate is
the other algorithms
from http www
data mining and
are denoted by
cross validation the
from the test
problem is to
number of datasets
analysis of variance
estimated from the
records in the
radial basis function
an error rate
set of size
error rate for
ocu ocl ocm
by ten fold
sec ftu c4r
with univariate splits
have median training
ib ibo im
in s plus
lowest mean error
issue 2 june
training times are
six numerical attributes
1 se dec
a categorical attribute
in the statlog
training time less
plus using the
that have median
the s plus
s plus using
we use version
uci dataset gives
ic0 and ic1
training times of
implemented in s
noise attributes the
of mean rank
trees are denoted
and 1 se
0 se dec
of mean ranks
uci dataset was
fastest algorithm is
fm1 and fm2
in loh and
solid vertical line
0 se and
categorical attributes with
software is obtained
error rate within
median sec ftu
the solid vertical
of median training
ftu c4r ib
the problem is
test set of
the lowest mean
trees and rules
of mean error
12 2 12
brodley and utgoff
of error rate
se and 1
basis function network
for the dataset
neural network algorithms
the algorithms are
the error rate
error rate of
the default settings
vertical line in
logical analysis of
split on a
half of table
given in the
n 4 p
and knowledge discovery
is not statistically
computers and industrial
to predict whether
industrial engineering v
algorithm is described
number of categories
and industrial engineering
standard error of
the original dataset
of table 5
of the dna
the dataset the
of each algorithm
and that have
has an error
algorithms that are
of the training
last three columns
the software is
are given in
ranks of the
estimate the error
tree algorithm is
analysis of data
in the training
the algorithm with
is described in
machine learning v
computers and operations
is obtained from
with the default
and operations research
algorithms are not
time less than
in the s
is given in
neural networks for
in terms of
algorithm with the
stat cmu edu
test set statlog
national indonesia contraceptive
pol which has
and rules statistical
categorical attribute into
rules statistical algorithms
1min 5min b
independent noise attributes
classifier is constructed
clark and pregibon
