principal
hs
curve
curves
polygonal
squared
vertex
quantizers
segments
quantizer
delta
dffi
scatterplot
training
learning
smoothing
curvature
vertices
parametrized
ekxk
voronoi
segment
elliptical
infimum
br
diameter
smooth
penalized
hastie
distance
projection
ice
intersecting
rectifiable
appendix
generating
smoother
penalize
concentrated
lipschitz
pfx
floes
stuetzle
banfield
stopping
raftery
closed
self
penalty
skeletonization
hoeffding
sphere
straight
inequality
nk
minimizes
spline
robust
covering
expectation
ae
js
surfaces
moments
noise
arc
2ffl
ffl
bivariate
kf
multivariate
extraction
nonparametric
circle
clustering
convergence
euclidean
differentiable
theoretical
grid
midpoint
sup
variance
ld
regression
minimizing
chart
constrain
inner
2k
gaussian
distributions
satellite
proportional
bias
tarpey
memisevic
tutz
delicado
scatterplots
indentification
ludger
groundbreaking
klanke
001101
semiparametric
mulier
krzyak
codepoints
krse
yuncai
visom
fyfe
meinicke
equicontinuous
abstractprincipal
collider
lanzarote
romagnoli
einbeck
koetsier
additive
recognition
convex
continuous
compact
theoretically
density
estimation
criterion
hereafter
neighbor
min
radius
twinned
verbeek
vlassis
kis
arzela
kgl
ascoli
zhiguo
projecting
suboptimal
nearest
comparable
project
exhibits
tibshirani
kui
bhushan
floe
3l
cherkassky
1016
gla
subjectively
1017
descent
concise
ffi
outlines
distribution
logarithm
entropy
balzs
1313
mang
heuristic
hujun
1009
helge
1391
kohonen
estimating
letters
dxe
1005
1303
minimized
image
1379
mika
alterations
burdensome
regions
penalizing
nonexistent
evers
produced
perturbation
considerations
schlkopf
nondifferentiable
blends
intelligence
1p
smola
empirical
neural
principal curves
principal curve
the hs
polygonal line
squared distance
hs algorithm
expected squared
s k
generating curve
delta f
first principal
f k
the polygonal
k ffl
average squared
k n
principal component
line algorithm
a curve
r d
delta x
of principal
the generating
a principal
data points
of curves
squared loss
curve f
k segments
self consistent
new definition
new vertex
hs principal
optimal vector
length l
the curve
projection step
segments k
v i
2 s
x f
the squared
vector quantizers
vector quantizer
l f
the distribution
learning scheme
of segments
f 2
curve in
curve produced
training data
a polygonal
segments and
over 0
that delta
curve with
theoretical algorithm
component line
curves s
local curvature
stopping condition
that principal
smooth curve
curves and
of x
f is
the principal
curve of
curves f
f g
theta min
is concentrated
the diameter
curve and
of f
in k
hs and
d d
the training
the expected
curve over
be proportional
f be
parametrized curve
constructing principal
elliptical distributions
for principal
polygonal lines
generating model
ekxk 2
self consistency
hs definition
length parametrized
data generating
vertex optimization
curves in
f n
optimization step
let f
curve is
curve the
g f
an f
x 2
distance criterion
theoretical learning
penalty factor
curves of
the data
distribution of
diameter of
given length
f over
points y
to theoretically
a smooth
arc length
ae f
the theoretical
j f
concentrated on
principal components
feature extraction
distance over
with k
in r
any x
most l
with vertices
exists a
curve g
distance delta
curve from
straight line
2 r
0 l
penalize the
training points
data size
vertex is
d dimensional
all f
l 0
computational complexity
vertex v
more robust
points of
ae s
delta n
the projection
set k
curves have
non intersecting
lipschitz condition
o nk
f t
the algorithm
of length
k ffi
k points
of k
which minimizes
line segment
line with
in appendix
was generated
n data
there exists
the penalty
appendix a
theoretically analyze
our polygonal
consistent points
produces polygonal
pfx 2
principal points
t 2ffl
kf t
projection index
rate o
ld d
which project
smooth infinitely
estimating principal
scatterplot smoothing
minimizes delta
neighbor regions
learning principal
exhibits better
and stuetzle
by hs
squared euclidean
penalized squared
clustering about
n produced
finite second
curvature penalty
original hs
k exceeds
f k n
the hs algorithm
polygonal line algorithm
s k ffl
the polygonal line
the first principal
first principal component
a principal curve
the generating curve
the expected squared
2 s k
of principal curves
average squared distance
delta x f
expected squared distance
the principal curve
distribution of x
f 2 s
the average squared
principal curves and
definition of principal
k segments and
in r d
a polygonal line
number of segments
with k segments
j f k
optimal vector quantizers
2 r d
the curve produced
the hs and
principal curve is
both the hs
delta f k
principal component line
polygonal line with
principal curve of
of curves s
curve produced by
the hs principal
expected squared loss
ae f g
of segments k
curve of length
the distribution of
is concentrated on
the training data
a new vertex
delta f is
diameter of k
x 2 r
n 1 3
new vertex is
squared distance between
class of curves
proportional to n
vertex v i
the new definition
of x is
to n 1
be proportional to
over 0 1
concentrated on a
the hs definition
squared distance over
curves have been
segments and length
than the hs
data generating model
theoretical learning scheme
hs principal curve
polygonal lines with
line with k
constructing principal curves
curves s k
that principal curves
squared distance delta
length parametrized curve
squared distance criterion
for constructing principal
arc length parametrized
hs and our
squared loss of
constrain the length
the data generating
of length l
the diameter of
to be proportional
new definition of
of s k
x 2 k
curves of length
in the hs
the stopping condition
k is d
the local curvature
that ae f
over a b
a curve over
that delta f
delta n f
x is concentrated
ae s r
there exists a
a given length
that delta x
algorithm is comparable
be a curve
of the hs
of a principal
and the curve
of the principal
of the algorithm
at most l
s k be
the projection step
since the diameter
f 1 n
a smooth curve
a straight line
of data points
n data points
length of f
the squared distance
convex set k
points of the
l f l
more robust to
t f x
all x 2
of the curve
of the polygonal
let f be
such that delta
if the distribution
comparable with the
for any x
that s k
distance between x
complexity of the
was generated by
statistical learning theory
produced by the
by hs the
l which minimizes
non intersecting curves
polygonal curve with
and delta f
a minimizing f
d ld d
on heuristic considerations
the empirically optimal
segments and with
by the hs
line s t
vertex is added
self consistent i
a curve from
an f 0
segment connecting y
g l 2k
stops when k
curve g over
of optimal vector
principal curves correspond
over n training
straight line s
then j f
which project to
principal curve if
lines with k
this learning scheme
any t 2ffl
principal curves has
finite second moments
for principal curves
for estimating principal
component line for
smooth curve f
the squared loss
principal component a
clustering about principal
about principal curves
points drawn independently
curve over 0
k ffl is
length l which
to the polygonal
the self consistency
squared euclidean distance
if theta min
a smooth infinitely
distance over n
curves in r
our polygonal line
the squared euclidean
and segments of
principal curves of
infinitely differentiable curve
for data points
