nge
hyperrectangle
hyperrectangles
bnge
knn
fwmi
training
rectangles
nearest
salzberg
seeds
domains
wettschereck
hungarian
nonge
cv
rectangle
obnge
theta
neighbor
dietterich
overlapping
weights
exemplar
learning
voting
aha
exemplars
iris
feature
nested
bias
mutual
nn
letter
fuzzy
artmap
batch
cleveland
noc
missing
a2
validation
h3
1991
waveform
inferior
nesting
axis
seed
statistically
recognition
sigma1
h2
nintervals
ngecv
fmmc
jurisica
replmissfeatures
createhyperrectangle
hypotheses
classification
weight
inappropriate
incremental
heuristic
gammann
cross
poor
greedy
task
features
f2
cover
superior
irrelevant
generalized
merge
1990
gles
classifier
tasks
match
sigma0
theta6080
theta700
3seeds
inappropriateness
bourennane
ffmc
nfeatures
h1
distance
closest
ties
trained
percentage
decision
detrano
luaces
ranilla
mitran
bahamonde
mining
tested
euclidean
led
carpenter
neural
substantially
worse
permits
venkateswarlu
overlap
eleven
rectan
kolluri
discovery
modifications
inductive
1992
c4
glasgow
evidence
initialized
significantly
nest
150
noisy
neighbors
appendix
provost
irvine
adjusted
simpson
interpretable
outperforms
disallows
classified
classes
symbolic
conducted
classify
oscar
generalize
permit
steven
igor
leave
quinlan
employed
foster
covers
sensitivity
adopted
inside
boundaries
covered
learned
fw
200
experiment
classifications
avoids
poorly
1310003500
toavoid
bohnebeck
hyperrectan
arshadi
b520
basedlearning
1180100
mitkas
venerable
niloofar
indatabases
brockhausen
athanasiadis
ungeneralized
browsingfor
ramamohanarao
theta500
luft
theta800
hyperrect
8657316
wolfley
bouillant
detitta
rectanglesconstructedby
deeps
theta50100
fortier
jinyan
kotagiri
performs
policy
hybrid
attains
theta theta
of nge
feature weights
nge and
overlapping rectangles
training examples
nearest hyperrectangle
nearest neighbor
of hyperrectangles
than nge
c c
the nge
nge cv
hyperrectangle is
task c
d wettschereck
nge is
wettschereck and
and knn
the training
mutual information
axis parallel
a hyperrectangle
nge in
nested rectangles
in nge
of seeds
to knn
g dietterich
between nge
nge s
table a2
bnge fwmi
for nge
training example
neighbor algorithm
nge algorithm
to nge
the nearest
in task
by nge
letter recognition
that bnge
nge that
training set
cross validation
11 domains
and nge
second match
nge limit
hyperrectangle comparison
generalized exemplar
detailed numbers
salzberg 1991
task a
k nearest
c theta
task b
aha 1990
rectangles are
in domains
missing features
match heuristic
knn fwmi
led 7
iris task
hyperrectangles in
second nearest
hyperrectangles are
new hyperrectangle
domains and
domains where
salzberg s
starting seeds
generalized exemplars
h j
t g
the mutual
new example
nge was
and bnge
fwmi and
compare h
fuzzy artmap
knn in
greedy nge
f2 noc
these domains
performance of
out cross
irrelevant features
statistically significant
tasks a
f i
performance relative
significantly inferior
information feature
leave one
relative to
a2 in
c task
decision boundaries
of rectangles
of training
nge fwmi
nearest hyperrectangles
nge to
25 seeds
nge with
overlapping hyperrectangles
rectangles but
an nge
hyperrectangles by
that nge
cleveland hungarian
nge called
are percentage
lower f
rectangle c
however nge
nge we
hungarian voting
nearest rectangle
batch nge
feature weight
domains nge
each hyperrectangle
bnge is
nge without
point differences
hungarian and
waveform 40
the led
hyperrectangles from
closest e
appendix for
search algorithm
bias is
test example
for detailed
and significantly
in performance
one out
of starting
output class
3 seeds
exemplar is
percentage point
best version
simple nearest
cv in
the performance
weights were
rectangles and
machine learning
inferior to
test set
single point
training data
the cleveland
batch algorithm
all domains
of nearest
significantly better
test examples
on task
decision boundary
or overlapping
of feature
rectangle is
the 11
weights in
nested or
entire training
better than
significantly worse
search procedure
euclidean distance
rectangles we
worse in
significantly superior
and nearest
voting domains
fwmi in
original nge
gammann on
nested hyperrectangles
nge does
outperforms nge
hyperrectangle and
replmissfeatures h
point rectangles
fwmi is
seeds nge
letter hungarian
point hyperrectangles
parallel hyperrectangles
bnge and
one hyperrectangle
nge relative
theta theta theta
performance of nge
c c c
wettschereck and t
t g dietterich
d wettschereck and
better than nge
c theta theta
and t g
nearest neighbor algorithm
number of seeds
c c theta
nge and knn
the mutual information
in task c
of nge and
nearest hyperrectangle comparison
version of nge
the k nearest
feature weights in
of starting seeds
the nge algorithm
of nge that
the second match
for detailed numbers
appendix for detailed
than nge in
second match heuristic
k nearest neighbor
in appendix for
in domains where
one out cross
out cross validation
number of starting
the axis parallel
iris task c
number of hyperrectangles
table a2 in
a2 in appendix
the nearest hyperrectangle
domains and significantly
inferior to knn
the 11 domains
mutual information feature
between nge and
to knn in
information feature weights
see table a2
the training examples
the training example
of the 11
of training examples
performance relative to
leave one out
tasks a and
of the nearest
the training set
in nge is
relative to figure
11 domains and
of nge cv
the led 7
nge cv in
nge s performance
theta theta c
are percentage point
of the nge
in all domains
point differences between
nested rectangles but
theta c c
order of presentation
task c task
nested or overlapping
percentage point differences
nge fwmi and
versions of nge
of presentation of
shown are percentage
the performance of
in performance in
the best version
relative to knn
simple nearest neighbor
experiment we tested
task b and
best version of
the decision boundaries
significantly better than
significantly inferior to
the nearest neighbor
class of the
to the nearest
of the training
the new example
entire training set
the training data
of examples from
the entire training
mutual information between
a statistically significant
number of training
training examples are
that overlapping rectangles
nge and its
the other domains
a hyperrectangle is
and table a2
lower f i
generalized exemplar is
with missing features
the second nearest
axis parallel hyperrectangles
second nearest hyperrectangles
nge in all
difference between nge
single point rectangle
weights were adjusted
implementation of nge
hungarian and voting
nge gammann on
and second nearest
task a recognition
the nge approach
nge a indicates
relative to nge
nearest neighbor nn
in the hungarian
led 7 domain
feature weights were
by nge cv
in the led
cleveland hungarian and
nge does not
h second closest
h j with
of nge called
in task b
batch algorithm bnge
c task a
differences between nge
a new hyperrectangle
significantly superior in
feature weight mechanism
salzberg s method
task c and
the original nge
of nge were
replmissfeatures h e
nearest rectangle is
variant of nge
of nge was
where axis parallel
of nge relative
hyperrectangle is zero
on task b
nge relative to
gammann on task
of nearest neighbor
of the domains
training examples and
axis parallel rectangle
in three domains
training set test
a test example
for continuous features
fuzzy min max
in these domains
in tasks a
a batch algorithm
which the training
in 6 of
100 150 200
50 100 150
search algorithm and
set test set
if a feature
search algorithm of
nearest neighbor and
tasks a b
the number of
nearest neighbor algorithms
example as a
as a new
a new example
p 0 05
sensitive to the
that the performance
f i is
same class as
is significantly better
poor performance of
significantly worse than
the bias of
machine learning v
detailed numbers 5
bias of nge
fwmi and bnge
however in domains
3 seeds 25
