compression
compressed
4g
f3
compressing
markov
row
compress
transient
dtmcs
aggregation
chains
column
spears
ga
averaging
transition
steady
weighted
similarity
probability
perfect
matrices
population
rows
matrix
mass
entries
jg
ctmcs
compresses
uncompressed
weights
powers
equivalence
sums
probabilities
nth
8k
gas
j2sy
qpn
jerror
metric
dtmc
columns
bold
8y
sixteen
minutes
advantageous
ctmc
spent
spaces
avenue
aggregated
pn
diana
jff
pairs
chain
summing
optimum
qu
theorems
767
avenues
producing
genetic
fi
455
averages
curves
priors
yielding
estimations
ab
8x
error
intuition
4555
5514
gafos
9006
0q
overlook
darwinian
nentials
ncd
d106
enormous
raising
yield
prior
timing
individuals
202
1289
gran
20375
3172
ularity
disaggregation
multiplying
situations
linearity
axioms
search
mathematical
distributions
mathematically
justification
nrl
ensue
renormalized
expo
aggre
insights
appendix
estimates
aic
lumping
navy
tq
outlined
transformations
lemma
negligible
multiplication
xq
mil
confusion
4th
qc
recombination
969
jth
indicator
supposes
red
derivation
averaged
680
subsection
masses
gation
savings
situation
theta
emphasis
transitioning
graphed
3rd
commensurate
restatement
repeat
expressions
truth
sition
qp
occasions
denoting
populations
axiomatization
comprehension
exponentials
occasion
concerning
consistently
dramatically
ergodic
practicality
dissimilarity
infinitesimal
lumped
invariant
force
447
explained
79
fax
82
succinctly
mutation
turns
partitioning
nearly
passage
complementation
aggregating
intriguing
generality
judged
ith
referred
gordon
transitions
yields
286
generalization
compression algorithm
column equivalent
the compression
q u
q n
states i
row equivalent
r f3
probability transition
f3 4g
of states
are row
compressed matrix
transient behavior
equivalent then
markov chains
and j
perfect compression
transition matrices
q c
the compressed
are column
column equivalence
compressing probability
or column
two states
4g 1
the ga
weighted average
matrix q
row entries
p n
row or
i j
column mass
compressed state
state j
to compress
compression is
steady state
n c
search space
m spears
if q
state i
the row
q r
q matrix
states are
weighted averaging
compute p
compression of
row averaging
pairs of
a 2
for compression
search spaces
of q
the markov
fi jg
similarity metric
equivalent states
then q
in q
is column
in minutes
and column
transition matrix
i and
the weighted
column sums
compress states
of dtmcs
bold curves
of compression
j set
for columns
average of
non j
if states
nth power
state behavior
is row
as similar
row and
the transient
lemma 4
n search
similarity i
n u
w m
of row
to compute
similar as
compression the
markov model
error associated
rows 3
curves represent
aggregation of
markov chain
that q
j in
4g k
if compression
four expressions
being compressed
compression will
row equivalence
q matrices
column similarity
compress q
new compressed
jg k
force q
compressing two
time n
the probability
a weighted
the steady
entries in
states can
j values
the weights
i find
n theta
compression time
ga will
is q
in states
the states
that states
time 0
q is
no error
the nth
rows i
for r
column entries
expressed simply
higher powers
chain model
minutes to
theta n
states that
powers of
spent in
negligible error
n j
the aggregation
columns i
situations under
u to
that pairs
summing the
q 2
of column
weights are
j are
to state
for row
sums for
the column
matrix the
theta 4
those two
equivalent in
when two
the entries
the goal
n by
n matrix
the aggregated
good estimates
are compressed
table the
4 theta
is perfect
4 matrix
as possible
of error
chosen for
n step
be compressed
compute q
for compressing
c proof
time spent
the amount
at time
79 82
which perfect
jg compressing
original q
y jff
reducing n
states removed
t performs
e 8k
consistently compressed
the compression algorithm
states i and
r f3 4g
pairs of states
i and j
q n c
or column equivalent
probability transition matrices
are column equivalent
are row equivalent
compressing probability transition
the compressed matrix
compression algorithm is
compute p n
of the compression
f3 4g 1
column equivalent then
row or column
to compute p
weighted average of
equivalent then q
q n u
w m spears
are row or
for r f3
row equivalent then
probability transition matrix
q n by
of states that
p n j
and column equivalence
is column equivalent
of q u
states are row
the row entries
powers of q
2 a 2
n by lemma
of states i
when two states
be as similar
so is q
is q n
matrix q u
thus the compression
a weighted average
if q is
lemma 4 5
row and column
similar as possible
as similar as
time in minutes
2 i j
the transient behavior
that q n
bold curves represent
table the time
compression algorithm can
q is row
equivalent then so
in states i
compression algorithm for
state j in
entries in q
equivalent in q
proof if q
column equivalent states
is row equivalent
spent in states
n search space
in minutes to
the nth power
the weighted averaging
q is column
the markov model
at time n
steady state behavior
states that are
c proof if
compression algorithm was
of the markov
two states are
curves represent the
rows 3 and
transient behavior of
pair of states
a 2 4
n theta n
average of the
error associated with
of row and
of the row
states can be
the steady state
to state j
i to state
3 a 2
i j x
weights are column
compute q n
a probability transition
for probability transition
q c should
that states are
compressed matrix q
are column sums
to compress q
if compression is
compression algorithm the
similarity i j
chosen for compression
to force q
compression algorithm has
in q u
the j set
force q 2
two states i
states are column
sums for columns
compression algorithm will
four expressions for
expressions for r
compression of those
q n r
n from q
f3 4g k
fi jg k
the compressed state
of time spent
the weights are
p n for
and j are
by lemma 4
equation 3 1
in state i
j in one
those two states
q u to
be expressed simply
that the ga
then q n
column sums for
amount of compression
the ga will
that are row
nth power of
the weighted average
a 2 3
a 2 1
expressed simply as
for the ga
values while the
algorithm for probability
i j ffl
markov chain model
matrix q c
columns i and
q 2 u
i j values
p n from
2 to 100
q u and
time spent in
the entries in
theta n matrix
prove that q
a similarity metric
from the compressed
fi i j
over the states
situations under which
and q n
n r and
the amount of
that pairs of
rows i and
good estimates of
c should be
then so is
the markov chain
4 theta 4
the time in
i find the
p i j
and j of
to compute q
a linear transformation
p 2 i
state i to
and j have
theta 4 matrix
of the compressed
a 2 i
for the derivation
l p l
be considered to
as possible to
using equation 3
where the weights
3 and 4
