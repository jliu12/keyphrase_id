prefetching
rds
prefetches
prefetch
rdss
pointer
greedy
compiler
10099
cache
miss
latency
treeadd
inserted
pointers
history
stall
mowry
perimeter
pf
traversal
prefetched
hit
bisort
linearization
em3d
mst
unnecessary
barnes
luk
uniprocessor
misses
kb
health
cycles
spaid
struct
coverage
voronoi
0100
dereference
bh
suif
uniprocessors
multiprocessor
chasing
linked
hide
octree
allocated
r10000
tolerating
multiprocessors
mips
instructions
visit
slots
numeric
addresses
pf_hit
nopf_miss
pf_miss
overhead
95
codes
tsp
preorder
singly
ahead
secondary
90
traversals
memory
visited
recursive
graduation
offer
recurrent
superscalar
primary
speedup
accesses
nodes
pixie
stalls
olden
keung
fp
suffering
interprocedural
locality
objects
record
dereferences
piler
schemes
offers
99
instruction
applicable
speedups
node
toronto
hiding
dynamically
bars
potentially
bodies
recognized
eliminating
controlled
scheduling
ers
recognize
inserts
int
inst
multithreading
array
101
gammad
penalty
iii
dash
oldest
gains
contention
simulations
structures
caches
half
lists
jaswanth
agating
15122
commonwealthfellowship
tamiya
sreeram
mallopt
eecg
greeding
nopf
tatsushi
5partial
tcm
graduating
instructions86
contiguous
tree
accessed
accelerate
vii
benchmark
reorder
suffer
graduate
penalties
automate
fetching
todd
assisted
impact
suite
markov
3g4
kornilios
inagaki
kourtis
lier
koziris
1024k
athanasaki
512kb
4kx4k
shimin
anastopoulos
evangelia
nectarios
0normalized
intensive
doubly
sigarch
remote
galaxies
ilar
treenode
oftware
onodera
canadian
000
processors
heap
creation
chi
automatic
exacerbate
pa8000
palem
yalamanchili
kids
greedy prefetching
inserted prefetching
history pointer
pointer prefetching
compiler inserted
10099 95
unnecessary prefetches
90 10099
pointer based
data linearization
95 90
the rds
the compiler
linearization prefetching
hand inserted
history pointers
rds accesses
an rds
of greedy
prefetch addresses
pf miss
prefetching rdss
rds type
recursive data
compiler based
linked lists
prefetching on
cache miss
based applications
the latency
automatic compiler
prefetching is
prefetch t
coverage factor
as rds
prefetching offers
to prefetch
data structures
prefetching for
primary cache
with hit
the history
prefetch instructions
with greedy
prefetching in
prefetching scheme
t left
data prefetching
our compiler
array based
t right
based codes
a pointer
prefetching schemes
propose three
chasing problem
these pointer
100 0100
recurrent pointer
over greedy
inserted greedy
rdss on
pf hit
prefetching distance
nodes ahead
prefetching has
d nodes
software controlled
traversal of
the prefetch
prefetching can
hit rates
can potentially
pointers to
point ers
pointer chain
pointer chasing
0100 0
we prefetch
and treeadd
based numeric
struct t
widely applicable
miss latency
by hand
the pf
dynamically allocated
mips r10000
shared memory
the cache
numeric codes
prefetching and
binary tree
perimeter and
memory stall
n i
c mowry
d cache
earlier study
the traversal
f int
prefetching the
most widely
secondary cache
a record
can offer
the prefetching
while l
for pointer
in pointer
applicable scheme
graduation slots
entire nodes
rds nodes
treeadd tsp
mowry is
prefetching g
luk is
fully hide
left prefetch
subsequent traversals
rds types
of rdss
b coverage
our uniprocessor
q null
schemes greedy
static prefetch
visited d
scheme greedy
f prefetch
cases pf
c unnecessary
performed detailed
inserts prefetches
preorder t
rdss is
cache nopf_miss
pf_miss pf_hit
accelerate pointer
offer even
prefetches with
pointer update
pf_hit of
rds we
greedy prefetch
bar labeled
load stall
kb doubly
successfully prefetching
fully hidden
recognize rds
rds traversal
markov prefetching
tsp voronoi
eliminating prefetches
for prefetching
hit in
half of
space overhead
recognized as
sections are
memory bandwidth
cache misses
k pointers
bh bisort
barnes the
perimeter power
on barnes
considerable success
memory stalls
store stall
hence prefetching
em3d health
i gammad
prefetching overhead
creation order
keung luk
three compiler
prefetching achieves
way tree
prefetches fig
health perimeter
power treeadd
health mst
that greedy
miss coverage
study 8
tree q
prefetches although
olden benchmark
f list
that automatic
data else
inst stall
to rds
bisort em3d
the mips
100 0
to recognize
history pointer prefetching
10099 95 90
90 10099 95
95 90 10099
compiler inserted prefetching
data linearization prefetching
of greedy prefetching
pointer based applications
the history pointers
hand inserted prefetching
automatic compiler inserted
recursive data structures
with greedy prefetching
with hit rates
greedy prefetching in
most widely applicable
of the rds
we propose three
greedy prefetching is
inserted prefetching can
our compiler based
compiler inserted greedy
the coverage factor
pointer chasing problem
recognized as rds
greedy prefetching on
inserted greedy prefetching
array based numeric
over greedy prefetching
inserted prefetching for
based numeric codes
while l f
perimeter and treeadd
for pointer based
cache miss latency
pointer based data
based data structures
half of the
the most widely
hide the latency
the mips r10000
widely applicable scheme
three compiler based
we performed detailed
to fully hide
can offer even
way tree and
coverage factor is
traversal of an
the prefetching distance
numeric codes 6
accelerate pointer based
the entire nodes
to hand inserted
greedy prefetch scheduling
the history pointer
inserted prefetching to
that greedy prefetching
prefetch t left
to recognize rds
prefetch instructions with
schemes greedy prefetching
applicable scheme greedy
construct the history
code with greedy
recurrent pointer update
pointer prefetching offers
the node visited
scheme greedy prefetching
of compiler inserted
0100 0 99
olden benchmark suite
recognize rds accesses
issue width 4
hit rates over
of greedy prefetch
greedy prefetching g
prefetches with hit
examples of greedy
compiler was able
else if q
pointer prefetching and
the bar labeled
rdss on uniprocessors
greedy prefetching offers
on subsequent traversals
kb doubly linked
prefetch addresses without
for our next
performance to hand
considerable success in
prefetching rdss on
d cache nopf_miss
pf_miss pf_hit of
of that hit
and data linearization
power treeadd tsp
pf_hit of that
fully hide the
pointer prefetching scheme
data else if
information to recognize
we prefetch the
prefetching is applicable
if q null
prefetching offers the
offer even larger
in an rds
n i gammad
100 0100 0
the pf miss
update the history
c mowry is
propose three compiler
t data else
prefetching figure 5
prefetch addresses is
compiler based schemes
to by these
rates over 99
visited d nodes
static prefetch instructions
automate the most
now investigate whether
node visited d
these pointer based
if the rds
rds accesses and
earlier study 8
as rds types
that automatic compiler
left prefetch t
test t data
instructions with hit
that are prefetched
even larger performance
treeadd tsp voronoi
larger performance gains
the pointer chasing
t left prefetch
prefetch instructions that
prefetch t right
pf hit and
eliminating prefetches with
that the compiler
fewer unnecessary prefetches
cycles all other
when we visit
the creation order
implementation of greedy
health mst perimeter
prefetching for pointer
no additional storage
additional storage or
to the mips
bisort em3d health
unnecessary prefetches although
storage or computation
in pointer based
chi keung luk
array based codes
em3d health mst
the compiler was
bh bisort em3d
impact of compiler
singly linked lists
mst perimeter power
the function argument
proposed a hardware
if test t
perimeter power treeadd
as we see
we see in
the compiler can
to insert prefetches
are broken down
applications in shared
non numeric applications
prefetching and data
traffic between the
data prefetching on
doubly linked lists
the bottom section
the traffic between
the caching behavior
a record type
that hit in
are dynamically allocated
software controlled prefetching
passed as the
controlled data prefetching
irregular applications in
data layout in
we can potentially
prefetching on a
this scheme is
in contrast with
shared memory multiprocessors
the compiler inserts
compiler based prefetching
