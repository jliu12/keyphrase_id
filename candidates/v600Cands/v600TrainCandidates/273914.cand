hopfield
neuromaton
neuron
neuromata
neurons
neural
acceptor
inp
string
regular
descriptional
nep
acceptors
omega
pspace
ln
neqp
weights
comparator
recognized
automata
ae
1g
languages
subnetwork
f0
recurrent
language
yb
emptiness
strings
ay
recognition
automaton
jffj
hnep
iff
expressions
prefixes
subexpressions
fi
neu
hneqp
bits
ff
concatenation
substrings
pn
jff
descriptive
network
expression
learning
networks
complement
recognizes
threshold
subexpression
id
deterministic
weight
alphabet
active
constructions
delay
ntimes
hinp
nbits
neuroma
romata
polynomial
transition
sigma
reversible
iteration
relevant
1y
symbols
subclass
ourselves
bit
passive
leading
thgr
neuro
0y
outgoing
exponential
notational
sigmag
nets
abbreviation
neurocomputing
edges
indyk
suppress
cycle
signal
hj
formalism
1010
kleene
piotr
vertices
thresholds
architecture
pi
realized
buffer
read
tick
cancels
oriented
confine
propagation
nondeterministic
guessed
substring
influence
binary
symmetric
encoded
clock
realizes
tereza
gammafinpg
concatena
0976
fiigg
automatonthe
holzer
romaton
fractioned
savick
fiig
extracting
nn
witness
match
nl
tape
ba
ja
symbol
counter
subclasses
prefix
ton
closed
beda
cyclic
discrete
init
equivalence
union
old
sp
iterations
logm
reconnected
mata
precedence
hi
confirms
backward
disjunction
glasses
nerve
rigor
respond
appeared
decreasing
acceptance
connections
lel
postfix
sufficiently
employed
simulates
gamma1
equiva
latex
mealy
connected
formal
besides
subsequently
lent
petr
stating
depicted
exploited
paths
labeled
construction
block
realize
reset
inexactly
synchronization
z z
the neuron
the neuromaton
ae ae
the hopfield
omega omega
neuromaton n
hopfield languages
hopfield neuromaton
hopfield condition
regular expression
a hopfield
a neuromaton
l l
neural acceptor
regular language
neuron n
regular expressions
output neuron
input string
regular languages
a a
neural network
of hopfield
the neural
descriptional complexity
hopfield language
recognized by
n y
of regular
string acceptor
neuromaton for
a regular
i i
expression ff
the neuromata
hopfield neuromata
input neuron
finite automata
f0 1g
2 f0
neurons in
the descriptional
pspace complete
time delay
neuron out
n neurons
of neurons
neurons and
neural acceptors
called hopfield
comparator neuron
neural networks
the regular
string a
leading from
of neural
the string
the input
block n
neural string
language ln
neuron v
neuron of
of neuromata
neuromata which
deterministic finite
recurrent neural
subnetwork i
emptiness problem
is pspace
size o
a neural
neuron c
n ay
neurons of
n yb
neuron id
neuromaton is
network n
language recognized
n b
o n
o jffj
hopfield networks
n 0
finite automaton
the subnetwork
a polynomial
to out
the relevant
the language
neuromata we
neuromata can
neuron and
1 neurons
networks hopfield
all neurons
neuromaton of
neuromata and
neuron inp
any neuromaton
symmetric neural
ffl fi
network computation
ii lemma
inp out
are pspace
the descriptive
transition function
the emptiness
with o
blocks n
fi has
type 0
ff n
the threshold
the network
construction from
ln is
all oriented
descriptive power
complexity point
definition 9
o 2
the output
the complement
the recognition
language recognition
2 v
cycle c
signal propagation
of n
or 1
is recognized
by neural
is active
discrete recurrent
new neuron
neurons are
acceptors for
cyclic neural
length regular
acceptor n
discrete neural
hopfield acceptors
neuron start
neurons that
inp to
2 nep
neuromaton output
acceptor the
of neuromaton
neurons inp
comparator neurons
inp 2
by neuromata
nep hnep
active iff
one neuron
clock neurons
neuron which
by hopfield
output does
that neuromata
language satisfying
x 2
will prove
any regular
we will
from definition
languages is
connected to
above mentioned
from n
so called
be recognized
an alphabet
recognition of
weights of
architecture v
oriented paths
string recognition
under union
role within
1 weights
n connections
acceptors the
of comparator
for regular
closed under
0 or
of weights
standard technique
language l
an input
old state
order recurrent
iff n
l n
z z z
ae ae ae
a a a
omega omega omega
l l l
i i i
the output neuron
the hopfield condition
the neuron n
of the neuromaton
of hopfield languages
neuron n y
the neuromaton n
a regular language
the input string
of the neural
2 f0 1g
class of hopfield
the hopfield neuromaton
a hopfield language
a regular expression
regular expression ff
the block n
by a neuromaton
of regular expressions
the descriptional complexity
the regular expression
the string a
of regular languages
of neural acceptors
the size o
the neural acceptor
a neural acceptor
so called hopfield
is a hopfield
in a polynomial
neural string acceptor
in the neuron
hopfield neuromaton n
a hopfield neuromaton
neuromaton for the
constant time delay
to n y
neural network n
recurrent neural network
output neuron out
of the string
by a regular
language recognized by
the subnetwork i
the neural network
an input string
for the recognition
is pspace complete
o n 1
regular expression of
leading from the
deterministic finite automata
the input neuron
in the neuromaton
hopfield neuromaton for
n y 0
hopfield languages is
satisfying the hopfield
neuromaton of size
when a regular
the language ln
descriptional complexity point
neurons in the
neuromaton n is
a neuromaton of
fi has the
input neuron inp
comparator neuron c
exists a neuromaton
0 or 1
the emptiness problem
the time delay
the recognition of
recognized by a
subclass of regular
that any regular
size o 2
the descriptive power
descriptive power of
pspace complete as
the regular language
ii lemma 3
network n 0
are pspace complete
of the size
recognized by the
will prove that
is recognized by
input string is
we will prove
of n 0
the type 0
complexity point of
the language recognized
complete as well
of the regular
emptiness problem for
deterministic finite automaton
the standard technique
the above mentioned
a 2 f0
for the regular
n 1 neurons
neuron n b
neuromata we will
learning and extracting
g ffl fi
ffl fi has
blocks n x
the neuron id
a neuromaton n
role within a
block n yb
iff n 2
recognition of regular
out 2 v
n 2 nep
from the descriptional
architecture v e
power of regular
neural acceptors for
from ii lemma
neuromata can be
output does not
second order recurrent
the neuron v
language given by
of the neuromata
expression of length
satisfies the hopfield
neuromata which are
n 1 weights
string that has
expression ff n
networks hopfield networks
any regular language
the neuromaton output
from definition 9
n b to
constructions of neural
the neural string
from n b
regular language given
between the descriptive
regular language satisfying
automata by neural
o n connections
discrete recurrent neural
been read so
signal propagation from
all neurons in
time delay of
1 weights of
a role within
descriptional complexity of
to the neuron
a cyclic neural
hopfield neuromata which
from n y
language satisfying the
called hopfield condition
on symmetric neural
neuromaton output does
neurons inp out
neural networks hopfield
length regular expression
neurons of the
cyclic neural network
the class of
with o n
2 v is
over an alphabet
of the input
the so called
decreasing sequence of
by neural nets
path leading from
input string that
the empty language
of weights in
n b 0
based on symmetric
regular expression which
sequence of weights
all oriented paths
x 2 f0
a constant time
state of the
the transition function
regular language is
to suppress the
the form fi
a polynomial space
read so far
