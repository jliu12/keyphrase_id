similarity
word
cooccurrence
unseen
mle
disambiguation
perplexity
verbs
kid
bigrams
bigram
linguistics
katz
divergence
guy
jensen
corpus
distributional
confusion
singletons
verb
training
unigram
noun
clustering
language
speech
kl
shannon
cooccurrences
o1
thesaurus
pereira
probability
di
lapata
1992
probabilities
erent
steinbiss
cooccur
neighbors
estimates
senses
rand
wordnet
closest
ect
pseudo
dagan
nouns
association
frequency
sparseness
essen
disagreements
mle1
utze
wsj
lexical
pc
smoothing
base
frequencies
1991
bo
jelinek
measures
cooc
informativeness
events
recognition
1993
words
church
selectional
distant
likelihood
keller
discounting
smoothed
lattices
statistics
statistical
rates
1987
doctor
modeling
syntactic
scores
membership
yarowsky
yielded
nearest
plausibility
maria
erences
text
ambiguous
learning
norm
hlt
settings
meeet
karov
centrust
whispers
tanimoto
grishman
semantic
beta
pairs
baseline
probabilistic
nlp
geneva
interpolation
brown
estimation
thing
lot
configurations
1997
weight
statistically
man
currence
mirella
weeds
egidio
pseudoword
meeting
dissimilarity
sch
american
corpora
chapter
switzerland
lin
byoung
cardie
weir
lillian
jianfeng
lee
dimensionality
omitting
predictions
resnik
terra
eat
tishby
darkness
bank
ten
weighted
tagging
mass
estimate
gram
gale
neighbor
retrieval
37th
counts
frank
role
edelman
grefenstette
20th
similarities
college
million
adjective
saul
mcdonald
talip
erence
interpolated
distributions
bayes
north
contexts
alternatives
claire
punctuation
mother
tasks
judgements
goodman
024
theoretic
human
conditioned
julie
empirical
english
tak
leaders
arpa
similarity based
w 1
back o
language model
confusion probability
word similarity
base language
the similarity
language modeling
w 2
computational linguistics
unseen bigrams
word pairs
kl divergence
p w
closest words
jensen shannon
shannon divergence
pseudo word
sense disambiguation
for unseen
o model
mle o1
word sense
similarity model
the kl
the confusion
the jensen
the mle
test set
unseen word
class based
mle 1
words in
of similarity
of word
linguistics p
1 w
error rates
similar words
most similar
based models
cooccurrence probabilities
word cooccurrence
the cooccurrence
of unseen
2 w
based methods
a word
cooccurrence statistics
data sparseness
similarity function
distributional similarity
e ect
unseen pairs
word w
language processing
di erent
the base
similarity measures
probability estimates
katz 1987
language models
1 norm
steinbiss 1992
and steinbiss
cooccur with
distant neighbors
essen and
distributional clustering
similarity measure
set error
divergence and
speech recognition
set perplexity
pseudo words
disambiguation task
error rate
training corpus
association for
the word
word is
the probability
linguistics v
of words
ambiguous word
to guy
several similarity
lot 0
word pair
maria lapata
bigram back
similar neighbors
word classes
for computational
the back
the association
a similarity
two words
word disambiguation
katz s
based estimates
bigrams in
frank keller
for word
the words
the training
similarity functions
the bigram
in language
the closest
occur with
chapter of
probability of
annual meeting
words that
based model
of speech
on computational
that similarity
l 1
a pseudo
the l
n gram
of lexical
unseen events
was mle
bo 1
mle1 jensen
1999 college
conditioned word
k most
bigram model
similarity models
to cooccur
point style
sch utze
deleting singletons
perplexity improvement
man 0
word combinations
with guy
guy kid
thing 0
unigram frequency
cooccurrence probability
smoothed estimates
seen word
is mle
word guy
cooccurrence smoothing
omitting singletons
highest confusion
linguistics on
information theoretic
ect of
the ten
statistical language
estimates for
natural language
american chapter
similarity between
north american
pereira 1997
the verbs
o models
using mle
then modeled
a bigram
pereira et
wsj text
lin 1991
model was
probabilities of
for language
for di
the e
estimates of
al 1992
based language
probability with
the test
measures of
test data
the unseen
the thesaurus
relative influence
brown et
similarity proceedings
sparse data
nearest neighbor
most likely
for l
frequencies of
to w
probability mass
on test
class membership
probability estimate
mle is
base language model
p w 2
the base language
back o model
the confusion probability
similarity based methods
jensen shannon divergence
w 1 w
2 w 1
the kl divergence
the jensen shannon
similarity based models
w 2 w
the similarity based
w 1 is
the back o
word w 1
computational linguistics p
the similarity model
word sense disambiguation
l 1 norm
unseen word pairs
similarity based model
a similarity based
1 w 1
a pseudo word
divergence and the
the language modeling
the l 1
for computational linguistics
association for computational
language model the
test set error
language model is
for unseen bigrams
essen and steinbiss
of similarity based
the closest words
and steinbiss 1992
on computational linguistics
w 1 and
of the association
to w 1
to occur with
test set perplexity
w 2 is
w w 1
of the similarity
computational linguistics v
p r w
for unseen word
r w 2
similarity function is
average and range
of unseen bigrams
bigram back o
confusion probability with
most similar neighbors
pseudo word disambiguation
similarity based estimates
confusion probability is
1 and w
similar to w
w 1 however
the association for
most similar to
the probability estimates
chapter of the
a training corpus
of a word
of w 1
and range of
w 1 in
the e ect
e ect of
part of speech
computational linguistics on
kl divergence and
function is indicated
highest confusion probability
katz s back
most similar words
closest words to
shannon divergence and
using word similarity
closest words for
sense disambiguation task
model is mle
linguistics on computational
cooccurrence statistics of
back o models
seen word pairs
base language models
june 20 26
to cooccur with
word cooccurrence probabilities
s w 1
the cooccurrence statistics
s back o
proportion of unseen
that similarity based
the point style
the k most
closest words in
the word guy
26 1999 college
37th annual meeting
respect to guy
20 26 1999
probability estimates of
model was mle
k most similar
then modeled by
language model was
distributional similarity proceedings
unseen bigrams in
similarity based language
on a pseudo
the similarity functions
point style the
1999 college park
words in the
is indicated by
for di erent
proceedings of the
american chapter of
north american chapter
the similarity between
et al 1992
an ambiguous word
on test set
and parameter settings
in the thesaurus
kl divergence is
set error rates
the probability estimate
j w 1
between w 1
pereira et al
w 2 as
words in v
and w 1
words that are
brown et al
measures of similarity
between a word
the similarity function
similarity proceedings of
by the point
words in order
a class based
a language model
probability with respect
l w 1
is varied the
error rates as
a particular word
conference on computational
in the language
indicated by the
from the training
the two words
of the word
in the corpus
college park maryland
l and j
2004 geneva switzerland
27 2004 geneva
23 27 2004
es august 23
august 23 27
for l and
1 w 2
20th international conference
annual meeting of
the 20th international
a word and
in the training
et al 1993
that w 1
meeting of the
the north american
of the north
an information theoretic
in v 1
set of experiments
the probability of
and the l
the test data
on human language
human language technology
l j and
pc w 1
class based models
used a similarity
models and parameter
the line style
error using different
1000 error rate
visitor at at
