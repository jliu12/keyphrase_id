chunk
chunks
workers
scheduling
hs
scheduler
worker
msg
workload
load
gss
mhlw
loop
redistribution
hsp
migrated
processors
static
loaded
hsr
mllw
messages
tc
loops
requesting
processor
locality
send
my
remote
processors0
traveling
dsss
sss
mm
iterations
migration
transferlimit
numa
duties
body
trapezoid
lightly
heavily
charge
exit
memories
balance
unbalance
request
parallelized
idle
efficiency
migrations
queue
finished
message
break
compile
remotely
multiprocessors
affinity
loopbodysize
firsttime
classification
overhead
cm
self
execute
executed
irregular
balancing
ads
sends
owner
guided
machines
hybrid
lds
transitive
partitioned
pending
multiprocessor
msgs
migrate
uniform
outermost
schedulings
replicated
memory
the scheduler
the workers
dynamic scheduling
self scheduling
static scheduling
msg to
local chunks
the chunks
of hs
the workload
non executed
local chunk
loop body
the processors
traveling exit
remote chunk
loop scheduling
a worker
distributed memory
local queue
data locality
load messages
messages traveling
parallel loop
a load
dynamic level
loaded worker
exit break
load migrated
scheduling level
load finished
send a
the load
the local
requesting processor
load request
local loop
processors efficiency
body i
break case
heavily loaded
the loop
scheduling on
parallel loops
worker sends
my local
migrated msg
load needed
finished msg
optimal static
no messages
locality is
data returned
workload redistribution
static level
scheduling algorithms
distribution scheme
in hs
guided self
case load
chunk and
next non
local memories
communication overhead
loop is
executed chunk
request failed
scheduling duties
request msg
returned msg
chunk is
scheme chosen
chunks to
non uniform
chunks of
in charge
of processors
static and
of workers
data distribution
charge of
of processors0
all workers
becomes idle
the requesting
scheduler is
the dynamic
workers are
chunks and
efficiency number
send a load
to the scheduler
messages traveling exit
no messages traveling
of the chunks
data locality is
of processors efficiency
msg to the
performance of hs
loop body i
the parallel loop
loop scheduling on
local queue is
local loop body
traveling exit break
my local queue
load finished msg
next non executed
load migrated msg
of the workers
all the workers
guided self scheduling
number of processors
of the loop
optimal static schedule
exit break case
data returned msg
worker sends it
else if no
load request msg
non executed chunk
heavily loaded worker
dynamic scheduling strategies
a worker sends
its local chunks
in charge of
charge of the
the local memories
the requesting processor
number of processors0
if no messages
the local computations
data distribution scheme
static and dynamic
the dynamic level
most heavily loaded
scheduling on distributed
efficiency number of
of the workload
of its local
the execution of
number of workers
and dynamic scheduling
on distributed memory
the communication overhead
the most heavily
the workload of
major concern and
static scheduling level
migrated msg to
the workload redistribution
chunks of iterations
static level in
remotely processed data
the local chunks
a load migrated
empty no messages
are dead my
workers are dead
near optimal static
processed data block
mhlw the most
distribution scheme chosen
dynamic scheduling level
a remote chunk
all workers are
processors efficiency number
my next non
hybrid scheduling hs
the remotely processed
the classification list
request failed msg
if all workers
msg to mhlw
chunk else send
load needed msg
dead my local
else send a
non executed local
locality is a
