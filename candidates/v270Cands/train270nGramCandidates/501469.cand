preemption
cache
preemptions
refill
priority
preempted
invocations
tasks
response
phasing
delay
task
jk
schedulability
blocks
worst
scenarios
lee
prediction
infeasible
scenario
wcet
fig
preempt
cycles
preemptive
overestimation
dc
scheduling
executes
invocation
reloading
overlapped
constraint
fft
widening
costs
fir
mapping
deadline
safe
counted
schedulers
lms
scheduler
mappings
maximizex
36000000worst
pc
bounding
gap
execute
dma
busquets
lud
mataix
staschulat
memory
objective
multiplied
block
regions
constraints
proportionally
displaced
increasingly
tighter
resumes
predictability
explained
queue
trend
misses
reloaded
disjoint
multitasking
extendible
rectify
unpredictability
doubly
instruction
ifip
execution
rolf
reload
inequalities
pessimistic
interactions
lowest
sensitive
preemption delay
related preemption
cache related
case response
priority task
the cache
preemption cost
cache blocks
cache refill
preemptions of
refill time
useful cache
response time
the preemption
of preemptions
cache mapping
preemption scenarios
higher priority
lee et
proposed technique
al s
worst case
task set
priority tasks
s technique
invocations of
the worst
during r
of cache
e theta
preemption costs
of useful
r 4
execute during
real time
lower priority
time prediction
j h
r i
blocks used
execution point
preempted task
case preemption
preemption scenario
cache regions
0 jk
fixed priority
of tasks
of lee
d r
theta d
cache block
the proposed
sensitive preemption
scenario sensitive
in fig
previous techniques
schedulability analysis
task j
the task
a preempted
cost table
the tasks
is preempted
by dc
during which
of invocations
infeasible task
tasks 1
linear programming
j during
main memory
regions used
time increases
task is
cache partitioning
four tasks
the technique
infeasible preemption
during preemption
task phasing
many infeasible
response times
each task
used by
time systems
function value
g j
preempted by
preemptions in
cache related preemption
related preemption delay
worst case response
case response time
cache refill time
useful cache blocks
number of preemptions
the cache related
the cache refill
al s technique
lee et al
higher priority task
the proposed technique
of preemptions of
of useful cache
et al s
the worst case
e theta d
of cache related
during r i
the preemption cost
response time prediction
d r 4
higher priority tasks
the higher priority
blocks used by
cache blocks used
of lee et
theta d r
lower priority task
preemption delay in
worst case preemption
preemption delay of
refill time increases
as the cache
cache blocks of
preemption cost table
scenario sensitive preemption
the cache regions
related by dc
of invocations of
number of useful
number of invocations
the execution point
of j during
a preempted task
objective function value
g j h
execute during the
r 4 e
that execute during
time prediction by
preemptions of j
tasks that execute
sensitive preemption cost
the preemption costs
time increases the
u u u
regions used by
preemption cost of
refill time is
the cache blocks
a higher priority
the lower priority
the task set
real time systems
tasks 1 2
4 e theta
j h s
cache mapping 1
prediction of cache
priority task j
cache regions used
cache mapping 2
when the cache
our target machine
by the proposed
example in fig
for real time
pc i r
during the preemption
delay of i
task is preempted
preempted task and
cache block c
memory blocks that
j during r
of the worst
on the cache
response time r
