plna
llna
kax
squares
concave
sla
bk
signal
recovered
norm
combinatorial
ax
residual
ls
corrupted
verbar
polyhedral
kx
parsimonious
sampled
minimization
noise
nonzero
parametrically
suppression
averages
vertex
learning
olvi
thetar
smooth
curve
linearization
mangasarian
supergradient
minimizing
fung
dayton
displays
min
dashed
1210
_1
53706
wisc
glenn
rtsch
terminating
measuring
shall
nonzeros
gammay
parsimony
kristin
justifiable
singular
razor
averaged
nondifferentiable
recovery
occam
cplex
gunnar
coefficient
thetan
misclassification
observed
bennett
matlab
finitely
training
marked
wi
plotted
orders
differentiable
solutions
curves
successive
madison
solves
strictly
magnitude
termination
mining
smoothing
street
wisconsin
componentwise
indebted
plna and
and llna
the plna
least squares
true system
gamma bk
true signal
plna llna
bk 1
combinatorial search
concave minimization
kax gamma
solution x
signal g
the true
llna solutions
squares solution
observed system
of kax
average kax
recovered signal
least norm
plna solution
both plna
g t
the recovered
observed signal
1 norm
curve marked
ax b
total least
by combinatorial
nonzero elements
the llna
sla 3
kax c
llna and
llna solution
signal recovered
by least
measuring how
the observed
5 noise
algorithm 4
system residual
noise vectors
polyhedral set
concave function
the least
machine learning
set residual
solution 25
the sla
an llna
linearization algorithm
of plna
norm approximation
a plna
average kx
ls gamma
smooth problem
llna figure
with seconds
kax ls
successive linearization
of nonzero
the average
coefficient vector
for values
over 5
vertex solution
solution 27
problem 14
averages of
problem 2
will denote
by 23
solutions obtained
c gamma
strictly less
a concave
dashed curves
minimization problem
the smooth
a polyhedral
vectors p
true solution
recovered by
vector x
problem min
plna and llna
gamma bk 1
the true signal
signal g t
the plna and
kax gamma bk
the true system
least squares solution
the least squares
and llna solutions
the recovered signal
algorithm 4 1
the curve marked
by combinatorial search
true signal g
both plna and
measuring how well
by least squares
the observed signal
the observed system
5 noise vectors
ax b p
plna llna and
recovered signal g
over 5 noise
kax c gamma
true system residual
sla 3 1
concave minimization problem
by algorithm 4
gamma x k
true solution x
for values of
coefficient vector x
on a polyhedral
an llna solution
true signal the
averaged over 5
plna solution 25
average kax c
averages of kax
are the recovered
c gamma bk
by both plna
observed signal and
comparison of plna
the smooth problem
squares solution 27
bk 1 was
signal recovered by
t with coefficient
the average kax
noise vectors p
with coefficient vector
a plna solution
signal the observed
successive linearization algorithm
llna solutions were
of nonzero elements
a polyhedral set
solutions obtained by
strictly less than
concave function on
dashed curves are
solved by algorithm
g t with
replaced by b
will denote the
how well the
number of nonzero
the 1 norm
a concave function
the solution x
minimization problem min
than the average
total least squares
nonzero elements of
from a normal
llna solution of
system training set
infinity in both
versus where x
solution 25 in
observed linear system
the concave minimization
linearization algorithm sla
tested the average
system also plotted
27 solved by
kax ls gamma
