redistribution
caterpillar
schedule
size50
circulant
sp2
dpt
msec
cyclic
transfer
reorganizations
array
superblock
communication
ibm
destination
bipartite
message
0150
processors
0250
kx
processor
contention
reorganization
0data
0total
0350
blocks
tavg
index
block
row
messages
0450
msecs
send
matching
unpack
transferred
layout
mpi
transmission
mbytes
shuffled
tmin
unpacking
matrix
secs
scheduling
ts
median
n1
pack
sized
generalized
minyi
reorganizing
reorganized
subsection
robin
tmax
packing
tmed
rows
hsien
interprocessor
minimizes
column
folded
bandwidth
supercomputing
redis
atmost
indices
submatrix
utilized
ching
hpc
receive
sizes
costs
kq
guo
submatrices
hsu
sender
node
experimental
reorganize
caterpillar algorithm
redistribution time
data transfer
communication step
sp2 our
algorithm caterpillar
msec on
the caterpillar
transfer time
generalized circulant
total array
array size50
time msec
circulant matrix
transfer cost
total redistribution
communication schedule
schedule computation
ibm sp2
algorithm total
all to
index computation
our algorithm
cyclic x
the redistribution
all communication
communication case
matching scheme
the ibm
destination processor
non all
bipartite matching
node contention
each communication
dpt t
size50 0150
data redistribution
communication steps
cyclic kx
distribution table
the schedule
table d
kx on
destination processors
and index
schedule and
block cyclic
the bipartite
from cyclic
to cyclic
send communication
array redistribution
message sizes
q processors
different message
p processors
schedule table
0150 0250
computation time
column reorganizations
sized messages
source processor
for redistribution
transmission cost
to all
on q
the dpt
0data transfer
source processors
redistribution from
a communication
a superblock
of communication
on p
a generalized
size50 0data
x on
the array
computation cost
communication scheduling
the data
redistribution problem
equal sized
block matrix
initial distribution
start up
0 total
block index
of redistribution
our scheme
msec on the
our algorithm caterpillar
algorithm caterpillar algorithm
ibm sp2 our
sp2 our algorithm
time msec on
the caterpillar algorithm
data transfer time
generalized circulant matrix
to all communication
total array size50
algorithm total array
caterpillar algorithm total
the ibm sp2
all to all
on the ibm
data transfer cost
the data transfer
total redistribution time
bipartite matching scheme
schedule and index
each communication step
schedule computation time
the schedule computation
all communication case
in each communication
a generalized circulant
non all to
the bipartite matching
array size50 0150
with different message
transfer time msec
of communication steps
redistribution time msec
distribution table d
and index computation
cyclic x on
cyclic kx on
number of communication
different message sizes
on q processors
of the caterpillar
processors to cyclic
size50 0150 0250
from cyclic x
to cyclic kx
send communication schedule
communication schedule table
a communication step
p processors to
on p processors
kx on q
time of our
initial distribution table
redistribution time of
the total redistribution
equal sized messages
in a communication
x on p
case with different
0data transfer time
the redistribution time
of our algorithm
transfer time of
table d i
0 total redistribution
the dpt t
array size50 0data
size50 0data transfer
communication case with
and index set
the network bandwidth
the all to
the schedule and
redistribution from cyclic
0150 0250 0350
the transmission cost
matching scheme 5
transfer time in
bandwidth is fully
schedule computation cost
and the caterpillar
schedule table s
0 data transfer
the non all
final distribution table
communication step therefore
index computation costs
0total redistribution time
the destination processor
