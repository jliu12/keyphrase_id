ele
game
player
games
agent
payo
equilibrium
learning
payos
agents
nash
players
pareto
reward
prole
monitoring
adversary
policy
reinforcement
payments
irrational
imperfect
maximin
rewards
economically
stochastic
action
normative
punishment
cient
actions
rationality
joint
played
play
g2
g1
deviate
perfect
attain
repeated
rational
folk
multiagent
deviates
mix
ai
equilibria
mixing
denition
punish
theorists
bowling
cooperative
converge
descriptive
convergence
defect
histories
plays
rg
veloso
economics
bayesian
stick
cooperate
policies
deviation
resp
prescribed
shneidman
parkes
xed
polynomial
ciently
whom
ciency
probabilistic
social
stipulates
monetary
settings
spirit
surplus
playing
payoff
history
strategies
payment
adopt
the game
stochastic games
repeated games
player 1
the agents
imperfect monitoring
policy prole
average reward
player 2
pareto ele
an ele
perfect monitoring
nash equilibrium
for player
learning in
learning equilibrium
e cient
the players
joint action
reinforcement learning
the agent
a nash
a game
learning algorithms
a policy
game is
economically e
the adversary
cient learning
probabilistic maximin
learning algorithm
in games
of repeated
equilibrium of
a pareto
both players
repeated game
game g
monitoring setting
side payments
the learning
games with
r max
equilibrium in
multi agent
t mix
game matrix
adversary s
game in
an agent
each agent
other player
other agent
game theory
a learning
a deviation
ele in
payos in
of rewards
games is
the payo
s payo
ele for
normative approach
in equilibrium
reward of
of games
return mixing
best response
agent i
agents will
all agents
average sum
to deviate
mixing time
the player
possible histories
in stochastic
of learning
of actions
common interest
expected payo
maximin value
its payo
monitoring we
algorithms themselves
payo obtained
the ele
ele algorithm
agent initially
a nash equilibrium
of repeated games
economically e cient
e cient learning
the learning algorithms
cient learning equilibrium
learning in games
for player 2
a pareto ele
the other agent
a policy prole
in the game
the game is
the other player
return mixing time
normative approach to
the probabilistic maximin
sum of rewards
average reward of
of possible histories
in stochastic games
perfect monitoring setting
reinforcement learning in
in a nash
average sum of
on learning in
equilibrium of the
approach to learning
the agents will
in repeated games
of an ele
the average reward
ele does not
learning algorithms themselves
adversary will always
of the players
probabilistic maximin value
the ele algorithm
the policy prole
a repeated game
the agent initially
the return mixing
agent initially plays
agent reinforcement learning
in a game
will always play
for player 1
the expected payo
be in equilibrium
repeated games with
nash equilibrium of
the adversary s
to learning in
if the agent
work on learning
a learning algorithm
case of repeated
on its own
the adversary will
learning equilibrium ele
games with perfect
ele in the
stochastic games is
player can observe
which an ele
a game in
bowling and veloso
to deviate from
the game matrix
not always exist
known the game
always exist in
xed sum game
the perfect monitoring
nash equilibrium had
if player 1
an ele does
sum stochastic games
learning v 67
adversary s payo
stick to their
game associated with
in non cooperative
strict imperfect monitoring
learning research in
perfect monitoring we
the joint action
the game g
payo obtained by
a normative approach
