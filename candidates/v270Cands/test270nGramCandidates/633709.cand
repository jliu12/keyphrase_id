nns
performances
nn
stepdisc
regression
bonnlander
ruck
selection
relevance
saliency
neural
leray
moody
czernichow
cibas
criterion
ecd
backward
ocd
obd
dorizzi
classification
derivatives
yacoub
0000000000000000000
refenes
hessian
feature
retraining
damage
pruning
validation
training
mutual
sv
weight
stopping
monotonous
mse
derivative
stepwise
perf
prediction
parametric
measures
wilks
kittler
frontier
criteria
wave
stop
fisher
correlated
multilayer
recognition
brain
forward
ard
1994
statistical
coefficient
noisy
rossi
obs
learning
stopped
pathological
frontiers
discriminating
hypothesis
mclachlan
epanechnikov
souli
fogelman
ebd
saliencies
priddy
hajlmarsson
ssr
intensive
heuristic
entropy
prohibitive
sensitivity
1977
weights
1996
ingredients
computationally
eliminated
feature selection
variable selection
selection methods
selected variables
the nn
mutual information
neural networks
for regression
choice criterion
validation set
weight pruning
relevance measures
stop criterion
l l
generalization error
a validation
sv p
order methods
for classification
wave problem
p selected
backward search
different variable
non linear
of variables
the hessian
the relevance
performance comparison
the selection
these methods
methods which
selection for
the saliency
variables perf
saliency is
selected variable
for nns
correlated variables
stepdisc 4
feature evaluation
good performances
non pathological
axis percentage
cell damage
method p
bonnlander 4
variable set
x l
pattern recognition
the generalization
5 2
selection method
variable subset
evaluation criterion
parametric methods
performances and
c r
take into
between variables
relevance of
cross validation
neural network
these measures
evaluation criteria
nn is
regression and
a variable
f x
r p
of variable
fisher test
of nns
model independent
pure noise
moody 5
gaussian problem
stepwise methods
fs p
relevance measure
variable relevance
two gaussian
refenes 5
dorizzi 5
for stopping
czernichow 5
architecture selection
original wave
floating search
x f
linear models
variable selection methods
different variable selection
of different variable
a validation set
the generalization error
feature selection methods
l l l
p selected variables
performance comparison of
f c r
of the generalization
comparison of different
method p selected
axis percentage of
feature selection method
selected variable set
selected variables perf
r p 2
stepdisc 4 2
bonnlander 4 3
l l x
of a variable
the relevance of
x l l
methods which have
feature selection for
relevance of a
may be used
all these methods
either for regression
selection is stopped
backward search and
the best performances
of selected variables
original wave problem
l x x
the original wave
5 2 7
moody 5 2
dorizzi 5 2
pure noise variables
for regression or
the two gaussian
the choice criterion
of remaining variables
czernichow 5 2
the nn is
c r all
refenes 5 2
selection for neural
using a validation
selection methods on
the selected variable
gaussian problem with
methods which use
for stopping the
order methods which
two gaussian problem
f x l
percentage of selected
compute the mutual
the final prediction
sv p 1
relevance measures for
4 3 2
et al 1996
for neural networks
4 2 2
take into account
f x f
x f x
5 2 3
non linear models
a feature selection
1 n p
best subset of
several authors have
the best subset
which have been
the mutual information
classification and regression
5 2 8
variables on the
a variable by
5 2 1
the training set
not take into
proposed to use
of feature selection
in 5 1
