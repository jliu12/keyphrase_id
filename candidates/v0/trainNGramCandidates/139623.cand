td
sutton
vn
watkins
absorbing
learning
terminal
chain
markov
predictions
xd
convergence
prediction
temporal
discounted
xv
converges
barto
rwn
werbos
tadi
vladislav
absorbs
lms
dp
reinforcement
estimator
visited
absorb
eigenvalues
vn i
absorbing markov
sutton s
terminal value
of td
td 0
the chain
terminal values
state i
temporal difference
markov chain
probability one
q learning
an absorbing
theorem t
that td
watkins 19
observed sequence
of watkins
vn 1
expected values
each state
i t
the terminal
r steps
the expected
td is
terminal states
v r
i 0
absorbing markov chain
an absorbing markov
with probability one
vn i t
of an absorbing
vn i 0
version of td
the terminal value
sutton s theorem
the v r
1 vn i
vn 1 i
if the chain
of td 0
i vn i
sutton s proof
of sutton s
converges with probability
barto sutton and
the chain has
of temporal difference
the expected values
i t 1
strictly diagonally dominant
the linear representation
temporal difference learning
machine learning v
convergence with probability
vn i vn
r random variables
