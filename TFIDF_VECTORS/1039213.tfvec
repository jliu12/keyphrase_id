ele:0.0302029509926
game:0.0295330994568
player:0.0273291645117
games:0.0268659822287
agent:0.0235607671232
payo:0.0226968899969
equilibrium:0.0214426817269
learning:0.0188176587982
payos:0.0165861888439
agents:0.0146026151862
nash:0.0139318855054
players:0.0135606927371
pareto:0.0114702208925
reward:0.0109214997824
prole:0.0107955020165
monitoring:0.00961269153102
adversary:0.00922993897275
policy:0.00900175851813
reinforcement:0.00862941456932
payments:0.00785661576814
irrational:0.00785661576814
imperfect:0.00757809332145
maximin:0.00698365846057
rewards:0.00678025430446
economically:0.00644377188906
stochastic:0.00598222032514
action:0.00574787777448
normative:0.00572779723472
punishment:0.00523774384543
cient:0.00505045432015
the game:0.0188704936988
stochastic games:0.0174942813126
repeated games:0.0165223767952
player 1:0.0145785677605
the agents:0.0138383620458
imperfect monitoring:0.0136066632431
policy prole:0.0136066632431
average reward:0.0136066632431
player 2:0.0136066632431
pareto ele:0.0136066632431
an ele:0.0136066632431
perfect monitoring:0.0126347587258
nash equilibrium:0.0122231420074
for player:0.0116628542084
learning in:0.0111010695232
learning equilibrium:0.010690949691
e cient:0.0103605838642
the players:0.0100633496108
joint action:0.00971904517367
reinforcement learning:0.00964840238135
the agent:0.00962388538121
a nash:0.00960389729153
a game:0.0092892457946
learning algorithms:0.0091018365789
a policy:0.00899835397843
game is:0.00890621758278
economically e:0.0087471406563
the adversary:0.00868007877429
cient learning:0.00785773414761
probabilistic maximin:0.00777523613894
a nash equilibrium:0.00931034446984
of repeated games:0.00926837966509
economically e cient:0.00926837966509
e cient learning:0.00837931002286
the learning algorithms:0.00837931002286
cient learning equilibrium:0.0082385597023
learning in games:0.0082385597023
for player 2:0.00720873973951
a pareto ele:0.00720873973951
the other agent:0.00617891977673
a policy prole:0.00617891977673
in the game:0.00611244110208
the game is:0.00582502114215
the other player:0.00558620668191
return mixing time:0.00514909981394
normative approach to:0.00514909981394
the probabilistic maximin:0.00514909981394
sum of rewards:0.00514909981394
average reward of:0.00514909981394
of possible histories:0.00514909981394
in stochastic games:0.00514909981394
perfect monitoring setting:0.00514909981394
reinforcement learning in:0.00514909981394
in a nash:0.00514909981394
average sum of:0.00465517223492
on learning in:0.00465517223492
equilibrium of the:0.00465517223492
approach to learning:0.00436602935863
the agents will:0.00411927985115
in repeated games:0.00411927985115
