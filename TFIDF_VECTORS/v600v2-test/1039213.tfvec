ele:0.0302029509926
game:0.0295330994568
player:0.0273291645117
games:0.0268659822287
agent:0.0235607671232
payo:0.0226968899969
equilibrium:0.0214426817269
learning:0.0188176587982
payos:0.0165861888439
agents:0.0146026151862
nash:0.0139318855054
players:0.0135606927371
pareto:0.0114702208925
reward:0.0109214997824
prole:0.0107955020165
monitoring:0.00961269153102
adversary:0.00922993897275
policy:0.00900175851813
reinforcement:0.00862941456932
payments:0.00785661576814
irrational:0.00785661576814
imperfect:0.00757809332145
maximin:0.00698365846057
rewards:0.00678025430446
economically:0.00644377188906
stochastic:0.00598222032514
action:0.00574787777448
normative:0.00572779723472
punishment:0.00523774384543
cient:0.00505045432015
actions:0.0043650782962
rationality:0.00429584792604
joint:0.00398814688342
played:0.00383740257074
play:0.00381952481129
deviate:0.00334642830755
perfect:0.00333385690785
attain:0.00325277918684
repeated:0.00323517006638
rational:0.0031651414276
folk:0.00309597455675
multiagent:0.00309508192398
deviates:0.00308193377476
mix:0.00298464644391
ai:0.00277958583123
equilibria:0.00269887550412
mixing:0.00264273560113
denition:0.00261945899903
punish:0.00261887192271
theorists:0.00261887192271
bowling:0.00261887192271
cooperative:0.00255545765759
converge:0.00253757660401
descriptive:0.00246636486109
convergence:0.00238132636275
defect:0.00237653701674
histories:0.00236815416295
plays:0.00235829810193
rg:0.00232341370489
veloso:0.00232198091756
economics:0.00229926311208
bayesian:0.00213615367356
stick:0.00202415662809
cooperate:0.00193254107231
policies:0.0018950686998
deviation:0.00187611912068
resp:0.00182034781798
prescribed:0.00179284417357
shneidman:0.00174591461514
parkes:0.00174591461514
xed:0.00171639142957
polynomial:0.00166987197151
ciently:0.00164081905896
ciency:0.0015603985334
probabilistic:0.00155186802315
social:0.00147981891665
stipulates:0.00143194930868
monetary:0.00143194930868
settings:0.00140976478001
spirit:0.00138979291562
surplus:0.00134943775206
playing:0.00129996688203
payoff:0.00128529617946
history:0.0012750921358
strategies:0.00125639955552
payment:0.0012327735099
adopt:0.00122599387827
articial:0.00118826850837
rst:0.00115412891243
knows:0.00113947053812
adopted:0.00113431093503
modied:0.00112387740633
maximizes:0.00110932933642
dened:0.00110187177658
shot:0.00108485541897
justied:0.00108485541897
strategic:0.00108485541897
quickly:0.00107696944335
dierent:0.00104984475316
stationary:0.00102995187682
behave:0.00102007370864
economic:0.00100827598357
online:0.00100603153711
outcome:0.00100603153711
response:0.00100351850957
matrix:0.000986545944435
individually:0.000972105381823
initially:0.000964709298842
max:0.000955561500626
jeffrey:0.00091245454157
mixed:0.000900512529428
dierences:0.000896422086786
people:0.000891019462755
motivation:0.000881497421266
attained:0.000881177799181
unknown:0.000879691209265
covergent:0.000872957307571
deviators:0.000872957307571
conitzer:0.000872957307571
rby:0.000872957307571
thuc:0.000872957307571
unplayed:0.000872957307571
irrationality:0.000872957307571
deviator:0.000872957307571
enforceable:0.000872957307571
knowng:0.000872957307571
noncooperative:0.000872957307571
vorobeychik:0.000872957307571
fassumed:0.000872957307571
awesome:0.000872957307571
deviating:0.000872957307571
tuomas:0.000872957307571
polynominal:0.000872957307571
satinder:0.000872957307571
punishing:0.000872957307571
ramications:0.000872957307571
osprings:0.000872957307571
groves:0.000872957307571
undiscounted:0.000872957307571
iterations:0.000870890571892
paid:0.000866644588023
complements:0.000866644588023
interactions:0.000863485537079
technically:0.000839454937986
dynamics:0.000837248419843
associates:0.000826690885291
learns:0.000826690885291
visit:0.000826690885291
learn:0.000820409529479
adopting:0.000814419974446
existence:0.000811490778973
appealing:0.000802603388935
yevgeniy:0.000773993639186
boella:0.000773993639186
conver:0.000773993639186
vickrey:0.000773993639186
devoid:0.000773993639186
leendert:0.000773993639186
torre:0.000773993639186
pretend:0.000773993639186
prisoner:0.000773993639186
decreased:0.000769553628812
setting:0.000760352219929
termed:0.000739552890944
rigorous:0.000730130759312
strict:0.000728449053349
dene:0.00072138369774
designer:0.000720968594069
equated:0.00071597465434
opponents:0.00071597465434
wellman:0.00071597465434
shoham:0.00071597465434
faithfulness:0.00071597465434
psychology:0.00071597465434
instructed:0.00071597465434
sandholm:0.00071597465434
nv:0.00071597465434
nding:0.00071205122452
exploration:0.000703364761689
average:0.000701911672733
accomplish:0.000694896457808
autonomous:0.000694896457808
uncertainty:0.000678568327047
yoav:0.000674718876031
paramount:0.000674718876031
foe:0.000674718876031
ages:0.000674718876031
outset:0.000674718876031
vu:0.000674718876031
pv:0.000674718876031
gence:0.000674718876031
recommending:0.000674718876031
guido:0.000674718876031
incentive:0.000674718876031
utility:0.000662983423563
stochastic games:0.0174942813126
repeated games:0.0165223767952
player 1:0.0145785677605
imperfect monitoring:0.0136066632431
policy prole:0.0136066632431
average reward:0.0136066632431
player 2:0.0136066632431
pareto ele:0.0136066632431
perfect monitoring:0.0126347587258
nash equilibrium:0.0122231420074
learning equilibrium:0.010690949691
e cient:0.0103605838642
joint action:0.00971904517367
reinforcement learning:0.00964840238135
learning algorithms:0.0091018365789
economically e:0.0087471406563
cient learning:0.00785773414761
probabilistic maximin:0.00777523613894
learning algorithm:0.00759506892751
repeated game:0.00680333162157
game g:0.00680333162157
monitoring setting:0.00680333162157
side payments:0.00680333162157
r max:0.0061115710037
multi agent:0.00604924347302
game matrix:0.0058314271042
game theory:0.00501253600708
normative approach:0.00485952258683
return mixing:0.00485952258683
best response:0.00485952258683
average sum:0.00436540785978
mixing time:0.00436540785978
possible histories:0.00407604821892
common interest:0.00388761806947
expected payo:0.00388761806947
maximin value:0.00388761806947
payo obtained:0.00388761806947
ele algorithm:0.00388761806947
agent initially:0.00388761806947
xed sum:0.00388761806947
initially plays:0.00388761806947
game m:0.00388761806947
always play:0.00388761806947
sum game:0.00349232628783
agent 1:0.00349232628783
agent reinforcement:0.00349232628783
non cooperative:0.00326083857514
machine learning:0.00298507130461
desired value:0.00296873919426
rg m:0.0029157135521
sum stochastic:0.0029157135521
payos obtained:0.0029157135521
individually rational:0.0029157135521
game theorists:0.0029157135521
players play:0.0029157135521
strict imperfect:0.0029157135521
nash ele:0.0029157135521
self play:0.0029157135521
equilibrium ele:0.0029157135521
folk theorems:0.0029157135521
game associated:0.0029157135521
monitoring case:0.0029157135521
ele exists:0.0029157135521
general sum:0.00261924471587
initially unknown:0.00261924471587
e ciently:0.00239188567715
behave according:0.00232231144865
always exist:0.0022265543957
e ciency:0.002114489433
bayesian approach:0.00208193479994
polynomial number:0.00202444476427
learning v:0.00202444476427
economically e cient:0.00926837966509
e cient learning:0.00837931002286
cient learning equilibrium:0.0082385597023
learning in games:0.0082385597023
return mixing time:0.00514909981394
sum of rewards:0.00514909981394
perfect monitoring setting:0.00514909981394
approach to learning:0.00436602935863
adversary will always:0.00411927985115
probabilistic maximin value:0.00411927985115
agent initially plays:0.00411927985115
agent reinforcement learning:0.00411927985115
work on learning:0.0034928234869
case of repeated:0.0033285835098
learning equilibrium ele:0.00308945988836
games with perfect:0.00308945988836
player can observe:0.00308945988836
bowling and veloso:0.00308945988836
known the game:0.00308945988836
xed sum game:0.00308945988836
sum stochastic games:0.00308945988836
learning v 67:0.00308945988836
adversary s payo:0.00308945988836
strict imperfect monitoring:0.00308945988836
repeated game m:0.00308945988836
multi agent reinforcement:0.00279310334095
set of possible:0.00260054974122
machine learning v:0.00219915158452
number of steps:0.00219005457281
multi agent systems:0.0021032250536
v 67 n:0.0021032250536
near optimal reinforcement:0.00205963992558
game theory literature:0.00205963992558
player 1 plays:0.00205963992558
multi agent interaction:0.00205963992558
rewards are based:0.00205963992558
learning in general:0.00205963992558
discuss the extension:0.00205963992558
stochastic games stochastic:0.00205963992558
imperfect monitoring settings:0.00205963992558
algorithms in computer:0.00205963992558
called folk theorems:0.00205963992558
learning in cooperative:0.00205963992558
theorems in economics:0.00205963992558
game is g2:0.00205963992558
corresponding rg m:0.00205963992558
player 1 deviates:0.00205963992558
long term average:0.00205963992558
denition for player:0.00205963992558
general sum stochastic:0.00205963992558
speed of convergence:0.00205963992558
