facial:0.0638878048445
pca:0.0302517388035
gabor:0.0188019130613
lfa:0.0155011447761
facs:0.0152450858643
face:0.0147124082124
ica:0.0130248463069
images:0.0120422543513
image:0.0118922041266
fld:0.0105200681709
recognition:0.00952811193147
optic:0.00952568287251
holistic:0.00885502342118
filters:0.00822138792117
subjects:0.00810964373906
kernels:0.00796751727169
principal:0.00773283126583
spatial:0.00675629126633
emotion:0.00626280335103
actions:0.00572808030604
eigenfaces:0.005126592507
motion:0.00471328258368
action:0.00463067908431
classification:0.00445115819818
representations:0.00418354509433
human:0.00410853383751
jets:0.00392372320929
classifier:0.00361286670803
coding:0.00358394645829
downsampling:0.00350668939031
coders:0.00350668939031
classifying:0.00336393933996
raiser:0.00336319132225
faces:0.00329394860421
expert:0.00312365795854
wavelet:0.00308066153519
filter:0.00305716584928
expressions:0.00300910457476
sparsification:0.00300573376312
graylevel:0.00280265943521
recognizing:0.00272829144498
discriminant:0.00266035560266
feret:0.00262846308005
pixels:0.00259117234871
frequencies:0.00255920172435
flow:0.00252809448038
mouth:0.00248251507976
expression:0.00248170154374
learned:0.00241556230975
smoothing:0.00241556230975
prototypical:0.00239579268167
experts:0.00232611653217
visual:0.00232473857904
dataset:0.00231052119735
naive:0.00228953339915
outputs:0.00222305063872
topographic:0.00220627123536
dependencies:0.00217342394046
performances:0.00212096574551
cottrell:0.00210277046404
eigenvectors:0.00209742607772
training:0.00208065218479
cosine:0.00207812259686
cortex:0.00206876256647
patches:0.00206354612144
sigma:0.0020579352085
scatter:0.00203416515076
wavelets:0.00201436285899
video:0.00201376665326
muscles:0.00200382250875
shift:0.00197910460261
movement:0.00197836616714
lighting:0.00197682709047
patch:0.00195750021288
fisher:0.00189306046089
pixel:0.00187325459931
similarity:0.00186962264932
texture:0.00186639060162
vision:0.00186405351338
deceit:0.00186013737313
downsampled:0.00186013737313
padgett:0.00186013737313
behavioral:0.00179500617379
kernel:0.00179119564107
48:0.00174620222536
spatially:0.00174458739912
discriminability:0.00168159566112
brow:0.00168159566112
friesen:0.00168159566112
multiscale:0.00167863571583
neural:0.00167856029756
ffi:0.00166044923848
velocity:0.00165820606827
muscle:0.00165501005317
cohn:0.00165501005317
feature:0.00164922610759
correlation:0.00164762726176
gaussian:0.00161626390908
neutral:0.00159067141905
automated:0.00157881736177
ekman:0.00157707784803
eigenfeatures:0.00157707784803
pixelwise:0.00157707784803
eigenface:0.00157707784803
ensemble:0.00155240011263
projected:0.00155036604364
unsupervised:0.0015403307676
findings:0.00153933088105
dimensionality:0.00153933088105
fiducial:0.00150286688156
affective:0.00150286688156
divisive:0.00150286688156
emotional:0.00150286688156
synthesis:0.00150249089511
locations:0.00149338929578
sheet:0.00148429118409
identity:0.00144798091314
trained:0.00144407574834
intelligence:0.0014352885107
template:0.0014348192343
eyes:0.00143064824648
learning:0.00143062462637
49:0.00142324658481
cortical:0.00139816159282
measurement:0.00135590578075
projection:0.0013494738165
neighbor:0.00133879211731
spontaneous:0.00132376274121
discriminants:0.00132376274121
consisted:0.0012896494874
genuine:0.00126596987542
nearest:0.0012543812604
outperformed:0.00125184020261
graylevels:0.00124009158209
atick:0.00124009158209
candide:0.00124009158209
penev:0.00124009158209
gammaimages:0.00124009158209
sphering:0.00124009158209
psychopathology:0.00124009158209
depression:0.00124009158209
sbw:0.00124009158209
musculature:0.00124009158209
wallraven:0.00124009158209
suicidal:0.00124009158209
movellan:0.00124009158209
unmixing:0.00124009158209
kleiner:0.00124009158209
investigations:0.00123109152442
conversational:0.00121868044817
coefficients:0.00121452643485
statistics:0.00121060051882
statistical:0.00120668763885
alignment:0.00120140690713
employ:0.001195026074
conservation:0.00118749862678
logistic:0.00117863917416
relationships:0.00117091475339
66:0.00116329589288
agreement:0.00113074427172
scales:0.00112661404172
pain:0.00112106377408
aus:0.00112106377408
dugelay:0.00112106377408
perronnin:0.00112106377408
cunningham:0.00112106377408
annoyance:0.00112106377408
blthoff:0.00112106377408
discriminating:0.00111321838806
sequences:0.00110685200463
euclidean:0.00108669825212
signals:0.00107139009691
cc:0.00106650891521
skin:0.00106082662015
frames:0.00105335422805
cheek:0.00105138523202
yacoob:0.00105138523202
happiness:0.00105138523202
wil:0.00100191125437
emotions:0.00100191125437
lid:0.00100191125437
blind:0.000988413545237
invariant:0.000979545890986
sw:0.000970871854805
manually:0.000970651162124
gave:0.00096650873285
cropped:0.000963508207851
wrinkles:0.000963508207851
subspace:0.000963416942423
frequency:0.000957459182224
classify:0.000956280083796
classified:0.000947320467088
cognitive:0.000938880151955
amplitude:0.000931440067577
radial:0.000910269123549
hsuan:0.000905539627191
narendra:0.000905539627191
bartlett:0.000905539627191
quantizing:0.000905539627191
florent:0.000905539627191
of facial:0.0220368041956
facial expression:0.0173493443929
local pca:0.0169896714149
facial action:0.0161225734108
facial actions:0.0136421775014
component analysis:0.0124136401248
optic flow:0.0123133065362
independent component:0.0119109766513
expression recognition:0.0111204697482
facial expressions:0.0110404918864
principal component:0.010661432315
lower face:0.0105416826147
the gabor:0.0105147541775
for facial:0.00868138568272
gabor representation:0.00815504227917
face image:0.00768725727752
facial motion:0.00744118772804
action coding:0.00744118772804
principal components:0.00724977397421
the facial:0.00683459021537
expression analysis:0.00682108875071
the ica:0.00679586856598
global pca:0.00679586856598
face recognition:0.00679212976932
face images:0.00651298177611
classifying facial:0.00620098977337
pca representation:0.00611628170938
face actions:0.00611628170938
ffi images:0.00611628170938
identity recognition:0.00611628170938
the face:0.00592302717493
representation was:0.00585287881485
human subjects:0.00563732200351
gabor wavelet:0.00558089079603
upper face:0.00558089079603
spatial analysis:0.00541408029607
the image:0.00528845534328
local feature:0.00512483818501
feature analysis:0.00504521971514
order dependencies:0.0049607918187
facial movement:0.0049607918187
holistic spatial:0.0049607918187
on principal:0.00475710799618
gabor filters:0.00473163937987
representations based:0.00473163937987
local filters:0.00468230305188
gabor filter:0.00468230305188
similarity measure:0.00464228771523
the kernels:0.00450898738346
high spatial:0.00448463974679
basis functions:0.00434395368662
coding system:0.00434069284136
spatial frequencies:0.004205901671
the images:0.00418643745975
best performance:0.00408528919194
pca jets:0.00407752113959
local representations:0.00407752113959
behavioral science:0.00407752113959
measure and:0.00395770467981
classification performance:0.00392691383331
local spatial:0.00392405977844
pca and:0.00378985620725
action units:0.00372059386402
facial behavior:0.00372059386402
facs is:0.00372059386402
shift invariant:0.00368016396212
was obtained:0.00361456041053
gabor wavelets:0.00351172728891
component representation:0.00351172728891
fisher s:0.00351172728891
pattern analysis:0.00340967329625
sparsification algorithm:0.00339793428299
ica representation:0.00339793428299
prototypical expressions:0.00339793428299
the lfa:0.00339793428299
action classification:0.00339793428299
analysis lfa:0.00339793428299
class scatter:0.00339793428299
the ffi:0.00334247777083
image analysis:0.00331850610913
neighbor classifier:0.00324844817764
for face:0.00321437702011
spatial filters:0.00310049488668
filter representation:0.00310049488668
spatially local:0.00310049488668
basis images:0.00310049488668
performances were:0.00310049488668
17 48:0.00310049488668
cosine similarity:0.00310049488668
the sparsification:0.00310049488668
correlation based:0.00307490291101
obtained with:0.00305461800987
physical model:0.00300599158897
and template:0.00300599158897
images the:0.00299315677799
performance was:0.00296883700725
recognizing facial:0.00292643940743
expert human:0.00292643940743
of emotion:0.00292643940743
for identity:0.00292643940743
second order:0.0028975275307
the independent:0.00288778285281
template matching:0.00284153227759
s linear:0.00284153227759
of gabor:0.00280289984175
in 48:0.00280289984175
linear discriminant:0.00279656304866
of face:0.00279656304866
kernels are:0.00275518030295
each image:0.00275399042813
analysis and:0.00273152392045
sigma 4:0.00271834742639
lfa output:0.00271834742639
guide sheet:0.00271834742639
and fld:0.00271834742639
64 54:0.00271834742639
lfa and:0.00271834742639
invariant local:0.00271834742639
expert coders:0.00271834742639
facial signals:0.00271834742639
48 40:0.00271834742639
image patches:0.00270704014803
subjects were:0.00268115602308
the principal:0.00266267632746
facial features:0.00262868854437
representation based:0.00262868854437
each sequence:0.00259773238134
machine intelligence:0.00257391851132
of kernels:0.00256241909251
image set:0.00256241909251
on pattern:0.00255725497219
the cosine:0.00250685832812
independent components:0.00250499299081
human experts:0.00250499299081
final representation:0.00248039590935
facial muscles:0.00248039590935
best performances:0.00248039590935
measuring facial:0.00248039590935
pca for:0.00248039590935
facial identity:0.00248039590935
ffi image:0.00248039590935
specific linear:0.00248039590935
local smoothing:0.00248039590935
flow fields:0.00245432114582
statistics of:0.00244834123412
nearest neighbor:0.00243520663721
images were:0.00237638616568
high order:0.00236173705888
to facial:0.00234115152594
class specific:0.00234115152594
linear projection:0.00234115152594
image representations:0.00234115152594
and machine:0.00230919438267
components of:0.00230141840518
intelligence v:0.00227311295355
computer vision:0.00224435400542
output o:0.0022423198734
the outputs:0.00222713100914
image sequences:0.00218486520466
image locations:0.00216563211843
actions were:0.00216563211843
for classifying:0.00215563179886
euclidean distance:0.00211007964107
recognition performance:0.0021029508355
the pca:0.0021029508355
sigma 3:0.0021029508355
were obtained:0.00208610531848
image representation:0.002049935274
analysis pca:0.002049935274
wavelet representation:0.002049935274
and nearest:0.002049935274
in behavioral:0.002049935274
automated systems:0.00203876056979
automated facial:0.00203876056979
class discriminability:0.00203876056979
kernels learned:0.00203876056979
downsampled by:0.00203876056979
include analysis:0.00203876056979
analysis ica:0.00203876056979
from posed:0.00203876056979
pca kernels:0.00203876056979
emotion classification:0.00203876056979
independent outputs:0.00203876056979
science investigations:0.00203876056979
statistical dependencies:0.00203876056979
naive subjects:0.00203876056979
expression measurement:0.00203876056979
distance similarity:0.00203876056979
the holistic:0.00203876056979
information maximization:0.00203876056979
3 sigma:0.00203876056979
u cc:0.00203876056979
naive human:0.00203876056979
shift variant:0.00203876056979
trained human:0.00203876056979
three lower:0.00203876056979
pca in:0.00203876056979
ica was:0.00203876056979
using optic:0.00203876056979
driven kernels:0.00203876056979
facial expression recognition:0.00982433818016
independent component analysis:0.00930228259131
facial action coding:0.00785947054413
principal component analysis:0.00722755138243
the gabor representation:0.00714438491185
of facial motion:0.00642994642067
similarity measure and:0.00633918260661
of the face:0.00626387786477
local feature analysis:0.0058946029081
for facial expression:0.0058946029081
analysis of facial:0.00558136955479
facial expression analysis:0.00523964702942
representations based on:0.00504565252116
on principal component:0.0050010694383
based on principal:0.0050010694383
action coding system:0.00458469115074
classifying facial actions:0.00458469115074
principal components of:0.00437906745506
the face image:0.00434106520928
the local pca:0.00428663094711
fisher s linear:0.00428663094711
high spatial frequencies:0.00428663094711
the independent component:0.00428663094711
the ffi images:0.00428663094711
local pca representation:0.00428663094711
lower face actions:0.00428663094711
second order dependencies:0.00392973527207
of facial expressions:0.00392973527207
the facial action:0.00392973527207
and template matching:0.00392973527207
holistic spatial analysis:0.00392973527207
and lower face:0.00392973527207
was obtained with:0.00392439640534
independent component representation:0.00357219245593
measure and template:0.00357219245593
that high spatial:0.00357219245593
cosine similarity measure:0.00357219245593
the cosine similarity:0.00357219245593
gabor filter representation:0.00357219245593
the sparsification algorithm:0.00357219245593
for identity recognition:0.00357219245593
of facial behavior:0.00357219245593
the ica representation:0.00357219245593
nearest neighbor classifier:0.00345773596724
the second order:0.0032071626318
machine intelligence v:0.00293028149486
of the image:0.00291311528399
transactions on pattern:0.00290466699143
on pattern analysis:0.00290466699143
analysis and machine:0.00289630603423
and machine intelligence:0.00289630603423
pattern analysis and:0.00289630603423
expert human subjects:0.00285775396474
feature analysis lfa:0.00285775396474
class specific linear:0.00285775396474
specific linear projection:0.00285775396474
shift invariant local:0.00285775396474
the final representation:0.00285775396474
local spatial filters:0.00285775396474
measure and nearest:0.00285775396474
for classifying facial:0.00285775396474
facial action classification:0.00285775396474
17 48 40:0.00285775396474
the image set:0.00285775396474
representation based on:0.00280314028953
the principal components:0.00273691715941
obtained with the:0.00264475771684
performances were obtained:0.00261982351471
measurement of facial:0.00261982351471
of facial expression:0.00261982351471
to facial expression:0.00261982351471
of the gabor:0.00261982351471
best performances were:0.00261982351471
the gabor filter:0.00261982351471
gabor wavelet representation:0.00261982351471
and independent component:0.00261982351471
optic flow is:0.00261982351471
of gabor filters:0.00261982351471
statistics of the:0.00254994891837
the principal component:0.00248060869102
the high order:0.0024707714988
of face images:0.00230515731149
from the statistics:0.00230515731149
and nearest neighbor:0.00230515731149
more effective than:0.00226423747822
of each sequence:0.00224251223163
best performance of:0.00218953372753
the statistics of:0.00215581672052
than global pca:0.00214331547356
among the pixels:0.00214331547356
gabor wavelet decomposition:0.00214331547356
order dependencies among:0.00214331547356
classification performance using:0.00214331547356
euclidean distance similarity:0.00214331547356
the independent components:0.00214331547356
kernels are derived:0.00214331547356
science investigations of:0.00214331547356
the ica algorithm:0.00214331547356
a representation based:0.00214331547356
s linear discriminants:0.00214331547356
a class specific:0.00214331547356
facial movement in:0.00214331547356
and expert human:0.00214331547356
44 64 54:0.00214331547356
for facial action:0.00214331547356
upper face actions:0.00214331547356
facial expression measurement:0.00214331547356
lfa output o:0.00214331547356
data driven kernels:0.00214331547356
the automated systems:0.00214331547356
template matching classifier:0.00214331547356
naive and expert:0.00214331547356
image synthesis model:0.00214331547356
identity recognition performance:0.00214331547356
the gabor wavelet:0.00214331547356
of classifying facial:0.00214331547356
three lower face:0.00214331547356
in behavioral science:0.00214331547356
small image patches:0.00214331547356
include analysis of:0.00214331547356
local pca kernels:0.00214331547356
lfa and fld:0.00214331547356
naive human subjects:0.00214331547356
of facial actions:0.00214331547356
classify the facial:0.00214331547356
distance similarity measure:0.00214331547356
of facial action:0.00214331547356
linear projection of:0.00214331547356
using optic flow:0.00214331547356
downsampled by a:0.00214331547356
kernels learned from:0.00214331547356
s linear discriminant:0.00214331547356
facial expression classification:0.00214331547356
independent components of:0.00214331547356
facial action codes:0.00214331547356
pattern analysis using:0.00214331547356
component analysis ica:0.00214331547356
projected down to:0.00214331547356
by the sparsification:0.00214331547356
64 54 26:0.00214331547356
the lfa output:0.00214331547356
driven kernels learned:0.00214331547356
global pca for:0.00214331547356
for face recognition:0.0021031312379
learned from the:0.00203410663227
did not improve:0.00203410663227
the upper face:0.00196486763603
analysis independent component:0.00196486763603
of the facial:0.00196486763603
of small image:0.00196486763603
chosen to match:0.00196486763603
of facial movement:0.00196486763603
the physical model:0.00196486763603
kernels for the:0.00196486763603
feature vector f:0.00196486763603
coding system facs:0.00196486763603
and the independent:0.00196486763603
pca and ica:0.00196486763603
computer vision systems:0.00196486763603
the upper and:0.00194457258849
upper and lower:0.00191448610412
the methods in:0.0018645353019
the first principal:0.00186045651826
best performance was:0.00186045651826
using euclidean distance:0.00186045651826
the zero mean:0.00186045651826
performance was obtained:0.00186045651826
the response properties:0.00186045651826
response properties of:0.00186045651826
representation and the:0.00182821520761
the rows of:0.00181717418354
for the upper:0.00179534371939
5 4 2:0.00179534371939
the optic flow:0.00178635756757
on the outputs:0.00178635756757
of facial features:0.00178635756757
second order statistics:0.00178635756757
added to m:0.00178635756757
for the difference:0.00178000713935
component analysis pca:0.00168188417372
components of each:0.00168188417372
face recognition using:0.00168188417372
not improve performance:0.00168188417372
ieee transactions on:0.00166180710187
dimensionality of the:0.00164496665453
linear discriminant analysis:0.00164215029565
dependencies among the:0.00160772290175
the difference in:0.00158652731619
the test image:0.00157734842843
representations such as:0.00157734842843
obtained using the:0.00155565807079
derived from the:0.00153959498517
matched to the:0.0015255799742
the first p:0.00150312472953
of basis functions:0.00144551027649
the requested action:0.00142887698237
families of gabor:0.00142887698237
grid wise fashion:0.00142887698237
components of conversational:0.00142887698237
the leading method:0.00142887698237
