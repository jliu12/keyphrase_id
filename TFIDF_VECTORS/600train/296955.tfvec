robot:0.0350778911054
trash:0.0323897926256
learning:0.0280068792294
pavlov:0.0199515506917
sensory:0.0192789624765
navigation:0.0176004061359
neural:0.015351559889
robots:0.0142039645141
theocharous:0.012261047961
sensor:0.0114434034096
khaleeli:0.0110349431649
recycling:0.0108479905081
occupancy:0.0104886173374
net:0.00992710200269
cans:0.00980883836878
opening:0.00935854473946
wall:0.00901827907786
mahadevan:0.00872554828122
training:0.00748067220381
mobile:0.00744139982108
bias:0.00737896005919
detectors:0.00737448118554
trained:0.00685338364312
learn:0.00617631828577
odometric:0.00613052398049
specularities:0.00552956784622
alvinn:0.00552956784622
pose:0.00483840912832
sensors:0.00476464781388
sonar:0.00473754187171
rapid:0.00463937313526
concept:0.00402621018444
specular:0.00394795155975
concepts:0.00393975447799
camera:0.00389505999543
quadrants:0.00388448499874
front:0.0038568488919
robotics:0.00374341789578
pomdp:0.00367831438829
door:0.00366887527884
lab:0.00357348586041
nomad:0.00332525844862
approximator:0.00311858050037
images:0.00308166469452
soda:0.00297183259364
east:0.00287485081501
grids:0.00285085545391
navigating:0.00282902440735
behaviors:0.00281349710489
human:0.00280151335865
supervised:0.0026982993158
color:0.00268716937905
layer:0.00268277868961
floor:0.00265552426199
actuator:0.00261766448437
labeled:0.00261573591095
observable:0.00251000700842
south:0.00250971626538
feedforward:0.00245451520649
sonars:0.0024522095922
receptacle:0.0024522095922
litter:0.0024522095922
receptacles:0.0024522095922
grdt:0.0024522095922
quickprop:0.0024522095922
reactive:0.00241049728816
teacher:0.00236877093585
feature:0.00234809965666
yellow:0.00233069099924
reflections:0.00231563481695
steering:0.00229521345311
epochs:0.00229521345311
grid:0.00222669606157
spatial:0.00222669606157
markov:0.00221969901899
recognize:0.00221163499788
planner:0.00220132516731
noisy:0.00218046909668
learned:0.00217119780509
near:0.0021697052693
colored:0.00213338256193
decision:0.00208575932141
undefined:0.00207376955903
hypotheses:0.00204156983914
reports:0.00201091911862
corridor:0.0019812217291
designer:0.00197867825011
tasks:0.00192951430219
hundred:0.00192839783053
100x100:0.00190528191915
hsi:0.00190528191915
invariances:0.00190528191915
doors:0.00190528191915
onboard:0.00190528191915
autonomous:0.0018226661261
predict:0.00172526290898
irregularities:0.00170490878637
observations:0.00166966055863
872:0.00166892161663
image:0.00165347914795
task:0.00162594066807
learns:0.00160942726209
decomposition:0.0016012303357
pursuit:0.0015537939995
effectiveness:0.00153512075357
decomposable:0.00153014230207
belief:0.00153012449528
reinforcement:0.00150800139626
robotic:0.00150800139626
nets:0.00141863614761
deposit:0.00141451220367
err:0.00139848231166
pulse:0.00138315381408
estimation:0.00136526883192
planning:0.00135477670982
despite:0.00134727932659
accelerating:0.00134081476101
coded:0.00133107044905
inputs:0.00132972530511
post:0.00131708703355
probabilistic:0.00131708703355
features:0.001306808681
uncertainty:0.00129174692236
pixels:0.00128097347412
action:0.00127770709612
strategies:0.00126789417757
trees:0.0012396446126
380:0.00123772090588
symbolic:0.00123645259694
office:0.00123475098221
months:0.00122791268067
concept1:0.0012261047961
lab18:0.0012261047961
hallways:0.0012261047961
00110011001101010011:0.0012261047961
00000000000000000000000000000011111111111111111111111110000000000000000000000000111111111111111111111111100000000000000000000000001111111111111111111111111000000111111000000111111000000111111:0.0012261047961
recy:0.0012261047961
cling:0.0012261047961
0000000000000000000000000000000000000000000000000000000000000000111111111111111111111111111111111111111111111111111111111111111111111111:0.0012261047961
001100000000000000000000000001111111111111111111111111000000000000000000000000000000000000000000000000001111111111111111111111111111111111111111111110000011111000000000000000000000000011111111111111111111111110000011111:0.0012261047961
preclassified:0.0012261047961
bumper:0.0012261047961
wiping:0.0012261047961
concept3:0.0012261047961
concept4:0.0012261047961
ojs:0.0012261047961
900000000000000000000000000000000011111111111111111111111111111111111111111111000000000000000000000000000000000000111111111111111111111111111111111111:0.0012261047961
boada:0.0012261047961
concept2:0.0012261047961
9501852:0.0012261047961
turret:0.0012261047961
klingspor:0.0012261047961
khaleeli20601001401800:0.0012261047961
challenging:0.00118720695006
detector:0.00112728488473
successful:0.00112283925733
testbed:0.00111292782082
trainer:0.00110841948287
subservient:0.00110841948287
grabber:0.00110841948287
percepts:0.00110841948287
openings:0.00110841948287
bleed:0.00110841948287
trainers:0.00110841948287
odometry:0.00110841948287
aligment:0.00110841948287
department:0.00110079183148
electrical:0.00109911316535
abstract:0.0010906437623
programmed:0.00107931972632
picking:0.00105447993915
acquire:0.00105447993915
train:0.00104852186342
layered:0.00104852186342
burden:0.00104265783193
occupied:0.00104265783193
dimensional:0.00104149787283
curve:0.00104011514204
hallway:0.00103952683346
thrun:0.00103952683346
obliquely:0.00103952683346
arguable:0.00103952683346
corridors:0.00103952683346
intersec:0.00103952683346
blanco:0.00103952683346
uncer:0.00103952683346
shallower:0.00103952683346
20060010000:0.00103952683346
rote:0.00103952683346
lifelong:0.00103952683346
angled:0.00103952683346
navigated:0.00103952683346
architecture:0.0010233479658
c2:0.00101464601663
32x32:0.000990610864548
percept:0.000990610864548
thru:0.000990610864548
grasping:0.000990610864548
slippage:0.000990610864548
tainty:0.000990610864548
the robot:0.0306935639831
trash can:0.0266218118429
neural net:0.025308382482
the trash:0.0232999429479
concept learning:0.0218175711052
the neural:0.0145297786697
mobile robots:0.0138709046994
s mahadevan:0.0134395650114
mahadevan g:0.0134395650114
g theocharous:0.0134395650114
theocharous n:0.0134395650114
rapid concept:0.0134395650114
feature detectors:0.0127321708814
sensory concept:0.0120956085103
n khaleeli:0.0120956085103
local occupancy:0.0120956085103
occupancy grid:0.0107516520091
recycling task:0.00940769550798
learning for:0.00892464139978
the navigation:0.00873663386807
spatial decomposition:0.00858418950713
sensory concepts:0.00806373900684
back opening:0.00806373900684
opening wall:0.00806373900684
robot learning:0.00806373900684
for mobile:0.00751901979322
the recycling:0.0073578767204
real robot:0.0073578767204
mobile robot:0.00727792221721
robot navigation:0.00709444520655
very near:0.00693545234972
high dimensional:0.00691694222885
net is:0.00689885550043
to learn:0.00678693627481
wall right:0.0067197825057
ff post:0.0067197825057
navigation system:0.0067197825057
trash cans:0.0067197825057
lab position:0.0067197825057
to lab:0.0067197825057
state estimation:0.00665164505956
multi output:0.00623821904332
the sensory:0.00613156393367
occupancy grids:0.00613156393367
learning is:0.00548282073613
east navigation:0.00537582600456
on pavlov:0.00537582600456
net feature:0.00537582600456
trained to:0.00506746086182
labeled examples:0.00476401280548
the sensor:0.00473834552597
training examples:0.00473834552597
right wall:0.00462988032051
of bias:0.00447739037889
navigation to:0.0044344300397
the net:0.00430521769358
human designer:0.00428277171105
robot to:0.00415881269555
detectors for:0.00405396868946
overall control:0.00403186950342
pavlov is:0.00403186950342
front far:0.00403186950342
called pavlov:0.00403186950342
up learning:0.00403186950342
soda cans:0.00403186950342
specular reflections:0.00403186950342
ff prior:0.00403186950342
virtual sensors:0.00403186950342
abstract observation:0.00403186950342
the specularities:0.00403186950342
opening back:0.00403186950342
for recycling:0.00403186950342
camera turn:0.00403186950342
far near:0.00403186950342
learning sensory:0.00403186950342
wall back:0.00403186950342
near very:0.00403186950342
decision trees:0.00400336323263
robot is:0.00381121024439
markov decision:0.00381121024439
net to:0.00381121024439
be trained:0.00374629157955
state distribution:0.00374629157955
behavior based:0.00374629157955
a nomad:0.0036789383602
nomad 200:0.0036789383602
a trash:0.0036789383602
predict features:0.0036789383602
engineering building:0.0036789383602
despite significant:0.0036789383602
sensor i:0.0036789383602
output net:0.0036789383602
to recognize:0.00352291259278
south east:0.00349081137683
bias is:0.00349081137683
shared representation:0.00347241024038
robots a:0.00347241024038
sensor values:0.00347241024038
neural network:0.00340394618438
decision tree:0.00340394618438
partially observable:0.00332582252978
a feedforward:0.00332582252978
navigation task:0.00332582252978
multiple concepts:0.00332582252978
robot has:0.00332582252978
concepts from:0.00327324210517
position c:0.00321207878328
floor of:0.00321207878328
bias to:0.00321207878328
a human:0.00317272382415
two general:0.00315889701731
can is:0.00311910952166
engineering department:0.00311910952166
left right:0.0030608037364
for navigation:0.00304047651709
a wall:0.00304047651709
to speed:0.00303473103766
hypothesis space:0.00297233672131
feedforward neural:0.00297233672131
figure shows:0.00284452627301
navigation and:0.00280971868467
for learning:0.00276677689154
curve for:0.00275193398538
machine learning:0.00269076105849
how pavlov:0.00268791300228
significant sensor:0.00268791300228
pavlov a:0.00268791300228
significant odometric:0.00268791300228
task pavlov:0.00268791300228
pose c2:0.00268791300228
bits indicating:0.00268791300228
can but:0.00268791300228
dimensional sensor:0.00268791300228
hundred real:0.00268791300228
odometric trace:0.00268791300228
2 south:0.00268791300228
alvinn system:0.00268791300228
navigation robot:0.00268791300228
sufficient bias:0.00268791300228
six boolean:0.00268791300228
pavlov can:0.00268791300228
abstract observations:0.00268791300228
robot testbed:0.00268791300228
turn behavior:0.00268791300228
alvinn 22:0.00268791300228
net was:0.00268791300228
colored trash:0.00268791300228
robot navigating:0.00268791300228
belief state:0.00268791300228
robot pavlov:0.00268791300228
and actuator:0.00268791300228
pomdp s:0.00268791300228
successful traces:0.00268791300228
right opening:0.00268791300228
output neural:0.00268791300228
sensor representation:0.00268791300228
trash receptacles:0.00268791300228
sensor reports:0.00268791300228
across related:0.00268791300228
accelerating sensory:0.00268791300228
reports feature:0.00268791300228
wall opening:0.00268791300228
1 pavlov:0.00268791300228
sensory state:0.00268791300228
extremely challenging:0.00268791300228
post scale:0.00268791300228
khaleeli 2:0.00268791300228
category learning:0.00268791300228
robotics is:0.00268791300228
speed sensory:0.00268791300228
as doors:0.00268791300228
hsi values:0.00268791300228
right far:0.00268791300228
several months:0.00268791300228
net correctly:0.00268791300228
learning 20:0.00268791300228
sonar pulse:0.00268791300228
robot called:0.00268791300228
trash receptacle:0.00268791300228
interesting concepts:0.00268791300228
find trash:0.00268791300228
entire floor:0.00268791300228
navigation architecture:0.00268791300228
output learning:0.00268791300228
three successful:0.00268791300228
g soda:0.00268791300228
original sensory:0.00268791300228
on 872:0.00268791300228
navigation domain:0.00268791300228
872 hand:0.00268791300228
an odometric:0.00268791300228
robot starting:0.00268791300228
door wall:0.00268791300228
cans and:0.00268791300228
almost totally:0.00268791300228
other irregularities:0.00268791300228
front left:0.00268791300228
pavlov the:0.00268791300228
figure 9:0.0026744337933
learning an:0.00265113799127
the trash can:0.022021030119
the neural net:0.0207256754062
learning for mobile:0.0155429766558
concept learning for:0.0155429766558
s mahadevan g:0.014129978778
rapid concept learning:0.014129978778
mahadevan g theocharous:0.014129978778
g theocharous n:0.014129978778
theocharous n khaleeli:0.0127169809002
for mobile robots:0.0125374705879
sensory concept learning:0.0113039830224
local occupancy grid:0.00989098514459
back opening wall:0.007064989389
the recycling task:0.007064989389
to lab position:0.007064989389
opening wall right:0.007064989389
of the trash:0.00647677356443
using a shared:0.00569885026724
east navigation to:0.0056519915112
feature detectors for:0.0056519915112
south east navigation:0.0056519915112
neural net feature:0.0056519915112
navigation to lab:0.0056519915112
wall right wall:0.0056519915112
where the robot:0.00518141885154
in the navigation:0.00490608339178
be trained to:0.00490608339178
of the robot:0.00433040289478
the robot is:0.00433040289478
opening back opening:0.0042389936334
robot has to:0.0042389936334
the navigation system:0.0042389936334
wall back opening:0.0042389936334
the overall control:0.0042389936334
running the robot:0.0042389936334
a shared representation:0.0042389936334
the feature detectors:0.0042389936334
state estimation procedure:0.0042389936334
trained to recognize:0.0042389936334
the navigation task:0.0042389936334
a local occupancy:0.0042389936334
neural net to:0.0042389936334
net is able:0.0042389936334
multi output net:0.0042389936334
right wall back:0.0042389936334
near very near:0.0042389936334
an abstract observation:0.0042389936334
mobile robot navigation:0.0042389936334
the engineering building:0.0042389936334
learning sensory concepts:0.0042389936334
neural net is:0.0042389936334
spatial decomposition and:0.0042389936334
dimensional and noisy:0.0042389936334
robot learning is:0.0042389936334
the net is:0.00415951829661
a nomad 200:0.00388606413866
a trash can:0.00388606413866
a real robot:0.00388606413866
data is often:0.00388606413866
spatial decomposition of:0.00388606413866
to the trash:0.00388606413866
high dimensional and:0.00388606413866
floor of the:0.00388606413866
of the engineering:0.00367956254384
a feedforward neural:0.00367956254384
the robot to:0.00353301156519
the robot has:0.00353301156519
very high dimensional:0.00353301156519
learning is to:0.00341931016034
a neural net:0.00341931016034
learning curve for:0.00341931016034
is to learn:0.00293197658922
detect and move:0.0028259957556
entire floor of:0.0028259957556
trained neural net:0.0028259957556
behavior based layer:0.0028259957556
by additional training:0.0028259957556
due to specularities:0.0028259957556
strategies provide sufficient:0.0028259957556
camera turn behavior:0.0028259957556
procedure is more:0.0028259957556
872 hand labeled:0.0028259957556
specularities and other:0.0028259957556
shows the learning:0.0028259957556
in state estimation:0.0028259957556
the robot as:0.0028259957556
decision process models:0.0028259957556
when the trash:0.0028259957556
of several months:0.0028259957556
concepts from high:0.0028259957556
six boolean variables:0.0028259957556
investigate two general:0.0028259957556
and other irregularities:0.0028259957556
sensor i reports:0.0028259957556
up learning based:0.0028259957556
in the recycling:0.0028259957556
several hundred real:0.0028259957556
the robot navigating:0.0028259957556
concept learning from:0.0028259957556
i reports feature:0.0028259957556
state distribution is:0.0028259957556
neural net correctly:0.0028259957556
of sensory concept:0.0028259957556
lab position c:0.0028259957556
the alvinn system:0.0028259957556
sample images with:0.0028259957556
color coded to:0.0028259957556
speed up learning:0.0028259957556
pavlov can be:0.0028259957556
study how pavlov:0.0028259957556
requires the robot:0.0028259957556
concepts and behaviors:0.0028259957556
the navigation domain:0.0028259957556
odometric trace of:0.0028259957556
net to learn:0.0028259957556
to specularities and:0.0028259957556
labeled examples of:0.0028259957556
trash can is:0.0028259957556
simultaneously using a:0.0028259957556
real robot testbed:0.0028259957556
pavlov is required:0.0028259957556
to robot learning:0.0028259957556
n khaleeli 2:0.0028259957556
as doors and:0.0028259957556
robot navigation architecture:0.0028259957556
shows an odometric:0.0028259957556
hundred real valued:0.0028259957556
robot as it:0.0028259957556
with a reactive:0.0028259957556
in robotics is:0.0028259957556
learning feature detectors:0.0028259957556
task pavlov is:0.0028259957556
feedforward neural net:0.0028259957556
ff post after:0.0028259957556
curve for training:0.0028259957556
how pavlov can:0.0028259957556
learning in robotics:0.0028259957556
to learn multiple:0.0028259957556
extremely challenging problem:0.0028259957556
sufficient bias to:0.0028259957556
despite significant odometric:0.0028259957556
of a feedforward:0.0028259957556
sensor and actuator:0.0028259957556
e g soda:0.0028259957556
trained on 872:0.0028259957556
3 bits indicating:0.0028259957556
such as doors:0.0028259957556
sensory concepts from:0.0028259957556
from high dimensional:0.0028259957556
trash can from:0.0028259957556
net feature detectors:0.0028259957556
an odometric trace:0.0028259957556
shows the neural:0.0028259957556
the specularities are:0.0028259957556
reports feature f:0.0028259957556
front back left:0.0028259957556
from limited training:0.0028259957556
detectors for navigation:0.0028259957556
2 south east:0.0028259957556
examples the neural:0.0028259957556
on 872 hand:0.0028259957556
data collection requires:0.0028259957556
door wall opening:0.0028259957556
sensory data is:0.0028259957556
a shared structure:0.0028259957556
accelerating sensory concept:0.0028259957556
of the specularities:0.0028259957556
positions a and:0.0028259957556
far near very:0.0028259957556
back left right:0.0028259957556
trash can but:0.0028259957556
behavior based architecture:0.0028259957556
concepts simultaneously using:0.0028259957556
ff post scale:0.0028259957556
right opening back:0.0028259957556
robot called pavlov:0.0028259957556
high dimensional sensor:0.0028259957556
provide sufficient bias:0.0028259957556
soda cans and:0.0028259957556
three successful traces:0.0028259957556
decomposition and multi:0.0028259957556
could be trained:0.0028259957556
an extremely challenging:0.0028259957556
by learning how:0.0028259957556
on spatial decomposition:0.0028259957556
for the navigation:0.0028259957556
the original sensory:0.0028259957556
net was trained:0.0028259957556
directly observable from:0.0028259957556
robot navigation using:0.0028259957556
learning s mahadevan:0.0028259957556
the state distribution:0.0028259957556
robotics is an:0.0028259957556
for the recycling:0.0028259957556
net correctly predicts:0.0028259957556
robot navigating to:0.0028259957556
the robot starting:0.0028259957556
net is trained:0.0028259957556
g soda cans:0.0028259957556
net feature detector:0.0028259957556
