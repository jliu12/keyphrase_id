tn:0.0339397294748
policy:0.0100390343865
mdps:0.00957813770258
bellman:0.0082458746007
mdp:0.00687775396567
dened:0.00563383522358
bk:0.00556373017694
kt:0.00556373017694
rust:0.00517715090339
lipschitz:0.00492307303028
planning:0.00476793811524
actions:0.00463744164162
discounted:0.00447677176102
kk:0.00435149020693
poly:0.00427230952623
samples:0.00423555110553
kv:0.00414052657994
curse:0.00397409298353
action:0.00374615304365
transition:0.00371594147003
pollard:0.00361049110662
measurable:0.00353645575993
rewards:0.00343887698283
markov:0.00317862541016
contraction:0.00310820729066
stochastic:0.00291974867756
policies:0.00290306862712
lip:0.00287344131077
log:0.00285928057775
jaj:0.00282831078957
dimensionality:0.00257372610245
probability:0.00256560965233
xed:0.00252802296729
kuffner:0.00233564281912
jared:0.00233564281912
denition:0.0022689930403
proposition:0.0022418530261
stationary:0.00224010182704
sampling:0.00221740883558
reward:0.00217694045326
markovian:0.00212123309218
polynomially:0.00211691482489
thuc:0.00207086036136
pomdps:0.00207086036136
limes:0.00207086036136
multigrid:0.0020232712473
uniformly:0.0020088000799
probabilities:0.00198747498927
logarithmic:0.00196583533998
selects:0.00194537627808
horizon:0.0019389804228
animations:0.00191562754052
inequality:0.00190618705183
nite:0.00189292488167
operators:0.00182679201068
myopic:0.00180524555331
maximal:0.0017563444699
triangle:0.00173394577626
kearns:0.00171943849142
vu:0.00171943849142
lhs:0.00171943849142
law:0.00164102434343
rst:0.00159530692198
discount:0.00158963719341
firstly:0.00150349631699
logarithmically:0.00149225725367
whilst:0.00149225725367
immediate:0.00148743873185
innite:0.00146512720342
rhs:0.00145129363551
sup:0.00143418702447
mappings:0.00141141683615
norm:0.00139572084063
nish:0.00138017552665
cf:0.00137749331963
processes:0.0013475786633
banach:0.00131977757152
sucient:0.0012672240022
denitions:0.00125783160535
supremum:0.00124328291626
vehicle:0.00119921203004
pseudo:0.00119198452881
drawing:0.00117881858664
kx:0.00117881858664
eurographics:0.00116782140956
thenn:0.00116782140956
yuskevich:0.00116782140956
siggraph:0.00116782140956
polynomialy:0.00116782140956
majorize:0.00116782140956
jajn:0.00116782140956
szepes:0.00116782140956
telescopicing:0.00116782140956
measurability:0.00116782140956
negativ:0.00116782140956
jgrid:0.00116782140956
downscale:0.00116782140956
mindmaker:0.00116782140956
draw:0.00116722576685
observable:0.00115937640431
cover:0.00115666077478
elementary:0.00115515030151
proving:0.00115336218273
reals:0.00114079675307
monte:0.00112300274073
integrals:0.00112300274073
carlo:0.00110592729628
behaviors:0.00110592729628
normalizing:0.0010895115652
phase:0.00107357587918
decision:0.00106938791083
random:0.00106187817004
storage:0.00104965510349
characterizing:0.00104373192076
dynkin:0.00103543018068
ications:0.00103543018068
nishing:0.00103543018068
followings:0.00103543018068
sharpening:0.00103543018068
acrobot:0.00103543018068
grenoble:0.00103543018068
auxilliary:0.00103543018068
pick:0.00103363424074
powers:0.00102949044098
readers:0.00102949044098
james:0.001002330878
entropy:0.000989356171321
calculations:0.000984063174643
autonomous:0.00097675146895
elegant:0.00097675146895
statement:0.00097574692772
inequal:0.000957813770258
originates:0.000957813770258
dynam:0.000957813770258
sample:0.000932045263992
understood:0.00092827724439
eective:0.000907772480166
cache:0.000907772480166
bracketing:0.000902622776655
victoria:0.000902622776655
sketches:0.000902622776655
sta:0.000902622776655
dynamic:0.000897963378317
operator:0.000885084120109
prac:0.000859719245708
krk:0.000859719245708
yk:0.000859719245708
telescoping:0.000859719245708
homepage:0.000859719245708
precompute:0.000859719245708
worrying:0.000859719245708
dependence:0.000859145504632
modied:0.00085730837723
greedy:0.000847838435654
polynomial:0.000846681724103
outer:0.000829448179178
nally:0.000829448179178
proven:0.000826495991776
tice:0.00082458746007
cherno:0.00082458746007
basics:0.00082458746007
animation:0.00082458746007
bounds:0.000821635774329
deterministic:0.00081059644932
inequalities:0.000806250536218
selecting:0.00078724132762
covering:0.000786334135993
superior:0.00077815051123
regularity:0.00077815051123
phases:0.000770100201005
article:0.000770100201005
pseudocode:0.000768974801287
speeding:0.000768974801287
worry:0.000768974801287
tsitsiklis:0.000768974801287
interactive:0.000754379843437
spaces:0.000749535256454
chow:0.000746128626837
lets:0.000746128626837
corollary:0.000744638263001
appropriately:0.00073168283246
economic:0.000725646817753
ics:0.000725646817753
whichever:0.000725646817753
negatively:0.000707077697392
ities:0.000707077697392
nished:0.000707077697392
factorized:0.000707077697392
xj:0.000707077697392
kf:0.000707077697392
shall:0.000706642121663
cite:0.000690087763324
dp:0.000690087763324
akin:0.000690087763324
clean:0.000690087763324
holder:0.000690087763324
suppressed:0.000690087763324
optimal actions:0.00934435047495
policy dened:0.00910177197515
v x:0.00783742804408
lemma 5:0.0077661254594
state space:0.00671490779849
let log:0.00654372243107
bellman operator:0.00650126569654
x tn:0.00650126569654
kv v:0.00650126569654
high probability:0.00644654371381
poly logarithmic:0.00584021904685
stationary policy:0.00584021904685
x 1:0.00579579516708
random bellman:0.00520101255723
v tn:0.00520101255723
good actions:0.00520101255723
bk x:0.00520101255723
maximal inequalities:0.00520101255723
line phase:0.00520101255723
immediate rewards:0.00520101255723
dynamic programming:0.00515034693425
decision processes:0.00496462408105
v k:0.00463838878343
d log:0.00440078031607
k r:0.00439361227614
l p:0.0042731231445
state x:0.00420761817539
transition probabilities:0.00420761817539
action space:0.00414250947166
log log:0.00414131510148
lipschitz constant:0.00404646118815
proposition 5:0.00400291639237
markov decision:0.00397169926484
us pick:0.00390075941792
uniformly optimal:0.00390075941792
line planning:0.00390075941792
markovian decision:0.00390075941792
v a2a:0.00390075941792
maximal inequality:0.00390075941792
cf 9:0.00390075941792
r d:0.00356735021772
theorem 5:0.0035206843655
random action:0.00350413142811
planning algorithm:0.00350413142811
norm kk:0.00350413142811
continuous state:0.00350413142811
horizon time:0.00350413142811
k p:0.00341116664407
log d:0.00336609454031
denition 5:0.0031264863021
optimal policies:0.00310688210375
triangle inequality:0.00307648497914
function v:0.00302946418287
log let:0.00297877444863
polynomial complexity:0.00297877444863
optimal policy:0.00287398852869
transition probability:0.00287398852869
xed point:0.00278529650916
main result:0.00269220246801
stochastic policy:0.00260050627861
space polynomial:0.00260050627861
samples depends:0.00260050627861
policy x:0.00260050627861
kk p:0.00260050627861
autonomous behaviors:0.00260050627861
stochastic stationary:0.00260050627861
go thuc:0.00260050627861
p jaj:0.00260050627861
eective horizon:0.00260050627861
probabilities characterizing:0.00260050627861
uniformly approximately:0.00260050627861
jared go:0.00260050627861
operators tn:0.00260050627861
uniformly good:0.00260050627861
optimal planning:0.00260050627861
inner probability:0.00260050627861
sparse sampling:0.00260050627861
metric entropy:0.00260050627861
bellman error:0.00260050627861
n 8e:0.00260050627861
depend polynomially:0.00260050627861
bellman operators:0.00260050627861
n a2a:0.00260050627861
poly logarithmically:0.00260050627861
nite action:0.00260050627861
vehicle animations:0.00260050627861
could call:0.00260050627861
greedy w:0.00260050627861
cache c:0.00260050627861
p lipschitz:0.00260050627861
interactive vehicle:0.00260050627861
rust 12:0.00260050627861
approximate planning:0.00260050627861
kuffner autonomous:0.00260050627861
elementary event:0.00260050627861
tn tn:0.00260050627861
j kuffner:0.00260050627861
scale exponentially:0.00260050627861
space discounted:0.00260050627861
vu james:0.00260050627861
considered algorithms:0.00260050627861
e tn:0.00260050627861
depend poly:0.00260050627861
k log:0.00247423348331
o line:0.00247423348331
log 1:0.00242787671289
random sample:0.00238490988568
n v:0.00234486472657
f x:0.00234201150807
lip p:0.00233608761874
partially observable:0.00233608761874
outer inner:0.00233608761874
limes superior:0.00233608761874
kk 1:0.00233608761874
action spaces:0.00233608761874
importance sampling:0.00233608761874
programming deterministic:0.00233608761874
compute v:0.00233608761874
measurable functions:0.00233608761874
reward function:0.00233608761874
given xed:0.00233608761874
kearns et:0.00233608761874
selecting good:0.00233608761874
tn a v:0.0372006278672
x 1 n:0.0178133109126
kv v k:0.00688900516059
f x 1:0.006565801234
x a 0:0.00622817710059
tn a e:0.00551120412847
v x tn:0.00551120412847
proposition 5 8:0.00551120412847
log d log:0.00551120412847
actions with high:0.00551120412847
curse of dimensionality:0.00517912315136
number of samples:0.0050316225988
markov decision processes:0.00428276208836
dened by a2a:0.00413340309636
v a2a tn:0.00413340309636
z n v:0.00413340309636
line planning algorithm:0.00413340309636
d log log:0.00413340309636
theorem 5 13:0.00413340309636
o line phase:0.00413340309636
planning in large:0.00413340309636
markov s inequality:0.00373690626035
let log 1:0.00373690626035
theorem 5 18:0.00373690626035
cover of f:0.00373690626035
corollary 5 3:0.00350479888171
let and let:0.00310747389081
interactive vehicle animations:0.00275560206424
distributed over x:0.00275560206424
eective horizon time:0.00275560206424
uniformly optimal policies:0.00275560206424
yields a uniformly:0.00275560206424
approximately optimal policy:0.00275560206424
let us pick:0.00275560206424
variables then sup:0.00275560206424
polynomial complexity theorem:0.00275560206424
need some denitions:0.00275560206424
let the stochastic:0.00275560206424
random bellman operators:0.00275560206424
denitions and results:0.00275560206424
selecting good actions:0.00275560206424
pollard s maximal:0.00275560206424
let the stationary:0.00275560206424
optimal and given:0.00275560206424
r k p:0.00275560206424
models the complexity:0.00275560206424
jaj and 1:0.00275560206424
markovian decision problems:0.00275560206424
dened by tn:0.00275560206424
dened by dened:0.00275560206424
n v x:0.00275560206424
greedy w r:0.00275560206424
set of mappings:0.00275560206424
prove an inequality:0.00275560206424
let log d:0.00275560206424
vu james j:0.00275560206424
functions let x:0.00275560206424
x a random:0.00275560206424
sup n 8e:0.00275560206424
set of measurable:0.00275560206424
let k log:0.00275560206424
v x g:0.00275560206424
transition probabilities characterizing:0.00275560206424
stationary policy dened:0.00275560206424
stochastic stationary policy:0.00275560206424
algorithm for near:0.00275560206424
norm of vectors:0.00275560206424
james j kuffner:0.00275560206424
planning in continuous:0.00275560206424
phase one computes:0.00275560206424
outer inner probability:0.00275560206424
continuous state space:0.00275560206424
near optimal planning:0.00275560206424
jared go thuc:0.00275560206424
random bellman operator:0.00275560206424
log l p:0.00275560206424
integer t 0:0.00275560206424
uniformly approximately optimal:0.00275560206424
j kuffner autonomous:0.00275560206424
selects only optimal:0.00275560206424
depend poly logarithmically:0.00275560206424
