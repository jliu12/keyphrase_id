acoustic:0.0175510404646
scores:0.0170683336359
speaker:0.0145051768058
classifiers:0.0102444234883
recognition:0.00972315678561
classifier:0.00874772993907
identification:0.00865222569202
face:0.00765245833581
score:0.00726281423617
speech:0.00718563530709
voice:0.00586623461289
eyes:0.00577727382491
interocular:0.0056645030669
eye:0.00562969170591
codebook:0.00558037897273
training:0.00525477125055
rejection:0.00508866387111
hyperbf:0.00503511383725
codebooks:0.00503511383725
mouth:0.00486462270189
person:0.00483555846059
rank:0.0042088520847
nose:0.00414433623023
integration:0.00406145269585
stranger:0.00377633537794
correlation:0.00371859045792
cues:0.0037067176837
utterance:0.00361344950741
eqn:0.00355524543071
visual:0.00322001577614
normalization:0.00321205887394
ranks:0.0030152640783
reject:0.00301072450204
database:0.00300885617445
biometric:0.00291877362114
interactions:0.00290528104564
image:0.00290175606419
normalized:0.00283244085154
utterances:0.00279018948636
signal:0.00257353631619
images:0.00252412752282
misrecog:0.00251755691862
strangers:0.00251755691862
tanh:0.00243231135095
rejected:0.00243089666194
speakers:0.00231669855231
subsystems:0.00230253151686
adaptation:0.00223612274577
familiar:0.00223512664805
estimators:0.00222360628627
integrated:0.00219728704679
measurement:0.00210080371425
session:0.00200404002568
regions:0.00198714428963
lip:0.00194584908076
deviation:0.00193236281491
features:0.00192980113515
confidence:0.00188859096225
utter:0.00188816768897
irst:0.00188816768897
cepstrum:0.00188816768897
templates:0.00181570355904
digitized:0.00177762271536
multimodal:0.00171344782756
people:0.0017130980661
candidates:0.00167751523242
sessions:0.00167514671016
quantization:0.00167514671016
recordings:0.00167411369182
mel:0.00167411369182
interacted:0.00167411369182
digit:0.00165773449209
oe:0.00164796528509
accepted:0.00163855703536
variations:0.00162253348764
static:0.00161208670233
outputs:0.0015863281803
persons:0.0015643292301
im:0.00155942288618
vectors:0.00148889965324
rejecting:0.00148767200943
illumination:0.00148767200943
ff:0.00146187667851
dispersion:0.00145938681057
vq:0.00145938681057
matching:0.00140310019479
accept:0.0013942332552
164:0.00139333335803
couples:0.00139001913139
interacting:0.00138709178964
verification:0.00138684962181
similarity:0.00137571527744
acquisition:0.00135049814552
frontal:0.00133321703652
anil:0.00133321703652
entries:0.00128617517856
letters:0.00127443324973
axis:0.00127443324973
vision:0.00127136794733
semispace:0.00125877845931
grabber:0.00125877845931
favouring:0.00125877845931
hampel:0.00125877845931
brunelli:0.00125877845931
intraspeaker:0.00125877845931
misrecognized:0.00125877845931
troids:0.00125877845931
hernndez:0.00125877845931
mfccs:0.00125877845931
kwat:0.00125877845931
1915:0.00125877845931
spectrum:0.00123763329682
reported:0.00122659697103
facial:0.00120636250841
fusion:0.00119206365522
filter:0.00117112828716
geometric:0.00116497418897
acceptance:0.00115733020229
robust:0.00115719251256
mapping:0.00115574204164
threshold:0.00114520680491
reliable:0.00114494982876
rankings:0.00114322382762
spectra:0.00114322382762
jain:0.00114322382762
mad:0.00111607579455
eqns:0.00111607579455
biometrics:0.00111607579455
pupils:0.00111607579455
1905:0.00111607579455
recognizer:0.00111607579455
dat:0.00111607579455
abidi:0.00111607579455
digits:0.00111575400707
intensity:0.00110967343172
hamming:0.00109042797238
geometrical:0.00106692742005
frame:0.00105969142432
symmetry:0.00105947328944
pixels:0.00105282682708
distance:0.00104185325783
waveforms:0.00103241414498
phonetic:0.00103241414498
negatives:0.00103241414498
scribed:0.00103241414498
independence:0.00102692662915
bank:0.00102444234883
scale:0.00102216414252
distances:0.00102017870482
interaction:0.00101935241535
authentication:0.0010050880261
text:0.000990931500729
psi:0.000986799221509
gaussian:0.000985838439221
finger:0.000972924540379
transitional:0.000972924540379
recog:0.000972924540379
unimodal:0.000972924540379
bivariate:0.000972924540379
cen:0.000972924540379
samples:0.000966181407457
thereby:0.000962582231257
audio:0.000952974122686
ij:0.00094706346357
sounds:0.000926679420926
noise:0.000919322457275
lying:0.000907851779522
plane:0.000901407493136
evaluated:0.000894265666008
ross:0.000888811357678
estimate:0.000875823325434
hybrid:0.000875334880936
fs:0.000867997651717
spectral:0.000867997651717
match:0.000861469747059
adapted:0.000856879073529
sigmoidal:0.000856723913781
acquired:0.000855672395613
energy:0.000847578631551
reference:0.000847438853549
distributions:0.000844108899223
weighted:0.000840300557762
normalize:0.000832255073786
median:0.000832255073786
ro:0.000828867246046
luis:0.000828867246046
arun:0.000828867246046
perceptron:0.000828867246046
lighting:0.000828867246046
fig:0.000823341685505
stochastic:0.000821541303319
security:0.000821541303319
delta:0.000815917727088
location:0.000815561193331
separation:0.000813135543917
channel:0.000813135543917
users:0.000805195897803
centroids:0.000804241672272
gang:0.000804241672272
template:0.000799809945373
the acoustic:0.0112112138498
face recognition:0.0107016588874
acoustic and:0.00980981211854
the scores:0.00722764069166
the speaker:0.00705276816205
speaker recognition:0.0070070086561
measurement level:0.0070070086561
identification system:0.00629453822147
recognition systems:0.00587730680171
of scores:0.00560560692488
acoustic features:0.00560560692488
linear classifier:0.00560560692488
the interocular:0.00560560692488
and mouth:0.00528957612154
and visual:0.00521743579303
nose and:0.00502285650455
integrated score:0.00490490605927
normalized scores:0.00490490605927
hyperbf network:0.00490490605927
the identification:0.00469346931877
the integrated:0.00463387261747
eyes nose:0.00440617675503
and face:0.00440617675503
geometric average:0.00440617675503
the database:0.00433737216725
the eye:0.00428066355494
scores are:0.00428066355494
multiple classifier:0.00420420519366
reference database:0.00420420519366
an hyperbf:0.00420420519366
speaker and:0.00420420519366
interocular distance:0.00420420519366
best candidates:0.00420420519366
the integration:0.00394760197603
the speech:0.0039066661702
total error:0.00377672293288
correlation values:0.00377672293288
familiar rejected:0.00350350432805
person identification:0.00350350432805
the training:0.00341515828179
recognition system:0.00334857100303
the eyes:0.00321049766621
accept reject:0.00314726911073
multiple classifiers:0.00314726911073
the score:0.00311115900883
the system:0.00301730878574
reported in:0.00300357074937
recognition letters:0.00294848771054
the classifiers:0.00293865340086
integration of:0.00287289620618
stranger accepted:0.00280280346244
speech signal:0.00280280346244
rank measurement:0.00280280346244
real interactions:0.00280280346244
background noise:0.00280280346244
familiar misrecog:0.00280280346244
adaptation vectors:0.00280280346244
weighted geometric:0.00280280346244
user face:0.00280280346244
multiple cues:0.00280280346244
0 familiar:0.00280280346244
reject rule:0.00280280346244
the rejection:0.00279047583586
best candidate:0.00279047583586
for face:0.00279047583586
system performance:0.0027591127885
pattern recognition:0.00274518695312
the adaptation:0.00272096096539
features used:0.00267541472184
the face:0.00263506540351
the image:0.00263233718951
is reported:0.00260369319898
the classifier:0.00258130024702
interval 0:0.00257043551102
classifiers and:0.00251781528859
single feature:0.00251781528859
of classifiers:0.00251781528859
scores is:0.00251781528859
and voice:0.00251781528859
scores and:0.00251781528859
database entries:0.00251781528859
the normalized:0.00251668031326
face and:0.00250164066256
vector quantization:0.00250164066256
training and:0.00248685693126
letters v:0.00246374129906
the rank:0.00246374129906
input signal:0.00235092272068
reported experiments:0.00235092272068
visual features:0.00235092272068
an identification:0.00235092272068
of eqn:0.00235092272068
rank correlation:0.00235092272068
right eye:0.00235092272068
normalization of:0.00231693630873
the user:0.00230124404107
a person:0.00223173702769
outputs of:0.00223173702769
standard deviation:0.00220528242378
then be:0.00215295123546
the confidence:0.00211177825634
average and:0.00210606265039
text independent:0.00210210259683
hybrid rank:0.00210210259683
second final:0.00210210259683
acquisition channel:0.00210210259683
test sessions:0.00210210259683
normalized ratio:0.00210210259683
dynamic codebooks:0.00210210259683
speakers in:0.00210210259683
corresponding ranks:0.00210210259683
level integration:0.00210210259683
identification systems:0.00210210259683
digitized image:0.00210210259683
score list:0.00210210259683
score distributions:0.00210210259683
utterances of:0.00210210259683
utterance length:0.00210210259683
corresponding regions:0.00210210259683
stochastic minimization:0.00210210259683
matching scores:0.00210210259683
verification system:0.00210210259683
speaker verification:0.00210210259683
first ten:0.00210210259683
final best:0.00210210259683
rank information:0.00210210259683
acoustic analysis:0.00210210259683
the utterance:0.00210210259683
5 familiar:0.00210210259683
integration module:0.00210210259683
hamming window:0.00210210259683
eye templates:0.00210210259683
energy outputs:0.00210210259683
the reference:0.00207069223294
negative examples:0.00206504019762
static or:0.00206504019762
was used:0.00203390750964
features and:0.00195561221615
to reject:0.00194604877791
of interactions:0.00194604877791
and standard:0.00193000826955
the static:0.00192242980226
the location:0.00190340576646
training vectors:0.00188836146644
psi i:0.00188836146644
person recognition:0.00188836146644
classifier can:0.00188836146644
different classifiers:0.00188836146644
error measure:0.00188836146644
classifiers can:0.00188836146644
non acceptable:0.00188836146644
score and:0.00188836146644
symmetry axis:0.00188836146644
leave one:0.00188836146644
for speaker:0.00188836146644
system is:0.00187937968411
the measurement:0.00185978085641
higher the:0.00185978085641
the correlation:0.00185978085641
the reported:0.00185354904699
the correct:0.00184835123038
system based:0.00183826314122
the available:0.00181951341305
static and:0.00181756646669
processing v:0.00181397397693
the classification:0.00179762879518
power spectrum:0.00176319204051
correlation value:0.00176319204051
the digit:0.00176319204051
integrated system:0.00176319204051
identification is:0.00176319204051
on vector:0.00176319204051
the higher:0.00175371498296
the different:0.00175010451137
of multiple:0.00173286443643
and scale:0.00171362367401
scale and:0.00171362367401
the recognition:0.00171362367401
the features:0.00169121349857
of people:0.00168485012031
features the:0.00168485012031
each person:0.00167428550152
second best:0.00167428550152
points lying:0.00167428550152
the mapping:0.00165344338856
database the:0.00163019656695
and dynamic:0.0016159332876
a reliable:0.00160864841878
or dynamic:0.0016052488331
ranks of:0.0016052488331
different features:0.0016052488331
the rankings:0.0016052488331
learning task:0.0016052488331
by means:0.00159944233623
can then:0.00159357296175
a vector:0.00159064233883
of features:0.00158599998544
the symmetry:0.00158599998544
threshold is:0.00156448977292
rejection of:0.00154878014821
acoustic and visual:0.00816668475878
nose and mouth:0.00604087792267
of the scores:0.00519698121014
the reference database:0.00445455532297
an hyperbf network:0.00445455532297
the acoustic and:0.00445455532297
and face recognition:0.00445455532297
face recognition systems:0.00445455532297
eyes nose and:0.00402725194845
the measurement level:0.00371212943581
the speaker and:0.00371212943581
to the integration:0.00371212943581
the interocular distance:0.00371212943581
speaker and face:0.00371212943581
the integrated score:0.00371212943581
the eyes nose:0.00335604329037
the total error:0.00335604329037
pattern recognition letters:0.00324404375954
recognition letters v:0.00324404375954
in the reference:0.0031708592281
the best candidate:0.00314759213948
of the eye:0.00314759213948
the integration of:0.00312930069739
is reported in:0.00303254701355
normalization of the:0.00299958567341
and visual features:0.00296970354865
weighted geometric average:0.00296970354865
rank measurement level:0.00296970354865
of the identification:0.00296970354865
location and scale:0.00296970354865
the adaptation vectors:0.00296970354865
the user face:0.00296970354865
using an hyperbf:0.00296970354865
the linear classifier:0.00296970354865
of the interocular:0.00296970354865
a linear classifier:0.00296970354865
the reported experiments:0.00296970354865
accept reject rule:0.00296970354865
the normalized scores:0.00296970354865
interval 0 1:0.00291937277409
of the user:0.00276302481874
the database entries:0.0026848346323
the correlation values:0.0026848346323
of the correlation:0.0026848346323
into the interval:0.0026848346323
of the mapping:0.00264238269008
the interval 0:0.00252712251129
of the classifiers:0.00251807371159
can then be:0.00248631258303
in the database:0.00240651906065
of the integrated:0.00239966853873
reported in figure:0.00230775951595
the static and:0.00223260979531
and standard deviation:0.00223260979531
level the output:0.00222727766149
measurement level is:0.00222727766149
in the reported:0.00222727766149
features used in:0.00222727766149
reported experiments the:0.00222727766149
speakers in the:0.00222727766149
the eye templates:0.00222727766149
the different features:0.00222727766149
the corresponding regions:0.00222727766149
hybrid rank measurement:0.00222727766149
list of scores:0.00222727766149
the different classifiers:0.00222727766149
acoustic features and:0.00222727766149
and second final:0.00222727766149
the energy outputs:0.00222727766149
identification system based:0.00222727766149
the identification system:0.00222727766149
the first ten:0.00222727766149
of the rankings:0.00222727766149
y t n:0.00222727766149
on vector quantization:0.00222727766149
face and voice:0.00222727766149
of multiple cues:0.00222727766149
based on vector:0.00222727766149
the speech signal:0.00222727766149
the score distributions:0.00222727766149
normalized ratio of:0.00222727766149
utterances of the:0.00222727766149
second final best:0.00222727766149
final best candidates:0.00222727766149
of people in:0.00222727766149
the acoustic features:0.00222727766149
and rank information:0.00222727766149
at the measurement:0.00222727766149
set of classifiers:0.00222727766149
a weighted geometric:0.00222727766149
static and dynamic:0.00219436254622
the higher the:0.0021422494457
system based on:0.00209481125719
training and test:0.00206525214878
mapping from the:0.00206525214878
reported in table:0.00206525214878
of the first:0.00202066794524
the scores are:0.00201362597422
of the speaker:0.00201362597422
a learning task:0.00201362597422
from the score:0.00201362597422
average and standard:0.00201362597422
the features used:0.00201362597422
leave one out:0.00201362597422
of multiple classifiers:0.00201362597422
of the best:0.00192193500496
by means of:0.0019163088829
the power spectrum:0.00188855528369
people in the:0.00188855528369
for face recognition:0.00188855528369
static or dynamic:0.00188855528369
is applied to:0.00181607627865
for the integration:0.00179975140405
n 16 p:0.00179975140405
using a weighted:0.00179975140405
output is a:0.00179975140405
match with the:0.00179975140405
ranks of the:0.00179975140405
number of people:0.00179975140405
applied to the:0.00177526869082
of the available:0.00175549003697
are reported in:0.00175549003697
the database the:0.00175549003697
given by the:0.00174688758636
derived from the:0.00173635166088
performance is evaluated:0.00173081963696
spectrum of the:0.00173081963696
of the face:0.00173081963696
the l 1:0.00173081963696
the system is:0.00170366775853
the equation above:0.00167445734648
the vectors of:0.00167445734648
of the known:0.00167445734648
a set of:0.00164859936411
set of examples:0.00162676908408
independence of the:0.00158542961405
in table iii:0.00158542961405
the confidence of:0.00158542961405
confidence of the:0.00158542961405
in the equation:0.00158542961405
of the image:0.0015646503487
use of multiple:0.00154893911159
of the database:0.00152461133807
follows 1 the:0.00151627350677
value of the:0.00148877132966
of the features:0.00148670237216
signal processing v:0.00148670237216
recognition systems the:0.00148485177432
user face is:0.00148485177432
for a reliable:0.00148485177432
recognition sub system:0.00148485177432
correlation values the:0.00148485177432
visual ones provide:0.00148485177432
recognition system based:0.00148485177432
are combined using:0.00148485177432
the speaker recognition:0.00148485177432
the rank correlation:0.00148485177432
to adapt session:0.00148485177432
integration of multiple:0.00148485177432
0 familiar misrecog:0.00148485177432
a leave one:0.00148485177432
and mouth regions:0.00148485177432
the eye to:0.00148485177432
defined in eqn:0.00148485177432
is approximated using:0.00148485177432
translated scaled and:0.00148485177432
of acceptable and:0.00148485177432
robust statistical techniques:0.00148485177432
corresponding features of:0.00148485177432
speaker recognition system:0.00148485177432
the same coordinates:0.00148485177432
classifiers and their:0.00148485177432
functions classifiers pattern:0.00148485177432
plane contribute with:0.00148485177432
of the acoustic:0.00148485177432
2005 r brunelli:0.00148485177432
rejecting a user:0.00148485177432
template matching process:0.00148485177432
the nose and:0.00148485177432
then be quantified:0.00148485177432
accepted or rejected:0.00148485177432
based on acoustic:0.00148485177432
integrated score the:0.00148485177432
1905 1915 december:0.00148485177432
s2 represent the:0.00148485177432
turn for testing:0.00148485177432
user as unknown:0.00148485177432
brunelli verification through:0.00148485177432
best integrated score:0.00148485177432
total error is:0.00148485177432
two best scores:0.00148485177432
rank information derived:0.00148485177432
a person identification:0.00148485177432
person identification using:0.00148485177432
lists of scores:0.00148485177432
an important capability:0.00148485177432
strangers misrecognized and:0.00148485177432
the pixel level:0.00148485177432
hyperbf network a:0.00148485177432
the normalized ratio:0.00148485177432
