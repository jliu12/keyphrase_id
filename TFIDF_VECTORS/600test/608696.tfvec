seller:0.0568735158722
sellers:0.0362106328851
myopic:0.031950558428
price:0.030848327058
profit:0.018704114065
pricing:0.0152951152411
shopbot:0.014716692552
kephart:0.014716692552
agent:0.0144491394736
prices:0.0139856773829
learning:0.0129644533926
agents:0.0123088607133
opponent:0.00994017373317
players:0.00968239203431
wars:0.00921057892831
policies:0.00912796836944
fl:0.00902594479118
discount:0.0089221505573
war:0.0089221505573
reward:0.00798040637813
economies:0.00781013650463
tesauro:0.00779119017459
player:0.00719021568467
profits:0.00710012409512
simultaneous:0.00674807154394
policy:0.0064471310243
sairamesh:0.00605981458024
myoptimal:0.00605981458024
consumers:0.00570029027009
lookahead:0.00537283770818
convergence:0.00519529115799
undercutting:0.00519412678306
economy:0.00509837174703
rewards:0.00489003058889
diamonds:0.00460528946416
nash:0.00460528946416
learner:0.00460396166504
economic:0.00449945826006
vs:0.00440647170737
myopically:0.00432843898588
crites:0.00432843898588
games:0.0042971382325
game:0.00413465844395
dynamics:0.00387462260971
consumer:0.00358085907281
buyers:0.00355006204756
foresight:0.00346275118871
stationary:0.00340458333875
quality:0.00319586669917
alternately:0.00314487401556
payoffs:0.0030701929761
reinforcement:0.00305626911806
instantaneous:0.00291362545942
asymmetric:0.00286932329713
equilibrium:0.00271456835952
buyer:0.00267640074693
lookup:0.00267100822669
undercut:0.00259706339153
unending:0.00259706339153
greenwald:0.00259706339153
rl:0.00254918587351
anticipate:0.00254918587351
dashed:0.0025420373167
amplitude:0.00244582632519
plot:0.00235626544166
filtering:0.00235626544166
approximators:0.00230264473208
trajectory:0.0022621402996
action:0.00224545950756
profitability:0.00213003722854
opponents:0.00213003722854
hanson:0.00213003722854
sandholm:0.00213003722854
converged:0.00209658267704
differentiation:0.00204620518446
markov:0.0020401403088
landscape:0.0020073005602
asymmetries:0.0020073005602
competing:0.00198979936862
cyclic:0.00192802044113
curve:0.00192635447615
discounting:0.00191188940513
infinitely:0.00185753061794
1998:0.00174473124525
competition:0.00171008708103
regime:0.00171008708103
minimax:0.00171008708103
baseline:0.00169130968161
curves:0.00168556016663
monotonically:0.00166492883396
symmetric:0.00162492028533
products:0.00156315598348
barto:0.00153509648805
priced:0.00153509648805
littman:0.00153509648805
prisoner:0.00153509648805
pfig:0.00153509648805
abandon:0.00153509648805
watkins:0.00153509648805
discounted:0.00153509648805
abandons:0.00153509648805
multiagent:0.00153465388835
cumulative:0.00144810126039
alternating:0.00144810126039
economically:0.00142002481902
wellman:0.00142002481902
allowable:0.00135728417976
equilibria:0.00133820037346
landscapes:0.00133820037346
markets:0.00133820037346
charging:0.00133820037346
deterministic:0.0013161365399
discretized:0.00128914146975
corresponded:0.00127459293676
persist:0.00127459293676
payoff:0.00127459293676
iterated:0.00126848226121
1999:0.00125983383733
compete:0.00122970998449
observable:0.00122970998449
markovian:0.00122250764722
immediate:0.00117858667206
dilemma:0.00117837325897
circle:0.00114471781144
chess:0.00114005805402
adjusting:0.001129383856
instantaneously:0.00110618702841
arrows:0.00110009144921
self:0.00108946283063
actions:0.00108218207866
strategic:0.00107582133715
consequences:0.00107244714367
td:0.00104829133852
asymmetry:0.00104829133852
filled:0.00104626128771
optimize:0.00104210398899
infeasible:0.00103366461099
autonomous:0.00103366461099
turns:0.00102596327741
history:0.00101157909342
tables:0.00101125056451
implied:0.00100937637244
pq:0.000978330530078
competitive:0.000953263993764
perfect:0.000944598392361
leading:0.000944449641449
cross:0.000944449641449
training:0.000942734113774
evolves:0.000939373388788
consistently:0.000932410951491
plots:0.000922285498315
offering:0.000904856119841
amongst:0.000904856119841
discretization:0.000904856119841
yielded:0.00088895717456
symmetry:0.000874345846627
adjust:0.000874345846627
tirole:0.000865687797177
scissors:0.000865687797177
useable:0.000865687797177
fudenberg:0.000865687797177
fluctua:0.000865687797177
infintely:0.000865687797177
damp:0.000865687797177
subgame:0.000865687797177
substitutability:0.000865687797177
kreps:0.000865687797177
welfare:0.000865687797177
hashimoto:0.000865687797177
montonically:0.000865687797177
hunters:0.000865687797177
pricebots:0.000865687797177
differen:0.000865687797177
tesfatsion:0.000865687797177
rampant:0.000865687797177
microeconomic:0.000865687797177
leigh:0.000865687797177
undercuts:0.000865687797177
yoshitsugu:0.000865687797177
collusive:0.000865687797177
deltaq:0.000865687797177
utilites:0.000865687797177
shopbots:0.000865687797177
gammon:0.000865687797177
bargain:0.000865687797177
charge:0.000859427646499
deterministically:0.000859427646499
extent:0.000857414592681
terminating:0.000845654840806
simplifying:0.000838815018574
despite:0.000832881776788
phenomena:0.000832464416978
simultaneously:0.000830624632049
problematic:0.000819806656324
realistic:0.000816891451199
adaptive:0.000812460142663
hu:0.000807637930904
circles:0.000807637930904
unpredictable:0.000807637930904
ordinary:0.000805408973774
q learning:0.0432905000212
seller 1:0.0207794400102
seller 2:0.0181820100089
the sellers:0.016450390008
simultaneous q:0.016384768067
the q:0.0145623429028
and kephart:0.0134933384081
price quality:0.0125295285218
vs myopic:0.0125295285218
discount parameter:0.0125295285218
price war:0.0121213400059
q functions:0.0121213400059
profit functions:0.0115657186355
price wars:0.0115657186355
myopic vs:0.0115657186355
the price:0.0112977186369
q function:0.0107471923101
shopbot model:0.0106019087492
both sellers:0.0103897200051
q derived:0.0103897200051
quality model:0.00867428897664
q learner:0.00867428897664
kephart 1999:0.00867428897664
agent q:0.00867428897664
the shopbot:0.00867428897664
both players:0.00844422252938
multi agent:0.00839840620514
of seller:0.00808420066006
of fl:0.00782896581808
average profit:0.00779229000381
tesauro and:0.00771047909035
for seller:0.00771047909035
expected profit:0.00771047909035
the myopic:0.00727578059405
two player:0.00692648000338
learning in:0.00681485557131
and seller:0.00674666920405
agent economies:0.00674666920405
the consumers:0.00646736052805
information filtering:0.00614125274864
parameter fl:0.00614125274864
two sellers:0.00606067000296
pricing policies:0.00606067000296
seller s:0.00606067000296
other seller:0.00606067000296
cyclic price:0.00578285931776
asymmetric solution:0.00578285931776
derived price:0.00578285931776
price pair:0.00578285931776
myopic opponent:0.00578285931776
profit for:0.00578285931776
immediate reward:0.00578285931776
in tesauro:0.00578285931776
the discount:0.00519486000254
state action:0.00485052039604
the seller:0.00485052039604
expected reward:0.00481904943147
a myopic:0.00481904943147
take turns:0.00481904943147
price curves:0.00481904943147
cross plot:0.00481904943147
kephart 1998:0.00481904943147
time step:0.0047917961512
state space:0.00469752996863
dashed line:0.00456689672721
plot of:0.00456087595298
single agent:0.0044160205053
filtering model:0.00432905000212
sellers in:0.00432905000212
each seller:0.00432905000212
zero sum:0.00432905000212
vs q:0.00432905000212
non stationary:0.00404210033003
current price:0.00404210033003
the state:0.00402761333935
by seller:0.00385523954517
2 open:0.00385523954517
of price:0.00385523954517
their prices:0.00385523954517
s price:0.00385523954517
than seller:0.00385523954517
setting prices:0.00385523954517
action pair:0.00385523954517
fl dashed:0.00385523954517
alternately take:0.00385523954517
myopic optimal:0.00385523954517
exact convergence:0.00385523954517
pricing algorithms:0.00385523954517
vs discount:0.00385523954517
approximate convergence:0.00385523954517
alternating turn:0.00385523954517
quality seller:0.00385523954517
curves at:0.00385523954517
indicates baseline:0.00385523954517
price curve:0.00385523954517
sairamesh and:0.00385523954517
economic models:0.0038382829679
the players:0.0038382829679
the agents:0.00374266567572
of q:0.00368966276429
and policies:0.00368001708775
learning is:0.00366804066089
lookup tables:0.00346324000169
longer term:0.00346324000169
profit per:0.00346324000169
b cross:0.00346324000169
the prices:0.00346324000169
of sellers:0.00346324000169
state s:0.00346167884986
for both:0.00345503423437
an agent:0.00336837586623
of simultaneous:0.00326206909087
learning by:0.00326206909087
a average:0.00323368026402
a seller:0.00323368026402
other agents:0.00318693215589
policies and:0.0031188880631
p 2:0.00296137165985
obtained at:0.00294634900473
reinforcement learning:0.0029440136702
diamonds and:0.00289142965888
price competition:0.00289142965888
arbitrary sum:0.00289142965888
high prices:0.00289142965888
derived policies:0.00289142965888
deterministic policy:0.00289142965888
cumulative profit:0.00289142965888
future rewards:0.00289142965888
derived policy:0.00289142965888
stationary environment:0.00289142965888
solid diamonds:0.00289142965888
open diamonds:0.00289142965888
self consistently:0.00289142965888
sairamesh 1998:0.00289142965888
two seller:0.00289142965888
and crites:0.00289142965888
defined order:0.00289142965888
that seller:0.00289142965888
model myopic:0.00289142965888
optimal pricing:0.00289142965888
minimum price:0.00289142965888
fixed strategy:0.00289142965888
myoptimal pricing:0.00289142965888
unending cyclic:0.00289142965888
instantaneous profits:0.00289142965888
expected profits:0.00289142965888
sellers alternately:0.00289142965888
optimal policies:0.00289142965888
myopic policy:0.00289142965888
function approximators:0.00289142965888
fully observable:0.00289142965888
competing sellers:0.00289142965888
reward or:0.00289142965888
term consequences:0.00289142965888
no convergence:0.00289142965888
and sairamesh:0.00289142965888
sandholm and:0.00289142965888
pricing policy:0.00289142965888
and shopbot:0.00289142965888
kephart hanson:0.00289142965888
war regime:0.00289142965888
diamonds vs:0.00289142965888
self consistent:0.00289142965888
wars when:0.00289142965888
optimal price:0.00289142965888
theoretical guarantees:0.00289142965888
s current:0.00285054747061
also found:0.00276585795324
three models:0.00275279351959
price and:0.00275279351959
per time:0.00275279351959
convergence to:0.00272691697101
each agent:0.00260965527269
software agents:0.00260965527269
history dependent:0.00259743000127
nash equilibrium:0.00259743000127
q table:0.00259743000127
sum games:0.00259743000127
prices are:0.00259743000127
two competing:0.00259743000127
1 solid:0.00259743000127
agent systems:0.00249511045048
step for:0.00244617158583
hanson and:0.00242526019802
and arrows:0.00242526019802
exact or:0.00242526019802
prices of:0.00242526019802
p 1:0.00238044739205
of theoretical:0.00231750135126
lookup table:0.00230296978074
full knowledge:0.00230296978074
good approximate:0.00230296978074
adjusting their:0.00230296978074
the profit:0.00230296978074
in agent:0.00230296978074
two step:0.00228043797649
arrows indicate:0.00220801025265
that simultaneous:0.00220801025265
learning rate:0.00220801025265
optimal policy:0.00220801025265
simultaneous q learning:0.0173611099981
myopic vs myopic:0.0122549011751
q learning in:0.0120026284658
price quality model:0.00919117588135
agent q learning:0.00919117588135
the price quality:0.00919117588135
and kephart 1999:0.00919117588135
tesauro and kephart:0.00816993411675
for both sellers:0.00816993411675
discount parameter fl:0.00816993411675
the shopbot model:0.00816993411675
for seller 1:0.00714869235216
the price war:0.00714869235216
the other seller:0.00646295378926
the q functions:0.00612745058757
in the shopbot:0.00612745058757
the two sellers:0.00612745058757
q learning is:0.00612745058757
the discount parameter:0.00612745058757
in tesauro and:0.00612745058757
and seller 2:0.00612745058757
q derived price:0.00612745058757
the q learner:0.00612745058757
the q function:0.00553967467651
single agent q:0.00510620882297
for both players:0.00510620882297
cross plot of:0.00510620882297
and kephart 1998:0.00510620882297
the information filtering:0.00510620882297
cyclic price wars:0.00510620882297
plot of q:0.00510620882297
q learning by:0.00510620882297
of q learning:0.00510620882297
of the discount:0.00510620882297
of q derived:0.00510620882297
the q derived:0.00510620882297
in the price:0.00510620882297
seller 2 s:0.00510620882297
the state space:0.00509981135503
of the q:0.00497149025127
information filtering model:0.00461639556376
learning in the:0.00426127735823
of seller 2:0.00408496705838
q functions and:0.00408496705838
alternately take turns:0.00408496705838
derived price curves:0.00408496705838
seller 2 open:0.00408496705838
price curves at:0.00408496705838
of simultaneous q:0.00408496705838
vs discount parameter:0.00408496705838
functions and policies:0.00408496705838
model a average:0.00408496705838
multi agent q:0.00408496705838
state action pair:0.00408496705838
profit for both:0.00408496705838
q s a:0.00408496705838
b cross plot:0.00408496705838
profit per time:0.00408496705838
by seller 1:0.00408496705838
a average profit:0.00408496705838
seller 1 s:0.00408496705838
fl dashed line:0.00408496705838
average profit per:0.00408496705838
sairamesh and kephart:0.00408496705838
time step for:0.00383882486865
in the information:0.00383882486865
values of fl:0.00369311645101
other seller s:0.00369311645101
s q function:0.00369311645101
value of fl:0.0034637289527
per time step:0.00330085706238
at each time:0.00309799695131
each time step:0.00309799695131
well defined order:0.00306372529378
the myopic opponent:0.00306372529378
arrows indicate a:0.00306372529378
solid diamonds and:0.00306372529378
the sellers alternately:0.00306372529378
seller 1 as:0.00306372529378
that the sellers:0.00306372529378
price wars when:0.00306372529378
price for seller:0.00306372529378
a myopic opponent:0.00306372529378
the q table:0.00306372529378
than seller 1:0.00306372529378
model myopic vs:0.00306372529378
expected profit for:0.00306372529378
against a myopic:0.00306372529378
parameter fl dashed:0.00306372529378
case the seller:0.00306372529378
term consequences of:0.00306372529378
that simultaneous q:0.00306372529378
sellers alternately take:0.00306372529378
that seller 2:0.00306372529378
line and arrows:0.00306372529378
the myopic optimal:0.00306372529378
hanson and sairamesh:0.00306372529378
step for seller:0.00306372529378
price war regime:0.00306372529378
longer term consequences:0.00306372529378
sandholm and crites:0.00306372529378
line indicates baseline:0.00306372529378
kephart hanson and:0.00306372529378
q derived policy:0.00306372529378
good approximate convergence:0.00306372529378
lack of theoretical:0.00306372529378
agent s current:0.00306372529378
more interesting and:0.00306372529378
optimal price for:0.00306372529378
q derived policies:0.00306372529378
in two player:0.00306372529378
seller 1 solid:0.00306372529378
information filtering and:0.00306372529378
filtering and shopbot:0.00306372529378
in agent economies:0.00306372529378
diamonds vs discount:0.00306372529378
when the sellers:0.00306372529378
diamonds and seller:0.00306372529378
2 open diamonds:0.00306372529378
and sairamesh 1998:0.00306372529378
of theoretical guarantees:0.00306372529378
1 solid diamonds:0.00306372529378
myopic optimal price:0.00306372529378
open diamonds vs:0.00306372529378
unending cyclic price:0.00306372529378
adjusting their prices:0.00306372529378
the immediate reward:0.00306372529378
and arrows indicate:0.00306372529378
as a function:0.00297079482843
state s 0:0.00290777744453
of p 2:0.00284085157215
a function of:0.00280828155565
multi agent systems:0.0027809408022
of the myopic:0.00276983733825
despite the lack:0.00276983733825
dashed line indicates:0.00276983733825
dashed line and:0.00276983733825
number of sellers:0.00276983733825
function of fl:0.00276983733825
of the sellers:0.00276983733825
all three models:0.00276983733825
in all three:0.00263154259399
for small values:0.00263154259399
the current price:0.00259779671453
each value of:0.00254990567752
is obtained at:0.00247564279678
full knowledge of:0.00247564279678
of multi agent:0.00247564279678
the extent that:0.00247564279678
the more interesting:0.00238082390554
small values of:0.00233072674575
the other agents:0.00230329492119
a plot of:0.00223769747088
to the extent:0.00218083308339
and multi agent:0.00218083308339
in our model:0.00213331612527
p 2 is:0.00213063867912
plot of the:0.00213063867912
in a well:0.00208570560165
in which both:0.00204502911364
autonomous agents and:0.00204502911364
very good approximate:0.00204248352919
price of approximately:0.00204248352919
assumptions of knowledge:0.00204248352919
or identical products:0.00204248352919
profit landscape for:0.00204248352919
turns setting prices:0.00204248352919
discount parameter in:0.00204248352919
current q function:0.00204248352919
symmetric solution in:0.00204248352919
sellers as a:0.00204248352919
vs q shopbot:0.00204248352919
vs myopic pricing:0.00204248352919
basis of price:0.00204248352919
the sellers products:0.00204248352919
if so whether:0.00204248352919
of single agent:0.00204248352919
prices in a:0.00204248352919
we study simultaneous:0.00204248352919
price dynamics trajectory:0.00204248352919
the asymmetric solution:0.00204248352919
current price pair:0.00204248352919
non stationary environment:0.00204248352919
random entry in:0.00204248352919
of pricing policies:0.00204248352919
step lookahead calculation:0.00204248352919
were generally set:0.00204248352919
two player alternating:0.00204248352919
state space transitions:0.00204248352919
have full knowledge:0.00204248352919
very high prices:0.00204248352919
generally set to:0.00204248352919
stationary environment for:0.00204248352919
myopic 2 average:0.00204248352919
whether such solutions:0.00204248352919
the profit functions:0.00204248352919
each seller s:0.00204248352919
profits for both:0.00204248352919
the policies implied:0.00204248352919
vs myopic expected:0.00204248352919
