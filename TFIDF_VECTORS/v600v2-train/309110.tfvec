maximizer:0.0235011342999
evader:0.0210339274896
players:0.0189904308308
minimizer:0.0170285219964
equilibrium:0.015741159086
pursuer:0.0147237492427
policies:0.0143667920613
games:0.0139594652806
game:0.0137729566585
policy:0.012735069661
stationary:0.0113149640288
player:0.0100635731823
patek:0.0093068733541
stochastic:0.00846944421394
shapley:0.00736187462135
primal:0.00734632936994
bertsekas:0.00699545800264
shortest:0.00643110275596
proper:0.00525421443162
terminal:0.00511894914018
contraction:0.0050313131797
monotonicity:0.00457108130789
ssp:0.00451944890382
improper:0.00442283686242
sup:0.00426579095015
prolonging:0.00420678549792
kushner:0.00420678549792
undiscounted:0.00420678549792
bellman:0.003810909598
dual:0.0036647576038
transition:0.00355782816367
opposing:0.00323532095412
chamberlain:0.00316702988467
mixed:0.00300216549612
evasion:0.00295898787097
stay:0.00288412216967
prolong:0.00271166934229
minimax:0.00268424974344
caught:0.00265383061137
lim:0.00255925374038
actions:0.00249937082388
clockwise:0.00242879411118
terminating:0.00233310944078
transitioning:0.00232890596355
action:0.00222258801163
probability:0.0022099533297
convergence:0.00219299290791
randomized:0.00218541781124
markov:0.00210610643964
shiau:0.00210339274896
move:0.00200392483081
continuity:0.00197635290389
discounted:0.00196855686059
seeks:0.00194623046574
toward:0.00192860006372
played:0.00191527341803
indefinitely:0.00182159558339
iteration:0.00179313762779
proposition:0.00176663341098
catch:0.00172079022746
semicontinuous:0.00169901617532
compact:0.00164232326995
lemma:0.00162901793599
location:0.00162309392553
termination:0.00156841559517
costs:0.00156827478509
delta:0.00156164475826
nonnegativity:0.0015526039757
infimum:0.0015243638392
monotonically:0.00150774540615
pursuit:0.00147427895414
virginia:0.00144408261523
probabilities:0.00142349291316
inevitable:0.00139244857702
drive:0.00130293478924
stage:0.00130235070702
absorbing:0.00129843599554
adjacent:0.00128690602784
spaces:0.00124968541194
supremum:0.00124787117684
horizon:0.00124787117684
strategies:0.00120300998889
decision:0.0011874126449
maximizing:0.00117627338256
charlottesville:0.00116335916926
dimitrib:0.00116335916926
prolongs:0.00116335916926
additive:0.0011576578401
converges:0.00115391383022
terminates:0.0011463224921
inequality:0.00114081102202
assumptions:0.00114031482427
corner:0.00112645191142
infinite:0.00111877491334
bilinear:0.00109856637276
decisions:0.00107718241044
decides:0.00106860269757
operator:0.00106149690974
verifies:0.00105597399929
happily:0.00105169637448
kakutani:0.00105169637448
wal:0.00105169637448
mizer:0.00105169637448
minimizing:0.00104792396977
thanks:0.00103045200326
inf:0.00103023434959
preceding:0.00102598433445
existence:0.00101340156079
ft:0.00100626263594
corners:0.000994864001725
stagewise:0.000986329290322
prevails:0.000986329290322
infima:0.000986329290322
suprema:0.000986329290322
duality:0.00097311523287
matrix:0.000968057793241
faced:0.000957636709016
formulation:0.000944198863642
randomize:0.000939916584708
weierstrass:0.000939916584708
tsitsiklis:0.000939916584708
interfere:0.000937991274177
shall:0.000924930717706
appendix:0.00092493070995
opponents:0.000903889780764
groundwork:0.000903889780764
olsson:0.000903889780764
dmi:0.000903889780764
path:0.000894794966711
kumar:0.000884766197786
admit:0.000884766197786
operators:0.000883657775926
characterized:0.000883657775926
tracts:0.000874432250331
induc:0.000874432250331
ij:0.000871177258612
ultimately:0.000868623192828
achievable:0.00085315819003
inflexible:0.000849508087659
convex:0.000837432115572
theorists:0.000827902038398
optimally:0.000820548815876
designation:0.00080883023853
uniqueness:0.000806918109032
proceeding:0.000803585808637
mathematical:0.000802083677469
payoffs:0.000791757471166
catches:0.000791757471166
regularity:0.000790541161558
underlying:0.000782550979558
play:0.00076699957286
feasible:0.000765744491068
commensurate:0.0007621819196
discounting:0.0007621819196
relating:0.000759747937835
rewards:0.000749183211983
arranging:0.000749183211983
nonstationary:0.000749183211983
norm:0.000721238345017
distributions:0.000721238345017
nonterminal:0.000715414888343
stages:0.000707345523675
controls:0.000707185251798
fied:0.000705540728619
kt:0.000705540728619
characterization:0.000700491865121
incentive:0.000696224288512
establishing:0.000694431844909
nonnegative:0.000694431844909
weighted:0.000693698032463
decreasing:0.000684730162554
collect:0.000677223738098
wind:0.000671062435859
establish:0.000667974943605
pur:0.000663457652842
mini:0.000663457652842
jb:0.000656185620197
persistence:0.000642529917677
land:0.000642529917677
gammap:0.000629907106882
satis:0.000629907106882
continuous:0.000627524355343
suit:0.000623935588418
covered:0.000618899462771
min:0.000613520891533
edu:0.000598428587139
componentwise:0.000596898554062
subject:0.000592087710198
deterministic:0.000590091222474
fixes:0.00058719041367
stochastic shortest:0.02550337542
equilibrium cost:0.020402700336
stationary policies:0.015302025252
stationary policy:0.0151261033979
cost vector:0.0139625569827
shortest path:0.0116990977097
terminal state:0.010471917737
p bertsekas:0.010201350168
d patek:0.010201350168
matrix game:0.00892618139699
unique fixed:0.00887839238541
two players:0.00846061080257
fixed point:0.00841648063493
value iteration:0.00789190434259
policies m:0.00765101262599
path games:0.00765101262599
probability one:0.00736397027554
policy iteration:0.00736305953599
current location:0.00710909024995
stochastic games:0.00658936371063
proper policy:0.006375843855
expected cost:0.00579624704108
move toward:0.00525932823999
one player:0.00525932823999
main results:0.00518292789967
assumption ssp:0.005100675084
location action:0.005100675084
player stochastic:0.005100675084
path game:0.005100675084
assumption r:0.0050794582401
d p:0.00494615098403
lemma 4:0.00478064479135
control constraint:0.0046541856609
transition costs:0.0046541856609
unique equilibrium:0.0046541856609
q e:0.0044958227709
x 2:0.00444511557484
path problems:0.00444318140622
two player:0.00439290914042
path problem:0.00430815654968
functions c:0.00404480211027
contraction mapping:0.00394595217129
constraint sets:0.00384647439632
dynamic games:0.003825506313
primal cost:0.003825506313
weighted sup:0.003825506313
players implement:0.003825506313
randomized policies:0.003825506313
thus 3g:0.003825506313
game indefinitely:0.003825506313
dual value:0.003825506313
policy m:0.003825506313
mixed decision:0.003825506313
equilibrium strategy:0.003825506313
actions simultaneously:0.003825506313
transition cost:0.003825506313
minimizing player:0.003825506313
primal dual:0.00381152297473
x delta:0.00377837670207
zero sum:0.00376027146781
u 2:0.00363336595818
policy 2:0.00361614105757
transition probabilities:0.00360349534542
action spaces:0.00349063924568
cost x:0.00349063924568
mixed strategies:0.00349063924568
sup norm:0.00349063924568
additive cost:0.00349063924568
u v:0.00345154619092
true 1:0.0033985792736
state 3:0.0033985792736
control actions:0.00329468185531
players may:0.00329468185531
e d:0.00326277126305
terminal states:0.003155596944
underlying control:0.003155596944
state 2:0.00313589295448
one another:0.00310054806342
finite state:0.00307275186208
mathematical formulation:0.00295946412847
proposition 4:0.00292471010722
g 3:0.00280549354498
optimal cost:0.00271210579318
inequality follows:0.00265425775294
state space:0.00259958118744
stochastic shortest path:0.025472630448
equilibrium cost vector:0.0120659828438
patek and d:0.0107253180834
d p bertsekas:0.0107253180834
unique fixed point:0.00973281427161
x 2 x:0.00913383392996
shortest path games:0.00804398856254
convergence of value:0.00670332380212
bellman s equation:0.00670332380212
u 2 u:0.00594847115212
q e d:0.00581788241432
g 2 x:0.00540711903978
subject to g:0.00540711903978
control constraint sets:0.00536265904169
one player stochastic:0.00536265904169
g 3 x:0.00536265904169
across from one:0.00536265904169
players are adjacent:0.00536265904169
shortest path game:0.00536265904169
iteration and policy:0.00536265904169
kushner and chamberlain:0.00536265904169
player stochastic shortest:0.00536265904169
terminating with probability:0.00536265904169
shortest path problems:0.00526017488008
shortest path problem:0.0051359052362
m and n:0.00508306769891
terminates with probability:0.00465493488589
following are true:0.00446953641666
lim t 1:0.00410872418896
stationary policy 2:0.00402199428127
pair of policies:0.00402199428127
unique equilibrium cost:0.00402199428127
maximizer to prolong:0.00402199428127
existence and characterization:0.00402199428127
let 2 m:0.00402199428127
prolong the game:0.00402199428127
fixed point x:0.00402199428127
m is proper:0.00402199428127
continuous as functions:0.00402199428127
policy 2 m:0.00402199428127
minimizer are proper:0.00402199428127
delta k w:0.00402199428127
weighted sup norm:0.00402199428127
c i u:0.00402199428127
players are across:0.00402199428127
non terminal states:0.00368713168597
point in x:0.00368713168597
k w 1:0.00368713168597
every x 2:0.00312617879475
lemma 4 2:0.00299382438771
x there exists:0.00286279551823
markov chain terminates:0.00268132952085
convergence of policy:0.00268132952085
minimizer is denoted:0.00268132952085
path the maximizer:0.00268132952085
along a least:0.00268132952085
transition cost functions:0.00268132952085
u v take:0.00268132952085
system but without:0.00268132952085
x gamma delta:0.00268132952085
forms an equilibrium:0.00268132952085
players implement actions:0.00268132952085
always move toward:0.00268132952085
location action 3:0.00268132952085
